{
    "Blurbs": {
        "/ M or 1 - 2 2 / am right. so we have 1 * 1 - 1 / M * 1 - 2 / M * 1 - 3 / M and so on up to 1 - + -1 / him You keep on putting them in. Okay. See you get this nice product here. And you do a little bit of algebra. And you find that the ": [
            3452.9,
            3486.9,
            83
        ],
        "0 or I guess I should put another one here. Oh, you can't put that. No, I want to say some of the above. Let's just talk about him. Forget this thing. Okay is a true. Not necessarily, right? Okay, how about be? Yes, right. How about sea? I know, right? How about D? pink Tell me that the expected value of x is equal to the expected value of ": [
            1959.2,
            2040.1,
            46
        ],
        "1in m chance that h a j will be that same one. That's kind of like the the birthday having the same birthday with two people. Right? Do you want to think about it? The other way is what's the probability that they will be different, but they won't have a collision. And then take the compliment. Okay now so that's good, right? That's one kind of element. Now. The ": [
            4199.5,
            4227.2,
            104
        ],
        "Have you guys heard of this? the idea here is that it's misleading to think about these probabilities kind of. let's just say what the birthday Paradox is and then you can think about whether or not you think it's misleading or not. What's the chance of two people in a group sharing the same birthday? Okay. So example, what is the chance and say a group of 30 people ": [
            3034.7,
            3068.8,
            71
        ],
        "How do you implement them did you do it in 12? Yeah, you got kind of an idea. So let's use a hash functions for this problem. Okay, here's kind of an application. So suppose suppose you have a company of 5,000 employees. And each of them is identified by their social security number. How many unique Social Security numbers are there? Wait, let me write down my social security ": [
            2662.0,
            2698.5,
            61
        ],
        "Listen to a podcast. Alright, so let's get started. So I wanted to share with you some. some slides that Andrew posted the other instructor on his from his lecture on what the heck? That's cool. Okay, so he's got a few slides. If you look at the website, you can find his slides from yesterday and I like how he kind of summarized what we did on Monday. And ": [
            1.9,
            63.0,
            0
        ],
        "Now. What all those things? Okay, so it's the expected value of the unexpectedness? Cuz remember how to how to compute expected value you basically take the average of all the random variable values. Just out of curiosity. What is the expected the average unexpectedness? Rihanna I guess. 2.5 + 1.5 is 4 or 4.5. Okay, so it's 9 divided by 6 is 3 / 2 so on average you're ": [
            1284.9,
            1341.9,
            32
        ],
        "Okay, so now let's get to back to the variance. I want to prove to you this this theorem. I gave this to you on the homework for you to to practice with it. But let's think about where does it come from? Okay, so we're taking the the definition of variance to be this year. Play so how does that turn into this? So let's start off with e ": [
            1711.8,
            1743.1,
            41
        ],
        "So we have some kind of competing views here. Why don't you guys take a minute and talk it over with your peers see if we can get one of these bars to be a little bit taller than the other. We're getting some convincing going on, right? Okay good. Right that there's their HOA HOA. I can go anywhere right just pick a random location. And then there's a ": [
            4120.8,
            4199.5,
            103
        ],
        "So we're just going to kind of go through them real fast. I'm not going to solve them because I think it might be a good exercise for you guys, but maybe just to get you start thinking about how to solve these expectation problems in like what the problem what kind of problems, you know, can you solve with them? Okay, so funny thank you notes and address 20 ": [
            310.0,
            335.6,
            6
        ],
        "The other person could have 364 days cuz it doesn't conflict with mine and the third person would have 363 right? all / 365 cute cuz that's 365 cubed is the number of ways. We could all just have birthdays with no restrictions the number for very close to one right? It's it's a it's a really high chance that three random people in a room. They all share they ": [
            3221.6,
            3256.3,
            76
        ],
        "What's the runtime of this algorithm? Okay, good. It's still I mean, it's not much different than the one we saw before, right? We just doing this intermediate step. Where were hashing the integer. Okay, what's the memory of this algorithm? Well, this is kind of a trick question. It would be big data of mplus and does this algorithm actually work? Okay, good your you might have a collision ": [
            2878.9,
            2950.8,
            67
        ],
        "Which one? The variances interview square, right? I know but I think the only way that they could be equal is if they're both 0 right Okay, let's move on to the next thing another algorithm. Element distinctness case you're given a list of integers A1 through a and they're not necessarily in any order. You want to know if all the elements are distinct if they're all different or ": [
            2119.9,
            2187.6,
            48
        ],
        "X and Y are independent then he of XY is e of x times you've watched. This is not necessarily true if the random variables are not independent. Okay good. So take that because we're going to use it a little bit later when we start talking about the variance. Okay, so when you have a big piece of data. sometimes it's nice to know certain properties of it and ": [
            1103.4,
            1134.6,
            27
        ],
        "a day and start on the next topic on. on Monday Yes, sure. How do you calculate the variance? Cuz cuz you see right expected value 22 computer. UC San Diego podcast ": [
            4395.8,
            4439.7,
            109
        ],
        "about B? number of heads versus the number of tails If I know the number of heads in the sequence, will that would that give me any information about the number of tails in the sequence? Yes, right. I mean they're there directly dependent on each other. How can we see this? How can we kind of prove that these are not independent? You can just pick a counterexample pick ": [
            879.5,
            908.5,
            22
        ],
        "all have different birthdays. Okay. So this is kind of this is the 99% chance that 3 people in a room has shared two different birthdays. Okay. How about so then you subtract it from one and this is the probability that they don't that that two people share the birthday. Okay, so in general There are and people were and is less than 365 write if if you had ": [
            3256.3,
            3289.0,
            77
        ],
        "already. Okay, so that's that now by the linearity of expectation the expected number of total collisions is the sum of all the expectations. What is what is the expected value of this indicator variable? Ready go. Remember that there are M memory locations. prank age of a I could map to any of those m. And age of AJ could also map to any of those m. Okay good. ": [
            4054.4,
            4120.8,
            102
        ],
        "among the physical locations. This is called an ideal hash function and there are ways to get like a good model of an ideal hash function using number Theory using like prime numbers and things like that. We're just going to assume that one exists and use it kind of theoretically Okay, so Now, let's check out this algorithm pick a hash function. That basically maps all positive integers into ": [
            2807.0,
            2844.8,
            65
        ],
        "an array that's infinitely long. Let's say that these are all integers right? So it doesn't matter how big they are. Once you find once you encounter an integer you turn. It's an array from Falls to true. right And So then whenever you encounter a new integer, you look up its array value. Let's say that takes constant time right you look a bit array value if it's Falls ": [
            2473.0,
            2500.3,
            55
        ],
        "and AJ were J is less than I or in other words. We're adding up to total number of collisions here. Okay. So every time that there's a collision that's going to add a little bit more to your run time. So what we want to do is figure out what is the expected number of collisions we can kind of think about what happens on the extremes, right? But ": [
            3861.5,
            3890.0,
            97
        ],
        "and that might help you get good better practice. Okay, and then here's another Bayes theorem problem. Okay, so I think that those are nice too. to look at okay, let's start with kind of the next topic or not. The next topic just kind of continue on with probability. We're going to look at concentration. And then we're going to look at how to use probability to find the ": [
            527.1,
            561.2,
            13
        ],
        "anybody remember what the math term for? This is set K what else we got outcome? element, right Bernoulli trial don't really have like a like a math term for it. But yeah, it's just something that has two outcomes. a trial two outcomes Okay, what else we got here event? What's the math term for it subset? conditional probability so we talked about what that was random variable. We ": [
            93.8,
            156.8,
            2
        ],
        "array are people. And the days of the year are the memory locations the hash of a person is your birthday, right? So think about all the students in the whole university right? We can kind of Give each person a number based on their birthday. And now you've kind of you kind of built this hashing function that sort of randomly give assigns people numbers. Cake collisions mean that ": [
            3351.9,
            3383.4,
            80
        ],
        "average unexpectedness kind of tells you On average how far are things to apart from the expected value? Think about rolling a dice right on average how far away are the dice roll from the expected value? Okay. So I guess that would be like a good example. Let's do dice. Right? So then you of one is going to be equal to do you guys remember the expected value ": [
            1215.4,
            1247.1,
            30
        ],
        "baseball players. What's the expected number of packs you need to buy before you get all of them could just get be lucky and get them all in the end the first and packs that you get it's probably unlikely, right? Probably likely that you have to buy more and more and more and then you might have to kind of by a bunch to get that last one. Hashing, ": [
            403.3,
            429.0,
            9
        ],
        "be there dependent. How about sea? You can kind of do the sort of sort of a similar counterexample. What's the probability that the number of heads is equal to 2? And the first two flips, right? intersect the number of heads equals 3 in all flips was just a probability right you can figure that out and then do the Split them up and show that the product is ": [
            1019.5,
            1060.8,
            25
        ],
        "bring em down in order to kind of get a reasonable time algorithm? Think about the extreme what if M was equal to one then you're putting everything into the same list and it's kind of like you're you're searching through the list every time you're going to get like a bad front. I'm like a like a big O of N squared so there has to be some sort ": [
            3763.4,
            3787.8,
            94
        ],
        "bunch of collisions, Okay. So this algorithm is great. Now we just have to figure out what size of em, do we want? Right? We don't have to make em super large anymore when I have to make it like bigger than M squared anymore because we're not scared of collisions. Right? We're okay with the collisions. We know how to deal with that. Okay. So how low can we ": [
            3738.0,
            3763.4,
            93
        ],
        "choosing sorting. So what you would want is you want em to be around the same size as and maybe twice as big or something like that and then you know that the expected run time is still going to be linear, but your amount of memory is small is smaller than what we use before and it's faster than sorting. Okay any questions? Okay, let's see. Let's call it ": [
            4357.4,
            4395.8,
            108
        ],
        "collisions while I can't really do that reliably because it's going to change dependent on my hash function, right? And it's it's in the hash function is supposed to be this random assignment and so in order to get to the number of collisions total number of collisions, it's better to talk about the collisions as a random variable write each hash function has a number of collisions that will ": [
            3925.8,
            3954.1,
            99
        ],
        "constant is just that value. Hey, so you got EFX squared - 2 of x squared plus b of x squared and simplifies to this. That's basically what we had before. Okay. So this this is usually what we used to calculate the variance because it's a lot easier to do it then actually calculating it that way. Okay, so oh, yeah, we already talked about this, right? What does ": [
            1885.0,
            1936.3,
            44
        ],
        "corresponding and envelopes, but then he gets distracted and puts the letters randomly into the envelopes one letter per envelope. What's the expected number of letters that are in their correct envelopes? I think so. I think about it like that. Oh, yeah, that's something I wanted to do. Okay. Yeah. So kind of a roadmap for solving this kind of thing figure out what your random variable is figure ": [
            335.6,
            369.2,
            7
        ],
        "day. And then there's one let's just wear under the assumption that everybody has every birthday has the same probability. Okay. So there's a 1 out of 33 65 chance that that person has the same birthday as me whenever 365 no big deal. Okay, what about if there are three people? Okay, so what's the what's the probability that it if you have three people that there are two ": [
            3160.2,
            3194.4,
            74
        ],
        "difference from me more. So the average unexpectedness equal to standard deviation. Okay good. Good because why would we know that we of you squared is not equal to any of you squared in general Frank we have we've seen that before already happening. Okay. Now let's look at an example. we have POF X1 and X2 are different random variables, right? X1 and X2. They both have expected value ": [
            1439.8,
            1499.2,
            36
        ],
        "don't have to go into the time to spend so much time on the details, but it's basically that this array now is is a bunch of no list. And you just keep on adding to the list whenever you find a new value find a new value hash it you put it on to the list and then if you've ever if you ever see that same value in ": [
            3688.3,
            3711.0,
            91
        ],
        "done is a very simple thing. Okay, and so I guess instead of true and false. I put zeros in once. Okay, what's the memory usage this algorithm? We're going to skip this because it's infinite, right? It doesn't really have a bound. I mean, I guess it's it's dependent on the size of your biggest integer in your array. That's not really a good thing to base your run ": [
            2545.0,
            2571.7,
            57
        ],
        "down to say ten thousand or something, but you wanted to do it in a way that you're unlikely to have collisions. You guys can probably think of some other examples will see it will look at another example in a minute. Okay, so ideally we want to use a very unpredictable function and assume that for this function for every virtual location V HOV is uniformly and randomly chosen ": [
            2776.0,
            2807.0,
            64
        ],
        "e of x minus e-squared, right? Is it going to be e of x squared - 2 XE plus b squared, right If you just kind of expand it. Okay, so what can we use here? Does anybody know any property of expectation that might be helpful? What is it? Linearity, right? So this is actually equal to e of x squared minus B of 2x e plus he of ": [
            1743.1,
            1793.2,
            42
        ],
        "e squared. Text let's simplify this a little bit. if x squared is fine is that -2 you can bring the two out. You can bring the E like that and we also have he's Square. He of how do I do this part? 2 * e EFX x e Wright plus and then the expected value chi-square does just the same value. So the expected value of of a ": [
            1793.2,
            1885.0,
            43
        ],
        "expected runtime of a randomized algorithm. We kind of did that in a way last time with the counting the number of times the max changes, so we'll see how it works on a different kind of algorithm. Okay. So remember what we said about linearity of expectation wear if your a random variable is a sum of two other random variables that you can kind of take the expectation ": [
            561.2,
            590.1,
            14
        ],
        "expected value of an indicator variable is is the probability that is equal to 1. Okay. Now let's do this one. What is EFX quantity squared? 1/4 Okay. Now this is kind of a weird one. What is he of x squared? Well, this is the probability. We're talking about the probability that x squared is equal to 0 is what? Also 1/2, right? What about the probability that x ": [
            623.5,
            675.9,
            16
        ],
        "feel has a bigger variance? Okay, good. We have a little bit of so why don't you guys? Where is the what happened to that? Oh now be is gaining more momentum. I don't think it's a Okay, it's okay. So be as kind of the leader here can anybody tell me why they think B is the right answer? Okay, good. Yeah, so x to the the date of ": [
            1567.0,
            1665.9,
            39
        ],
        "first ball goes into any slot right the probability of the first object causing. No collisions is one, right? What's the probability that the second object doesn't cause any collisions? 1 - 1 / am right or I heard somebody say it and -1 / M right? Now given that the two the first two didn't Collide what's the probability that the third one's not going to collide either? -2 ": [
            3414.9,
            3452.9,
            82
        ],
        "go with it. Right. So that would be the number associated to that outcome and each random variable. You can talk about the expected value and the way we're going to do it is Everybody's favorite property of expected value. Okay, good. Let's do this. What is the expected total number of collisions? Okay, so What I'm going to do is use an indicator random variable. I'm going to say ": [
            3954.1,
            3993.8,
            100
        ],
        "going to be about 1.5 away from the expected value that kind of gives you a sense of how tight the range is. Okay. So these things are are pretty easy to kind of comprehend by just writing them out the variance and the standard deviation. These These are these are a little bit more useful or at least the standard deviation is a little bit more useful right you ": [
            1341.9,
            1372.6,
            33
        ],
        "going to try to figure out why is the algorithm going to be correct with a high probability with this ideal hash model, right if you think about making making the size M bigger and bigger and bigger, right? There's a lot there's a less likely chance that you're going to have a collision. Okay. So this all kind of has to do with this thing called the birthday paradox. ": [
            3008.9,
            3031.7,
            70
        ],
        "good and login right sorting takes best time sorting takes and big data and login. And then if you step through to find duplicates, this will take at most Big O of n right? So total run time to get big oven login fixate oven login. Okay, how much memory does this require? Okay, good. We need to have at least and memories to hold the data, right? just got ": [
            2271.9,
            2324.9,
            50
        ],
        "group of 30 people two people share the same birthday. How could that be? Well even more surprising. with 60 people it's more than 99% How could that be? Okay. Well, let's let's look at the math behind it. Okay. when you have Okay, so if you have two people, what's the probability that they share the same birthday, but you have one person one person's birthday on a specific ": [
            3113.2,
            3160.2,
            73
        ],
        "guys always want to know what the standard deviation is of the homework. So the tests and stuff like that. It kind of gives you a sense of how far away are most of the submissions. So the variance what it does is instead of just The expected value of the unexpectedness does the expected value of the square of the unexpectedness? Okay, and what that does is It makes ": [
            1372.6,
            1407.8,
            34
        ],
        "have a file cabinet with what is 10 to the 9 trillion or billion a billion really want to have a billion slots in your file cabinet? No, not really. You want to save some space. So instead you make a hash function that that converts each social security number to not a unique number because it's not it's not possible to do that because you're going from a billion ": [
            2748.9,
            2776.0,
            63
        ],
        "he also has some nice practice problems that you can use to help study for the final and practice for the homework and stuff. okay, so I like this because he kind of list out all of the terms that we learned from Monday and do we start probability on Monday or last week? Started last week like a little bit, right? So we have sample space probability space. Does ": [
            63.0,
            93.8,
            1
        ],
        "if there's a repetition then you want an output repetition, right or not distinct or something like that? Okay. What is it like a very kind of simple algorithm that could solve this problem reasonably efficiently. okay, good so short Then scan right? Okay. So how long would it take to sort the list then step through to find duplicates? What's the best run time that you can get? Okay, ": [
            2187.6,
            2271.9,
            49
        ],
        "if you had 365 people in a room by the pigeonhole principle. It's certain that two people share or you have to have more than three. But if you have less than this is the formula that you plug in maybe like as an exercise. Try to plug in some values and see what you got. Right you're going to see that when you plug in 23, that's when it ": [
            3289.0,
            3320.3,
            78
        ],
        "into your putting each integer into a set and then into the same set and then every time you get a new integer, you look in that set to see if it's there. Yeah. Okay. So that is the death kind of the general idea. But instead of like a set instead of like a container think about it more as like an array of blue aliens where you have ": [
            2447.4,
            2473.0,
            54
        ],
        "is a value that Pokemon. Okay, so we need the number of Memories locations to be more than and squared. Another so this is basically what I said Okay. So let's do this same problem again. now I'm going to I'm going to take them to be. equal to Big Omega of let's just say that it's big Theta of N squared Okay. Now it's really unlikely that we're going ": [
            3538.7,
            3575.3,
            86
        ],
        "it mean for the variance to be zero? Let's just do it again. What does it mean for the pharynx to beat zero does it mean that the value of the random variable X must always be zero the value of the random variable must be constant G of x squared is equal to x if x squared is equal to e View Square Dory of you is equal to ": [
            1936.3,
            1959.2,
            45
        ],
        "it to the last part of the last night. So this is going to take big'o of 1 plus the size of that list at that time. So and other words, this is 1 plus the number of indices before I That collided with that same hash value, right? Okay, and so all in all. We're adding up and plus the number the total number of collisions between Pairs Ai ": [
            3818.2,
            3861.5,
            96
        ],
        "itself? I mean the same thing right? It's also 1/4. What's the probability of the number of Tails being one? It's also 1/4 right? I mean it's this is kind of like a stupid example because that intersection that's the they're sort of like the same set. Right? So it makes sense that the product of those two single probabilities should not be equal to the probability itself. Okay, so ": [
            984.7,
            1019.5,
            24
        ],
        "kind of spread out to the extremes and they're like both really far away from the expected value in the middle. Whereas X1 the kind of like spread out evenly and there are some that are closer and some that are farther away which is different than them all being far away. So stop be any questions. Okay, so this would be a good exercise. to calculate each variance Okay. ": [
            1665.9,
            1707.7,
            40
        ],
        "kind of start splitting fifty-fifty. Right and when you get up to 60, that's when you get like something more than 99% hard to believe but it's true. Got any questions about this? So why did I switch the topic from hash functions to birthdays because birthdays are kind of a nice model to think about when you think about hash function right in this case the elements in the ": [
            3320.3,
            3351.9,
            79
        ],
        "know of x i j is equal to 1 / M for every pair i j to just add that up a bunch of times and you get and choose to over M, which is around Big O and squared / m So that's the number of collisions that we expect to have and that gives you a sense of why when m is really close to N squared. You ": [
            4285.3,
            4311.6,
            106
        ],
        "look through that list to see if your uvula you've already already put it in there. This is kind of like your first idea right where you keep on putting things in the list and you search for them. But now instead we have a bunch of lists and it's it's easy to figure out which lift it should be in. okay, so here's kind of the algorithm and we ": [
            3656.6,
            3688.3,
            90
        ],
        "next thing is how many terms are in this sum? Right. Remember we're going to some this is something over all pairs. IJ I got to go back to Counting. Good. answers to write Andrew's too many pairs in a set of n elements Now we got all the details and we've got that the total number of collisions is the some overall pairs of e of X IJ. We ": [
            4227.2,
            4285.3,
            105
        ],
        "not equal to the probability. Cast of this is these are dependent also. any questions Okay. So here's a nice a nice. It's sort of like goes against what we were just talking about how expected values only their only linear with respect to the some. But in fact, they're all so they also commute with Multiplication but only in the circumstance where X and Y are independent. So if ": [
            1060.8,
            1103.4,
            26
        ],
        "number real fast. So you guys can just plan you have right? 9 right so you have what 1 * 10? Roughly I think that there are some like restrictions or something. You can't have six six six in there or something. It can't start with 420. Or is that a restriction? Anyhow? So cancel the 9 is big but you only have 5000 Floyd so you really want to ": [
            2698.5,
            2748.9,
            62
        ],
        "of 0 x 1 is kind of like spread around like negative to negative 1 0 1 2 and x 2 is negative to negative to nicely both have expected value of 0 I guess that takes away this one, that's fine. Okay. What so what I'm asking now is what is the variance? How did the variances compare know remember the variance is sort of a measure of how ": [
            1499.2,
            1534.4,
            37
        ],
        "of Middle Ground where we can get maybe a linear time algorithm with a nice amount of memory Okay, so let's calculate the runtime of this algorithm. So inside of here. The worst case happens when you don't find that that element in your list because that means you have to kind of look through every part of your list and you didn't find it anywhere and then you append ": [
            3787.8,
            3818.2,
            95
        ],
        "of restrict the amount of space it might take the runtime a lot longer. Think about why that why that works and it's different for every algorithm. But in general that's kind of like the relationship you should think of Okay, so what if we had access to unlimited memory? Anybody have a an idea of an algorithm that could solve this problem more efficiently. Okay, so you're putting it ": [
            2390.0,
            2447.4,
            53
        ],
        "of rolling a six-sided dice? 3.5 G is equal to 3.5. So the unexpectedness of 1 is equal to 2.5 right of 2 is equal to 1.5 U of 3 is equal to point five you of 4 is equal 2.5 you of 5 is equal to 1.5 and you if 6 is equal to 2.5. Okay, but that that gives you another value for each one of those rules. ": [
            1247.1,
            1284.9,
            31
        ],
        "of the Sun at the sum of the expectations. It doesn't do that in with other functions. It's just special for addition. For example, it does not do it with squaring. Okay. So let's just look at this example. If P of X is d p of x equals 0 as a half of x equals 1 is 1/2 What is the expected value of x? 1/2 right remember the ": [
            590.1,
            621.7,
            15
        ],
        "of them share the same birthday. Okay. Now let's think about how to count this to find the probability. We're saying at least two of them share the same birthday. So when you hear at least let's turn it around and think about the complement. The compliment is that everybody has a different birthday, right? So what's the probability that everybody has a different birthday? Well I could have 365. ": [
            3194.4,
            3220.6,
            75
        ],
        "of these things now. Let's look at a the idea here is to be independent the value of x doesn't influence the value of y right. And so if you look at it, you can kind of you can kind of Reason out that doesn't matter how many how many heads you flipped in the first two flips. It doesn't affect what happens in the second two flips. But what ": [
            844.8,
            879.5,
            21
        ],
        "one. Another way to say is the probability of their intersection is equal to the product of their probabilities. Okay, and then Bayes theorem remember what that was kind of a way to? Turn the tables on the conditional probabilities and what else and more so his advice is to have such a kind of remind yourself of what each thing means. any questions Okay, he's got some great problems. ": [
            267.0,
            308.6,
            5
        ],
        "only expect to have very few, right? What about when am is close to N? then this thing becomes Big O of N squared over and which is Big O of n So this is the total expected time in the ideal hash model. As long as m is greater than end in the total expected time is Big O of n this is much better than our original Pro ": [
            4311.6,
            4357.4,
            107
        ],
        "out what your expected value is and figure out what your indicator variable is. And then figure out use all of that to figure out what is the expected value? Okay, another kind of sort of same kind of topic you have. One random major league baseball player into every pack right there and major league baseball players and say you're a collector you want to get all of those ": [
            369.2,
            403.3,
            8
        ],
        "per location. What's the expected number of items per location right by how many times do they? Get in there another type of problem that we're going to look at in a little bit more detail today. What's the expected number of empty locations? I ain't so you guys can 20 items into a table of size five nights 10 you can think about it in like these smaller terms ": [
            494.5,
            527.1,
            12
        ],
        "probability is less than 80 to the negative and shoes to over em, and really what I want you to get from this is that we want P to be close to 1 so we want them to be bigger than and choose to and you can think of any shoes to to be around and squared over to Okay, so Right, we want there to be the probability of ": [
            3486.9,
            3515.4,
            84
        ],
        "really make sense because you could just sort it and find it in linear or in N log in time. So what we're going to do is look at another way to kind of get around this problem. And the way to do this is to not think think of collisions not as like the enemy don't think of it as like a bad thing embrace it and see if ": [
            3601.0,
            3625.8,
            88
        ],
        "really want to know what's the average amount? What do we expect to happen? Okay. So remember collisions depend on the choice of the hash function in the ideal model each output is equally likely right. So for each input AI you get a random. number in this in this range from one to m Okay, let's put our thinking caps on. How can I find the total number of ": [
            3890.0,
            3925.8,
            98
        ],
        "right? And so maybe I have a hash this hash to the value 11, right? So I turned Eleven on and then this other number also match to 11. And so I see that there's a collision but the two numbers that has to it we're different. So that's bad. Okay, so it kind of does one of the things and not the other if there is actually repetitions in ": [
            2950.8,
            2975.9,
            68
        ],
        "sequence. Why is the number of tails in the sequence X12 is the number of heads in the first two flips access number chosen to see none of the above. Which one of these pairs of events are independent. at least for the number of flips is 4 exactly four Okay good. So we're saying some of its. Okay, so, let's see. Let's take a minute to look at some ": [
            794.2,
            844.8,
            20
        ],
        "side, maybe instead of like a hundred integers. Okay. The idea is that we're going to do it randomly. But not not randomly like you get a different value each time, but it's equally likely for you to pick any of those values. But the idea of the hash function is always pick the same value every time and this in this sense. It gives you sort of a map. ": [
            2636.8,
            2661.1,
            60
        ],
        "some example. Okay. So let's say what's the probability that? number of heads is equal to 3 intersect number of tails is equal to 1 Why you can pick which test at which position is the tail on the other three have to be heads, right? So there's four different things. So that should be 1/4. right Now what's the probability of the number of heads be equal to three ": [
            908.5,
            984.7,
            23
        ],
        "something that we've certain things that we've heard before maybe are like standard deviation or variance or things like that. But what are those things and how do they relate to random variables and expected values? Okay. So here is how close on average will we be to the expected value? What is the unexpectedness? Okay, so you Is a random variable. But it's value is how far away is ": [
            1136.7,
            1179.9,
            28
        ],
        "spread out things are. When is the variance going to be zero? was that right when every random variable value is the same right? That means that they're all together. They're all kind of scrunched up right next to the expected value. And when is the variance big it's when things are spread out more. So just fine. I like the feeling of the this data which one do you ": [
            1534.4,
            1567.0,
            38
        ],
        "squared is equal to 1? also 1/2 Okay, so this is also 1/2. you can kind of plug it in directly into the definition of expected value Okay, so that kind of just shows you that you can't take that square out of the expected value sign. Okay, let's move on to Independent Independence when we're talkin about random variables. It kind of has the same feeling as the independence ": [
            675.9,
            713.7,
            17
        ],
        "talked about that one right member that was a function. function from sample space 2 reels distribution function of a random variable we talked about that to remember that was the probability that the random variable will be equal to a certain number. And then we had expectation. This was the kind of that average. of the probabilities of the random variable And what else we have binomial distribution? That ": [
            156.8,
            214.0,
            3
        ],
        "that list, then you found a repeat. Okay, so this one is correct. It works. It's great. What's the memory using this algorithm? Well, let's say the size of an is big old M. The total size of all the linked list will be Big O of n so the total memory with me because you might have like a bunch of really long linked list if you have a ": [
            3711.0,
            3738.0,
            92
        ],
        "the order of Big O of M login? and the space is on the order of big Theta of n Okay, so you're going to see that when you when you work with algorithms the time in the space kind of have like an inverse relationship sometimes which means that if I allow much more space I can maybe make the run time faster and if I if I kind ": [
            2362.5,
            2390.0,
            52
        ],
        "the random variable X to its expected value. And that kind of gives you a sense of how much the data is spread out, right if the unexpectedness is large then that means on average right now. That's the average unexpectedness. Sorry. Okay, I saw the sorry the unexpected. This is a random variable. So for each outcome you you figure out what is distance is to the expected value. ": [
            1179.9,
            1214.1,
            29
        ],
        "the small window of integers from 1 to m. And then what are we going to do if the hash value? Create an array that has m. locations right array of size n then has your integer go to that array location of the hatchet integer if it's not a wand and turn it into a one and if it is a one then say that you found a repeat. ": [
            2844.8,
            2877.8,
            66
        ],
        "there being a Kalitta being no collisions is one right? There is the probability that there is no collisions. So if we make them really really big bigger than 10 squared / 2, then p is going to be closer and closer and closer to 1. Because we're going to have a key to the negative zero write something about you that's close to e to the negative zero, which ": [
            3515.4,
            3538.7,
            85
        ],
        "thing? Don't even have it plugged in. Come on now. Okay. Which of the following pairs of random variables on a sample space of the sequence of heads and tails coin coin is flipped four times are independent K. We have X12 is the number of heads in the first two flips actually forms of the number of heads in the last two flips. The number of heads in the ": [
            741.7,
            794.2,
            19
        ],
        "things that are closer to the expected value even closer and things that are far apart that pushes it away. So it's sort of magnifies the spread and then the standard deviation is just to take the square root of the variance. and that just gives you more of a sense of How close together Things Are? Okay. So right way all the difference from me equally way the large ": [
            1407.8,
            1439.8,
            35
        ],
        "this algorithm will find it right because the same number will has two the same value. But if there's no repetition it might it might give you kind of like a false sense that there that all the elements are distinct. or the other way around if there's they could all be distinct, but the algorithm will save that they found a repeat. Okay. So the idea now is we're ": [
            2975.9,
            3008.9,
            69
        ],
        "this is something that we're going to look at today in more detail. Have you guys done anything what hash functions before? It's basically a way to map kind of a a big piece of information into a smaller. smaller memory location encoding in a weird way and so the values returned by a hash function are called hash values or simply hashes and Open hashing each item has shipped ": [
            429.0,
            467.9,
            10
        ],
        "this thing called a hash function. You guys are probably heard of it and used it before. And the idea is that it's to stimulate a big amount of memory. You use something called virtual memory by converting each in this case integer into a smaller set. So instead of using those distances in centimeters, you can convert those who maybe I don't know I set with a more reasonable ": [
            2605.7,
            2636.8,
            59
        ],
        "time on or debaser memory time on right because you could be working with I don't know. Maybe your integers are distances between galaxies in centimeters. Then, you know, it's really not useful especially maybe if you only have if you only know of like a few galaxies, right then it's not really useful to have that many memory locations. Okay. So what we're going to do is to find ": [
            2571.7,
            2605.7,
            58
        ],
        "to a particular location in an array in applications can hold more than one item, and we're going to look at this also because the idea is that you're going from like a big. Big size data too small so it might be the case that more than one data point goes to the same hash value. Okay. So here's a few problems to do with hashing number of items ": [
            467.9,
            494.5,
            11
        ],
        "to be at least an but you can sort in place or merge sort actually uses a constant multiple of n where n is the size of the data. So it's not unreasonable to sort it with n memory. Okay? So you sort it with and memory and you can get this. Okay, so what do we have so far? We basically have an algorithm that the time. Is on ": [
            2324.9,
            2362.5,
            51
        ],
        "to have any collisions and this this algorithm still runs in Big O of n time, but we're using big old and squared memory of the balance. I was talking about where we can kind of give more memory and get a better run time. Okay. Well it kind of just sort of depends on what you have more of if you don't have a lot of memory just doesn't ": [
            3575.3,
            3601.0,
            87
        ],
        "turn it to true if it's true that you've already seen it before. pictures of kind of the idea is an array of memory locations indexed by integers. Okay, and we're just going to assume that there are infinitely many. So what's the runtime of this algorithm if you assume that a ray look up is constant time. Okay. Good. Good. Good. Good. Good good. Big Love and right you've ": [
            2500.3,
            2545.0,
            56
        ],
        "two people share the same birthday. Okay, so let's talk about a general birthday type Paradox. If you have an object and M places and people and M calendar days, we're putting each object at random into one of the places. What's the probability that two objects occupy the same place? what's kind of think about it as like putting these little balls into these little Slots, okay. So the ": [
            3383.4,
            3414.9,
            81
        ],
        "two people share the same birthday. What are you guys gas? Any guess any any ideas? 10% write 30 goes into 360 around 10 times around 10% or I don't know. 20% 30% do you think it's anybody think it more than 50% Good, so, I don't know if this is surprising to you if you haven't seen it before but it's more than a 50% chance and it a ": [
            3068.8,
            3113.2,
            72
        ],
        "was basically like the distribution of the Bernoulli trial that we saw. Variance we're going to look at that today. Use of an indicator variable. This was useful when you did linearity of expectation. What you're going to see a little bit more up today linearity of expectation and its applications independence of events. Did you guys remember what that means? Right. So the the event doesn't affect the other ": [
            214.0,
            267.0,
            4
        ],
        "when were talking about probabilities. Okay. So we're saying that why are random variables are the same sample space X and Y are called independent if for all possible values P of x equals B, and Y equals you is equal to their product and it has to be this has to work over all pairs of values. X equal to be white with you. Okay, wait, where's my clicker ": [
            713.7,
            741.7,
            18
        ],
        "x i j. is equal to 1 if age of AI is equal to age of AJ. if those two entries collide and 0 otherwise okay now X is equal to the sum of all i j pears x i j I think this is the number of of collisions Okay, does that make sense? Right cuz you're just turning them on and off. We talked about these indicator functions ": [
            3993.8,
            4054.4,
            101
        ],
        "you can use it to your advantage. Okay, so the idea to do something called chaining where every time instead of turning the each array value on and off with 0 and 1. Instead what you do is you kind of put each object into its hashed array value and make the sort of list that sort a linked list of these values. And so then you can kind of ": [
            3625.8,
            3656.6,
            89
        ],
        "you. I think that can only happen if it's 0 right. Definitely he's all right, cuz it's saying the average unexpectedness is 0 which means that on average you're you're a random variable when a variable is going to be zero away from your unexpected. any questions right Which one has to be negative? Oh, I see what you're saying. Yeah, you're right. Yeah, I think D is also right. ": [
            2040.1,
            2113.8,
            47
        ]
    },
    "File Name": "Mathematics for Algorithms and Systems - B00 - Jones, Miles E - Winter 2019-lecture_14.flac",
    "Full Transcript": "Listen to a podcast.  Alright, so let's get started.  So I wanted to share with you some.  some slides that Andrew posted the other instructor on his  from his lecture on  what the heck?  That's cool.  Okay, so he's got a few slides. If you look at the website, you can find his slides from yesterday and I like how he kind of summarized what we did on Monday. And he also has some nice practice problems that you can use to help study for the final and practice for the homework and stuff.  okay, so I like this because  he kind of list out all of the terms that we learned from Monday and do we start probability on Monday or last week?  Started last week like a little bit, right? So we have sample space probability space. Does anybody remember what the math term for? This is  set K what else we got outcome?  element, right  Bernoulli trial  don't really have like a  like a math term for it. But yeah, it's just something that has two outcomes.  a trial  two outcomes  Okay, what else we got here event?  What's the math term for it subset?  conditional probability so  we talked about what that was random variable. We talked about that one right member that was a function.  function  from  sample space  2 reels  distribution function of a random variable we talked about that to remember that was the probability that  the random variable will be equal to a certain number.  And then we had expectation. This was the  kind of that average.  of the probabilities of the random variable  And what else we have binomial distribution?  That was basically like the distribution of the Bernoulli trial that we saw.  Variance we're going to look at that today.  Use of an indicator variable. This was useful when you did linearity of expectation.  What you're going to see a little bit more up today linearity of expectation and its applications independence of events. Did you guys remember what that means?  Right. So the the event doesn't affect the other one. Another way to say is the probability of their intersection is equal to the product of their probabilities.  Okay, and then Bayes theorem remember what that was kind of a way to?  Turn the tables on the conditional probabilities and what else and more so his advice is to have such a kind of remind yourself of what each thing means.  any questions  Okay, he's got some great problems.  So we're just going to kind of go through them real fast. I'm not going to solve them because I think it might be a good exercise for you guys, but maybe just to get you start thinking about how to solve these expectation problems in like what the problem what kind of problems, you know, can you solve with them? Okay, so funny thank you notes and address 20 corresponding and envelopes, but then he gets distracted and puts the letters randomly into the envelopes one letter per envelope. What's the expected number of letters that are in their correct envelopes?  I think so. I think about it like that.  Oh, yeah, that's something I wanted to do. Okay. Yeah.  So kind of a roadmap for solving this kind of thing figure out what your random variable is figure out what your expected value is and figure out what your indicator variable is.  And then figure out use all of that to figure out what is the expected value?  Okay, another kind of sort of same kind of topic you have.  One random major league baseball player into every pack right there and major league baseball players and say you're a collector you want to get all of those baseball players. What's the expected number of packs you need to buy before you get all of them could just get be lucky and get them all in the end the first and packs that you get it's probably unlikely, right? Probably likely that you have to buy more and more and more and then you might have to kind of by a bunch to get that last one.  Hashing, this is something that we're going to look at today in more detail.  Have you guys done anything what hash functions before?  It's basically a way to map kind of a a big piece of information into a smaller.  smaller memory location encoding in a weird way  and so the values returned by a hash function are called hash values or simply hashes and  Open hashing each item has shipped to a particular location in an array in applications can hold more than one item, and we're going to look at this also because the idea is that you're going from like a big.  Big size data too small so it might be the case that more than one data point goes to the same hash value.  Okay. So here's a few problems to do with hashing number of items per location. What's the expected number of items per location right by how many times do they?  Get in there another type of problem that we're going to look at in a little bit more detail today. What's the expected number of empty locations?  I ain't so you guys can 20 items into a table of size five nights 10 you can think about it in like these smaller terms and that might help you get good better practice.  Okay, and then here's another Bayes theorem problem. Okay, so I think that those are nice too.  to look at  okay, let's start with kind of the next topic or not. The next topic just kind of continue on with probability. We're going to look at concentration. And then we're going to look at how to use probability to find the expected runtime of a randomized algorithm.  We kind of did that in a way last time with the counting the number of times the max changes, so we'll see how it works on a different kind of algorithm.  Okay. So remember what we said about linearity of expectation wear if your a random variable is a sum of two other random variables that you can kind of take the expectation of the Sun at the sum of the expectations. It doesn't do that in with other functions. It's just special for addition. For example, it does not do it with squaring. Okay. So let's just look at this example. If P of X is d p of x equals 0 as a half of x equals 1 is 1/2  What is the expected value of x?  1/2 right remember the  expected value of an indicator variable is is the probability that is equal to 1.  Okay. Now let's do this one. What is EFX quantity squared?  1/4  Okay. Now this is kind of a weird one. What is he of x squared?  Well, this is the probability.  We're talking about the probability that x squared is equal to 0 is what?  Also 1/2, right?  What about the probability that x squared is equal to 1?  also 1/2  Okay, so this is also 1/2.  you can kind of plug it in directly into the  definition of expected value  Okay, so that kind of just shows you that you can't take that square out of the expected value sign.  Okay, let's move on to Independent Independence when we're talkin about random variables. It kind of has the same feeling as the independence when were talking about probabilities. Okay. So we're saying that why are random variables are the same sample space X and Y are called independent if for all possible values P of x equals B, and Y equals you is equal to their product and it has to be this has to work over all pairs of values.  X equal to be white with you.  Okay, wait, where's my clicker thing?  Don't even have it plugged in.  Come on now.  Okay.  Which of the following pairs of random variables on a sample space of the sequence of heads and tails coin coin is flipped four times are independent K. We have X12 is the number of heads in the first two flips actually forms of the number of heads in the last two flips. The number of heads in the sequence. Why is the number of tails in the sequence X12 is the number of heads in the first two flips access number chosen to see none of the above. Which one of these pairs of events are independent.  at least for the number of flips is 4  exactly four  Okay good.  So we're saying some of its. Okay, so, let's see.  Let's take a minute to look at some of these things now.  Let's look at a  the idea here is to be independent the value of x doesn't influence the value of y right. And so if you look at it, you can kind of you can kind of Reason out that doesn't matter how many how many heads you flipped in the first two flips. It doesn't affect what happens in the second two flips.  But what about B?  number of heads versus the number of tails  If I know the number of heads in the sequence, will that would that give me any information about the number of tails in the sequence? Yes, right. I mean they're there directly dependent on each other.  How can we see this? How can we kind of prove that these are not independent? You can just pick a counterexample pick some example. Okay. So let's say what's the probability that?  number of heads is equal to  3  intersect number of tails is equal to 1  Why you can pick which test at which position is the tail on the other three have to be heads, right? So there's four different things. So that should be 1/4.  right  Now what's the probability of the number of heads be equal to three itself? I mean the same thing right? It's also 1/4.  What's the probability of the number of Tails being one?  It's also 1/4 right? I mean it's this is kind of like a stupid example because that intersection that's the they're sort of like the same set. Right? So it makes sense that the product of those two single probabilities should not be equal to the probability itself.  Okay, so be there dependent. How about sea?  You can kind of do the sort of sort of a similar counterexample. What's the probability that the number of heads is equal to 2?  And the first two flips, right?  intersect the number of heads equals 3 in all flips  was just a probability right you can figure that out and then do the  Split them up and show that the product is not equal to the probability.  Cast of this is these are dependent also.  any questions  Okay.  So here's a nice a nice. It's sort of like goes against what we were just talking about how expected values only their only linear with respect to the some. But in fact, they're all so they also commute with  Multiplication but only in the circumstance where X and Y are independent.  So if X and Y are independent then he of XY is e of x times you've watched. This is not necessarily true if the random variables are not independent. Okay good. So  take that because we're going to use it a little bit later when we start talking about the variance.  Okay, so when you have a big piece of data.  sometimes it's nice to know certain properties of it and  something that we've  certain things that we've heard before maybe are like standard deviation or variance or things like that. But what are those things and how do they relate to random variables and expected values? Okay. So here is how close on average will we be to the expected value? What is the unexpectedness? Okay, so you  Is a random variable.  But it's value is how far away is the random variable X to its expected value.  And that kind of gives you a sense of how much the data is spread out, right if the unexpectedness is large then that means on average right now. That's the average unexpectedness. Sorry.  Okay, I saw the sorry the unexpected. This is a random variable. So for each outcome you you figure out what is distance is to the expected value.  average unexpectedness kind of tells you  On average how far are things to apart from the expected value? Think about rolling a dice right on average how far away are the dice roll from the expected value? Okay. So I guess that would be like a good example. Let's do dice. Right? So then you of one is going to be equal to do you guys remember the expected value of rolling a six-sided dice?  3.5 G is equal to 3.5. So the unexpectedness of 1 is equal to 2.5 right of 2 is equal to 1.5 U of 3 is equal to  point five you of 4 is equal 2.5 you of 5 is equal to 1.5 and you if 6 is equal to 2.5.  Okay, but that that gives you another value for each one of those rules. Now. What all those things?  Okay, so it's the expected value of the unexpectedness?  Cuz remember how to how to compute expected value you basically take the average of all the random variable values.  Just out of curiosity. What is the expected the average unexpectedness?  Rihanna  I guess.  2.5 + 1.5 is 4 or 4.5. Okay, so it's 9 divided by 6 is  3 / 2  so on average you're going to be about 1.5 away from the expected value that kind of gives you a sense of how tight the range is.  Okay. So these things are are pretty easy to kind of comprehend by just writing them out the variance and the standard deviation. These These are these are a little bit more useful or at least the standard deviation is a little bit more useful right you guys always want to know what the standard deviation is of the homework. So the tests and stuff like that. It kind of gives you a sense of how far away are most of the submissions. So the variance what it does is instead of just  The expected value of the unexpectedness does the expected value of the square of the unexpectedness? Okay, and what that does is  It makes things that are closer to the expected value even closer and things that are far apart that pushes it away. So it's sort of magnifies the spread and then the standard deviation is just to take the square root of the variance.  and that just gives you more of a sense of  How close together Things Are?  Okay. So right way all the difference from me equally way the large difference from me more.  So the average unexpectedness equal to standard deviation.  Okay good.  Good because why would we know that we of you squared is not equal to any of you squared in general Frank we have we've seen that before already happening.  Okay. Now let's look at an example.  we have  POF X1 and X2 are different random variables, right?  X1 and X2. They both have expected value of 0 x 1 is kind of like spread around like negative to negative 1 0 1 2 and x 2 is negative to negative to nicely both have  expected value of 0  I guess that takes away this one, that's fine.  Okay. What so what I'm asking now is what is the variance? How did the variances compare know remember the variance is sort of a measure of how spread out things are.  When is the variance going to be zero?  was that  right when every random variable value is the same right? That means that they're all together. They're all kind of scrunched up right next to the expected value. And when is the variance big it's when things are spread out more. So just fine. I like the feeling of the this data which one do you feel has a bigger variance?  Okay, good. We have a little bit of  so  why don't you guys?  Where is the  what happened to that?  Oh now be is gaining more momentum.  I don't think it's a  Okay, it's okay. So be as kind of the leader here can anybody tell me why they think B is the right answer?  Okay, good. Yeah, so  x to the the date of kind of spread out to the extremes and they're like both really far away from the expected value in the middle. Whereas X1 the kind of like spread out evenly and there are some that are closer and some that are farther away which is different than them all being far away. So  stop be any questions.  Okay, so this would be a good exercise.  to calculate  each variance  Okay.  Okay, so now let's get to back to the variance. I want to prove to you this this theorem. I gave this to you on the homework for you to to practice with it. But let's think about where does it come from? Okay, so we're taking the  the definition of variance  to be this year.  Play so how does that turn into this? So let's start off with e e of x minus e-squared, right? Is it going to be e of x squared - 2  XE plus b squared, right  If you just kind of expand it.  Okay, so what can we use here?  Does anybody know any property of expectation that might be helpful?  What is it?  Linearity, right? So this is actually equal to e of x squared minus B of 2x e  plus he of e squared.  Text let's simplify this a little bit.  if x squared is fine is that  -2 you can bring the two out. You can bring the E like that and  we also have  he's Square.  He of how do I do this part?  2 * e  EFX x e Wright  plus and then the expected value chi-square does just the same value. So the expected value of of a constant is just that value.  Hey, so you got EFX squared - 2 of x squared plus b of x squared and simplifies to this.  That's basically what we had before. Okay. So this this is usually what we used to calculate the variance because it's a lot easier to do it then actually calculating it that way.  Okay, so  oh, yeah, we already talked about this, right?  What does it mean for the variance to be zero? Let's just do it again.  What does it mean for the pharynx to beat zero does it mean that the value of the random variable X must always be zero the value of the random variable must be constant G of x squared is equal to x if x squared is equal to e View Square Dory of you is equal to 0 or I guess I should put another one here.  Oh, you can't put that.  No, I want to say some of the above.  Let's just talk about him.  Forget this thing. Okay is a true.  Not necessarily, right?  Okay, how about be?  Yes, right.  How about sea?  I know, right?  How about D?  pink  Tell me that the expected value of x is equal to the expected value of you.  I think that can only happen if it's 0 right.  Definitely he's all right, cuz it's saying the average unexpectedness is 0 which means that on average you're you're a random variable when a variable is going to be zero away from your unexpected.  any questions  right  Which one has to be negative?  Oh, I see what you're saying. Yeah, you're right.  Yeah, I think D is also right.  Which one?  The variances interview square, right?  I know but I think the only way that they could be equal is if they're both 0  right  Okay, let's move on to the next thing another algorithm.  Element distinctness case you're given a list of integers A1 through a and they're not necessarily in any order.  You want to know if all the elements are distinct if they're all different or if there's a repetition then you want an output repetition, right or not distinct or something like that? Okay. What is it like a very kind of simple algorithm that could solve this problem reasonably efficiently.  okay, good so short  Then scan right?  Okay. So how long would it take to sort the list then step through to find duplicates? What's the best run time that you can get?  Okay, good and login right sorting takes best time sorting takes and big data and login.  And then if you step through to find duplicates, this will take at most Big O of n right?  So total run time to get big oven login fixate oven login. Okay, how much memory does this require?  Okay, good. We need to have at least and memories to hold the data, right?  just got to be at least an  but you can sort in place or merge sort actually uses a constant multiple of n where n is the size of the data. So it's not unreasonable to sort it with n memory. Okay?  So you sort it with and memory and you can get this.  Okay, so  what do we have so far? We basically have an algorithm that the time.  Is on the order of Big O of M login?  and the space is on the order of big Theta of n  Okay, so you're going to see that when you when you work with algorithms the time in the space kind of have like an inverse relationship sometimes which means that if I allow much more space I can maybe make the run time faster and if I if I kind of restrict the amount of space it might take the runtime a lot longer.  Think about why that why that works and it's different for every algorithm. But in general that's kind of like the relationship you should think of  Okay, so what if we had access to unlimited memory?  Anybody have a an idea of an algorithm that could solve this problem more efficiently.  Okay, so you're putting it into your putting each integer into a set and then into the same set and then every time you get a new integer, you look in that set to see if it's there. Yeah. Okay. So that is the death kind of the general idea. But instead of like a set instead of like a container think about it more as like an array of blue aliens where you have an array that's infinitely long. Let's say that these are all integers right? So it doesn't matter how big they are. Once you find once you encounter an integer you turn. It's an array from Falls to true.  right  And So then whenever you encounter a new integer, you look up its array value.  Let's say that takes constant time right you look a bit array value if it's Falls turn it to true if it's true that you've already seen it before.  pictures of kind of the idea  is an array of memory locations indexed by integers. Okay, and we're just going to assume that there are infinitely many.  So what's the runtime of this algorithm if you assume that a ray look up is constant time.  Okay. Good. Good. Good. Good. Good good.  Big Love and right  you've done is a very simple thing.  Okay, and so I guess instead of true and false. I put zeros in once.  Okay, what's the memory usage this algorithm? We're going to skip this because it's infinite, right? It doesn't really have a bound. I mean, I guess it's it's dependent on the size of your biggest integer in your array.  That's not really a good thing to base your run time on or debaser memory time on right because you could be working with  I don't know. Maybe your integers are distances between galaxies in centimeters. Then, you know, it's really not useful especially maybe if you only have if you only know of like a few galaxies, right then it's not really useful to have that many memory locations.  Okay. So what we're going to do is to find this thing called a hash function. You guys are probably heard of it and used it before.  And the idea is that it's to stimulate a big amount of memory. You use something called virtual memory by converting each in this case integer into a smaller set. So instead of using those distances in centimeters, you can convert those who maybe I don't know I set with a more reasonable side, maybe instead of like a hundred integers. Okay. The idea is that we're going to do it randomly.  But not not randomly like you get a different value each time, but it's equally likely for you to pick any of those values. But the idea of the hash function is always pick the same value every time and this in this sense. It gives you sort of a map.  How do you implement them did you do it in 12?  Yeah, you got kind of an idea. So let's use a hash functions for this problem.  Okay, here's kind of an application. So suppose suppose you have a company of 5,000 employees. And each of them is identified by their social security number. How many unique Social Security numbers are there?  Wait, let me write down my social security number real fast. So you guys can just plan you have right?  9 right  so you have what 1 * 10?  Roughly I think that there are some like restrictions or something.  You can't have six six six in there or something.  It can't start with 420.  Or is that a restriction? Anyhow?  So cancel the 9 is big but you only have 5000 Floyd so you really want to have a file cabinet with what is 10 to the 9 trillion or billion a billion really want to have a billion slots in your file cabinet? No, not really. You want to save some space. So instead you make a hash function that that converts each social security number to not a unique number because it's not it's not possible to do that because you're going from a billion down to say ten thousand or something, but you wanted to do it in a way that you're unlikely to have collisions.  You guys can probably think of some other examples will see it will look at another example in a minute.  Okay, so ideally we want to use a very unpredictable function and assume that for this function for every virtual location V HOV is uniformly and randomly chosen among the physical locations. This is called an ideal hash function and there are ways to get like a good model of an ideal hash function using number Theory using like prime numbers and things like that. We're just going to assume that one exists and use it kind of theoretically  Okay, so  Now, let's check out this algorithm pick a hash function.  That basically maps all positive integers into the small window of integers from 1 to m.  And then what are we going to do if the hash value?  Create an array that has m.  locations right array of size n  then has your integer go to that array location of the hatchet integer if it's not a wand and turn it into a one and if it is a one then say that you found a repeat.  What's the runtime of this algorithm?  Okay, good. It's still I mean, it's not much different than the one we saw before, right? We just doing this intermediate step. Where were hashing the integer.  Okay, what's the memory of this algorithm?  Well, this is kind of a trick question.  It would be big data of mplus and does this algorithm actually work?  Okay, good your you might have a collision right? And so maybe I have a hash this hash to the value 11, right? So I turned Eleven on and then this other number also match to 11. And so I see that there's a collision but the two numbers that has to it we're different. So that's bad.  Okay, so it kind of does one of the things and not the other if there is actually repetitions in this algorithm will find it right because the same number will has two the same value. But if there's no repetition it might it might give you kind of like a false sense that there that all the elements are distinct.  or the other way around if there's  they could all be distinct, but the algorithm will save that they found a repeat.  Okay. So the idea now is we're going to try to figure out why is the algorithm going to be correct with a high probability with this ideal hash model, right if you think about making making the size M bigger and bigger and bigger, right? There's a lot there's a less likely chance that you're going to have a collision.  Okay. So this all kind of has to do with this thing called the birthday paradox.  Have you guys heard of this?  the idea here is that  it's misleading to think about these probabilities kind of.  let's just say what the birthday Paradox is and then you can think about whether or not you think it's  misleading or not. What's the chance of two people in a group sharing the same birthday? Okay. So example, what is the chance and say a group of 30 people two people share the same birthday. What are you guys gas? Any guess any any ideas?  10%  write 30 goes into 360 around 10 times around 10% or I don't know.  20% 30%  do you think it's anybody think it more than 50%  Good, so, I don't know if this is surprising to you if you haven't seen it before but it's more than a 50% chance and it a group of 30 people two people share the same birthday. How could that be?  Well even more surprising.  with 60 people  it's more than 99%  How could that be?  Okay. Well, let's let's look at the math behind it.  Okay.  when you have  Okay, so if you have two people, what's the probability that they share the same birthday, but you have one person one person's birthday on a specific day. And then there's one let's just wear under the assumption that everybody has every birthday has the same probability. Okay. So there's a 1 out of 33 65 chance that that person has the same birthday as me whenever 365 no big deal.  Okay, what about if there are three people?  Okay, so what's the what's the probability that it if you have three people that there are two of them share the same birthday.  Okay. Now let's think about how to count this to find the probability. We're saying at least two of them share the same birthday. So when you hear at least let's turn it around and think about the complement. The compliment is that everybody has a different birthday, right? So what's the probability that everybody has a different birthday? Well  I could have 365.  The other person could have 364 days cuz it doesn't conflict with mine and the third person would have 363 right?  all / 365  cute cuz that's 365 cubed is the number of ways. We could all just have birthdays with no restrictions the number for very close to one right? It's it's a it's a really high chance that three random people in a room. They all share they all have different birthdays.  Okay. So this is kind of this is the 99% chance that 3 people in a room has shared two different birthdays.  Okay. How about so then you subtract it from one and this is the probability that they don't that that two people share the birthday.  Okay, so in general  There are and people were and is less than 365 write if if you had if you had 365 people in a room by the pigeonhole principle. It's certain that two people share or you have to have more than three. But if you have less than this is the formula that you plug in maybe like as an exercise.  Try to plug in some values and see what you got. Right you're going to see that when you plug in 23, that's when it kind of start splitting fifty-fifty. Right and when you get up to 60, that's when you get like something more than 99% hard to believe but it's true.  Got any questions about this?  So why did I switch the topic from hash functions to birthdays because birthdays are kind of a nice model to think about when you think about hash function right in this case the elements in the array are people.  And the days of the year are the memory locations the hash of a person is your birthday, right? So think about all the students in the whole university right? We can kind of  Give each person a number based on their birthday. And now you've kind of you kind of built this hashing function that sort of randomly give assigns people numbers.  Cake collisions mean that two people share the same birthday.  Okay, so let's talk about a general birthday type Paradox. If you have an object and M places and people and M calendar days, we're putting each object at random into one of the places. What's the probability that two objects occupy the same place?  what's kind of think about it as like putting these little balls into these little  Slots, okay. So the first ball goes into any slot right the probability of the first object causing. No collisions is one, right?  What's the probability that the second object doesn't cause any collisions?  1 - 1 / am right or I heard somebody say it and -1 / M right?  Now given that the two the first two didn't Collide what's the probability that the third one's not going to collide either?  -2 / M or 1 - 2 2 / am right.  so we have 1 * 1 - 1 / M * 1 - 2 / M * 1 - 3 / M and so on up to  1 - + -1 / him  You keep on putting them in. Okay. See you get this nice product here. And you do a little bit of algebra. And you find that the probability is less than 80 to the negative and shoes to over em, and really what I want you to get from this is that  we want P to be close to 1 so we want them to be bigger than and choose to and you can think of any shoes to to be around and squared over to Okay, so  Right, we want there to be the probability of there being a Kalitta being no collisions is one right? There is the probability that there is no collisions. So if we make them really really big bigger than 10 squared / 2, then p is going to be closer and closer and closer to 1.  Because we're going to have a key to the negative zero write something about you that's close to e to the negative zero, which is a value that Pokemon.  Okay, so we need the number of Memories locations to be more than and squared.  Another so this is basically what I said Okay. So let's do this same problem again.  now  I'm going to I'm going to take them to be.  equal to Big Omega of let's just say that it's  big Theta of N squared  Okay. Now it's really unlikely that we're going to have any collisions and this this algorithm still runs in Big O of n time, but we're using big old and squared memory of the balance. I was talking about where we can kind of give more memory and get a better run time.  Okay. Well it kind of just sort of depends on what you have more of if you don't have a lot of memory just doesn't really make sense because you could just sort it and find it in linear or in N log in time.  So what we're going to do is look at another way to kind of get around this problem.  And the way to do this is to not think think of collisions not as like the enemy don't think of it as like a bad thing embrace it and see if you can use it to your advantage.  Okay, so the idea to do something called chaining where every time instead of turning the each array value on and off with 0 and 1.  Instead what you do is you kind of put each object into its hashed array value and make the sort of list that sort a linked list of these values. And so then you can kind of look through that list to see if your uvula  you've already  already put it in there. This is kind of like your first idea right where you keep on putting things in the list and you search for them. But now instead we have a bunch of lists and it's it's easy to figure out which lift it should be in.  okay, so here's kind of the algorithm and  we don't have to go into the time to spend so much time on the details, but it's basically that this array now is is a bunch of no list. And you just keep on adding to the list whenever you find a new value find a new value hash it you put it on to the list and then if you've ever if you ever see that same value in that list, then you found a repeat.  Okay, so this one is correct. It works. It's great. What's the memory using this algorithm?  Well, let's say the size of an is big old M. The total size of all the linked list will be Big O of n so the total memory with me because you might have like a bunch of really long linked list if you have a bunch of collisions,  Okay. So this algorithm is great. Now we just have to figure out what size of em, do we want? Right? We don't have to make em super large anymore when I have to make it like bigger than M squared anymore because we're not scared of collisions. Right? We're okay with the collisions. We know how to deal with that. Okay. So how low can we bring em down in order to kind of get a reasonable time algorithm?  Think about the extreme what if M was equal to one then you're putting everything into the same list and it's kind of like you're you're searching through the list every time you're going to get like a bad front. I'm like a like a big O of N squared so there has to be some sort of Middle Ground where we can get maybe a linear time algorithm with a nice amount of  memory  Okay, so let's calculate the runtime of this algorithm. So inside of here.  The worst case happens when you don't find that that element in your list because that means you have to kind of look through every part of your list and you didn't find it anywhere and then you append it to the last part of the last night. So this is going to take big'o of 1 plus the size of that list at that time.  So  and other words, this is 1 plus the number of indices before I  That collided with that same hash value, right?  Okay, and so all in all.  We're adding up and plus the number the total number of collisions between Pairs Ai and AJ were J is less than I or in other words. We're adding up to total number of collisions here.  Okay. So every time that there's a collision that's going to add a little bit more to your run time.  So what we want to do is figure out what is the expected number of collisions we can kind of think about what happens on the extremes, right? But really want to know what's the average amount? What do we expect to happen?  Okay. So remember collisions depend on the choice of the hash function in the ideal model each output is equally likely right.  So for each input AI you get a random.  number in this in this range from one to m  Okay, let's put our thinking caps on.  How can I find the total number of collisions while I can't really do that reliably because it's going to change dependent on my hash function, right? And it's it's in the hash function is supposed to be this random assignment and so in order to get to the number of collisions total number of collisions, it's better to talk about the collisions as a random variable write each hash function has a number of collisions that will go with it. Right. So that would be the number associated to that outcome and each random variable. You can talk about the expected value and the way we're going to do it is  Everybody's favorite property of expected value.  Okay, good. Let's do this. What is the expected total number of collisions?  Okay, so  What I'm going to do is use an indicator random variable.  I'm going to say x i j.  is equal to 1  if  age of AI is equal to age of AJ.  if those two entries collide  and 0 otherwise  okay now X is equal to  the sum of all i j pears  x i j  I think this is the number of  of collisions  Okay, does that make sense? Right cuz you're just turning them on and off. We talked about these indicator functions already.  Okay, so that's that now by the linearity of expectation the expected number of total collisions is the sum of all the expectations.  What is what is the expected value of this indicator variable?  Ready go.  Remember that there are M memory locations.  prank  age of a I could map to any of those m.  And age of AJ could also map to any of those m.  Okay good. So we have some kind of competing views here.  Why don't you guys take a minute and talk it over with your peers see if we can get one of these bars to be a little bit taller than the other.  We're getting some convincing going on, right?  Okay good.  Right that there's their HOA HOA. I can go anywhere right just pick a random location. And then there's a 1in m chance that h a j will be that same one. That's kind of like the the birthday having the same birthday with two people. Right? Do you want to think about it? The other way is what's the probability that they will be different, but they won't have a collision.  And then take the compliment.  Okay now so that's good, right? That's one kind of element. Now. The next thing is how many terms are in this sum?  Right. Remember we're going to some this is something over all pairs.  IJ  I got to go back to Counting.  Good.  answers to write  Andrew's too many pairs in a set of n elements  Now we got all the details and we've got that the total number of collisions is the some overall pairs of e of X IJ. We know of x i j is equal to 1 / M for every pair i j to just add that up a bunch of times and you get and choose to over M, which is around Big O and squared / m  So that's the number of collisions that we expect to have and that gives you a sense of why when m is really close to N squared. You only expect to have very few, right?  What about when am is close to N?  then this thing becomes Big O of N squared over and which is Big O of n  So this is the total expected time in the ideal hash model. As long as m is greater than end in the total expected time is Big O of n  this is much better than our original Pro choosing sorting.  So what you would want is you want em to be around the same size as and maybe twice as big or something like that and then you know that the expected run time is still going to be linear, but your amount of memory is small is smaller than what we use before and it's faster than sorting.  Okay any questions?  Okay, let's see.  Let's call it a day and start on the next topic on.  on Monday  Yes, sure.  How do you calculate the variance? Cuz cuz you see right expected value 22 computer.  UC San Diego podcast "
}