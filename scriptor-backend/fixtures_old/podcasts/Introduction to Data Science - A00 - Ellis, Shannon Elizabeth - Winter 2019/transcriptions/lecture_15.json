{
    "Blurbs": {
        "Audrey Assad is what type of question how common is watching Sesame Street in the US? Inferential wouldn't be inferential because an inference you're going to be drawing relationships between two things. So I'm going to say this one would just be a descriptive analysis. You're really just calculating one number and not relating it to anything else. But I think that was a a good guess. What is the ": [
            1127.3,
            1150.9,
            39
        ],
        "Childhood to predict their success in elementary school, but we had some answering to the other ones. They tell me how they came to answer D the correct answer or how they ruled out the other ones. What type of analysis is question a how common is watching Sesame Street in the US? I just so far. We talk about descriptive analysis exploratory data analysis inference and machine learning today. ": [
            1090.8,
            1125.3,
            38
        ],
        "Francisco and with New York, you might know that San Francisco is incredibly hilly City. So you might start to look at elevation over here. We have all of the homes in San Francisco. And here we have all of the homes in New York City and we can see that the house is at the highest elevation 10 to be in San Francisco or New York tend to have ": [
            3552.0,
            3570.4,
            127
        ],
        "Francisco. So if you want to chat with each other based on what you know from these cities what might give us a clue as to if I told you about a house, what were the singers the house is the child each other and then I'll ask for your feedback. Yeah, New York, New York is New York City? All right who has a thought as to what they ": [
            3463.9,
            3520.8,
            125
        ],
        "I'm so that was something that she could take back to her bosses and say hey we should tell this to all of our nonprofit station use format be with a much bigger but rather than a paste on this experiment what rear end FaceTime is a b testing question. Can we predict which donors are most likely to stay current or switch to become recurring today? Remember what I ": [
            365.0,
            385.2,
            11
        ],
        "I've said a few times when she learning approaches are what we used to do this type of analysis. I'm going to have you over you through these on your own child each other. And which of these questions is most appropriate for machine learning. Give everybody a few more seconds. 3 2 okay. So 67% of you said that it is D. Can we use information about one's Early ": [
            1001.8,
            1090.8,
            37
        ],
        "It's Matt. It's based on truth and the argument hear from somebody at Microsoft is that in fact the data matters more than a match because you can say to your in Pudding to the math if there was a biased than the algorithms. In fact can be racist. This is what the reading you're doing for. Your kids reading is all about we talk about this example before is ": [
            3288.9,
            3310.0,
            119
        ],
        "Listen to a podcast. All right. Hello everyone. We're going to get started as people settle down. So as per usual starting. With the fact that you have a reading quiz, your final reading quiz is due this Friday and your fourth assignment which includes your proposal for how you how you would analyze your project is due next Friday. This is General notes here at the bottom your third ": [
            1.9,
            58.8,
            0
        ],
        "So just to review when you're protecting a continuous variable regression is the simplest and most common approach in the supervised learning category. When you're doing classification decision trees can be helpful. If you're doing unsupervised learning the computer is using mathematical representations to take and put all these emojis and classify them into different categories. We haven't talked to Tom about dimensionality reduction. We're not going to but I ": [
            2485.9,
            2513.7,
            94
        ],
        "So this example these three up here or all ducks. So your classifier the computer was determined they all have similar feet or similar pills. They have similar ears. Where is this bunny and this mouse have different features different feet different ears different noses, and it would classify these into three groups based on the features within the input data. Hear when you do an unsupervised learning you're doing ": [
            1742.2,
            1766.4,
            63
        ],
        "So you want to determine emotions you want a cluster into some the motion and you want to do a basement on supervised way. So you don't have to go in and tell the computer exactly what in the picture to look at so I'm going to say that that is the best response if you wanted to do some sort of supervisor protest you would have to go in ": [
            2804.4,
            2822.0,
            102
        ],
        "So you're using data you currently have in hand or historical data data from the past two, then build a model and remember model is a mathematical equation that best explains the date of that you're using and you're going to use that model to make predictions in the future. Then we're talking about predictive analyses were talking about machine learning techniques to work with a do you have now ": [
            861.9,
            883.5,
            31
        ],
        "When should be quick review? decorative tile with each other Scary the few more seconds. 3 2 1 Okay, so we see a downward pattern from left to right. I'm going to argue for the sake of his success this example that we are here going to do a supervisor approach. So now we're doing supervised here and we're predicting age were predicting something that is continuous. So here we ": [
            3039.4,
            3101.5,
            113
        ],
        "a big hit so that is the answer to how one of their companies. People to be more recurring donor. So they offered the incentive of a blanket. I think people should use and that one company by offering a blanket got a lot more people to sign up to being returned on her. So that's absolutely true. But they did something at Classy at the company where she works ": [
            294.1,
            313.3,
            8
        ],
        "a box plot to display these data. So that was the idea there if you were using a barfly for quantitative data, you probably should not if you are using a bar plot for categorical data that is okay set the difference between what page said don't use it for quantitative data. And then what I said you use it for categorical okay with that where to send the rest ": [
            770.4,
            791.3,
            27
        ],
        "a clustering or dimensionality reduction, generally. And it uses the what we call structure within the data for the features that are within the data set to automatically identify the groups. So I told you I would mention Pages third question when she was looking at how to determine whether or not somebody would become a recurring donor. She said that she could do it in a supervised way in ": [
            1766.4,
            1791.4,
            64
        ],
        "a small number of photos where they were confident. So they hired people to correctly label photos and then use those as their training data to generate their model. They use a a neural net that is already out there. So an unsupervised approach that takes the images as input and then determines the room that are in as their output uses lots of layers. They fired a bit for ": [
            4021.7,
            4044.5,
            147
        ],
        "about a lot. Okay, any questions on the three questions that you talked about with regards to recurring donors the one big topic? She spent a lot of time on. Okay, who remembers what the take-home message was of her Kickstarter and they're like fun examples that she said she included on her resume when applying for jobs and she use this hashtag or bar plus maybe remember what the ": [
            547.3,
            571.1,
            20
        ],
        "about data partitioning. We're talking about the dataset you have splitting it so that you use some of the data to train your model and then some of it to do test out once you built the model to see if it works on data that the model was not trained on. This is a general question just that I have and it is if you've ever learned or done ": [
            1247.9,
            1267.8,
            44
        ],
        "about that all the time could understand the point of trying and the importance of recurrent donors. Just have to communicate with stakeholders throughout the company after they did that a b tests and determined that with the one for Matt was much more effective at getting recurring donors. She shared that with the high rocks at her company and have to get them to buy into her idea. If ": [
            486.9,
            506.5,
            17
        ],
        "accuracy in your training day that you've likely over fit your model. What's is a recap of what we talked about there? The second example of talked about today is categorizing listing photos at Airbnb. Which Russian? Hey, I lost my focus. And I know we're getting towards the end. Is a question of yours, can you train the model and specify which features and how to wait them in ": [
            3801.1,
            3843.2,
            139
        ],
        "all know if you are unfamiliar with machine learning You are not alone. So we have when we're talking about data partitioning as I mentioned as you have this data set that you're going to use to build your predictive model. It has observations. It has features you are then going to take some 4% of it and use this to build your model. So you're going to the model ": [
            1384.1,
            1403.5,
            49
        ],
        "all of the houses that are in your testing date is that and send them down the tree so we know that in our training data, all of the San Fran house has ended up with the San Fran and all the New York with the New York and you're texting dating site as you send them down the tree you start classifying and you see that yes, I'm over ": [
            3746.4,
            3763.5,
            136
        ],
        "an example of a b testing they had example a where they had the small buttons and an example where they moved into the top and they said an example of a or is it an example of which one increases our has more people become returning donors and they found that when the button was bigger and higher they got more people to sign up being as recurring donors. ": [
            346.3,
            365.0,
            10
        ],
        "and so it bar meaning like get rid of so get rid of body parts was the take home from her Kickstarter that they started which sword is a fun idea. But as she told you and she's told me that this was acting on all of her job interviews cuz it was something that was different from everybody else had done. So Friday was Barbara Potts, but I have ": [
            648.7,
            668.6,
            22
        ],
        "and vocabulary a new ideas and there's going to be a lot of time for y'all to discuss and ask questions to each other as questions to me think through things. So we are going to Jump Right In by first reviewing the guest lecture from last week. I think Paige p a p giannini is a guest lecturer was really really helpful. If she gave you an idea of ": [
            83.9,
            101.7,
            2
        ],
        "answer is simple answers yet. Another question. That's a great question example is a true example from Airbnb and in this case would want to categorize listing photos at Airbnb the somebody wants to put their place up on Airbnb so that other people can run it out. How would you categorize the photos they've submitted? Go to few more seconds. 3 2 1 I hope so. We see that ": [
            3860.1,
            3916.3,
            141
        ],
        "are bedrooms. These are not these are bathrooms. These are not and these are pools while these are not and I think this is probably the most impressive because these look the most like pools when you can see that these in fact or not pools to a single Airbnb unless this is some super fancy Airbnb. Any questions on what we talked about so far? Or I'm going to ": [
            4119.1,
            4143.7,
            151
        ],
        "as one and machine learning for predictive analysis as another analytical skill Joseph highlight the fact that she has to communicate as a data scientist with lots of different groups right though in the how much is a donor worth. They wrote a blogpost so that all of the nonprofit they work with so a general audience who doesn't necessarily have data science skills are are necessarily people that think ": [
            464.9,
            486.9,
            16
        ],
        "assignment. Nope, second assignment grade. So that's a typo or end credit are on try and Ed and Disturbed workbook. If you want more practice in Python that is being used in section is available on TriNet and the first exam is also now viewable on TriNet. EXO today we're going to be talking about machine learning to get to that because they're going to be lots of new Concepts ": [
            58.8,
            83.9,
            1
        ],
        "at all. There's one measure of model assessment that can be used for both categorical and continuous. Although it's more helpful for categorical. So really when you're predicting accuracy is saying did I guess this person right? Yes or no and divided by the total number of samples predicted. So in the age example, somebody was 49 for 6 to be 50 would be counted the same way as somebody ": [
            2948.8,
            2970.8,
            109
        ],
        "be and then some people think C or D. So who wants to defend their answer how they came to their conclusion? Okay, so shoe size in your example were correlated with how you could use regression to look at the relationship between those variables. So the outcome variable here the thing we're trying to predict as you mentioned is quantitative. So you could use regression in that case. So ": [
            2601.0,
            2630.1,
            96
        ],
        "be talking about supervised learning regression talking about age and then continuous variable is the type of variable. We are predicting. So this is something I've shown you all before this is a scatter plot between an independent variable and a dependent variable where each point is a different person in the dataset and we can see that there is time linear relationship between these two variables should be a ": [
            2032.7,
            2058.3,
            74
        ],
        "best fit line and this line can be described by a mathematical equation and the relationship between these two variables can be described by this line. And that line is a predictive model space here is that you use this data set and the relationship between the observations to then generate V model. You know, how the model so you don't need the underlying data cuz this is what you're ": [
            2058.3,
            2083.9,
            75
        ],
        "best foot points a which split Point somewhere in here get the most of the houses are in San Fran in San Fran and most other New York in New York. So we'll use the split point up here that's going to classify all of these to the right at San Francisco. So this will all be right but this is a mix of this is not all blue. So ": [
            3660.7,
            3680.8,
            132
        ],
        "big data that you were going to split it. So you can train the date on part of it and you're going to use the other part to test your model you then select what features you either in a supervised approach select the features or an unsupervised approach the computer determines the features. So now we're going to talk about model selection. A general tenant in this approach. Is ": [
            1925.1,
            1948.6,
            69
        ],
        "build a model and predict for something else in the future? Set an example of this which happens all the time in the real world for banks and credit card companies is if you want to use the data you have now to determine whether a future transaction might be fraudulent. So can we use the data science question come use the time of the charge the location of the ": [
            883.5,
            905.4,
            32
        ],
        "called root mean squared error. So you predict someone's age is 50 and their actual age is 49. Then you would subtract the difference between those two. So I would be that one year you would swear that difference you add that up across all the people in your data set and I'm going through as quickly which means I won't ask you to do this on an exam and ": [
            2892.8,
            2911.3,
            106
        ],
        "case of them a training model. So back to your question from before if you generate a better model that more specifically fit your needs. Can you get a more accurate approach? So you want to make sure that your model is as accurate as possible without overfitting. So that's the balance that you're always trying to generate there. Okay, so these are examples from their model determined that these ": [
            4099.1,
            4119.1,
            150
        ],
        "charge and price of the charge and the goal would be to determine whether or not that charge is fraudulent. So this is a predictive analysis where you would use machine learning. There are a number of definitions out there about what machine learning is. This one you can read on your own time is kind of lengthy, but from the next ruler whose I'm in Academia now is machine ": [
            926.8,
            949.6,
            34
        ],
        "charge and the price of the charge to predict whether or not it's fraudulent. So we were talking about the data were using to answer the question fees in machine learning had to be called features. We talked about variables before features and variables are synonymous button prediction and machine learning. They're often called features. So the features of this model would be time of the charge location of the ": [
            905.4,
            926.8,
            33
        ],
        "data, so there's some balance between how accurate you want your training dataset to be I'm so that you can make sure your test accuracy and a dataset not used to build. The model is higher there ways to do it over fitting that we're not going to discuss in this class for whatever you to be familiar with the topic of overfitting and if you see a hundred percent ": [
            3784.2,
            3801.1,
            138
        ],
        "despite candidates having the same. Background and credentials stool after generating it. Once they knew that's decided they weren't using male female as an input. They still had bias in the hour of them that they generated. So it is always your goal ever going to talk about this a bit more on Thursday. It's anticipated Pisces check for them after you build Remodel and use your algorithms to improve ": [
            3330.3,
            3354.7,
            121
        ],
        "determine causality, you may be trying to predict measurements for individuals last class. We talked about inference when you are not trying to do prediction. And today we're going to talk about predictive analysis, which is when you use machine learning. So in predictive analysis, you apply machine learning techniques to data you have currently to generate a model that will be able to make a prediction on future data. ": [
            838.9,
            861.9,
            30
        ],
        "determine what features to look at any images. So what pixels to look at what colors to be looking at and how to what features of the image to train the model on so often when you're using images it's going to be an unsupervised approach to allow the computer to figure out what features Also, this has been done in lots of different ways. So I have one link ": [
            2822.0,
            2844.0,
            103
        ],
        "did as well as clearly as you did, so sensitivity and specificity or two measures sensitivity says of those are we predicted correctly or safe to be positive what percent were actually positive so which ones truly worried that value and there was always that were negative what percent were predicted to be negative. So these are just breakdowns of your accuracy will talk about an example of this to ": [
            2996.3,
            3017.5,
            111
        ],
        "do supervised learning for continuous variables. The most common approach is regression. When you're doing supervised learning for categorical variables, if you're trying to determine which observations are fall into which groups are trying to determine what is difference between these blue circles and these purple plus size. This is a classification problem. If you're trying to save these observations are group a and these other ones are goofy. You're ": [
            1695.3,
            1719.8,
            61
        ],
        "doing a classification when you were in the supervised learning setting. Over here any unsupervised learning. This is what Facebook uses when you get a pictures to determine what that your face is the one in the picture. So when you're doing on supervised learning you often you give it data as the input and then the computer determines what's most similar among the input and classifies them into groups. ": [
            1719.8,
            1742.2,
            62
        ],
        "effect of watching Sesame Street on children's brains? What type of analysis would that be? Exploratory. Okay. So what would you look for if you're doing exploratory analysis there? Okay, so you're going to look through at the relationship between how much somebody watches Sesame Street and how smart know how well they did on a test and then look at the relationship between that they would start looking at ": [
            1150.9,
            1183.1,
            40
        ],
        "expect you to do. So here you would probably calculating both rmse and accuracy. You wouldn't want to know exactly how many did you guess right if you're protecting age of you said they were 73 and they were 73 that would make your accuracy increase food also want to know your root mean squared error. If you didn't get it all the way right? How close were you were ": [
            3164.1,
            3185.0,
            115
        ],
        "far we talk about data partitioning splitting into training and testing set talk about feature selection whether or not it is supervised or unsupervised. We talked about a number and number of different models that you would select based on what type of question you're asking to talk about before getting it examples is how you assess your model. The first one and this is for continuous variables is something ": [
            2865.8,
            2892.8,
            105
        ],
        "features and build our tree when you use lots of features, you can get your accuracy up to 96% And if you take it even further at the end here all of these circles are either green or blue and our model is 100% accurate. Around you you're building this in your training days that you have that held out for testing data that so then you're going to take ": [
            3724.0,
            3746.4,
            135
        ],
        "features indicated whether or not the people are very similar and if there are any that are much more different than the rest of them, you might have to look into why they're different. So that's an example of how you could use this during exploratory data analysis. So are the red burning you give the features of them put the model determine the pattern in the data and it ": [
            2284.9,
            2303.4,
            85
        ],
        "generates predictions. A simple example could take a bunch of emojis and you can answer the question. Is it Kate and you would use your model the computer would in an unsupervised way to determine patterns the input data and maybe put what category 2 would have the emojis that are Kate and category one would have all the other food emojis. This is just a general simple example of ": [
            2303.4,
            2326.7,
            86
        ],
        "get you a better idea of what this means variables. You could use root mean squared error or accuracy when you categorical variables, you would probably start by measuring accuracy and then you can get a clearer picture by looking at sensitivity and specificity. Don't even give it a dating site with a number of features and asked to predict each individual Aid what prediction approach would you use this? ": [
            3017.5,
            3039.4,
            112
        ],
        "getting tristesse validate and where they're getting trained validate test. So if you want to tell me or background later, I'm definitely interested in knowing in this court class. We are going to go with train test valid. That is what I hear more often. And the data science community. So I would love to know where the confusion happened that was mostly for my interest and to let you ": [
            1365.8,
            1384.1,
            48
        ],
        "going to dine use in the future later. When I give you somebody's height you're able to go up to the line and predict that person's age. So this is a general idea behind using regression 4 prediction of quantitative variables. So you use this model and in the future if I tell you someone's height you just go to this model and say, okay. I know their height, what ": [
            2083.9,
            2102.0,
            76
        ],
        "has been built to determine that this image is an Audi A7. Sample of a while back earlier in the last summer. They took Google images and they were able to correlate what cars were in different neighborhoods with political affiliations. And the way they did that was by generating a neural net net is you put in put in you Bill complicated model and you get out a label. ": [
            2461.5,
            2483.9,
            93
        ],
        "have an advanced degree tear is a case for classification. What is regression would be used for predicting continuous variables? We're to talk about regression first as this is the concept we've talked about already in the in French last lecture and wouldn't have these up here. They're mostly here for you to look at when you're studying but they're supposed to guys you so will honestly I just I ": [
            2011.3,
            2032.7,
            73
        ],
        "haven't yet is that when you're doing regression, you're not limited to one variable for your predictor variable and then one is your outcome. You can have multiple predictors. So in this case the simplest approach would be supervised regression, but there is a possibility of using a surprise dimensionality reduction any other thoughts on that. So wouldn't be supervised classification because our output is a quantitative variable. And for ": [
            2686.4,
            2711.9,
            99
        ],
        "here. If you want to check out more that people have gone into historical images and determine this is a neutral man. And this is an angry woman or this is a happy person. This person is surprised. This person is sad and this person is angry people working on these phones and these are unsupervised approaches where the inputs are images and the outputs are some classification. So so ": [
            2844.0,
            2865.8,
            104
        ],
        "here. Most of them are green but some New York Home snuck in and over here yet most of our blue but some San Fran houses fell in and your accuracy and your test set is 90% This is a topic we haven't talked about yet. And today's lecture is that you can train a model that is 100% accurate, but that won't perform. Well when you give it new ": [
            3763.5,
            3784.2,
            137
        ],
        "how you can build a model to determine whether or not an emoji is Kate later on if you were given the Emoji you see here to try it is it cake and if it's not it would be going to the knot k category and if it were and had features similar to what you saw in this category, it would be given the classification cake would follow follow ": [
            2326.7,
            2347.6,
            87
        ],
        "idea of what's going on in unsupervised learning. There are lots of inputs your model determines what the output should be. So when we talkin about neural Nets it's a mathematical abstraction that was inspired by what's going on in all of our brains and you were out put it either on or off based on the sum of all of the inputs. You give it to its supervised learning ": [
            2374.8,
            2396.2,
            89
        ],
        "if you were using a supervisor approach to machine learning you would use specific features related to the prediction task who wants to explain to me how they came to that conclusion. Why isn't it Dee whatever computer determines is best for prediction? Yeah. Otherwise, right so if you were doing so I classified you're doing supervised learning. So this would only be the answer if you were using an ": [
            1868.7,
            1903.0,
            67
        ],
        "in a manual labor profession. They do have children. This indicates that they have a high school-level education. So you can see that this will not always be perfect that people that this is a simplified treat but this is the tree that would generally get you the best classification. I need to send in trees are helpful for classification. 3 supervised learning we had the prediction of Ages in ": [
            2189.1,
            2215.0,
            81
        ],
        "in the majority 58% of you are new to machine learning and then B&C or what I was getting at. We have 33 boats for Abby and 26 bullets for see so this is something that still puzzles me and I don't know the answer. So if you have thoughts on this, I would definitely want to know but there's this Twitter poll that was actually result of a presentation ": [
            1321.9,
            1343.6,
            46
        ],
        "into feed not cake would be going on in the unsupervised approach. What's generally has to do with and is modeled after what happens in biology. So in all of your brains, you have neurons and interneurons take lots of input process what's going on in that input and then sends an output down the axon to the next neuron take lots of input sends a single output that's an ": [
            2347.6,
            2374.8,
            88
        ],
        "is a difference in price per square foot because we're both of them are incredibly expensive cities to live in New York 10 to have super tiny apartments that are very expensive. So if you start to look at price per square foot based on as it's related to Elevation, you can see lots of green dots appear more blue dots over here and some confusion down here says you ": [
            3594.1,
            3614.4,
            129
        ],
        "is based off of what happened in and so I said this is you know, this isn't damn explain what's happening here, but they did is imagism put an out you get what type of card is they built unknown that in this example where you take an image of a car and we break down based on what you see with in different parts of damage and the model ": [
            2440.4,
            2461.5,
            92
        ],
        "is is there a Jewish Alliance and the difference between them have to do with overfitting is generally what the question was here. The idea was if they took the model of a neuron that that existed out of box and just use that they would get this green curve with a slightly lower accuracy and they retrained it to more specifically fit their needs. So this is just in ": [
            4080.4,
            4099.1,
            149
        ],
        "is labeled a kitchen that's not a kitchen. This is labeled living room, but it's actually the hallways of the living room. This was labeled bathroom, but that's not a bad thing when you can see that just by using the label based on what humans and put into a computer is not always a good idea. So Airbnb decided to take labels from Airbnb and it's supplement them with ": [
            4000.1,
            4021.7,
            146
        ],
        "it. You can't just build predictive models on unrelated data you and said would use information about previous elections or voting district demographics or information about the voters himself. So did have to be somewhat related or you will have a model that is worthless and does not predict anything. So when you talk about feature selection, we're talking about which information from our data set are going to answer ": [
            1537.0,
            1558.7,
            55
        ],
        "just using your intuition making a bunch of class. But you want to use machine learning using these in a machine learning approach would use a decision tree. So you want to find which boundary is most appropriate for separating out these houses from one another in a tree. So it'd be highest home in New York is 73 M this little blue dot here. We need to find the ": [
            3637.4,
            3660.7,
            131
        ],
        "learning is the science of getting computers to act without being explicitly programmed. So can we give data to a computer? Tell it what we want to do and it figure out the best approach so very largely that is like we're going to be talking about today. And is a method of data analysis that automates analytical model building. So it's both getting the computer to do what we ": [
            949.6,
            971.0,
            35
        ],
        "linear regression later the future. If you gave me some same idea here, you told me somebody salary their manually refresh in their children, I could predict maybe not accurately but I can predict what their education level would be based on this decision tree. This is a basic decision tree. I'm just increasing get lots more complicated than this will come back to an example of this later in ": [
            2215.0,
            2237.4,
            82
        ],
        "listings abide by what the people are saying and that everything is what they say it is. So here are a bunch of photos and this is an example of why you can't just take the photos that exist on Airbnb and use the labels that individuals gave to the days that to train your model. So this is an example of a data set that is messy because this ": [
            3978.6,
            4000.1,
            145
        ],
        "lives rather than for punitive purposes. This is something your reading. We'll talk about religion or model update your algorithms. You are responsible for the mileage to put out into the world. That was a general reminder so far. We have talked about data partitioning feature selection supervised and unsupervised machine learning how to assess your model and the fact that bias data can and will lead to buy a ": [
            3354.7,
            3378.0,
            122
        ],
        "lower elevation houses. So you can maybe use some cut off to determine whether a house is in San Francisco or New York because you picked a cut off here something you would all be classified as New York, and this would incorrectly be classified as San Fran. But you can use more than one feature. So you don't just have to use elevation. We also might know that there ": [
            3570.4,
            3594.1,
            128
        ],
        "machine learning before what do you call the date is that use for model training one for feature selection and one for quantifying performances. Let me know how many people here are familiar with machine learning and answer the question. I have so take a second to read this over. Can I be a few more seconds? 3 2 1 so if you are new to machine learning you are ": [
            1267.8,
            1321.9,
            45
        ],
        "machine learning scientist at Airbnb wrote a blogpost about how they did this and event B idea here is twofold why you would want to categorize photos that are put up on Airbnb. Is that make the home tour easier? Not everybody upload the same photos are in the same order. So you wanted to tell me what photos I have and then put them in the same order. So ": [
            3938.8,
            3958.2,
            143
        ],
        "many and what the most frequent of late least frequent are when you're looking at the count of a categorical variable. So what type of variable on with page talking about here? Secure looking at quantitative data, so she's saying not to use a bar plot when you're trying to summarize quantitative data. If you're trying to summarize quantitative data, it's best to look at Fox Plus or histograms of ": [
            697.6,
            721.3,
            24
        ],
        "matter what you do and it's determining what features are driving is classification determine how your company would act going forward. Okay. So how did each other you were planning to use a supervisor approach to machine learning? What data would you use as the input to your model? Go to a few more seconds responses came and quickly. 3 2 1 all right to 85% of you said that ": [
            1812.1,
            1868.7,
            66
        ],
        "model possible start there if using something simple works, you don't have to go any more complex. Art supply store going to talk about model shooting models in a supervised learning space. The two general approaches here are regression and classification. I talked about this before but if you are predicting categorical variables such as one's education level, did they graduate high school? Do they have a Bachelors? Do they ": [
            1985.2,
            2011.3,
            72
        ],
        "more seconds. 3 2 1 Okay. So the two most popular answers were either be classification supervised or C classification unsupervised and I'm going to argue it could be either of those in this example. We are going to use a supervised classification techniques, but either would be appropriate here. Alright, so who wants to propose a feature that would distinguish a house in York from a house in San ": [
            3433.4,
            3463.9,
            124
        ],
        "my former boss gave and so Michael Hoffman, he is a assistant professor up in Canada and he asked the same question and you can see that there's a pretty even split between those of the assumption that said they call it training test out and train validate test. So I would love to know based on the fact that we had a pretty even split here where people are ": [
            1343.6,
            1365.8,
            47
        ],
        "now we're between b c and d which makes sense to this is a somewhat vague prompt, They're thinking behind their choice. That is a fair point of logic. So it's in his face. And when you're working with images is often an unsupervised approach because you often want the computer to figure out what features in that image to determine so that's why I would easily be unsupervised clustering. ": [
            2770.0,
            2804.4,
            101
        ],
        "of data are used for generating the model? I'll make us a quick one. Give it a few more seconds. 3 2 1 okay, so by and large we are on the same page that you use the training data to generate the model or to train the model. All right. So what type of data partitioning we're taking retired ages that were using some of it the training set ": [
            1447.5,
            1495.4,
            52
        ],
        "of the time talking about machine learning today. If you are new to machine learning and are not sure what that word means. There's going to be a lot of new words a lot of new Concepts. I'll give you all time to chat with each other and answer questions to make sure you're getting it as we're going through out any questions before I get into machine learning about ": [
            791.3,
            810.2,
            28
        ],
        "order to figure out the best tree and the answer is yes, and there are lots of different types of trees and different approaches to how to fit a single tree and whether or not we want to put multiple trees and then take the best tree among them there. Lots of these like tuning parameters what we call them to change exactly how you fit it. So yes, the ": [
            3843.2,
            3860.1,
            140
        ],
        "other features that may predict shoe size and I do with dimensionality reduction as you can take all of those and then summarize all of the features based on a few smaller. We haven't talked about this in detail a bad idea. Then would be you would actually ultimately still in that case you supervised regression after you did that when I went to make a point is cuz I ": [
            2667.2,
            2686.4,
            98
        ],
        "predictions. Any questions up to this point? I'm going to go to this first example rather quickly. And then I do here is we want to predict weather at home give it features is in San Francisco, California or New York so I can ask what type of machine learning task is predicting whether a home is in San Francisco, California or New York City. If I read a few ": [
            3378.0,
            3433.4,
            123
        ],
        "reason we don't cover in this course is because once you know Python and understand it you can spend a few hours learning the basis of face exposed equal on a weekend. So nothing's equals easy different people have different skill-set. If you are good at python learning SQL is not a very difficult with something that you can do online tutorials and get a handle on how to work ": [
            426.2,
            446.6,
            14
        ],
        "save this life example about predicting stuff but you all for Thursday. So we'll start talking about machine learning and I'm moving to algorithm. UC San Diego podcast for more visit podcast. Ucf.edu ": [
            4143.7,
            4166.9,
            152
        ],
        "school. So what can we use the data to predict their success later on the last one is how old is Sesame Street cause an increase in educational attainment. So this is that caused all type of question where you have to set up an experiment that actually gets at what the cause is everything else here just establishes a relationship. So they do here is go to asking questions ": [
            1204.9,
            1229.0,
            42
        ],
        "see all of this data for you're going to hold the test set back. So the check that or from the original data set that were held out and not using train the model and these are helpful and fine-tuning the prediction accuracy validation data, as you can tell from this looking slightly different are they decide separate to the one you started with and it is going to determine ": [
            1403.5,
            1422.7,
            50
        ],
        "set unsupervised. You let the computer determine it More specifically there are two types of General approaches to supervised learning one is for categorical variables and one is for continuous variable. We talked about regression in the inference lecture that will show up here to you can build a regression model that shows the relationship for continuous variable and you can use to provide learning to do regression when you ": [
            1666.4,
            1695.3,
            60
        ],
        "she talked a lot about the data science skills that she uses as a data scientist and she talked about the fact that she's his wife both are pythons, but the thing that she uses all the time is SQL or SQL remember a relational database lecture we talked about doing all these joints and getting the day to you want that is where you would use to equal. The ": [
            405.3,
            426.2,
            13
        ],
        "some label based on the classification you're trying to generate so there are branches in the street and then there are leaves at the end with the label you're trying to classify into so this is a decision tree and It works is that later on was the street is Bill. If you give me a new individual I can say OK KO the salaries more than 40K. They are ": [
            2168.6,
            2189.1,
            80
        ],
        "some sort. This was tweeted up again. Just this past weekend by Rafael Irizarry. He's a famous biostatistician at Harvard biostats. If you heard anything about the death count in Puerto Rican aftermath of the hurricane, he was the statistician. I'm gathering this data and working with the Puerto Rican government to make sure that there was counselor collect carpet. So he is frequently and he said that we should ": [
            721.3,
            747.3,
            25
        ],
        "start to build in multiple features. You can start to get a better idea as to what separates out. The house is in San Francisco versus the houses in New York. It was a different teacher. So here they look at elevation year built number of bathrooms bedrooms price square feet and price per square feet in idea of which features will be helpful in your model. And that is ": [
            3614.4,
            3637.4,
            130
        ],
        "take-home was from that. Every other a second to chat with each other refresh your memories about what was discussed there. What was bar bar plot? . Who remembers what this? Was there any part of what barbar Platz was? Okay. So this the point of this was to get rid of some type of data representation that was so far or not as good as another type of visualization ": [
            571.1,
            648.7,
            21
        ],
        "taught you all that. You should use Bart Arts at some point in time. So what's the difference between what she saying to ban and what I told you all is a good idea to use through remembers when you should use a bar plot Does the guy from the data visualization the first lecture? Okay, so if there's categories of you with categorical data, and you can see how ": [
            668.6,
            697.6,
            23
        ],
        "than 40K would go down this edge of the tree anybody who made more than 40K would be over here and you continue to break down the street whether or not they had a manual laborer profession might be a feature that would help separate out individuals more people would start goofing into each of these you would determine if they have children and at the end they would get ": [
            2148.7,
            2168.6,
            79
        ],
        "that Amazon set out in order to determine whose resumes they should look at more closely. They wanted the first screening just to be done by a machine learning approach. They generated this AI recruiting tool but due to the fact that Amazon has hired more males historically, they're recruiting tool despite the fact that it didn't take mail in as a feature said that it should hire more males ": [
            3310.0,
            3330.3,
            120
        ],
        "that Dynamite class must die. So these bar pops when you're looking at quantitative data are often called Dynamite plus cuz they kind of look like in the cartoons when I don't know what character does that the Roadrunner that like sets off a dynamite Moon Tunes cartoons. So this is called Dynamite pop and the argument here. Is that hides the data that really you should use. Points and ": [
            747.3,
            770.4,
            26
        ],
        "that answer using data science each other about all three of these questions and I will then ask y'all what she did and what the answers were. All right who remembers how page answer the question how much is a reoccurring donor Worth or what? The answer was to that question? So it never saw that there was more than a one-time donor and the thought was maybe something on ": [
            125.1,
            221.2,
            4
        ],
        "that in an exploratory analysis. And then in the next 1 what is the relationship between early childhood education programming and success in elementary school that is a more specific type of inferential question. So B&C or both some sort of exploratory and inferential question here were predicting we're going to use data we have now information about one's early childhood and we're going to predict their success in elementary ": [
            1183.1,
            1204.9,
            41
        ],
        "that information and tell it what differentiates between the groups in your data set. Alternatively, if you don't tell the computer that these are different than these it's up to the computer determined based on the data in the dataset what features of the days that separate out the groups of two variables and you pop then variable x 1 and variable x 2 and you plot then you can ": [
            1620.5,
            1645.8,
            58
        ],
        "that question what type of analysis she used this isn't super important. Okay, so she used her Bible analysis. It was that curve that you showed going down over time and it showed that overtime people drop out from being recurring donors and you can get some idea of what these typical trend is what the typical donor on Gibbs. So this was something that she could and communicate to ": [
            244.1,
            265.9,
            6
        ],
        "that the best data or big data set that are clean data set. So whenever you have the information you want and you have it across all of your observations and the best models are simple model. So the best approach when you are trying to do machine learning is not necessarily to go out and find the fanciest new model start simple start with things. I have worked in ": [
            1948.6,
            1966.8,
            70
        ],
        "that you're communicating effectively. I want to come with the package has to talk to Marketing sales and account managers are not necessarily data scientist or analytical people to get the data and to talk with them about how and what features they would need in order to predict which donors are most likely to stay recurrent or switch to become recurring which is something that marketing and sales cares ": [
            525.3,
            547.3,
            19
        ],
        "the announcements or Pages guest lecture. Okay. So my goal today is for you all to be able to identify a question that can be answered using machine learning and to specify the appropriate General machine learning approach given a dataset and a question. I returned it to what we've been doing so far. We talked about descriptive and exploratory analysis. We said that if you are not trying to ": [
            810.2,
            838.9,
            29
        ],
        "the lecture. When you're trying to pick models there if your on unsupervised learning approach remember, you're not telling the computer that these are different than these you're allowing the computer to determine that. And hear all the features. So your data are given as inputs and you don't provide any labels. There are lots of different ways and we're not going to talk about the details between the different ": [
            2237.4,
            2262.0,
            83
        ],
        "the nonprofits that her company classy works with to determine how they should approach and the fact that it is worth it to approach trying to get more donors who remembers the way that the second question was answered or what the answer was to how can we get more people to become recurring donors? Okay, so there is some incentive and I never don't remember exactly what that was ": [
            265.9,
            294.1,
            7
        ],
        "the order of fifty bucks. Anybody else have a different Recollections, okay. 430 but the answer's still told that it was more than a one-time donor. That is absolutely correct. So together we got to about right and it was somewhere in the 400 and then a one-time Joyner was worth $25. So you got a lot more from the typical recurring donor. And does anybody remember how she answered ": [
            221.2,
            244.1,
            5
        ],
        "the past. See if your predictions are correct based on the simple model and only go more complex. If you need to do you want the biggest assets that are the cleanest for you if they did it that they're no good if they have lots of missing information or information teachers that are not helpful for the biggest state. Is that possible 4 prediction and you want the simplest ": [
            1966.8,
            1985.2,
            71
        ],
        "the predictive question. We're answering Show picture selection determines which variables are most productive and you include those in the model. I want to point out here. We've talked before about the fact that just because there's a relationship between variables doesn't mean that one causes the other so we're talking about feature selection predictive modeling. We're exploiting the relationships, but it doesn't mean that the variables are the features ": [
            1558.7,
            1591.1,
            56
        ],
        "the same reason it wouldn't be a clustering over here. All right, you want to predict someone's emotion based on an image? How would you approach this with machine learning? child each other convince each other Eric winding down like a very few more seconds. 3 2 1 All right. We have some dissension among the ranks on this one. So regression was generally ruled out by the class, but ": [
            2711.9,
            2770.0,
            100
        ],
        "the two most popular answers again or the classification ones and here I'd imagine that maybe more people put see because we're using photos and I said that when we use photos of optavia unsupervised, which is in fact the way Airbnb opted to use it. So we're going to talk about clustering in an unsupervised manner but B is also an option here. Stop someone from it was a ": [
            3916.3,
            3938.8,
            142
        ],
        "their approaches and what they see here is that they classify bedroom with an accuracy of 95% and an accuracy for living room of 92% We haven't talked about these curves too much but what they're showing here is that they can do a really good job at first pass of correctly classifying images to the room that they're from from the beginning. Question. Yeah. Okay. So the question here ": [
            4044.5,
            4080.4,
            148
        ],
        "then you divided by the total number of people in your data set and then you square that so because this is root mean square error, generally if your predictions are good, you will have a smaller error than if your predictions were bad if they were bad. These numbers would be far apart from each other and this number would be bigger. So General reminders when you are predicting ": [
            2911.3,
            2930.9,
            107
        ],
        "things out cuz that's what this Sunday's people try to use it to explain in a clear way what's going on in neural Nets and it doesn't do a good job aside from telling you things come in inputs and you get outputs and stuff in the middle is complicated. So they know that math is happening here, but inputs come in I'll put go out the ideas at this ": [
            2420.0,
            2440.4,
            91
        ],
        "this idea based on actual biology that you get signals and you then determine outputs from your neurons. Desktop won't be the last time you see something like this. This is a machine-learning talks all the time. And it is mostly unhelpful the way you should all take from this when you see it is that there are lots of input things happen in the model and then you get ": [
            2396.2,
            2420.0,
            90
        ],
        "to be the variables in your data set. So what day did you have and which of them are you going to use in your model? I'm the one point I want to make is that the you can't just predict anything from data that are unrelated. So if you want to determine the outcome of us elections, you wouldn't use data about elephant height has nothing to do with ": [
            1516.6,
            1537.0,
            54
        ],
        "to build a model for going is attesting set to determine how accurate are model is within the same day to set and a validation set is a separate data set to determine if your model is generalizable. So we have an idea of what data partitioning is. Now, we're going to talk about what feature selection is. Remember. I mentioned that we were talking about machine learning feature tend ": [
            1495.4,
            1516.6,
            53
        ],
        "to determine how you got more people to become recurring donors. Yesterday change the format of the page and if you remember they had those radio buttons on a one version the monthly button was quite small and on another button the monthly button was much bigger and at the top and I think in a different color, they remember what that experiment process was called. Okay, so that was ": [
            313.3,
            346.3,
            9
        ],
        "training these days on historical data to any biases that exist in your data are going to be perpetuated in the predictions you generate. A new representative of Arc recently tweeted out something to the effect of the fact that albertans which were driven by Max are racist and lots of people in the machine learning World jumped in and a lot of people said, well math can't be racist. ": [
            3263.8,
            3288.9,
            118
        ],
        "tree and you do this for each of the features. You're going to include And you continue to build your tree. So if your first one is elevation you then might split by price per square foot and each time. We can see the accuracy that most of these are blue and most of these are green and our accuracy at this point is 86% as we continue to use ": [
            3701.2,
            3724.0,
            134
        ],
        "unsupervised approach. I'm when you're doing supervised approach you're going to use specific features and they have to be related to the prediction test. This is the example of elephant height not predicting election results. I'm you have to use a day and you're not going to in a supervisor approach. Just give the computer all the data. Okay. So this one we talked about data partitioning you have this ": [
            1903.0,
            1925.1,
            68
        ],
        "use something called a decision tree. So the decision treat you start with your training gate at the top and then you make a bunch of decisions based on the features in your data set. So we're trying to predict someone's education level. You might be able to start bending them into categories by separating out individuals who have a salary less than 40K and anybody was a salary less ": [
            2128.5,
            2148.7,
            78
        ],
        "using data. We have to build a model 2 answer predict something in the future. There are four basic steps. And this is what we're going to walk through in the first part of the lecture and then we're going to go through three examples wouldn't talk about data partitioning what feature selection is what model selection is and then how you assess the models you Jenner? So we're talking ": [
            1229.0,
            1247.9,
            43
        ],
        "visually see that these four or more similar to one another and that these four more similar to one another and that these two groups are different from one another if you're allowing the computer to determine how to classify the data based on the properties within the data set that is unsupervised learning the supervisor. You tell the computer with the labels are for the observations in your data ": [
            1645.8,
            1666.4,
            59
        ],
        "want and teaching it how to build those models. We're Gonna Leave This is the highest overview of how to think about model predictive analyses you start with data you train a model and then you use that model to make predictions about something. So we're going to be using this General framework throughout today's lecture. You start with data you train a model and then you predict something. And ": [
            971.0,
            1001.8,
            36
        ],
        "want you to know that that falls in the unsupervised learning category. Any questions up to this point? So I want you to protect someone's shoe size. I want you to propose how you would approach this using machine learning. If a child each other convince each other of your guess. Give everybody a few more seconds. 3 2 1 activate 65% of class saying a a few people saying ": [
            2513.7,
            2601.0,
            95
        ],
        "was talking about there? So this is what you talked about the least because she's still in the middle of doing this. So I'm going to talk about this a little in today's lecture. But this is where you would use machine-learning to answer this question. So she gave us a nice primer for the top like we're going to be talking about today. I just wanted to recapture that ": [
            385.2,
            405.3,
            12
        ],
        "ways than these types of models identify patterns in the Android data and generate predictions is output. They mentioned this is how facial recognition works and it's processing and is used often exploratory data analysis to determine if samples are different from other samples. So if you had a big data set and you expected everybody to be very similar you could use what's notice TCA determined based on the ": [
            2262.0,
            2284.9,
            84
        ],
        "we're not we're only getting 63% Correct. If you move it all the way down to zero and classify everything all of the houses and up over here. So you're looking for some split point that balances the error on each side. So you get some glue over here and some green over here. They building a decision tree is finding the best split point at each part of your ": [
            3680.8,
            3701.2,
            133
        ],
        "were using cause the election outcome. They just have some relationship that we're going to exploit. Okay, so we're talking about feature selection. Now the time we have to differentiate between supervised learning and unsupervised learning. So in supervised learning we tell the computer how to classify the observations. We tell the computer that these four observations are blue circles and that these four are ready. You give the computer ": [
            1591.1,
            1620.5,
            57
        ],
        "what a data scientist does the types of questions she answers and the types of skills. She has and the types of Technology. She uses so my tax for you all to get your brain working to start thinking about this is too in a minute talk to each other about the three questions that page asked and let me know what the answer was and how she came to ": [
            101.7,
            125.1,
            3
        ],
        "when people go to Airbnb they can see the same format no matter which place they're looking at it also allows for efficient listing dilation without having a machine learning approach to this an individual would have to go and say this person said they have a three-bedroom apartment do they actually have a three-bedroom apartment face on the photos they submitted so it allows that to ensure that the ": [
            3958.2,
            3978.6,
            144
        ],
        "whether or not your predictive model Works in a completely different data that was collected separately from the day that you started with. All right, sweet training data if testing data these both come from the original data set and then validation date at which is a separate dataset to determine if your model is generalizable. All right, so to check understanding of what we just talked about what portion ": [
            1422.7,
            1447.5,
            51
        ],
        "which she look at survival analysis. So she determine which features she wanted to look at or she could just put all the data in and then determine is there one group that will never become a recurring donor one that has the potential to become recurring donors. And that's where marketing should focus its efforts. And then one that already are and are going to stay recurring donors and ": [
            1791.4,
            1812.1,
            65
        ],
        "who was 49 at 62 years old so doesn't count taking back how close you are to the actual value. It just says where you right a wrong divided by the total number of samples. So we mentioned just now that accuracy will tell you what percentage of predicted correctly when you're talkin about categorical variables. You can determine a little more specifically how well you did and why you ": [
            2970.8,
            2996.3,
            110
        ],
        "with relational databases. She talked about the fact that she uses a number of analytical skills. You need to know how to set up an experimental design when you design that a b testing and put the radio buttons in different places. You have to make sure you set up an experiment that can answer the question you want to answer key statistics throughout so she talked about survival analysis ": [
            446.6,
            464.9,
            15
        ],
        "would their age most likely be? Retrogression and supervised learning you knew the features. We told them out of the features. We generated model, which was a mathematical equation that describes the underlying data and then we were able to use that model to make a prediction about a continuous variable. On the other hand classification is what we use for predicting categorical variables and to do this we often ": [
            2102.0,
            2128.5,
            77
        ],
        "would use if they wanted to build this model what my distinguish the house is in these two markets. every isosceles cast our brains are getting tired. I know. Think about what you discussed hopefully at some ideas and we'll see what was used to do this. Sadie is you can use your intuition sometimes determine what dating app should use for classification tasks. So if you're familiar with San ": [
            3520.8,
            3552.0,
            126
        ],
        "would use regression and on an exam. I would specify that reduce supervised and not make you guess we're not doing classification because age is a continuous variable. All right. So given that we're doing regression. How would you assess your model? Feel free to chat with each other if you're stuck. Give everybody a few more seconds. 3 2 1 I love it when you guys do what I ": [
            3101.5,
            3164.1,
            114
        ],
        "you are using Pharmacy the smallest value for error if you want good predictions, you want your error to be small and if you said any of these that made him because my question wasn't as clear as it could have been. Okay, so you want low or a messy when you're predicting H as a general reminder since we haven't talked about ethics of time in a while you're ": [
            3242.2,
            3263.8,
            117
        ],
        "you be able to communicate urinalysis and show that it was truly effective before anybody goes to make a change the Natural State at a company is to continue to do things the way they've been done. It's much harder to get people to change the way they're doing something cuz it takes effort. So make sure that if you have an analysis that explains why I should change it ": [
            506.5,
            525.3,
            18
        ],
        "you closer to the actual value then some random value? That's much smaller. Okay, so you wouldn't use sensitivity specificity or are you see, which I haven't even talked about area under the curve. These are all for categorical prediction. Hey and then whatever value would you want from your model? Assuming we're doing rmse. 3 2 1 Well, I'm bored or most of us are onboard you want when ": [
            3185.0,
            3242.2,
            116
        ],
        "you want smaller error. The one thing is that a few outliers can lead to a big increase in a root mean square error, even while the other projectors are pretty good. So if you get a huge root mean squared error at the end of your prediction is sometimes good to go in and say are you samples not being predicted accurately or is it just not predicting well ": [
            2930.9,
            2948.8,
            108
        ],
        "your answer was assuming a supervisor Goshen, okay? To figure out what does he could you set height but like you can generate it's not just by the phone. Okay. So the argument up front is that you could use unsupervised dimensionality reduction. The idea here is you can use lots and lots of different features so maybe incorporate so the first one was height, but then incorporate gender or ": [
            2630.1,
            2667.2,
            97
        ]
    },
    "File Name": "Introduction to Data Science - A00 - Ellis, Shannon Elizabeth - Winter 2019-lecture_15.flac",
    "Full Transcript": "Listen to a podcast.  All right.  Hello everyone. We're going to get started as people settle down.  So as per usual starting.  With the fact that you have a reading quiz, your final reading quiz is due this Friday and your fourth assignment which includes your proposal for how you how you would analyze your project is due next Friday. This is General notes here at the bottom your third assignment. Nope, second assignment grade. So that's a typo or end credit are on try and Ed and Disturbed workbook. If you want more practice in Python that is being used in section is available on TriNet and the first exam is also now viewable on TriNet.  EXO today we're going to be talking about machine learning to get to that because they're going to be lots of new Concepts and vocabulary a new ideas and there's going to be a lot of time for y'all to discuss and ask questions to each other as questions to me think through things. So we are going to Jump Right In by first reviewing the guest lecture from last week. I think Paige p a p giannini is a guest lecturer was really really helpful. If she gave you an idea of what a data scientist does the types of questions she answers and the types of skills. She has and the types of Technology. She uses so my tax for you all to get your brain working to start thinking about this is too in a minute talk to each other about the three questions that page asked and let me know what the answer was and how she came to that answer using data science each other about all three of these questions and I will then ask y'all what she did and what the answers were.  All right who remembers how page answer the question how much is a reoccurring donor Worth or what? The answer was to that question?  So it never saw that there was more than a one-time donor and the thought was maybe something on the order of fifty bucks. Anybody else have a different Recollections, okay.  430 but the answer's still told that it was more than a one-time donor. That is absolutely correct. So together we got to about right and it was somewhere in the 400 and then a one-time Joyner was worth $25. So you got a lot more from the typical recurring donor. And does anybody remember how she answered that question what type of analysis she used this isn't super important.  Okay, so she used her Bible analysis. It was that curve that you showed going down over time and it showed that overtime people drop out from being recurring donors and you can get some idea of what these typical trend is what the typical donor on Gibbs. So this was something that she could and communicate to the nonprofits that her company classy works with to determine how they should approach and the fact that it is worth it to approach trying to get more donors who remembers the way that the second question was answered or what the answer was to how can we get more people to become recurring donors?  Okay, so there is some incentive and I never don't remember exactly what that was a big hit so that is the answer to how one of their companies. People to be more recurring donor. So they offered the incentive of a blanket. I think people should use and that one company by offering a blanket got a lot more people to sign up to being returned on her. So that's absolutely true. But they did something at Classy at the company where she works to determine how you got more people to become recurring donors.  Yesterday change the format of the page and if you remember they had those radio buttons on a one version the monthly button was quite small and on another button the monthly button was much bigger and at the top and I think in a different color, they remember what that experiment process was called.  Okay, so that was an example of a b testing they had example a where they had the small buttons and an example where they moved into the top and they said an example of a or is it an example of which one increases our has more people become returning donors and they found that when the button was bigger and higher they got more people to sign up being as recurring donors. I'm so that was something that she could take back to her bosses and say hey we should tell this to all of our nonprofit station use format be with a much bigger but rather than a paste on this experiment what rear end FaceTime is a b testing question. Can we predict which donors are most likely to stay current or switch to become recurring today? Remember what I was talking about there?  So this is what you talked about the least because she's still in the middle of doing this. So I'm going to talk about this a little in today's lecture. But this is where you would use machine-learning to answer this question. So she gave us a nice primer for the top like we're going to be talking about today. I just wanted to recapture that she talked a lot about the data science skills that she uses as a data scientist and she talked about the fact that she's his wife both are pythons, but the thing that she uses all the time is SQL or SQL remember a relational database lecture we talked about doing all these joints and getting the day to you want that is where you would use to equal. The reason we don't cover in this course is because once you know Python and understand it you can spend a few hours learning the basis of face exposed equal on a weekend. So nothing's equals easy different people have different skill-set. If you are good at python learning SQL is not a very difficult with something that you can do online tutorials and get a handle on how to work with relational databases.  She talked about the fact that she uses a number of analytical skills. You need to know how to set up an experimental design when you design that a b testing and put the radio buttons in different places. You have to make sure you set up an experiment that can answer the question you want to answer key statistics throughout so she talked about survival analysis as one and machine learning for predictive analysis as another analytical skill Joseph highlight the fact that she has to communicate as a data scientist with lots of different groups right though in the how much is a donor worth. They wrote a blogpost so that all of the nonprofit they work with so a general audience who doesn't necessarily have data science skills are are necessarily people that think about that all the time could understand the point of trying and the importance of recurrent donors.  Just have to communicate with stakeholders throughout the company after they did that a b tests and determined that with the one for Matt was much more effective at getting recurring donors. She shared that with the high rocks at her company and have to get them to buy into her idea. If you be able to communicate urinalysis and show that it was truly effective before anybody goes to make a change the Natural State at a company is to continue to do things the way they've been done. It's much harder to get people to change the way they're doing something cuz it takes effort. So make sure that if you have an analysis that explains why I should change it that you're communicating effectively. I want to come with the package has to talk to Marketing sales and account managers are not necessarily data scientist or analytical people to get the data and to talk with them about how and what features they would need in order to predict which donors are most likely to stay recurrent or switch to become recurring which is something that marketing and sales cares about a lot.  Okay, any questions on the three questions that you talked about with regards to recurring donors the one big topic? She spent a lot of time on.  Okay, who remembers what the take-home message was of her Kickstarter and they're like fun examples that she said she included on her resume when applying for jobs and she use this hashtag or bar plus maybe remember what the take-home was from that.  Every other a second to chat with each other refresh your memories about what was discussed there.  What was bar bar plot?  .  Who remembers what this? Was there any part of what barbar Platz was?  Okay. So this the point of this was to get rid of some type of data representation that was so far or not as good as another type of visualization and so it bar meaning like get rid of so get rid of body parts was the take home from her Kickstarter that they started which sword is a fun idea. But as she told you and she's told me that this was acting on all of her job interviews cuz it was something that was different from everybody else had done. So Friday was Barbara Potts, but I have taught you all that. You should use Bart Arts at some point in time. So what's the difference between what she saying to ban and what I told you all is a good idea to use through remembers when you should use a bar plot  Does the guy from the data visualization the first lecture?  Okay, so if there's categories of you with categorical data, and you can see how many and what the most frequent of late least frequent are when you're looking at the count of a categorical variable. So what type of variable on with page talking about here?  Secure looking at quantitative data, so she's saying not to use a bar plot when you're trying to summarize quantitative data. If you're trying to summarize quantitative data, it's best to look at Fox Plus or histograms of some sort. This was tweeted up again. Just this past weekend by Rafael Irizarry. He's a famous biostatistician at Harvard biostats. If you heard anything about the death count in Puerto Rican aftermath of the hurricane, he was the statistician. I'm gathering this data and working with the Puerto Rican government to make sure that there was counselor collect carpet. So he is frequently and he said that we should that Dynamite class must die. So these bar pops when you're looking at quantitative data are often called Dynamite plus cuz they kind of look like in the cartoons when I don't know what character does that the Roadrunner that like sets off a dynamite Moon Tunes cartoons. So this is called Dynamite pop and the argument here. Is that hides the data that really you should use.  Points and a box plot to display these data. So that was the idea there if you were using a barfly for quantitative data, you probably should not if you are using a bar plot for categorical data that is okay set the difference between what page said don't use it for quantitative data. And then what I said you use it for categorical  okay with that where to send the rest of the time talking about machine learning today. If you are new to machine learning and are not sure what that word means. There's going to be a lot of new words a lot of new Concepts. I'll give you all time to chat with each other and answer questions to make sure you're getting it as we're going through out any questions before I get into machine learning about the announcements or Pages guest lecture.  Okay. So my goal today is for you all to be able to identify a question that can be answered using machine learning and to specify the appropriate General machine learning approach given a dataset and a question.  I returned it to what we've been doing so far. We talked about descriptive and exploratory analysis. We said that if you are not trying to determine causality, you may be trying to predict measurements for individuals last class. We talked about inference when you are not trying to do prediction. And today we're going to talk about predictive analysis, which is when you use machine learning.  So in predictive analysis, you apply machine learning techniques to data you have currently to generate a model that will be able to make a prediction on future data. So you're using data you currently have in hand or historical data data from the past two, then build a model and remember model is a mathematical equation that best explains the date of that you're using and you're going to use that model to make predictions in the future. Then we're talking about predictive analyses were talking about machine learning techniques to work with a do you have now build a model and predict for something else in the future?  Set an example of this which happens all the time in the real world for banks and credit card companies is if you want to use the data you have now to determine whether a future transaction might be fraudulent. So can we use the data science question come use the time of the charge the location of the charge and the price of the charge to predict whether or not it's fraudulent. So we were talking about the data were using to answer the question fees in machine learning had to be called features. We talked about variables before features and variables are synonymous button prediction and machine learning. They're often called features. So the features of this model would be time of the charge location of the charge and price of the charge and the goal would be to determine whether or not that charge is fraudulent. So this is a predictive analysis where you would use machine learning.  There are a number of definitions out there about what machine learning is. This one you can read on your own time is kind of lengthy, but from the next ruler whose I'm in Academia now is machine learning is the science of getting computers to act without being explicitly programmed. So can we give data to a computer? Tell it what we want to do and it figure out the best approach so very largely that is like we're going to be talking about today.  And is a method of data analysis that automates analytical model building.  So it's both getting the computer to do what we want and teaching it how to build those models.  We're Gonna Leave This is the highest overview of how to think about model predictive analyses you start with data you train a model and then you use that model to make predictions about something. So we're going to be using this General framework throughout today's lecture. You start with data you train a model and then you predict something.  And I've said a few times when she learning approaches are what we used to do this type of analysis.  I'm going to have you over you through these on your own child each other. And which of these questions is most appropriate for machine learning.  Give everybody a few more seconds.  3  2  okay. So 67% of you said that it is D. Can we use information about one's Early Childhood to predict their success in elementary school, but we had some answering to the other ones. They tell me how they came to answer D the correct answer or how they ruled out the other ones.  What type of analysis is question a how common is watching Sesame Street in the US?  I just so far. We talk about descriptive analysis exploratory data analysis inference and machine learning today.  Audrey Assad is what type of question how common is watching Sesame Street in the US?  Inferential wouldn't be inferential because an inference you're going to be drawing relationships between two things. So I'm going to say this one would just be a descriptive analysis. You're really just calculating one number and not relating it to anything else. But I think that was a a good guess. What is the effect of watching Sesame Street on children's brains?  What type of analysis would that be?  Exploratory. Okay. So what would you look for if you're doing exploratory analysis there?  Okay, so you're going to look through at the relationship between how much somebody watches Sesame Street and how smart know how well they did on a test and then look at the relationship between that they would start looking at that in an exploratory analysis. And then in the next 1 what is the relationship between early childhood education programming and success in elementary school that is a more specific type of inferential question. So B&C or both some sort of exploratory and inferential question here were predicting we're going to use data we have now information about one's early childhood and we're going to predict their success in elementary school. So what can we use the data to predict their success later on the last one is how old is Sesame Street cause an increase in educational attainment. So this is that caused all type of question where you have to set up an experiment that actually gets at what the cause is everything else here just establishes a relationship.  So they do here is go to asking questions using data. We have to build a model 2 answer predict something in the future. There are four basic steps. And this is what we're going to walk through in the first part of the lecture and then we're going to go through three examples wouldn't talk about data partitioning what feature selection is what model selection is and then how you assess the models you Jenner?  So we're talking about data partitioning. We're talking about the dataset you have splitting it so that you use some of the data to train your model and then some of it to do test out once you built the model to see if it works on data that the model was not trained on.  This is a general question just that I have and it is if you've ever learned or done machine learning before what do you call the date is that use for model training one for feature selection and one for quantifying performances. Let me know how many people here are familiar with machine learning and answer the question. I have so take a second to read this over.  Can I be a few more seconds?  3 2  1  so if you are new to machine learning you are in the majority 58% of you are new to machine learning and then B&C or what I was getting at. We have 33 boats for Abby and 26 bullets for see so this is something that still puzzles me and I don't know the answer. So if you have thoughts on this, I would definitely want to know but there's this Twitter poll that was actually result of a presentation my former boss gave and so Michael Hoffman, he is a assistant professor up in Canada and he asked the same question and you can see that there's a pretty even split between those of the assumption that said they call it training test out and train validate test. So I would love to know based on the fact that we had a pretty even split here where people are getting tristesse validate and where they're getting trained validate test. So if you want to tell me or background later, I'm definitely interested in knowing in this court class. We are going to go with train test valid. That is what I hear more often.  And the data science community. So I would love to know where the confusion happened that was mostly for my interest and to let you all know if you are unfamiliar with machine learning You are not alone. So we have when we're talking about data partitioning as I mentioned as you have this data set that you're going to use to build your predictive model. It has observations. It has features you are then going to take some 4% of it and use this to build your model. So you're going to the model see all of this data for you're going to hold the test set back. So the check that or from the original data set that were held out and not using train the model and these are helpful and fine-tuning the prediction accuracy validation data, as you can tell from this looking slightly different are they decide separate to the one you started with and it is going to determine whether or not your predictive model Works in a completely different data that was collected separately from the day that you started with.  All right, sweet training data if testing data these both come from the original data set and then validation date at which is a separate dataset to determine if your model is generalizable.  All right, so to check understanding of what we just talked about what portion of data are used for generating the model?  I'll make us a quick one.  Give it a few more seconds.  3 2 1  okay, so by and large we are on the same page that you use the training data to generate the model or to train the model.  All right. So what type of data partitioning we're taking retired ages that were using some of it the training set to build a model for going is attesting set to determine how accurate are model is within the same day to set and a validation set is a separate data set to determine if your model is generalizable.  So we have an idea of what data partitioning is. Now, we're going to talk about what feature selection is. Remember. I mentioned that we were talking about machine learning feature tend to be the variables in your data set. So what day did you have and which of them are you going to use in your model?  I'm the one point I want to make is that the you can't just predict anything from data that are unrelated. So if you want to determine the outcome of us elections, you wouldn't use data about elephant height has nothing to do with it. You can't just build predictive models on unrelated data you and said would use information about previous elections or voting district demographics or information about the voters himself. So did have to be somewhat related or you will have a model that is worthless and does not predict anything. So when you talk about feature selection, we're talking about which information from our data set are going to answer the predictive question. We're answering  Show picture selection determines which variables are most productive and you include those in the model.  I want to point out here. We've talked before about the fact that just because there's a relationship between variables doesn't mean that one causes the other so we're talking about feature selection predictive modeling. We're exploiting the relationships, but it doesn't mean that the variables are the features were using cause the election outcome. They just have some relationship that we're going to exploit.  Okay, so we're talking about feature selection. Now the time we have to differentiate between supervised learning and unsupervised learning.  So in supervised learning we tell the computer how to classify the observations. We tell the computer that these four observations are blue circles and that these four are ready. You give the computer that information and tell it what differentiates between the groups in your data set.  Alternatively, if you don't tell the computer that these are different than these it's up to the computer determined based on the data in the dataset what features of the days that separate out the groups of two variables and you pop then variable x 1 and variable x 2 and you plot then you can visually see that these four or more similar to one another and that these four more similar to one another and that these two groups are different from one another if you're allowing the computer to determine how to classify the data based on the properties within the data set that is unsupervised learning the supervisor. You tell the computer with the labels are for the observations in your data set unsupervised. You let the computer determine it  More specifically there are two types of General approaches to supervised learning one is for categorical variables and one is for continuous variable. We talked about regression in the inference lecture that will show up here to you can build a regression model that shows the relationship for continuous variable and you can use to provide learning to do regression when you do supervised learning for continuous variables. The most common approach is regression.  When you're doing supervised learning for categorical variables, if you're trying to determine which observations are fall into which groups are trying to determine what is difference between these blue circles and these purple plus size. This is a classification problem. If you're trying to save these observations are group a and these other ones are goofy. You're doing a classification when you were in the supervised learning setting.  Over here any unsupervised learning. This is what Facebook uses when you get a pictures to determine what that your face is the one in the picture. So when you're doing on supervised learning you often you give it data as the input and then the computer determines what's most similar among the input and classifies them into groups. So this example these three up here or all ducks. So your classifier the computer was determined they all have similar feet or similar pills. They have similar ears. Where is this bunny and this mouse have different features different feet different ears different noses, and it would classify these into three groups based on the features within the input data.  Hear when you do an unsupervised learning you're doing a clustering or dimensionality reduction, generally.  And it uses the what we call structure within the data for the features that are within the data set to automatically identify the groups.  So I told you I would mention Pages third question when she was looking at how to determine whether or not somebody would become a recurring donor. She said that she could do it in a supervised way in which she look at survival analysis. So she determine which features she wanted to look at or she could just put all the data in and then determine is there one group that will never become a recurring donor one that has the potential to become recurring donors. And that's where marketing should focus its efforts. And then one that already are and are going to stay recurring donors and matter what you do and it's determining what features are driving is classification determine how your company would act going forward.  Okay. So how did each other you were planning to use a supervisor approach to machine learning? What data would you use as the input to your model?  Go to a few more seconds responses came and quickly.  3 2 1  all right to 85% of you said that if you were using a supervisor approach to machine learning you would use specific features related to the prediction task who wants to explain to me how they came to that conclusion.  Why isn't it Dee whatever computer determines is best for prediction?  Yeah.  Otherwise, right so if you were doing so I classified you're doing supervised learning. So this would only be the answer if you were using an unsupervised approach. I'm when you're doing supervised approach you're going to use specific features and they have to be related to the prediction test. This is the example of elephant height not predicting election results. I'm you have to use a day and you're not going to in a supervisor approach. Just give the computer all the data.  Okay. So this one we talked about data partitioning you have this big data that you were going to split it. So you can train the date on part of it and you're going to use the other part to test your model you then select what features you either in a supervised approach select the features or an unsupervised approach the computer determines the features. So now we're going to talk about model selection.  A general tenant in this approach. Is that the best data or big data set that are clean data set. So whenever you have the information you want and you have it across all of your observations and the best models are simple model. So the best approach when you are trying to do machine learning is not necessarily to go out and find the fanciest new model start simple start with things. I have worked in the past. See if your predictions are correct based on the simple model and only go more complex. If you need to do you want the biggest assets that are the cleanest for you if they did it that they're no good if they have lots of missing information or information teachers that are not helpful for the biggest state. Is that possible 4 prediction and you want the simplest model possible start there if using something simple works, you don't have to go any more complex.  Art supply store going to talk about model shooting models in a supervised learning space.  The two general approaches here are regression and classification. I talked about this before but if you are predicting categorical variables such as one's education level, did they graduate high school? Do they have a Bachelors? Do they have an advanced degree tear is a case for classification. What is regression would be used for predicting continuous variables?  We're to talk about regression first as this is the concept we've talked about already in the in French last lecture and wouldn't have these up here. They're mostly here for you to look at when you're studying but they're supposed to guys you so will honestly I just I be talking about supervised learning regression talking about age and then continuous variable is the type of variable. We are predicting.  So this is something I've shown you all before this is a scatter plot between an independent variable and a dependent variable where each point is a different person in the dataset and we can see that there is time linear relationship between these two variables should be a best fit line and this line can be described by a mathematical equation and the relationship between these two variables can be described by this line. And that line is a predictive model space here is that you use this data set and the relationship between the observations to then generate V model. You know, how the model so you don't need the underlying data cuz this is what you're going to dine use in the future later. When I give you somebody's height you're able to go up to the line and predict that person's age. So this is a general idea behind using regression 4 prediction of quantitative variables. So you use this model and in the future if I tell you someone's height you just go to this model and say, okay.  I know their height, what would their age most likely be?  Retrogression and supervised learning you knew the features. We told them out of the features. We generated model, which was a mathematical equation that describes the underlying data and then we were able to use that model to make a prediction about a continuous variable.  On the other hand classification is what we use for predicting categorical variables and to do this we often use something called a decision tree. So the decision treat you start with your training gate at the top and then you make a bunch of decisions based on the features in your data set. So we're trying to predict someone's education level. You might be able to start bending them into categories by separating out individuals who have a salary less than 40K and anybody was a salary less than 40K would go down this edge of the tree anybody who made more than 40K would be over here and you continue to break down the street whether or not they had a manual laborer profession might be a feature that would help separate out individuals more people would start goofing into each of these you would determine if they have children and at the end they would get some label based on the classification you're trying to generate so there are branches in the street and then there are leaves at the end with the label you're trying to classify into so this is a decision tree and  It works is that later on was the street is Bill. If you give me a new individual I can say OK KO the salaries more than 40K. They are in a manual labor profession. They do have children. This indicates that they have a high school-level education. So you can see that this will not always be perfect that people that this is a simplified treat but this is the tree that would generally get you the best classification.  I need to send in trees are helpful for classification.  3 supervised learning we had the prediction of Ages in linear regression later the future. If you gave me some same idea here, you told me somebody salary their manually refresh in their children, I could predict maybe not accurately but I can predict what their education level would be based on this decision tree. This is a basic decision tree. I'm just increasing get lots more complicated than this will come back to an example of this later in the lecture.  When you're trying to pick models there if your on unsupervised learning approach remember, you're not telling the computer that these are different than these you're allowing the computer to determine that.  And hear all the features. So your data are given as inputs and you don't provide any labels. There are lots of different ways and we're not going to talk about the details between the different ways than these types of models identify patterns in the Android data and generate predictions is output. They mentioned this is how facial recognition works and it's processing and is used often exploratory data analysis to determine if samples are different from other samples. So if you had a big data set and you expected everybody to be very similar you could use what's notice TCA determined based on the features indicated whether or not the people are very similar and if there are any that are much more different than the rest of them, you might have to look into why they're different. So that's an example of how you could use this during exploratory data analysis.  So are the red burning you give the features of them put the model determine the pattern in the data and it generates predictions.  A simple example could take a bunch of emojis and you can answer the question. Is it Kate and you would use your model the computer would in an unsupervised way to determine patterns the input data and maybe put what category 2 would have the emojis that are Kate and category one would have all the other food emojis. This is just a general simple example of how you can build a model to determine whether or not an emoji is Kate later on if you were given the Emoji you see here to try it is it cake and if it's not it would be going to the knot k category and if it were and had features similar to what you saw in this category, it would be given the classification cake would follow follow into feed not cake would be going on in the unsupervised approach.  What's generally has to do with and is modeled after what happens in biology. So in all of your brains, you have neurons and interneurons take lots of input process what's going on in that input and then sends an output down the axon to the next neuron take lots of input sends a single output that's an idea of what's going on in unsupervised learning. There are lots of inputs your model determines what the output should be. So when we talkin about neural Nets it's a mathematical abstraction that was inspired by what's going on in all of our brains and you were out put it either on or off based on the sum of all of the inputs. You give it to its supervised learning this idea based on actual biology that you get signals and you then determine outputs from your neurons.  Desktop won't be the last time you see something like this. This is a machine-learning talks all the time. And it is mostly unhelpful the way you should all take from this when you see it is that there are lots of input things happen in the model and then you get things out cuz that's what this Sunday's people try to use it to explain in a clear way what's going on in neural Nets and it doesn't do a good job aside from telling you things come in inputs and you get outputs and stuff in the middle is complicated. So they know that math is happening here, but inputs come in I'll put go out the ideas at this is based off of what happened in and so I said this is you know, this isn't damn explain what's happening here, but they did is imagism put an out you get what type of card is they built unknown that in this example where you take an image of a car and we break down based on what you see with in different parts of damage and the model has been built to determine that this image is an Audi A7.  Sample of a while back earlier in the last summer. They took Google images and they were able to correlate what cars were in different neighborhoods with political affiliations. And the way they did that was by generating a neural net net is you put in put in you Bill complicated model and you get out a label.  So just to review when you're protecting a continuous variable regression is the simplest and most common approach in the supervised learning category.  When you're doing classification decision trees can be helpful.  If you're doing unsupervised learning the computer is using mathematical representations to take and put all these emojis and classify them into different categories. We haven't talked to Tom about dimensionality reduction. We're not going to but I want you to know that that falls in the unsupervised learning category.  Any questions up to this point?  So I want you to protect someone's shoe size. I want you to propose how you would approach this using machine learning.  If a child each other convince each other of your guess.  Give everybody a few more seconds.  3 2 1  activate 65% of class saying a a few people saying be and then some people think C or D. So who wants to defend their answer how they came to their conclusion?  Okay, so shoe size in your example were correlated with how you could use regression to look at the relationship between those variables. So the outcome variable here the thing we're trying to predict as you mentioned is quantitative. So you could use regression in that case. So your answer was assuming a supervisor Goshen, okay?  To figure out what does he could you set height but like you can generate it's not just by the phone.  Okay. So the argument up front is that you could use unsupervised dimensionality reduction. The idea here is you can use lots and lots of different features so maybe incorporate so the first one was height, but then incorporate gender or other features that may predict shoe size and I do with dimensionality reduction as you can take all of those and then summarize all of the features based on a few smaller. We haven't talked about this in detail a bad idea. Then would be you would actually ultimately still in that case you supervised regression after you did that when I went to make a point is cuz I haven't yet is that when you're doing regression, you're not limited to one variable for your predictor variable and then one is your outcome. You can have multiple predictors. So in this case the simplest approach would be supervised regression, but there is a possibility of using a surprise dimensionality reduction any other thoughts on that.  So wouldn't be supervised classification because our output is a quantitative variable. And for the same reason it wouldn't be a clustering over here.  All right, you want to predict someone's emotion based on an image? How would you approach this with machine learning?  child each other convince each other  Eric winding down like a very few more seconds.  3 2 1  All right. We have some dissension among the ranks on this one. So regression was generally ruled out by the class, but now we're between b c and d which makes sense to this is a somewhat vague prompt, They're thinking behind their choice.  That is a fair point of logic. So it's in his face. And when you're working with images is often an unsupervised approach because you often want the computer to figure out what features in that image to determine so that's why I would easily be unsupervised clustering. So you want to determine emotions you want a cluster into some the motion and you want to do a basement on supervised way. So you don't have to go in and tell the computer exactly what in the picture to look at so I'm going to say that that is the best response if you wanted to do some sort of supervisor protest you would have to go in determine what features to look at any images. So what pixels to look at what colors to be looking at and how to what features of the image to train the model on so often when you're using images it's going to be an unsupervised approach to allow the computer to figure out what features  Also, this has been done in lots of different ways. So I have one link here. If you want to check out more that people have gone into historical images and determine this is a neutral man. And this is an angry woman or this is a happy person. This person is surprised. This person is sad and this person is angry people working on these phones and these are unsupervised approaches where the inputs are images and the outputs are some classification.  So so far we talk about data partitioning splitting into training and testing set talk about feature selection whether or not it is supervised or unsupervised. We talked about a number and number of different models that you would select based on what type of question you're asking to talk about before getting it examples is how you assess your model.  The first one and this is for continuous variables is something called root mean squared error. So you predict someone's age is 50 and their actual age is 49. Then you would subtract the difference between those two. So I would be that one year you would swear that difference you add that up across all the people in your data set and I'm going through as quickly which means I won't ask you to do this on an exam and then you divided by the total number of people in your data set and then you square that so because this is root mean square error, generally if your predictions are good, you will have a smaller error than if your predictions were bad if they were bad. These numbers would be far apart from each other and this number would be bigger. So General reminders when you are predicting you want smaller error.  The one thing is that a few outliers can lead to a big increase in a root mean square error, even while the other projectors are pretty good. So if you get a huge root mean squared error at the end of your prediction is sometimes good to go in and say are you samples not being predicted accurately or is it just not predicting well at all.  There's one measure of model assessment that can be used for both categorical and continuous. Although it's more helpful for categorical. So really when you're predicting accuracy is saying did I guess this person right? Yes or no and divided by the total number of samples predicted. So in the age example, somebody was 49 for 6 to be 50 would be counted the same way as somebody who was 49 at 62 years old so doesn't count taking back how close you are to the actual value. It just says where you right a wrong divided by the total number of samples.  So we mentioned just now that accuracy will tell you what percentage of predicted correctly when you're talkin about categorical variables. You can determine a little more specifically how well you did and why you did as well as clearly as you did, so sensitivity and specificity or two measures sensitivity says of those are we predicted correctly or safe to be positive what percent were actually positive so which ones truly worried that value and there was always that were negative what percent were predicted to be negative. So these are just breakdowns of your accuracy will talk about an example of this to get you a better idea of what this means variables. You could use root mean squared error or accuracy when you categorical variables, you would probably start by measuring accuracy and then you can get a clearer picture by looking at sensitivity and specificity.  Don't even give it a dating site with a number of features and asked to predict each individual Aid what prediction approach would you use this? When should be quick review?  decorative tile with each other  Scary the few more seconds.  3 2 1  Okay, so we see a downward pattern from left to right. I'm going to argue for the sake of his success this example that we are here going to do a supervisor approach. So now we're doing supervised here and we're predicting age were predicting something that is continuous. So here we would use regression and on an exam. I would specify that reduce supervised and not make you guess we're not doing classification because age is a continuous variable.  All right. So given that we're doing regression. How would you assess your model?  Feel free to chat with each other if you're stuck.  Give everybody a few more seconds.  3  2  1  I love it when you guys do what I expect you to do. So here you would probably calculating both rmse and accuracy. You wouldn't want to know exactly how many did you guess right if you're protecting age of you said they were 73 and they were 73 that would make your accuracy increase food also want to know your root mean squared error. If you didn't get it all the way right? How close were you were you closer to the actual value then some random value? That's much smaller. Okay, so you wouldn't use sensitivity specificity or are you see, which I haven't even talked about area under the curve. These are all for categorical prediction.  Hey and then whatever value would you want from your model?  Assuming we're doing rmse.  3 2 1  Well, I'm bored or most of us are onboard you want when you are using Pharmacy the smallest value for error if you want good predictions, you want your error to be small and if you said any of these that made him because my question wasn't as clear as it could have been. Okay, so you want low or a messy when you're predicting H as a general reminder since we haven't talked about ethics of time in a while you're training these days on historical data to any biases that exist in your data are going to be perpetuated in the predictions you generate.  A new representative of Arc recently tweeted out something to the effect of the fact that albertans which were driven by Max are racist and lots of people in the machine learning World jumped in and a lot of people said, well math can't be racist. It's Matt. It's based on truth and the argument hear from somebody at Microsoft is that in fact the data matters more than a match because you can say to your in Pudding to the math if there was a biased than the algorithms. In fact can be racist. This is what the reading you're doing for. Your kids reading is all about we talk about this example before is that Amazon set out in order to determine whose resumes they should look at more closely. They wanted the first screening just to be done by a machine learning approach. They generated this AI recruiting tool but due to the fact that Amazon has hired more males historically, they're recruiting tool despite the fact that it didn't take mail in as a feature said that it should hire more males despite candidates having the same.  Background and credentials stool after generating it. Once they knew that's decided they weren't using male female as an input. They still had bias in the hour of them that they generated. So it is always your goal ever going to talk about this a bit more on Thursday. It's anticipated Pisces check for them after you build Remodel and use your algorithms to improve lives rather than for punitive purposes. This is something your reading. We'll talk about religion or model update your algorithms. You are responsible for the mileage to put out into the world. That was a general reminder so far. We have talked about data partitioning feature selection supervised and unsupervised machine learning how to assess your model and the fact that bias data can and will lead to buy a predictions.  Any questions up to this point?  I'm going to go to this first example rather quickly. And then I do here is we want to predict weather at home give it features is in San Francisco, California or New York so I can ask what type of machine learning task is predicting whether a home is in San Francisco, California or New York City.  If I read a few more seconds.  3 2 1  Okay. So the two most popular answers were either be classification supervised or C classification unsupervised and I'm going to argue it could be either of those in this example. We are going to use a supervised classification techniques, but either would be appropriate here.  Alright, so who wants to propose a feature that would distinguish a house in York from a house in San Francisco. So if you want to chat with each other based on what you know from these cities what might give us a clue as to if I told you about a house, what were the singers the house is the child each other and then I'll ask for your feedback.  Yeah, New York, New York is New York City?  All right who has a thought as to what they would use if they wanted to build this model what my distinguish the house is in these two markets.  every isosceles cast  our brains are getting tired. I know.  Think about what you discussed hopefully at some ideas and we'll see what was used to do this.  Sadie is you can use your intuition sometimes determine what dating app should use for classification tasks. So if you're familiar with San Francisco and with New York, you might know that San Francisco is incredibly hilly City. So you might start to look at elevation over here. We have all of the homes in San Francisco. And here we have all of the homes in New York City and we can see that the house is at the highest elevation 10 to be in San Francisco or New York tend to have lower elevation houses. So you can maybe use some cut off to determine whether a house is in San Francisco or New York because you picked a cut off here something you would all be classified as New York, and this would incorrectly be classified as San Fran.  But you can use more than one feature. So you don't just have to use elevation. We also might know that there is a difference in price per square foot because we're both of them are incredibly expensive cities to live in New York 10 to have super tiny apartments that are very expensive. So if you start to look at price per square foot based on as it's related to Elevation, you can see lots of green dots appear more blue dots over here and some confusion down here says you start to build in multiple features. You can start to get a better idea as to what separates out. The house is in San Francisco versus the houses in New York.  It was a different teacher. So here they look at elevation year built number of bathrooms bedrooms price square feet and price per square feet in idea of which features will be helpful in your model.  And that is just using your intuition making a bunch of class. But you want to use machine learning using these in a machine learning approach would use a decision tree. So you want to find which boundary is most appropriate for separating out these houses from one another in a tree.  So it'd be highest home in New York is 73 M this little blue dot here.  We need to find the best foot points a which split Point somewhere in here get the most of the houses are in San Fran in San Fran and most other New York in New York.  So we'll use the split point up here that's going to classify all of these to the right at San Francisco. So this will all be right but this is a mix of this is not all blue. So we're not we're only getting 63% Correct. If you move it all the way down to zero and classify everything all of the houses and up over here. So you're looking for some split point that balances the error on each side. So you get some glue over here and some green over here. They building a decision tree is finding the best split point at each part of your tree and you do this for each of the features. You're going to include  And you continue to build your tree. So if your first one is elevation you then might split by price per square foot and each time. We can see the accuracy that most of these are blue and most of these are green and our accuracy at this point is 86% as we continue to use features and build our tree when you use lots of features, you can get your accuracy up to 96%  And if you take it even further at the end here all of these circles are either green or blue and our model is 100% accurate.  Around you you're building this in your training days that you have that held out for testing data that so then you're going to take all of the houses that are in your testing date is that and send them down the tree so we know that in our training data, all of the San Fran house has ended up with the San Fran and all the New York with the New York and you're texting dating site as you send them down the tree you start classifying and you see that yes, I'm over here. Most of them are green but some New York Home snuck in and over here yet most of our blue but some San Fran houses fell in and your accuracy and your test set is 90%  This is a topic we haven't talked about yet. And today's lecture is that you can train a model that is 100% accurate, but that won't perform. Well when you give it new data, so there's some balance between how accurate you want your training dataset to be I'm so that you can make sure your test accuracy and a dataset not used to build. The model is higher there ways to do it over fitting that we're not going to discuss in this class for whatever you to be familiar with the topic of overfitting and if you see a hundred percent accuracy in your training day that you've likely over fit your model.  What's is a recap of what we talked about there?  The second example of talked about today is categorizing listing photos at Airbnb.  Which Russian?  Hey, I lost my focus. And I know we're getting towards the end.  Is a question of yours, can you train the model and specify which features and how to wait them in order to figure out the best tree and the answer is yes, and there are lots of different types of trees and different approaches to how to fit a single tree and whether or not we want to put multiple trees and then take the best tree among them there. Lots of these like tuning parameters what we call them to change exactly how you fit it. So yes, the answer is simple answers yet. Another question. That's a great question example is a true example from Airbnb and in this case would want to categorize listing photos at Airbnb the somebody wants to put their place up on Airbnb so that other people can run it out. How would you categorize the photos they've submitted?  Go to few more seconds.  3 2 1  I hope so. We see that the two most popular answers again or the classification ones and here I'd imagine that maybe more people put see because we're using photos and I said that when we use photos of optavia unsupervised, which is in fact the way Airbnb opted to use it. So we're going to talk about clustering in an unsupervised manner but B is also an option here.  Stop someone from it was a machine learning scientist at Airbnb wrote a blogpost about how they did this and event B idea here is twofold why you would want to categorize photos that are put up on Airbnb. Is that make the home tour easier? Not everybody upload the same photos are in the same order. So you wanted to tell me what photos I have and then put them in the same order. So when people go to Airbnb they can see the same format no matter which place they're looking at it also allows for efficient listing dilation without having a machine learning approach to this an individual would have to go and say this person said they have a three-bedroom apartment do they actually have a three-bedroom apartment face on the photos they submitted so it allows that to ensure that the listings abide by what the people are saying and that everything is what they say it is.  So here are a bunch of photos and this is an example of why you can't just take the photos that exist on Airbnb and use the labels that individuals gave to the days that to train your model. So this is an example of a data set that is messy because this is labeled a kitchen that's not a kitchen. This is labeled living room, but it's actually the hallways of the living room. This was labeled bathroom, but that's not a bad thing when you can see that just by using the label based on what humans and put into a computer is not always a good idea. So Airbnb decided to take labels from Airbnb and it's supplement them with a small number of photos where they were confident. So they hired people to correctly label photos and then use those as their training data to generate their model.  They use a a neural net that is already out there. So an unsupervised approach that takes the images as input and then determines the room that are in as their output uses lots of layers. They fired a bit for their approaches and what they see here is that they classify bedroom with an accuracy of 95% and an accuracy for living room of 92% We haven't talked about these curves too much but what they're showing here is that they can do a really good job at first pass of correctly classifying images to the room that they're from from the beginning.  Question. Yeah.  Okay. So the question here is is there a Jewish Alliance and the difference between them have to do with overfitting is generally what the question was here. The idea was if they took the model of a neuron that that existed out of box and just use that they would get this green curve with a slightly lower accuracy and they retrained it to more specifically fit their needs. So this is just in case of them a training model. So back to your question from before if you generate a better model that more specifically fit your needs. Can you get a more accurate approach? So you want to make sure that your model is as accurate as possible without overfitting. So that's the balance that you're always trying to generate there.  Okay, so these are examples from their model determined that these are bedrooms. These are not these are bathrooms. These are not and these are pools while these are not and I think this is probably the most impressive because these look the most like pools when you can see that these in fact or not pools to a single Airbnb unless this is some super fancy Airbnb.  Any questions on what we talked about so far?  Or I'm going to save this life example about predicting stuff but you all for Thursday. So we'll start talking about machine learning and I'm moving to algorithm.  UC San Diego podcast for more visit podcast. Ucf.edu "
}