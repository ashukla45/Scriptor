{
    "Blurbs": {
        "2 3 But what you'll notice is as you're asking people their gpas difference between these layers. Dog and include some undergrads and some grads. It's all going to a dance together to like a 3-2 or something. So you and your friends are all going to come back together and you're all going to be staying three two, or three one. That's the average GPA. Why would you ever ": [
            627.5,
            651.7,
            27
        ],
        "And those are the ones you go to. It's simple because you didn't do much in terms of fancy methodology and it's random because you some random number generator or pseudo random number generator and some computer program to choose the people. So there's the best possible approach for many situations now, it's trying to get fancy. And this is very dangerous to get fancy because you can inject all ": [
            443.0,
            468.5,
            19
        ],
        "I can go calculate the mean and median and both you'll notice the median is totally unchanged by the alteration of one data point. So if you would like something that is resistant to that kind of change and look sort of centrally what's really going on in the middle of the dataset and doesn't care about the end. The meeting is a great idea. But if you want to ": [
            2315.6,
            2336.9,
            86
        ],
        "IQR. So that's where it shows up in that picture. Now. The next thing you do is you taste Q3. The upper quartile and you go a distance of 1 1/2 IQR is above that of the IQR. Is this box Heights Hugo one box height and then another half box height and you draw something on his defense. Now John 2p was a statistician who decided we should go ": [
            2779.8,
            2808.0,
            105
        ],
        "Listen to a podcast. Okay, welcome back. And good morning. We're back at math 183. Sorry for last class has technology failures. Hopefully those won't happen again. We will get lots of done today or to be beautiful. I wanted to point a few things out before we start. All sorts of people been sending me emails that you don't need to be sending me. If you just look at ": [
            1.9,
            34.1,
            0
        ],
        "So one thing you might do is say let's just use Social Security numbers from the Social Security Administration database approach already lost all people that don't have social security numbers, which is tons of people who live here. But if you can set up a sampling frame where you actually have access to those human beings then at least you can begin doing something actionable. Okay. Now you have ": [
            370.7,
            397.4,
            16
        ],
        "So you said something about response with the people that respond to things are not representative of all human beings you want to know who responds to things women respond to things far. More than men. It's just a statistic. So this is obviously not representative and I'm quite worried about how she responded. This is a big issue volunteer bias. There's a lot of different words for this. You ": [
            896.0,
            919.6,
            37
        ],
        "a big mess. So let me show you how to not be clever. And to get things right believe it or not. So here's how it begins. The population are huge. Big Mass. Maybe it's all people in the u.s. In case you set this in your goal time is your goal. Okay. Now you can't always get at everybody. That's a problem. So immediately would you have to do ": [
            322.8,
            347.6,
            14
        ],
        "also there's some truly anomalous data points. And those are the dots on KB on the lower and upper whiskers. So there is one definition that you should know for outliers the people often ask you about and you can decide using that definition if you want. It's easy to make a boxplot in R. You just take boxplot whodathunk Addie anything else but the name of your data frame ": [
            2885.7,
            2910.9,
            109
        ],
        "an even number then you have to average them. But here we have an odd number of things. So I just chose 3, so that's known as the lower quartile or q1. It is one quarter of the way into the data. Just like you one for business people is 1/4 into the business cycle. If you've heard that kind of language before you can take the top half ignoring ": [
            2623.4,
            2644.2,
            99
        ],
        "and see if your new waterproofing technique works. As phones break or not. It's because hardly you put the waterproofing on or you didn't. What's if you've seen this idea in life by now, but hopefully now you can contrast it with observational studies. Another reason. This distinction is so important is because the conclusions that you can draw from these are totally different. So whenever you have an observational ": [
            1193.0,
            1219.4,
            48
        ],
        "and then go out and talk to them. This is better than almost any other strategy that can be devised because everyone has an equal chance of being included and when you randomly sample your sample tends to look like the population. So here's a visualization. Maybe the whole square is the whole universe of people there all the pixels in there and you just color some of them blue. ": [
            422.7,
            443.0,
            18
        ],
        "applied to data to produce a single value. Okay. So one thing I've noticed istics always come from samples the SS parallel here will be important later. We'll talk about populations and parameters that start with the letter p Okay, so there's lots of choices for how you might summarize your data. You will be well-versed in some of these and others will feel a little new to you. But ": [
            1811.9,
            1835.8,
            68
        ],
        "are still in the fences. So you draw a little whisker and you go go go until you get to the last data point that lives inside the fences and you do the same thing down there. So what it says very quickly is the mass of your date of the 50 Cent 50% Central is this box and you can see how much it's worth of spills out. And ": [
            2859.6,
            2885.7,
            108
        ],
        "be done. Okay, that's not a hard problem hard problems or when the population is millions of people and there's no way you could talk to them all if you try people died as you were trying to go talk to everyone and new ones are born so it's not even possible. So what you do is you draw what's called a sample that is a small representative. It was ": [
            146.4,
            165.6,
            6
        ],
        "be honest to that reality for whatever reason than the mean would be a great choice, so here is often what people do in society. They tend to use the median when they have weird distributions or things with outliers. Because people tend not to want to talk too much about the outliers. They tend not to want to think about that housing prices home price. Maybe even heard that ": [
            2336.9,
            2365.1,
            87
        ],
        "but a dollar sign to pull out the column of data you care to make a boxplot for and then you have your box plot, and it does everything for you. Now in the last 2 minutes, I want to talk about the standard deviation formula. I hope you went to discussion. They often talk about things that we don't have enough time to talk about here. So this is ": [
            2910.9,
            2933.1,
            110
        ],
        "can also see how well you did in real-time good. Everyone understands a simple random sample now, basically you read that LGBT students tend to have more siblings. Because your chance of being LGBT actually goes up as you get later in the birth order. Is a true statistic? Your chance of being a gay male based on surveys observational studies is about 1.5 to 3% depending on what population ": [
            1443.3,
            1478.3,
            58
        ],
        "can't trust volunteers about anything in terms of the representativeness of the larger group that you went to talk to. Okay, what about the move from all Facebook users to the 5000 friends of my former student? What bothers you Go ahead. Good. Who do you think his friends are people that work at Facebook if you work at Facebook you probably like Facebook done. So there's all sorts of ": [
            919.6,
            959.0,
            38
        ],
        "causality? Okay, ask yourself did the researcher have a hand in dictating things or did the data already exists? Or maybe they just watch the day to get created. So B&C the data already exists college graduates. They're done on KK scores already done. So in a did they influence it will they assign them to one of the two groups randomly? So there is the researchers hand now Diaz ": [
            1660.5,
            1727.8,
            64
        ],
        "data and you haven't messed with this Arrow. Thing happening. It just flows out naturally unhindered. Okay, so getting transcripts this is called extension date. I do that already exists. That's one way to make sure you have an observational study study newspapers from me and usage unless you wrote the newspapers. This is observational just looking at what's going on in observing Society observational study is not the gold ": [
            1083.0,
            1113.3,
            44
        ],
        "data scientist, you need to understand the pipeline of how data works. And one thing we'll see you at the very beginning is it is very important that the data you collect be. Good data. And you recognize since you have a memory of 2016 all these poles were basically worthless. Right and it's because that was garbage data collection. And if you form beliefs on garbage collection, you get ": [
            101.3,
            125.2,
            4
        ],
        "data together by waiting it appropriately if only 20% of people are graduate students. Okay that goes into 7 calculation. Now the reason you do this is here. You have a sense maybe undergrads have much different GPA in this when you go to graduate school and all the grades are free and everybody gets A's and B's it's very hard to get a c in graduate school. You have ": [
            517.2,
            540.7,
            22
        ],
        "do such a thing well? It actually helps you operationalize and I know I can go stand somewhere and collect a bunch of data. People are coming at me. It's much harder to get access to the schools ID rules that identifies people's gradual suits in undergrads and then randomly pick from it. So this is as a way to create something that's physically doable. That's it problems on there ": [
            651.7,
            678.8,
            28
        ],
        "does then in person is probably better. I can also see an gradescope that 84 View of already turned in homework 1 do Friday. This is a test of the pipeline. You should already be done with this basically and you should be moving on to homework 2, which is due Tuesday of next week because you can already answer a lot of questions on it. So the reason I ": [
            60.0,
            79.3,
            2
        ],
        "don't make things do a lot earlier is because they don't even assign me Graeter's until the end of the week. So but that doesn't mean you can't get going on homework. Okay enough talking Let's do let's learn things. So we're going to pick up and continue our study of data and thinking about data and I want to show you this pipeline. If you want to become a ": [
            79.3,
            101.3,
            3
        ],
        "formula is intimidating when you first see it. But in this class you will get lots of experience using it on homework to so here's the idea. This song is going to go through every single data point you have and what it's going to do is going to take the data value why so by and it's going to see how far it is from the meat that's what ": [
            2959.6,
            2979.8,
            112
        ],
        "friend do it. No. This is not graded. This is just for you to learn stuff. I'll post these on the internet slightly before exams. So if you want to review them that's possible also. You want to find out the average number of siblings for UCSD student? You get the school roster and choose names using a random number generator. What type of survey did you just do? We ": [
            1418.7,
            1443.3,
            57
        ],
        "friends 437 replies that turns out to be the sample. You may have cringed. I hope you did. So we're going to go from bottom up and tell me the cringe Factor as we went from 5000 down to these 437. What are you bothered by in that transition step? Go ahead. Okay, so to reiterate you said large drop this could be very worrisome. What do you think? Good. ": [
            852.4,
            896.0,
            36
        ],
        "from what's called an observational study. So this is a vague term that has a rough definition, but the cleanest thing is just to say that when you collected the data. You did not interfere or manipulate how those data came to be. So one way this happens if the data already exists and you just go collect them, for example, if I want to look at scores of students ": [
            1028.4,
            1057.6,
            42
        ],
        "garbage beliefs. Welcome to almost all data that you get coming at you through the Google news and the CNN's and the Fox news is it's all garbage data. So how do you make better data? And how do you put it into a nice pipeline? Well, we're going to start here. There's some population you want to study If a population of 20 people talk to 20 people and ": [
            125.2,
            146.4,
            5
        ],
        "groups of people who has siblings attending UCSD all automatically, you know, their sibling number is greater than or equal to one could be even higher and the people that didn't have a sibling could give the answer 0 so their average is going to be a little lower. Okay, minivans and fly lots of human beings lots of siblings so on. From which of these studies? Could you infer ": [
            1638.5,
            1660.5,
            63
        ],
        "harder. So if you go injected 50 rats with fire Benzene, look at their average lifespan, you're probably comparing it to rats who have not been injected with pyro benzene. And that data probably already exists. So sometimes it's more subtle and you don't have to mention other things. Although that's not the best way to do a study. Let's take all of your beautiful day. And suck it up ": [
            1727.8,
            1755.8,
            65
        ],
        "has very little skewed to the right. We're starting to get more right skew and then we have high right skew Will the mean be less than about equal to or greater than the median in each of the three pictures. I'll give you a minute to come up with a beautiful response and then we'll call on someone. Okay lunch to go. You get one or two clean beautiful ": [
            2088.0,
            2154.8,
            80
        ],
        "he went on and went to Facebook and he is now in charge of data security privacy concerns a Facebook member that Cambridge analytica thing is he was the person that had to fix that. We talked on the phone a few weeks ago. It was a disaster. Basically, it's very hard to fix something that happened when he was in his early days that the company boss comes and ": [
            754.0,
            777.9,
            32
        ],
        "here. There's a hundred percent of the data and there's the range so it's cool the five number summary gives you both of those measures of spread if you were to want them. No, I tend not to use those very much. Hopefully went to discussion section and they took both standard deviation will do that in the moment. And that's tends to be more common. Now. Here's another really ": [
            2726.0,
            2747.7,
            103
        ],
        "important visualization. This is known as a box plot. So instead of making a histogram. to show your 221 earthquake magnitudes You can put them in this figure right here. So what it does is it draws a box? And screw this middle rectangle that took three horizontal lines. Okay. So those three horizontal lines accurate occur at q1 Q2 and Q3. So the height of this box is the ": [
            2747.7,
            2779.8,
            104
        ],
        "into maybe two groups or three or however many you need. And there's certain things happening to those groups maybe ones getting a drug maybe ones not getting the drug. So when the day to pour out you have influenced the structure of what's going on. So this is one way to isolate things that matter to you for example of the drug works or not while you're putting things ": [
            1139.9,
            1168.0,
            46
        ],
        "into my computer sound good. So it's every year I get rid of the questions that are too easy that everyone gets right. So the first question has finally Met its demise. It will not be asked anymore and harder things are put in place. Okay. So now you understand roughly some macro is too structured data. Let's hop to the end here and how you summarize data. So if ": [
            1755.8,
            1783.1,
            66
        ],
        "into two groups or one gets the drug and one doesn't so it's the dataflow out you will be able to have some sense of other things work or not. Okay, so often randomized controlled drug trials looks like this. Here's another one does waterproofing material work. So go put it on 50 phones and submerge them in water and take 15 on waterproof phones and submerge them in water ": [
            1168.0,
            1193.0,
            47
        ],
        "into two groups. If you choose their group identity randomly. Then group a and Group B look totally identical basically just because Randomness create identicalness. They look identical on every single trait. Their ages will look the same the balance of genders will look the same Etc. The one way the only way in which the groups differ is what they're getting from. You treatment versus control. Did they get ": [
            1250.1,
            1278.6,
            50
        ],
        "involved. So then he said, okay. Well, that's interesting. How am I going to get all Americans? People off grid in Alaska. Good luck. Okay, so he said, you know, I'm just going to sample Facebook users because I work at Facebook and I can send things out to Facebook users. This box has no you can't just end things out to Facebook users. We don't allow that here. But ": [
            804.2,
            829.7,
            34
        ],
        "is make some sort of Play production the sampling frame. This is the actual Universal be pulling from in a perfect world. It would be the population. But the problem is I have no way of getting all people in the US some people live in Alaska in the middle of the nowhere Middleton or off-grid right? So how you going to get to those people you have no way. ": [
            347.6,
            370.7,
            15
        ],
        "it goes between the quartiles and you can summarize all these beautiful numbers into something known as the five number summary people love this because it gives sort of the most important things about your data set. So you're going to tell them the smallest and biggest numbers computer can figure those out using sorting algorithms etcetera CS people in the room now depending on where they want on square ": [
            2672.3,
            2697.9,
            101
        ],
        "know if you're if you're in I've been part of a double-blind experiment related to asthma when I was a kid and we didn't know a group I was in so was blinded and the doctor didn't also and my mom said we have to make sure the David gets the medicine. He's probably going to die if he's not in the correct group and the doctor said, I don't ": [
            1350.5,
            1369.2,
            54
        ],
        "know. I'm sorry. This is actually true and luckily I was Okay, let's go to surprise him enough for me talking. If you weren't here yesterday, we downloaded this app. You can go to app stores called Socrative. You can see the spelling in the upper left corner here. What I do is I launched a quiz that goes out all your phones. Now. You have to remember the name ": [
            1369.2,
            1394.9,
            55
        ],
        "last house. We saw outliers is just some big word and we all emotionally felt at the page. Hey, so if you want to rigorous definition according to John tukey of what an outlier is. Now you have it great. Now so that's what the dots in fences are. Now, what about all the data that you still haven't captured? There may be outside Q3 and outside you one but ": [
            2834.8,
            2859.6,
            107
        ],
        "let's organize some things you saw in 4th grade into a larger hierarchy. Sometimes you care about where the data is entered its centrality now, that's a big word in there. Lots of different ways to do this, you know, one of these is called the median. So all you do is you take your data. Hopefully it's numeric. Otherwise, you're in trouble you put it in numerical order from ": [
            1835.8,
            1859.3,
            69
        ],
        "level and so on right? So you have this huge pots. You don't drink the whole thing in order to decide if it was done correctly. You take a few spoonfuls, right? This is a sampling. Now it may or may not have gone. Well it may or may not have been a good sample. We'll look at reasons why you could not in Sac maybe want to sample all ": [
            208.9,
            229.1,
            9
        ],
        "like you're going to get different answers. That's how you know, it's stratified and here you do know because of all of this text above 80% That's good. How did you ask all the students in his math 183 class using Socratic? So tempting to put Buster garbage sample. You can see in the explanation here. Now if you went and you said okay, we're going to slice up the ": [
            1505.8,
            1548.8,
            60
        ],
        "little fulcrum and you kept a histogram out of paper and you try to balance it on your finger, it's where your finger goes and the reason that happens is the mean actually uses the data values like 990 in on this picture 990 is way off to the right. So there's a little block of color way over there. And that creates a pork arm on the picture where ": [
            2038.9,
            2064.3,
            78
        ],
        "median. Now it sometimes the mean is a better choice. Sometimes the median is a better choice. When you should not do is insert a false binary in which one is better always is a silly way to approach life a more nuanced way as what are all the options and in which settings are some better than others. And for what reasons that's the right way to approach this ": [
            1970.6,
            1996.5,
            75
        ],
        "names for this. Some people call a convenience sample bias. You don't need to know these exact words. Really you just need to have in your soul that something bad just happened and eventually when you take a sampling class, you can learn all the language for this kind of nonsense and finally from the top step down. What bothers you there. In the very back. You're not going to ": [
            959.0,
            983.2,
            39
        ],
        "now, we can visualize this some people hate formulas and they love pictures. So here's a histogram of a bunch of data and you can see that I've color coded it. And put the median down. It will be a place on the x-axis and half the data values or to the left and blue and half her to the right. So it's the place to to which the left ": [
            1996.5,
            2020.1,
            76
        ],
        "number 7, so then what you do is you take all the numbers to the left of the red circle. And that is the first half of the data and you find the median of that so half of 1/2 gives you a quarter if you just found 25% of the way into the data. And there's an odd number of things you can choose the middle one. If there's ": [
            2604.7,
            2623.4,
            98
        ],
        "number in the very last zero on a hundred percent of the way into the day. If you just change those values, it just totally changes everything right you just dip your way in a 25 + 75% and subtract those from each other than you're something that's a little more robust. So these are known as the upper quartile and lower quartile. So here's an example in some high ": [
            2553.6,
            2578.9,
            96
        ],
        "of the room. It will always be my initials, but you're right here at the top do you qu? That will get you into the room. You can see how many people are in the room right here the number to the right of the bar. Now you can do this on your computer. You can do this on your cell phone. The worst thing you do is watch your ": [
            1394.9,
            1418.7,
            56
        ],
        "of undue that's wearing action. Now the hardest part about this was the division by 10-1 you want to sort of average together all the deviations? And so you might think we should put an end here if you take 181a, you will finally learn why there's an N -1 instead of an end has to do with something on his bias that we can't talk about here. And now ": [
            3002.5,
            3026.0,
            114
        ],
        "one and a half up from Q3. And he also decided we should go 1 and 1/2 IQ ours down from q1. He thought that this was the right amount to go to be far away from the central core of the data. And when you draw those fences any datapoints that live beyond them you visualize with a circle and these are outliers according to the box plot definition ": [
            2808.0,
            2834.8,
            106
        ],
        "one could have chosen on how to resolve these middle two things into a single number but the average is the most common Okay, all sorts of pros and cons to this. Will get cities in a moment, but let's look at another one. This is your good old friend the mean also known as the average they are total synonyms. You should blend them in your brain. The problem ": [
            1901.5,
            1926.1,
            72
        ],
        "our to see what the mean and median were and you can see from low speed to high school the difference between these two keeps growing. And in fact, the mean is greater than the median. This is true in most cases for most unimotor things. But there are weird counter examples. So in general right skewing tends to move the mean higher than the median but not always your ": [
            2263.8,
            2293.1,
            84
        ],
        "people to start feeling better. Even if you don't really give them the drug known as the placebo effect. So if you blind the study then you don't tell people what group they're in. I don't know what group you're in. Here's a pill take. It might be the placebo might be the real thing. So you still have the placebo effect in both groups now and then you have ": [
            1305.5,
            1327.6,
            52
        ],
        "phrase. Maybe you bought a house before in San Diego is like 490,000 or $500,000 days and you don't want that disrupted by the homes that cost 15 million in La Jolla because you're probably not buying one of those. So that's why they use the median there. They don't want it all skewed by the million-dollar things on K people send you some mean when they have nice distributions ": [
            2365.1,
            2387.4,
            88
        ],
        "population into lots of clusters will use a stat class. We use a CS class. We use a Humanities class then it starts to feel cluster e but here we just taking a beautiful huge complex population of 35000 in reduced it to 270. That's just garbage. There's no slicing. It was just a shrinkage is all that happened. Okay, obviously, we haven't used cluster yet. So I'm not going ": [
            1548.8,
            1576.2,
            61
        ],
        "relation to how you broke it up. Another thing that people do is go cluster sampling. So here you take your population and you slice it differently. So the idea and this is you still create slices or strata won't call them straddle. Come in clusters. Have a different word. But maybe you say okay. I don't know. How do I go talk to graduate students. How do I talk ": [
            586.7,
            609.0,
            25
        ],
        "represent the population done. So as long as you feel this in your soul, that's what you want right now and then you can organize them later in life. Now. Let's talk about data. Let's say you have a beautiful perfect sample. What are the different ways that data could look or be structured about it. So let's just talk about the two high-level differences. So maybe your data came ": [
            1006.4,
            1028.4,
            41
        ],
        "rule for a while. See how you like it. And then remember that you can choose between the two things. So every time for the next two weeks when you hear someone talking about the mean or median say is that what I would have chosen do I want to Leverage The outliers in the screw into the calculation or do I not and after you do this for one ": [
            2409.0,
            2431.9,
            90
        ],
        "says, I want to know how much Americans love Facebook. simple question very hard to actually study. That's the problem. So here's what he did. He said here's the population all Americans and the idea the measure on them is love now. I don't know what that mean with lots of ways. You can get this 0 to 10 love scale. Whatever. I'm going to already. There's some measurement issue ": [
            777.9,
            804.2,
            33
        ],
        "school class that I asked a bunch of students. Okay, most of them up here, right? Favorite prime numbers my goodness in order that was nice to me and wants to know where we can find the median which is known as the middle quartile or tell Stones like quarter 4/4 or 4 quarters in a dollar. So two quarters in is 50% of the data in so then the ": [
            2578.9,
            2604.7,
            97
        ],
        "sentences. Go ahead. The mean should be greater than the median cause in which pictures. In high school pictures you claim. The mean is greater than the median cuz the outliers there may not be outliers. You do know. You're going to help help. Louder, please. Okay, so I'll serve you right but I think I heard they're all these data values that are spilling out to the right hand ": [
            2154.8,
            2218.5,
            81
        ],
        "should think about this. This issue so as things get more skewed the mean and median depart from one another. So the question of which one should you use depends on whether you want to account for that movement and it matters to you or do you want to avoid that and it doesn't really matter to you. Okay. So here are the actual numbers. I just plug them into ": [
            2240.6,
            2263.8,
            83
        ],
        "side way far and if you think about what those do to the torque on they. Tour way out there on the right hand side. So the mean has to move over to account for those spill out and they might even be outliers. This picture doesn't happen to have any family that won a 20 in the center or the middle one. That's exactly right. So this how you ": [
            2218.5,
            2240.6,
            82
        ],
        "sit have to do to into which the right has half a date on some histogram the x axis of a histogram if you want to think about it that way now the mean there's the same dataset you can see if you read the same but the mean will not be at the splitting point of color. It will be at the balancing point. So if you put a ": [
            2020.1,
            2038.9,
            77
        ],
        "smallest to biggest and then there should be a number in the middle. So the median of the road has an equal amount of Road often on both sides just like the median of a data set has an equal number of data values on each side. So hear the meeting is for you probably seen this before now, you can recognize it as one of the many measures that ": [
            1859.3,
            1878.9,
            70
        ],
        "sort of skinny and then puts all of its weight. Near the median in the other sort of slowly spews out and has tons of data in a huge range. So we need a way to talk about the difference between these two and that's encapsulated in the spread. So it's Brad again is just a vague word trying to capture how far you have to go out in order ": [
            2452.8,
            2477.4,
            92
        ],
        "sorts of bias. What are the problems with simple random samples if you're studying something very rare. And he's choosing people. You may not get any of those people who have that rare trait to them. So sometimes you know sort of a high-level how your world is structured. So what you do if you break it into strata or sections or pieces. So let's say you want to know ": [
            468.5,
            492.6,
            20
        ],
        "standard for many people when it comes to research and they care about something known as an experiment or randomized control trial. So here you are manipulating the way or the the way day to get created Guided by the hand of the researcher and I'll show you the most common thing here you want to study some population. So you study some sample of them and you break them ": [
            1113.3,
            1139.9,
            45
        ],
        "stration of what this huge monster energy looks like and if you do this in a really good way, hopefully the sample represents the population until you can use the small group to understand a large group. Now it turns out this is very difficult to do as you saw again the smartest people in the world basically all got it wrong. Just a couple years ago. Once you have ": [
            165.6,
            190.6,
            7
        ],
        "study. If you start to notice some interesting trend. Then it's just an association. There's no causal relationship. But if you run an experiment and you notice an interesting friend going on then you can infer causality because what's happened is you've wiped away every other possible explanation except for the causal one. So here's what I mean by that when you take a bunch of people and throw them ": [
            1219.4,
            1250.1,
            49
        ],
        "talk to some grads. I'll do a simple random sample on those. That's the right hand side and I'll bring it back way. I see broken up and the pieces you broke it up into look different. In relation to what you're trying to measure GPA. They may look similar. In other ways. Like where do they live San Diego? They look similar, right, but they're different in route in ": [
            562.1,
            586.7,
            24
        ],
        "textbook will get that wrong when it's make that claim just so you know, but it's good to know roughly what happens if Emily left giving things are going to pull the mean to the left of the median. Okay. So let's look at it with some actual simpler day two sets of History data sets. All I've done is change the top number from 7 up through 700 and ": [
            2293.1,
            2315.6,
            85
        ],
        "that don't have outliers. The reason people I mean the mean and median starts become the same thing in that case believe it or not. So one could just always use the median if one wished but the problem is most people understand the meaning because we use it everyday so much. So there's a good reason to use the mean if you can. So I would say try this ": [
            2387.4,
            2409.0,
            89
        ],
        "that we're looking at here? Not just which one happens to be in the middle if they were to be ordered. So in this case, you're going to go average them together and you'll notice that the mean of the first is 5 but suddenly the second data set has a huge meme. What you're saying? There's something interesting going on with your values, even though they have the same ": [
            1950.0,
            1970.6,
            74
        ],
        "the actual effect if the drug does anything that's not enough. Sometimes you have to double blind it in addition to blinding the people to work for you and you have to Blind the researchers so they can't know because if I know what group you're in and I hand you the pill. There might be subtle things. I do that indicate to you. Which group you're in because I ": [
            1327.6,
            1350.5,
            53
        ],
        "the average GPA of UCSD students. Well, you could decide to break the whole world into those people that are undergrads versus grads. And one reason you might do this is because you want to make sure both populations could really included. No, they don't occur in the same amount, right? There's a lot more undergrads in there are grad. You can factor that back in issue recombine all the ": [
            492.6,
            517.2,
            21
        ],
        "the chicken is not fully cooked. You've done a good sample. You know that okay another one home phones who has those My parents are almost ready to give up. There's and their ancient so the only people get on home phones or Well, I'll let you just put that in there. Anyhow, another problem with the sample. The next election is a future event people might say they're going ": [
            278.3,
            303.1,
            12
        ],
        "the drug or the placebo? And so if you see differences in the data coming out, they're not from underlying structural differences between the groups. There because of the effect you created now, even this structure has problems. So if you don't people randomly into two groups, and then you give some of them a pill and say this is I think it's yours. Whatever your ailment is. Turns out ": [
            1278.6,
            1305.5,
            51
        ],
        "the median you can look at it. It's median and you can see that it's 13 and then you subtract those two numbers 13 - 3 is a distance of 10 Au in a distance of 10, you have encapsulated the middle 50% of the data. Or if you subtract the ends in a span of 17, you can get all of the data or 100% SMSD IQR interquartile range ": [
            2644.2,
            2672.3,
            100
        ],
        "the most garbage e, All you do is you take your entire day to sit and you say I'm just going to look at the biggest value in it and the smallest value subtracting and get that span. So 100% of the data will live in this spam and your reporting how big that span is. So this is sort of losing all but two of the data points. That's ": [
            2500.9,
            2528.7,
            94
        ],
        "the most important measure of spread in my opinion. So here's our data set. It has n values. Those are all numbers. You can immediately find the average of those numbers. If you want. We will use a notation y bar or X bar to mean the meme. Okay, so Dad itself is a number that's the measure of center. So now you can calculate the standard deviation of this ": [
            2933.1,
            2959.6,
            111
        ],
        "things on the internet. For example, the office hours are now up you can see them. This is one of the many documents that's here. In the 183 Triton add folder off stars in locations. So feel free also to email questions if they are appropriate for email make a decision on whether the thing is answerable and small amounts of text and doesn't require tons of mathematics. If it ": [
            34.1,
            60.0,
            1
        ],
        "this big long list of social security numbers, you could randomly choose people from it. If you do this, you've created what's called a simple random sample SRS. And it turns out this is one of the best possible things you can do. If you can delineate every single person in your population at least in the sampling frame through some identify and then randomly choose people from that list ": [
            397.4,
            422.7,
            17
        ],
        "this difference is. And that's measuring service spread? Now some of these spreads these differences might be positive and some might be negative depending on whether the date is above or below the mean so I don't want to just add all the spreads together. Because the positive and negative stuff will cancel out so you swear to make it positive and eventually you take a square root to sort ": [
            2979.8,
            3002.5,
            113
        ],
        "this year like some people don't go to the gym. They're not included in. This has to go to the gym. So that's not representative of the population of always UCSD students. But it's often done. If you something like geographically you want to study San Diego may be breaking into clusters based on neighborhoods, like Kensington and UTC and so on. Okay, so people get confused when they see ": [
            678.8,
            704.7,
            29
        ],
        "to give you a question where you have to choose cluster. You're going to have to tell me which to do clustering. Noticed you can select multiple correct possible answers. Okay, so you can see the day and see or wrong. They're slicing it out. But the question is to the slices look similar or do they start to differ? So for example, the first one if one of the ": [
            1576.2,
            1638.5,
            62
        ],
        "to grasp most of the data on the one on the left. You have to go like a unit or two and you've gotten almost all the data, but on this right one, you got to go way out all the way to 2 and 8 probably to think you've gotten most of the data. So, how do you measure the spread again? Lots of ways first idea. This is ": [
            2477.4,
            2500.9,
            93
        ],
        "to really try to do nothing. Okay, but it's hard to get A's and B's in undergrad. I don't know why this is some artifact of how we've done things for a long time weeding people out. Whatever. I don't know. It seems reasonable to you. So if you knew this different you would want to really make sure graduate students got included. So you just say we're going to ": [
            540.7,
            562.1,
            23
        ],
        "to undergrad? None of that is operationalize herbal, but what I can do is stand in front of my gym. And if people are coming in to say what's your GPA? What's your GPA? What's your GPA and I'll send my friend to a different gym and a different friend to a third gym. Okay, so you sliced up your data from the people who go to gym 1 vs ": [
            609.0,
            627.5,
            26
        ],
        "to vote in some future event, but will they Okay, awesome things come up the day of and then like I couldn't get to the voting booth, even though I wanted to so you can't trust the reliability even on their own internal judgement of how they're going to do. So turns out to be quite difficult and every time you try to be clever, it turns out to be ": [
            303.1,
            322.8,
            13
        ],
        "toe and login etcetera. What kind of speed So here's about here's a list of these earthquake magnitude in the US 221 different earthquakes. You measured their magnitude on the Richter Scale now 50% of the data live between the first and third quartiles and the distance between those two numbers is the IQR how far in distance to we have to go to capture what we want and over ": [
            2697.9,
            2726.0,
            102
        ],
        "truth if you really want to get good at this you take an entire class solely about sampling Theory because it's super complicated. So that's another day. I just wanted you to get a sense of how hard this is. Now let's talk about what goes wrong and I'll give you an actual example from my life. So I had this former student. I told him in high school. Then ": [
            731.8,
            754.0,
            31
        ],
        "try to determine the centrality of a data set. Of course what happens if they're not an odd number of data points annoyance, right? So if you have an even number of data points put them in order now, there's two that are in the middle and you can just go average the two convention people have chosen when there's an even number of data points there many other conventions ": [
            1878.9,
            1901.5,
            71
        ],
        "two things that slice the data different ways again stratified you're breaking the data and just write it will tend to look different on whatever it is. You're measuring undergrads versus crabs when GPA but when you slice it up, whatever you're trying to measure is going to look very similar you just done this out of convenience. often based on geography Okay. Now those are some ideas but in ": [
            704.7,
            731.8,
            30
        ],
        "use Facebook if you don't like it, and hence, you won't be in the sample frame, right you went from all to just Facebook users. I'm in that category hate Facebook. I know all the studies show decreases happiness. So I stopped using it. Is it funny every single study I've ever read about Facebook decreases happiness makes life worse. But anyhow bad Temple frame. This sample frame does not ": [
            983.2,
            1006.4,
            40
        ],
        "voters. They're going to vote in the 2020 election. So you decide? Okay. I'll call some people on landlines. 1007 say home phone Now hopefully in your soul, you might be a little worried about both of these cases. And the reason your word is because I've injected bias into both of them. So bias is just a word when the sample does not look Faithfully like the population. So ": [
            229.1,
            258.9,
            10
        ],
        "wants to pull the picture desperately down into the right causing the finger to move over to 333 to help balance sub actually using the values that creates a torque idea, which is interesting. Okay, so there you go. There's some picture of the mean and median. Now, let's see if you can think about the relationship in General Tso a few pictures here. The first one is something that ": [
            2064.3,
            2088.0,
            79
        ],
        "we got to stop people are busting at the seams to get in. Thanks for a great class will see you Friday. ": [
            3026.0,
            3030.4,
            115
        ],
        "week, you'll see the value of both of these tools and you'll start to see why decisions are being made the way they do. Now the problem is measures of center or not good enough to help us really summarize a dataset. So here are two pictures. They have the same Center. They're both you and the modal. And yet something is totally different about the two right one is ": [
            2431.9,
            2452.8,
            91
        ],
        "what you could do is send things out to your Facebook friends and he has a lot of Facebook friends 5000 or so because he works at Facebook. So and people he's a friend accumulator, I guess. Okay. So different languages like sample frame Target frame. This is you end up sending things out too and then your actual sample. After send out those 5000 messages on Facebook to his ": [
            829.7,
            852.4,
            35
        ],
        "who graduated from UCSD data already exists. I didn't manipulate those grades. I just go get them or maybe you just sit there and observe a situation behind a mirrored wall. And I have no idea that you're observing them and just like recording ethnographic notes or something. So you're just observing the situation rather than inserting yourself into it. Okay, so there's some sample and it's spitting out the ": [
            1057.6,
            1083.0,
            43
        ],
        "why I said garbage e trying to summarize all the data using two of them. Okay, you can see pros and cons here. A better one is to say let's not go all the way to the 0% and 100% marks in the data. Let's go to the 25% Mark and the 75% mark. Because those are harder to manipulate if you're going all the way to the very first ": [
            2528.7,
            2553.6,
            95
        ],
        "with the median is it doesn't actually look at the data values. It just puts them in order. So for example, if you change one of the data values and the right side from 6 to 990, it doesn't change the median. But somehow the data set is totally different now, right? So you would like some sort of measure of center that actually says hey, what are the numbers ": [
            1926.1,
            1950.0,
            73
        ],
        "you ever wondered what a statistic is. A statistic is a taking your data. Maybe it's a bunch of numbers and doing something to them to compress them down. Okay, it's not helpful for me to have all of your ages 270 numbers phone at me much more helpful. If I could just take the average at the mall and get a single number. And that's what statistics are functions ": [
            1783.1,
            1811.9,
            67
        ],
        "you study if you are the firstborn in your family. If you're the second born in your family goes up by half a percent third-born another half percent Etc. Let's see how you did stratified sample if it's stratified. You should be breaking into pieces. Obviously. We're doing that here LGBT an on Ultra Beauty when you look at the pieces and you start measuring their siblings. You should feel ": [
            1478.3,
            1505.8,
            59
        ],
        "your goal in life is to reduce all by us from sampling or to minimize it if you want to be more honest about what's realistic in the world. So each of these has some bias, for example, when you sample from huge pots of soup some of you know that the heavy ingredients always sink and they're not part of the sample. So maybe the spicing is correct, but ": [
            258.9,
            278.3,
            11
        ],
        "your sample, you can expect out your data from them and then do a bunch of things that we'll talk about later. So this the pipeline and we'll look at all these different steps now to show you what sampling looks like I'll give you some different kinds of examples often when you cook food you want to decide if it has been spiced appropriately correct salt amount correct heat ": [
            190.6,
            208.9,
            8
        ]
    },
    "File Name": "Statistical Methods - A00 - Quarfoot, David James - Spring 2019-lecture_2.flac",
    "Full Transcript": "Listen to a podcast.  Okay, welcome back.  And good morning.  We're back at math 183. Sorry for last class has technology failures. Hopefully those won't happen again. We will get lots of done today or to be beautiful. I wanted to point a few things out before we start.  All sorts of people been sending me emails that you don't need to be sending me. If you just look at things on the internet. For example, the office hours are now up you can see them. This is one of the many documents that's here.  In the 183 Triton add folder off stars in locations. So feel free also to email questions if they are appropriate for email make a decision on whether the thing is answerable and small amounts of text and doesn't require tons of mathematics. If it does then in person is probably better.  I can also see an gradescope that 84 View of already turned in homework 1 do Friday. This is a test of the pipeline. You should already be done with this basically and you should be moving on to homework 2, which is due Tuesday of next week because you can already answer a lot of questions on it. So the reason I don't make things do a lot earlier is because they don't even assign me Graeter's until the end of the week. So but that doesn't mean you can't get going on homework.  Okay enough talking Let's do let's learn things.  So we're going to pick up and continue our study of data and thinking about data and I want to show you this pipeline.  If you want to become a data scientist, you need to understand the pipeline of how data works. And one thing we'll see you at the very beginning is it is very important that the data you collect be. Good data.  And you recognize since you have a memory of 2016 all these poles were basically worthless. Right and it's because that was garbage data collection. And if you form beliefs on garbage collection, you get garbage beliefs. Welcome to almost all data that you get coming at you through the Google news and the CNN's and the Fox news is it's all garbage data. So how do you make better data? And how do you put it into a nice pipeline? Well, we're going to start here. There's some population you want to study  If a population of 20 people talk to 20 people and be done. Okay, that's not a hard problem hard problems or when the population is millions of people and there's no way you could talk to them all if you try people died as you were trying to go talk to everyone and new ones are born so it's not even possible.  So what you do is you draw what's called a sample that is a small representative. It was stration of what this huge monster energy looks like and if you do this in a really good way, hopefully the sample represents the population until you can use the small group to understand a large group. Now it turns out this is very difficult to do as you saw again the smartest people in the world basically all got it wrong.  Just a couple years ago. Once you have your sample, you can expect out your data from them and then do a bunch of things that we'll talk about later. So this the pipeline and we'll look at all these different steps now to show you what sampling looks like I'll give you some different kinds of examples often when you cook food you want to decide if it has been spiced appropriately correct salt amount correct heat level and so on right? So you have this huge pots. You don't drink the whole thing in order to decide if it was done correctly. You take a few spoonfuls, right? This is a sampling. Now it may or may not have gone. Well it may or may not have been a good sample.  We'll look at reasons why you could not in Sac maybe want to sample all voters. They're going to vote in the 2020 election.  So you decide? Okay. I'll call some people on landlines.  1007 say  home phone  Now hopefully in your soul, you might be a little worried about both of these cases. And the reason your word is because I've injected bias into both of them. So bias is just a word when the sample does not look Faithfully like the population.  So your goal in life is to reduce all by us from sampling or to minimize it if you want to be more honest about what's realistic in the world. So each of these has some bias, for example, when you sample from huge pots of soup some of you know that the heavy ingredients always sink and they're not part of the sample. So maybe the spicing is correct, but the chicken is not fully cooked. You've done a good sample. You know that okay another one home phones who has those  My parents are almost ready to give up. There's and their ancient so the only people get on home phones or  Well, I'll let you just put that in there. Anyhow, another problem with the sample. The next election is a future event people might say they're going to vote in some future event, but will they  Okay, awesome things come up the day of and then like I couldn't get to the voting booth, even though I wanted to so you can't trust the reliability even on their own internal judgement of how they're going to do. So turns out to be quite difficult and every time you try to be clever, it turns out to be a big mess. So let me show you how to not be clever.  And to get things right believe it or not. So here's how it begins. The population are huge. Big Mass. Maybe it's all people in the u.s. In case you set this in your goal time is your goal. Okay. Now you can't always get at everybody. That's a problem. So immediately would you have to do is make  some sort of  Play production the sampling frame. This is the actual Universal be pulling from in a perfect world. It would be the population. But the problem is I have no way of getting all people in the US some people live in Alaska in the middle of the nowhere Middleton or off-grid right? So how you going to get to those people you have no way. So one thing you might do is say let's just use Social Security numbers from the Social Security Administration database approach already lost all people that don't have social security numbers, which is tons of people who live here.  But if you can set up a sampling frame where you actually have access to those human beings then at least you can begin doing something actionable.  Okay. Now you have this big long list of social security numbers, you could randomly choose people from it.  If you do this, you've created what's called a simple random sample SRS.  And it turns out this is one of the best possible things you can do. If you can delineate every single person in your population at least in the sampling frame through some identify and then randomly choose people from that list and then go out and talk to them. This is better than almost any other strategy that can be devised because everyone has an equal chance of being included and when you randomly sample your sample tends to look like the population. So here's a visualization. Maybe the whole square is the whole universe of people there all the pixels in there and you just color some of them blue. And those are the ones you go to.  It's simple because you didn't do much in terms of fancy methodology and it's random because you some random number generator or pseudo random number generator and some computer program to choose the people. So there's the best possible approach for many situations now, it's trying to get fancy.  And this is very dangerous to get fancy because you can inject all sorts of bias.  What are the problems with simple random samples if you're studying something very rare.  And he's choosing people. You may not get any of those people who have that rare trait to them.  So sometimes you know sort of a high-level how your world is structured. So what you do if you break it into strata or sections or pieces.  So let's say you want to know the average GPA of UCSD students.  Well, you could decide to break the whole world into those people that are undergrads versus grads.  And one reason you might do this is because you want to make sure both populations could really included.  No, they don't occur in the same amount, right? There's a lot more undergrads in there are grad. You can factor that back in issue recombine all the data together by waiting it appropriately if only 20% of people are graduate students. Okay that goes into 7 calculation. Now the reason you do this is here. You have a sense maybe undergrads have much different GPA in this when you go to graduate school and all the grades are free and everybody gets A's and B's it's very hard to get a c in graduate school. You have to really try to do nothing.  Okay, but it's hard to get A's and B's in undergrad.  I don't know why this is some artifact of how we've done things for a long time weeding people out. Whatever. I don't know. It seems reasonable to you. So if you knew this different you would want to really make sure graduate students got included. So you just say we're going to talk to some grads. I'll do a simple random sample on those. That's the right hand side and I'll bring it back way. I see broken up and the pieces you broke it up into look different.  In relation to what you're trying to measure GPA.  They may look similar. In other ways. Like where do they live San Diego? They look similar, right, but they're different in route in relation to how you broke it up. Another thing that people do is go cluster sampling.  So here you take your population and you slice it differently.  So the idea and this is you still create slices or strata won't call them straddle. Come in clusters. Have a different word.  But maybe you say okay. I don't know. How do I go talk to graduate students. How do I talk to undergrad? None of that is operationalize herbal, but what I can do is stand in front of my gym.  And if people are coming in to say what's your GPA? What's your GPA? What's your GPA and I'll send my friend to a different gym and a different friend to a third gym. Okay, so you sliced up your data from the people who go to gym 1 vs 2 3  But what you'll notice is as you're asking people their gpas difference between these layers.  Dog and include some undergrads and some grads. It's all going to a dance together to like a 3-2 or something. So you and your friends are all going to come back together and you're all going to be staying three two, or three one. That's the average GPA.  Why would you ever do such a thing well?  It actually helps you operationalize and I know I can go stand somewhere and collect a bunch of data. People are coming at me. It's much harder to get access to the schools ID rules that identifies people's gradual suits in undergrads and then randomly pick from it. So this is as a way to create something that's physically doable. That's it problems on there this year like some people don't go to the gym. They're not included in. This has to go to the gym. So that's not representative of the population of always UCSD students.  But it's often done. If you something like geographically you want to study San Diego may be breaking into clusters based on neighborhoods, like Kensington and UTC and so on.  Okay, so people get confused when they see two things that slice the data different ways again stratified you're breaking the data and just write it will tend to look different on whatever it is. You're measuring undergrads versus crabs when GPA but when you slice it up, whatever you're trying to measure is going to look very similar you just done this out of convenience.  often based on geography  Okay. Now those are some ideas but in truth if you really want to get good at this you take an entire class solely about sampling Theory because it's super complicated. So that's another day. I just wanted you to get a sense of how hard this is.  Now let's talk about what goes wrong and I'll give you an actual example from my life. So I had this former student. I told him in high school. Then he went on and went to Facebook and he is now in charge of data security privacy concerns a Facebook member that Cambridge analytica thing is he was the person that had to fix that.  We talked on the phone a few weeks ago. It was a disaster. Basically, it's very hard to fix something that happened when he was in his early days that the company boss comes and says, I want to know how much Americans love Facebook.  simple question  very hard to actually study. That's the problem. So here's what he did. He said here's the population all Americans and the idea the measure on them is love now. I don't know what that mean with lots of ways. You can get this 0 to 10 love scale. Whatever. I'm going to already. There's some measurement issue involved. So then he said, okay. Well, that's interesting. How am I going to get all Americans?  People off grid in Alaska. Good luck. Okay, so he said, you know, I'm just going to sample Facebook users because I work at Facebook and I can send things out to Facebook users.  This box has no you can't just end things out to Facebook users. We don't allow that here. But what you could do is send things out to your Facebook friends and he has a lot of Facebook friends 5000 or so because he works at Facebook.  So and people he's a friend accumulator, I guess. Okay. So different languages like sample frame Target frame. This is you end up sending things out too and then your actual sample.  After send out those 5000 messages on Facebook to his friends 437 replies that turns out to be the sample.  You may have cringed. I hope you did.  So we're going to go from bottom up and tell me the cringe Factor as we went from 5000 down to these 437. What are you bothered by in that transition step?  Go ahead.  Okay, so to reiterate you said large drop this could be very worrisome. What do you think?  Good. So you said something about response with the people that respond to things are not representative of all human beings you want to know who responds to things women respond to things far. More than men. It's just a statistic.  So this is obviously not representative and I'm quite worried about how she responded. This is a big issue volunteer bias. There's a lot of different words for this. You can't trust volunteers about anything in terms of the representativeness of the larger group that you went to talk to.  Okay, what about the move from all Facebook users to the 5000 friends of my former student? What bothers you  Go ahead.  Good.  Who do you think his friends are people that work at Facebook if you work at Facebook you probably like Facebook done. So there's all sorts of names for this. Some people call a convenience sample bias. You don't need to know these exact words. Really you just need to have in your soul that something bad just happened and eventually when you take a sampling class, you can learn all the language for this kind of nonsense and finally from the top step down. What bothers you there.  In the very back.  You're not going to use Facebook if you don't like it, and hence, you won't be in the sample frame, right you went from all to just Facebook users. I'm in that category hate Facebook. I know all the studies show decreases happiness. So I stopped using it.  Is it funny every single study I've ever read about Facebook decreases happiness makes life worse. But anyhow bad Temple frame. This sample frame does not represent the population done. So as long as you feel this in your soul, that's what you want right now and then you can organize them later in life. Now. Let's talk about data.  Let's say you have a beautiful perfect sample. What are the different ways that data could look or be structured about it. So let's just talk about the two high-level differences. So maybe your data came from what's called an observational study.  So this is a vague term that has a rough definition, but the cleanest thing is just to say that when you collected the data.  You did not interfere or manipulate how those data came to be.  So one way this happens if the data already exists and you just go collect them, for example, if I want to look at scores of students who graduated from UCSD data already exists. I didn't manipulate those grades. I just go get them or maybe you just sit there and observe a situation behind a mirrored wall.  And I have no idea that you're observing them and just like recording ethnographic notes or something. So you're just observing the situation rather than inserting yourself into it. Okay, so there's some sample and it's spitting out the data and you haven't messed with this Arrow.  Thing happening. It just flows out naturally unhindered. Okay, so getting transcripts this is called extension date. I do that already exists. That's one way to make sure you have an observational study study newspapers from me and usage unless you wrote the newspapers.  This is observational just looking at what's going on in observing Society observational study is not the gold standard for many people when it comes to research and they care about something known as an experiment or randomized control trial. So here you are manipulating the way or the the way day to get created Guided by the hand of the researcher and I'll show you the most common thing here you want to study some population. So you study some sample of them and you break them into maybe two groups or three or however many you need.  And there's certain things happening to those groups maybe ones getting a drug maybe ones not getting the drug.  So when the day to pour out you have influenced the structure of what's going on.  So this is one way to isolate things that matter to you for example of the drug works or not while you're putting things into two groups or one gets the drug and one doesn't so it's the dataflow out you will be able to have some sense of other things work or not. Okay, so often randomized controlled drug trials looks like this. Here's another one does waterproofing material work. So go put it on 50 phones and submerge them in water and take 15 on waterproof phones and submerge them in water and see if your new waterproofing technique works.  As phones break or not. It's because hardly you put the waterproofing on or you didn't.  What's if you've seen this idea in life by now, but hopefully now you can contrast it with observational studies. Another reason. This distinction is so important is because the conclusions that you can draw from these are totally different.  So whenever you have an observational study.  If you start to notice some interesting trend.  Then it's just an association. There's no causal relationship.  But if you run an experiment and you notice an interesting friend going on then you can infer causality because what's happened is you've wiped away every other possible explanation except for the causal one. So here's what I mean by that when you take a bunch of people and throw them into two groups.  If you choose their group identity randomly.  Then group a and Group B look totally identical basically just because Randomness create identicalness.  They look identical on every single trait. Their ages will look the same the balance of genders will look the same Etc. The one way the only way in which the groups differ is what they're getting from. You treatment versus control. Did they get the drug or the placebo?  And so if you see differences in the data coming out, they're not from underlying structural differences between the groups.  There because of the effect you created now, even this structure has problems.  So if you don't people randomly into two groups, and then you give some of them a pill and say this is I think it's yours. Whatever your ailment is.  Turns out people to start feeling better. Even if you don't really give them the drug known as the placebo effect.  So if you blind the study then you don't tell people what group they're in. I don't know what group you're in. Here's a pill take.  It might be the placebo might be the real thing.  So you still have the placebo effect in both groups now and then you have the actual effect if the drug does anything that's not enough. Sometimes you have to double blind it in addition to blinding the people to work for you and you have to Blind the researchers so they can't know because if I know what group you're in and I hand you the pill.  There might be subtle things. I do that indicate to you. Which group you're in because I know if you're if you're in I've been part of a double-blind experiment related to asthma when I was a kid and we didn't know a group I was in so was blinded and the doctor didn't also and my mom said we have to make sure the David gets the medicine. He's probably going to die if he's not in the correct group and the doctor said, I don't know. I'm sorry. This is actually true and luckily I was  Okay, let's go to surprise him enough for me talking.  If you weren't here yesterday, we downloaded this app. You can go to app stores called Socrative. You can see the spelling in the upper left corner here.  What I do is I launched a quiz that goes out all your phones. Now. You have to remember the name of the room. It will always be my initials, but you're right here at the top do you qu?  That will get you into the room. You can see how many people are in the room right here the number to the right of the bar.  Now you can do this on your computer. You can do this on your cell phone. The worst thing you do is watch your friend do it. No. This is not graded. This is just for you to learn stuff.  I'll post these on the internet slightly before exams. So if you want to review them that's possible also.  You want to find out the average number of siblings for UCSD student?  You get the school roster and choose names using a random number generator. What type of survey did you just do?  We can also see how well you did in real-time good. Everyone understands a simple random sample now, basically  you read that LGBT students tend to have more siblings.  Because your chance of being LGBT actually goes up as you get later in the birth order.  Is a true statistic?  Your chance of being a gay male based on surveys observational studies is about 1.5 to 3% depending on what population you study if you are the firstborn in your family.  If you're the second born in your family goes up by half a percent third-born another half percent Etc.  Let's see how you did stratified sample if it's stratified. You should be breaking into pieces. Obviously. We're doing that here LGBT an on Ultra Beauty when you look at the pieces and you start measuring their siblings.  You should feel like you're going to get different answers. That's how you know, it's stratified and here you do know because of all of this text above 80% That's good.  How did you ask all the students in his math 183 class using Socratic?  So tempting to put Buster garbage sample.  You can see in the explanation here. Now if you went and you said okay, we're going to slice up the population into lots of clusters will use a stat class. We use a CS class. We use a Humanities class then it starts to feel cluster e but here we just taking a beautiful huge complex population of 35000 in reduced it to 270. That's just garbage.  There's no slicing. It was just a shrinkage is all that happened. Okay, obviously, we haven't used cluster yet. So I'm not going to give you a question where you have to choose cluster. You're going to have to tell me which to do clustering.  Noticed you can select multiple correct possible answers.  Okay, so you can see the day and see or wrong. They're slicing it out. But the question is to the slices look similar or do they start to differ? So for example, the first one if one of the groups of people who has siblings attending UCSD all automatically, you know, their sibling number is greater than or equal to one could be even higher and the people that didn't have a sibling could give the answer 0 so their average is going to be a little lower.  Okay, minivans and fly lots of human beings lots of siblings so on.  From which of these studies? Could you infer causality?  Okay, ask yourself did the researcher have a hand in dictating things or did the data already exists? Or maybe they just watch the day to get created. So B&C the data already exists college graduates. They're done on KK scores already done.  So in a did they influence it will they assign them to one of the two groups randomly? So there is the researchers hand now Diaz harder.  So if you go injected 50 rats with fire Benzene, look at their average lifespan, you're probably comparing it to rats who have not been injected with pyro benzene.  And that data probably already exists. So sometimes it's more subtle and you don't have to mention other things. Although that's not the best way to do a study. Let's take all of your beautiful day. And suck it up into my computer sound good.  So it's every year I get rid of the questions that are too easy that everyone gets right. So the first question has finally  Met its demise. It will not be asked anymore and harder things are put in place.  Okay. So now you understand roughly some macro is too structured data. Let's hop to the end here and how you summarize data.  So if you ever wondered what a statistic is.  A statistic is a taking your data. Maybe it's a bunch of numbers and doing something to them to compress them down.  Okay, it's not helpful for me to have all of your ages 270 numbers phone at me much more helpful. If I could just take the average at the mall and get a single number.  And that's what statistics are functions applied to data to produce a single value. Okay. So one thing I've noticed istics always come from samples the SS parallel here will be important later. We'll talk about populations and parameters that start with the letter p  Okay, so there's lots of choices for how you might summarize your data. You will be well-versed in some of these and others will feel a little new to you. But let's organize some things you saw in 4th grade into a larger hierarchy. Sometimes you care about where the data is entered its centrality now, that's a big word in there. Lots of different ways to do this, you know, one of these is called the median. So all you do is you take your data. Hopefully it's numeric. Otherwise, you're in trouble you put it in numerical order from smallest to biggest and then there should be a number in the middle. So the median of the road has an equal amount of Road often on both sides just like the median of a data set has an equal number of data values on each side. So hear the meeting is for you probably seen this before now, you can recognize it as one of the many measures that try to determine the centrality of a data set.  Of course what happens if they're not an odd number of data points annoyance, right? So if you have an even number of data points put them in order now, there's two that are in the middle and you can just go average the two convention people have chosen when there's an even number of data points there many other conventions one could have chosen on how to resolve these middle two things into a single number but the average is the most common  Okay, all sorts of pros and cons to this.  Will get cities in a moment, but let's look at another one. This is your good old friend the mean also known as the average they are total synonyms. You should blend them in your brain.  The problem with the median is it doesn't actually look at the data values. It just puts them in order. So for example, if you change one of the data values and the right side from 6 to 990, it doesn't change the median.  But somehow the data set is totally different now, right?  So you would like some sort of measure of center that actually says hey, what are the numbers that we're looking at here? Not just which one happens to be in the middle if they were to be ordered.  So in this case, you're going to go average them together and you'll notice that the mean of the first is 5 but suddenly the second data set has a huge meme.  What you're saying? There's something interesting going on with your values, even though they have the same median.  Now it sometimes the mean is a better choice. Sometimes the median is a better choice.  When you should not do is insert a false binary in which one is better always is a silly way to approach life a more nuanced way as what are all the options and in which settings are some better than others. And for what reasons that's the right way to approach this now, we can visualize this some people hate formulas and they love pictures.  So here's a histogram of a bunch of data and you can see that I've color coded it.  And put the median down. It will be a place on the x-axis and half the data values or to the left and blue and half her to the right. So it's the place to to which the left sit have to do to into which the right has half a date on some histogram the x axis of a histogram if you want to think about it that way now the mean there's the same dataset you can see if you read the same but the mean will not be at the splitting point of color. It will be at the balancing point. So if you put a little fulcrum and you kept a histogram out of paper and you try to balance it on your finger, it's where your finger goes and the reason that happens is the mean actually uses the data values like 990 in on this picture 990 is way off to the right. So there's a little block of color way over there.  And that creates a pork arm on the picture where wants to pull the picture desperately down into the right causing the finger to move over to 333 to help balance sub actually using the values that creates a torque idea, which is interesting.  Okay, so there you go. There's some picture of the mean and median.  Now, let's see if you can think about the relationship in General Tso a few pictures here. The first one is something that has very little skewed to the right. We're starting to get more right skew and then we have high right skew  Will the mean be less than about equal to or greater than the median in each of the three pictures. I'll give you a minute to come up with a beautiful response and then we'll call on someone.  Okay lunch to go.  You get one or two clean beautiful sentences.  Go ahead.  The mean should be greater than the median cause in which pictures.  In high school pictures you claim. The mean is greater than the median cuz  the outliers there may not be outliers.  You do know.  You're going to help help.  Louder, please.  Okay, so I'll serve you right but I think I heard they're all these data values that are spilling out to the right hand side way far and if you think about what those do to the torque on they. Tour way out there on the right hand side. So the mean has to move over to account for those spill out and they might even be outliers. This picture doesn't happen to have any family that won a 20 in the center or the middle one. That's exactly right. So this how you should think about this.  This issue so as things get more skewed the mean and median depart from one another. So the question of which one should you use depends on whether you want to account for that movement and it matters to you or do you want to avoid that and it doesn't really matter to you. Okay. So here are the actual numbers. I just plug them into our to see what the mean and median were and you can see from low speed to high school the difference between these two keeps growing.  And in fact, the mean is greater than the median.  This is true in most cases for most unimotor things.  But there are weird counter examples.  So in general right skewing tends to move the mean higher than the median but not always your textbook will get that wrong when it's make that claim just so you know, but it's good to know roughly what happens if Emily left giving things are going to pull the mean to the left of the median. Okay. So let's look at it with some actual simpler day two sets of History data sets. All I've done is change the top number from 7 up through 700 and I can go calculate the mean and median and both you'll notice the median is totally unchanged by the alteration of one data point.  So if you would like something that is resistant to that kind of change and look sort of centrally what's really going on in the middle of the dataset and doesn't care about the end. The meeting is a great idea. But if you want to be honest to that reality for whatever reason than the mean would be a great choice, so here is often what people do in society.  They tend to use the median when they have weird distributions or things with outliers.  Because people tend not to want to talk too much about the outliers. They tend not to want to think about that housing prices home price. Maybe even heard that phrase. Maybe you bought a house before in San Diego is like 490,000 or $500,000 days and you don't want that disrupted by the homes that cost 15 million in La Jolla because you're probably not buying one of those. So that's why they use the median there. They don't want it all skewed by the million-dollar things on K people send you some mean when they have nice distributions that don't have outliers. The reason people I mean the mean and median starts become the same thing in that case believe it or not. So one could just always use the median if one wished but the problem is most people understand the meaning because we use it everyday so much.  So there's a good reason to use the mean if you can.  So I would say try this rule for a while. See how you like it.  And then remember that you can choose between the two things. So every time for the next two weeks when you hear someone talking about the mean or median say is that what I would have chosen do I want to Leverage The outliers in the screw into the calculation or do I not  and after you do this for one week, you'll see the value of both of these tools and you'll start to see why decisions are being made the way they do.  Now the problem is measures of center or not good enough to help us really summarize a dataset. So here are two pictures. They have the same Center. They're both you and the modal.  And yet something is totally different about the two right one is sort of skinny and then puts all of its weight.  Near the median in the other sort of slowly spews out and has tons of data in a huge range. So we need a way to talk about the difference between these two and that's encapsulated in the spread.  So it's Brad again is just a vague word trying to capture how far you have to go out in order to grasp most of the data on the one on the left. You have to go like a unit or two and you've gotten almost all the data, but on this right one, you got to go way out all the way to 2 and 8 probably to think you've gotten most of the data. So, how do you measure the spread again? Lots of ways first idea. This is the most garbage e,  All you do is you take your entire day to sit and you say I'm just going to look at the biggest value in it and the smallest value subtracting and get that span. So 100% of the data will live in this spam and your reporting how big that span is.  So this is sort of losing all but two of the data points. That's why I said garbage e trying to summarize all the data using two of them.  Okay, you can see pros and cons here.  A better one is to say let's not go all the way to the 0% and 100% marks in the data. Let's go to the 25% Mark and the 75% mark.  Because those are harder to manipulate if you're going all the way to the very first number in the very last zero on a hundred percent of the way into the day. If you just change those values, it just totally changes everything right you just dip your way in a 25 + 75%  and subtract those from each other than you're something that's a little more robust. So these are known as the upper quartile and lower quartile. So here's an example in some high school class that I asked a bunch of students. Okay, most of them up here, right?  Favorite prime numbers my goodness in order that was nice to me and wants to know where we can find the median which is known as the middle quartile or tell Stones like quarter 4/4 or 4 quarters in a dollar. So two quarters in is 50% of the data in so then the number 7, so then what you do is you take all the numbers to the left of the red circle.  And that is the first half of the data and you find the median of that so half of 1/2 gives you a quarter if you just found 25% of the way into the data.  And there's an odd number of things you can choose the middle one. If there's an even number then you have to average them. But here we have an odd number of things. So I just chose 3, so that's known as the lower quartile or q1. It is one quarter of the way into the data.  Just like you one for business people is 1/4 into the business cycle. If you've heard that kind of language before you can take the top half ignoring the median you can look at it. It's median and you can see that it's 13 and then you subtract those two numbers 13 - 3 is a distance of 10 Au in a distance of 10, you have encapsulated the middle 50% of the data.  Or if you subtract the ends in a span of 17, you can get all of the data or 100%  SMSD IQR interquartile range it goes between the quartiles and you can summarize all these beautiful numbers into something known as the five number summary people love this because it gives sort of the most important things about your data set. So you're going to tell them the smallest and biggest numbers computer can figure those out using sorting algorithms etcetera CS people in the room now depending on where they want on square toe and login etcetera. What kind of speed  So here's about here's a list of these earthquake magnitude in the US 221 different earthquakes. You measured their magnitude on the Richter Scale now 50% of the data live between the first and third quartiles and the distance between those two numbers is the IQR how far in distance to we have to go to capture what we want and over here. There's a hundred percent of the data and there's the range so it's cool the five number summary gives you both of those measures of spread if you were to want them.  No, I tend not to use those very much. Hopefully went to discussion section and they took both standard deviation will do that in the moment. And that's tends to be more common. Now. Here's another really important visualization. This is known as a box plot.  So instead of making a histogram.  to show your 221 earthquake magnitudes  You can put them in this figure right here. So what it does is it draws a box?  And screw this middle rectangle that took three horizontal lines.  Okay. So those three horizontal lines accurate occur at q1 Q2 and Q3.  So the height of this box is the IQR.  So that's where it shows up in that picture. Now. The next thing you do is you taste Q3.  The upper quartile and you go a distance of 1 1/2 IQR is above that of the IQR. Is this box Heights Hugo one box height and then another half box height and you draw something on his defense.  Now John 2p was a statistician who decided we should go one and a half up from Q3. And he also decided we should go 1 and 1/2 IQ ours down from q1.  He thought that this was the right amount to go to be far away from the central core of the data. And when you draw those fences any datapoints that live beyond them you visualize with a circle and these are outliers according to the box plot definition last house. We saw outliers is just some big word and we all emotionally felt at the page.  Hey, so if you want to rigorous definition according to John tukey of what an outlier is.  Now you have it great.  Now so that's what the dots in fences are. Now, what about all the data that you still haven't captured? There may be outside Q3 and outside you one but are still in the fences. So you draw a little whisker and you go go go until you get to the last data point that lives inside the fences and you do the same thing down there. So what it says very quickly is the mass of your date of the 50 Cent 50% Central is this box and you can see how much it's worth of spills out.  And also there's some truly anomalous data points. And those are the dots on KB on the lower and upper whiskers.  So there is one definition that you should know for outliers the people often ask you about and you can decide using that definition if you want. It's easy to make a boxplot in R. You just take boxplot whodathunk Addie anything else but the name of your data frame but a dollar sign to pull out the column of data you care to make a boxplot for and then you have your box plot, and it does everything for you.  Now in the last 2 minutes, I want to talk about the standard deviation formula. I hope you went to discussion. They often talk about things that we don't have enough time to talk about here.  So this is the most important measure of spread in my opinion.  So here's our data set. It has n values. Those are all numbers.  You can immediately find the average of those numbers. If you want. We will use a notation y bar or X bar to mean the meme.  Okay, so Dad itself is a number that's the measure of center. So now you can calculate the standard deviation of this formula is intimidating when you first see it.  But in this class you will get lots of experience using it on homework to so here's the idea.  This song is going to go through every single data point you have and what it's going to do is going to take the data value why so by and it's going to see how far it is from the meat that's what this difference is.  And that's measuring service spread?  Now some of these spreads these differences might be positive and some might be negative depending on whether the date is above or below the mean so I don't want to just add all the spreads together.  Because the positive and negative stuff will cancel out so you swear to make it positive and eventually you take a square root to sort of undue that's wearing action.  Now the hardest part about this was the division by 10-1 you want to sort of average together all the deviations?  And so you might think we should put an end here if you take 181a, you will finally learn why there's an N -1 instead of an end has to do with something on his bias that we can't talk about here. And now we got to stop people are busting at the seams to get in. Thanks for a great class will see you Friday. "
}