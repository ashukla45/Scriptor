{
    "Blurbs": {
        "2 squared / N2. So what I'm working very hard right now it's doing this coming up a distribution. Of the difference of the averages that come out of our two populations. It's a very complex object, but it's actually the easiest way to study these two populations. It's a sample from both and subtract what's going on with the individual averages in Okay, so I wanted to show you ": [
            2313.9,
            2342.6,
            82
        ],
        "About a datum in the second population and there's a perfect linkage between your worlds and you could even pair up your data and some nice way. Then this is called paired data down here at the bottom. It's however your two different worlds. There's no way to sort of leap across from one to the other. And if I know the value of R in the first one, it ": [
            232.8,
            256.7,
            8
        ],
        "And I'm trying to get 95% of the area. Because it's a 95% CI to be Central to it. Okay, so you end up taking that 95 Central Area take an extra two and a half on the left side, but you don't really care about its sweeping through all that to get to your T star value. So we get this number 1.999. Feel so Tui. Now one of ": [
            639.5,
            668.7,
            24
        ],
        "And knows you can call this data values X if you want I can be the name so they had an average and you just had your confidence interval by using this kind of formula. When we took a pair dataset and then took all the differences that made a long list of data. I wouldn't call it acts like cardi maybe for the differences and took you wanna build ": [
            2474.7,
            2497.0,
            87
        ],
        "It's the hard work is really in the reading comprehension. Easy stuff is putting stuff in the formulas that most students find the second half of the class easier than the first because the second half is mostly dictated by a small list of formulas. And as long as you have a good reading comprehension and can convert statements about the real world over into some statistical setting then it's ": [
            2622.5,
            2646.6,
            93
        ],
        "Listen to a podcast back everyone. My voice can make it or not. I was on a no speaking requirement yesterday. So hopefully I saved up all my speaking and I just noticed something when you teach at 8 a.m. The batteries on the microphone never fail cuz I think they were placed in every night. So I don't have to switch my batteries out anymore. I don't care too ": [
            1.9,
            36.2,
            0
        ],
        "Obviously, those aren't the same number but statistics far apart that they couldn't be the same, but we've got to stop perfect timing. I'll let you guys read the rest of the slide for this example. Have a good day. sandiego.edu ": [
            3000.4,
            3025.1,
            107
        ],
        "Okay, it's just complicated here because the random variables are averages and their model by T distributions, which is irrelevant in this case. Okay, so if I take the variance of this first distribution That is a need to square the standard deviation. I'll get S 1 squared / N1. And then the variance of the second thing here. We need to square the standard deviation. So we get S ": [
            2288.5,
            2313.9,
            81
        ],
        "Okay. So here's the women argument more women go to college these days. That's true. Actually somewhere between 51 and 54% of all college students are identified as female depending on the school you're at what is a recent trend? So have these women who have gone to college more off and had the chance to make babies yet. Okay, so I don't know right? Okay, here's an argument that ": [
            1304.8,
            1332.8,
            45
        ],
        "So all you have to do from now on is first decide which of these three rows are in by reading the problem and saying while we're there two populations are one if there were two populations were the data collected in such a way that pair them up or not. Hey. Then get you to one of these formulas and then you just need to use the appropriate pieces. ": [
            2598.7,
            2621.1,
            92
        ],
        "We already know that's very slick to reduce two things down to one. No new infrastructure was involved. You just have to wrap your mind around the fact you're working on differences. Okay. So if we're back in our old universe, but we're just studying differences then everything we needed to be true about the data and that old Universe just needs to be true about the difference is now ": [
            970.0,
            989.8,
            35
        ],
        "a confidence interval take the average of the differences in pad. Okay, and finally if you can look at two different populations Do you want to build a c i take the individual averages in your samples and subtract those averages? That's your best guess on what's going on when you compare the two worlds and then pad it? Switch to notice here. Is that everything looks so similar? It's ": [
            2497.0,
            2519.9,
            88
        ],
        "about averages and you only care about UCSD cuz what else is there in life? Okay, maybe height of aliens Planet X and Y. Okay. So here is really two different worlds literally and you want to measure Heights and some unit system. Then we have husbands and their wives assuming heterosexual marriages. And then finally you could do IQ scores of moms and dads of gifted kids. Okay. So ": [
            115.5,
            144.9,
            4
        ],
        "about individual husbands and their wives you can just tell me this couple had a difference of age of two. Which means in this case that the husband was two years older and this was -3, which means the wife is 3 years older or the husband was three years younger everyone think about it and was cool as you go from two columns of data down to one and ": [
            378.7,
            398.7,
            14
        ],
        "about one goes across to the other. It's a perfect cuz there's variability and everything. But as soon as you know, the first numbers bigger going to predict the second one is Big, although there are plenty of counter examples to this in life. Okay pre and post weight. So these are measurements on a different human beings going through some weight loss study. And you can measure them before ": [
            331.1,
            353.4,
            12
        ],
        "all these fancy East Coast private schools average SAT score with a 1530 or 1550 out of 1600. So people are obsessed with gifted kids. They feel like if you understand that Universe then maybe you could lift everyone up to it or something. I don't know why people get so obsessed. I just like This world for some reason. Anyhow, here's a question. I love this. If you look ": [
            1181.8,
            1210.9,
            42
        ],
        "also going to be a big number probably cuz you're in the southern hemisphere, which is warm on January 1st. Okay. That's the thing. You have to decide when we start studying this data what curve we're going to be on to help us understand it. So here we have a list of 62 numbers. And we're going to explore that list. So it's really just a one sample. Study ": [
            536.4,
            563.6,
            20
        ],
        "always your best guess padded. The only things that really change our what's going on with the degree of Freedom. Now, the first two cases are all the same. So the first two cases are the same because in the engines making a long list of numbers. MK watches and things in it. So your GF is in -1 and your standard error of some sort of standard deviation. It ": [
            2519.9,
            2543.6,
            89
        ],
        "an unequal number of things. But it could happen that you're too independent worlds and you just happen to randomly choose the same sample sizes. Another way. You can know your data repaired is if there's a difference column listed on the page. Although you could be really mean and try to trick students by putting a different column what I do that. Who knows? Anyhow, so let's take a ": [
            1384.7,
            1410.9,
            48
        ],
        "and Snodgrass is 0 if you like you can set this up as Mew x equals me. Why? The reason you might set it up if the difference is because you end up studying differences in order to answer the problem. So it remind you of where you're going to that's all and here I could be excited about a two-sided alternative. As long as the twin thing is bigger ": [
            2920.7,
            2944.2,
            104
        ],
        "and all of Statistics. It's just a long and messy. So hopefully we can all agree to be conservative for the moment on this thing. Okay next thing. The things we want to take the difference out or not. Just simple random variable. They're actually averages. Okay, so I'll call him X and Y instead of X1 and X2 for a moment case ox1 bar, which I'm not calling ex ": [
            2185.1,
            2211.6,
            77
        ],
        "and going ahead and doing a study. Now, what do you do when you set up a null and alternative hypothesis are? Well what you care about the parameter of interest you can always labels Meuse MD. This is the average of all of the differences all of the parents of all of the gifted children, whatever that word means they that is argued about ferociously in the literature. But ": [
            1437.3,
            1470.9,
            50
        ],
        "and it's at similarity. That's very nice for us. So just a few details. So what's new about two populations for a sec now, they're Two Worlds. They're big they have lots of people. And you don't know anything about either so you need to sample from both. So here's some examples maybe care about men versus women and you want to measure this idea SAT score which only care ": [
            89.1,
            115.5,
            3
        ],
        "any good I won't repeat the answer to that. over the microphone Hey, you never know. Play some mix of good and bad in everything, right? Okay. So anyhow, I'm giving you a new more complicated infrastructure, but the cool thing is it fits everything we've been doing so far. So when we just had one population and you sampled from that, you just got a big list of data. ": [
            2441.5,
            2472.8,
            86
        ],
        "at the parents, assuming heterosexual parents of gifted kids will be a mom and a dad. And you might wonder if the IQ of the mom and the dad. Are the same? or not So first thing we're going to argue for both sides here. Someone argue. This is very dangerous. Why either the moms or the dads should have higher IQs than the other parent. You don't have to ": [
            1210.9,
            1247.6,
            43
        ],
        "average together all the proportions from all these different letters and that's a mean. And you can do the same thing for Snodgrass. Okay, so if these people really are the same. Then three letter word percentages on average should be roughly the same. And if the three-letter word percentages are much different. Then author profile Theory says these probably aren't the same human being cuz human beings are very ": [
            2837.9,
            2868.4,
            101
        ],
        "average wants to be near the truth. That's how the universe works if it's a good sample, but there's some spread out in this and what's going on. That's the standard error is 1 / \u221a N1 and you also have the same idea over here just with the subscript 2 everywhere. So the problem is how do we study two universes that are varying? We just have to bring ": [
            1990.5,
            2023.4,
            70
        ],
        "bar so this is actually random variable as you collect different samples, you would get different averages in your sample. And so there's a picture of what's going on for X1 bar. It's actually a t distribution and used to be normal back in the good old days. Okay, it's centered somewhere. The true value of Mew as when you collect a sample and you ask for the average the ": [
            1964.1,
            1990.5,
            69
        ],
        "bars really a t Distribution Center didn't you want and we know what is standard error is it's the standard deviation divided by the square root of n Okay, and the same thing over for what we were calling ex to borrow which of Kauai now just to make it easier. Because I didn't the two things I want to subtract. So whenever you're to subtract 2 T distributions, the ": [
            2211.6,
            2234.7,
            78
        ],
        "be in the 5,000 articles that have been produced about this not the one study I cherry-picked to demonstrate something to you. Okay. Anyhow enough about that. Whenever you run a test, you always have to make sure that you've met all the conditions that are necessary. So here they are. What's going on? This time is since we're doomed repairing up our data and looking at the differences. This ": [
            916.9,
            946.1,
            33
        ],
        "believe what you're saying. It just has to be reasonable. Danger Go ahead. Okay. So this is the historical cultural argument. The men will have the higher IQs because historically societies put resources more toward men than with it. Okay. I don't know if it's true or not. Thinking binaries. Anyway, it probably has some truth. Or negative truth. I don't know. Okay, you can ready to argue the opposite. ": [
            1247.6,
            1301.2,
            44
        ],
        "book to the next until you know, this you can pick up certain authors and instantly feel like you know what Stephen King's writing feels like or JK Rowling, you've all read those books, right? Harry Potter stuff is a certain feel like kind of words that are used JRR Tolkien and you know when you're reading something and then some of these features that stay the same are how ": [
            2763.4,
            2787.9,
            98
        ],
        "but we going to afford into harder situations. Okay. So today we're going to work on two parameters instead of one so far. All you focused on is a single average in some population and then later we'll go to three or more. Okay. So what's new today? Let's figure this out. Well, some of our infrastructure is going to change but the cool thing is that some won't change ": [
            59.6,
            89.1,
            2
        ],
        "by the fact that I wrote roughly here. Now one of the complicated things is which teachers tribution we know what's going on individually in each of our populations as we sample. But when you subtract them, it's even more complicated. So in this class. whenever we look at a difference of two d t distributions it again BT, but will the degree of Freedom will be the minimum of ": [
            2128.8,
            2153.5,
            75
        ],
        "case we do we always do take your best guess of what's going on for what you're trying to measure. And Pat it. Each way. So in this case, we need the t-distribution help adding and the standard error formula is going to be what it usually is. It's always a standard deviation over square root of n standard deviation. The thing we're measuring is not individual temperatures, but it's ": [
            584.4,
            608.4,
            22
        ],
        "climate, but it was back then. Now no one really knows where he was but with interesting the series of letters came out during the Civil War written by this very strange name quintus curtius. Snodgrass doesn't seem like a real name at all. And the style of these letters feels Twain Ian. So some people argue that the letters were written by Twain. And maybe Twain was hiding out ": [
            2700.7,
            2732.0,
            96
        ],
        "consistent. So it's a cool way to use statistics to decide about some weird authorship question and like they've done this kind of stuff with Shakespeare. Also, this is why there's growing revolt against Shakespeare having written a bunch of these things that everyone says are from Shakespeare. Okay, so let's start trying this problem. So here's my notation Mucinex for the tween things, you know are from Twain and ": [
            2868.4,
            2894.7,
            102
        ],
        "could be of the original data in the top line or could be the standard deviation of the differences in the middle line. Okay in this bottom one here this the most complicated we decided the degree of Freedom would be the minimum. Of the individual degrees of freedom minus one. So take whichever numbers less than that list. And we did that out of convenience because the truth is ": [
            2543.6,
            2569.0,
            90
        ],
        "degrees on average in our 62 cities. But there's the rest of the earth. We didn't sample from and the plus or minus here is trying to be honest to that fact. Okay, the .62 to here comes out of our standard error calculation, which is how much are simple very divided by the square root of N and this too has helped helping to decide how big the confidence ": [
            744.7,
            772.4,
            28
        ],
        "difference is not zero, but is there is a difference now because it's a two-sided alternative. I just know that there's some difference. I don't know if the moms are supposedly smarter or the dads. Now, it's cool. As you can go run a new study based on what you're seeing here. Like these data seem to suggest the moms have the higher IQs. So if you wanted to go ": [
            1693.9,
            1715.6,
            59
        ],
        "differences in temperatures. in various cities Luckily, we have all of these numbers cuz I gave them in the problem. And so we can go plug everything in and see what's going on. Now. We need to go find this critical value this point on the horizontal axis for the T distribution has a certain amount of area Central. Okay, so you'll notice it was supposed to be on t61. ": [
            608.4,
            638.4,
            23
        ],
        "do it in reverse if you wanted all the negative signs become positive and vice versa. Okay. Now you have a big list of differences. In fact, there are 62 differences. It's the temperature changes and all your cities and you go find the average and you get one point one. But there's some standard deviation of differences isn't always the same value find a 95% CI for the differences ": [
            483.8,
            509.5,
            18
        ],
        "doesn't help me make predictions over in the second one. This is independent data. You really have two worlds have nothing to do with each other and you're just taking data from both and those are the two Extremes in which there's no linkage across the two universes Independence and there's a perfect start of one-to-one relationship where you can match up everyone in One population with the other which ": [
            256.7,
            280.3,
            9
        ],
        "each of these has two populations some quantitative thing you want to measure and you're really interested in the averages of those two worlds and you be most excited if maybe they were equal. Or perhaps one was different than the other night as you look at these. Maybe something in your soul. Look into your soul. Did it feel a difference between these examples? Hopefully it did. If not, ": [
            144.9,
            179.8,
            5
        ],
        "early to care about him scared me. That's my brilliant observation for the day. Okay, here's where we are. I told you the truth last class. That is there something called a t distribution and it's a more honest faithful representation of what you do when you have meetings and you want to build confidence intervals and run hypothesis test. So we're going to use that machinery and move forward ": [
            36.2,
            59.6,
            1
        ],
        "end of the info your noting that what is in the interval what number that's so important. Pesos zero is in the Centreville. So if zeros in the interval that says the difference in the temperatures across the Earth could be zero based on these data. It could also be negative or could be positive. Okay. So the worst thing you can do is say this proves global warming doesn't ": [
            832.2,
            865.3,
            30
        ],
        "exist because hypothesis test and confidence intervals. Don't prove anything is true or false. They triangulate you toward a belief system that harmonizes with the data that comes out of the universe. Okay. So anyway, so zeros in the interval. So you might want to keep believing that there's been no temperature change. Turn off again. This doesn't prove anything true or false. And also this is one study based ": [
            865.3,
            896.4,
            31
        ],
        "find this sample error, this is supposed to be a standard deviation of the \u221a Aunt Sue have to be given the standard deviation of the differences. You can see the number 7.5 what's incredibly frustrating is you can't find this number 7.5 using the 6.5 and the 3.5. It's not possible. So I have to give you a difference column if the problem is about pair data because I ": [
            1512.9,
            1548.0,
            53
        ],
        "getting the truths and that's what I told people know if it's still black and white. I love it, but now I realize all that was nonsense. so now I do a lot of things that aren't truthy like English and chamber music I just feel it the truth and those sort of an emotive thing. OK it's time for non paired populations your Two Worlds. They really have nothing ": [
            1859.3,
            1888.8,
            65
        ],
        "have to tell you the 7.5. It is possible to find the average of the differences in the sample. This is the 3.4 that's going to be the difference of the two averages. So that is find out about if I just give you the left two columns, but 7.5 number isn't okay. So what are we doing here? We're going to go calculate the t-stat. That's a place on ": [
            1548.0,
            1573.8,
            54
        ],
        "if you could come up with the definition we could all agree upon and you could type talk to all parents ever and take all the differences ever and average them. That would be Mew but we don't have me of sub d Okay, so this is what your nose going to look like. And if we assume that's true, then we're ready to start doing some sort of hypothesis ": [
            1470.9,
            1489.5,
            51
        ],
        "in high school if you're here in America. Some sort of humorist. I guess might be the rest real name for him. So the interesting thing about Mark Twain is he lived during the Civil War by 1865 ish? And people don't really know where he was during the Civil War hard to lose famous people during important times, but somehow we lost him not possible today social media client ": [
            2672.5,
            2700.7,
            95
        ],
        "individual sample size is -1 case of the minimum of seven and nine the smaller number 7. He says the curve all the analysis is going to happen on. now I typed in a bunch of the data into r And I got that the tween average 23.2% of tweens words or two letter words that are three letter words. And 20.97 of the Snodgrass words are three letter words. ": [
            2968.8,
            3000.4,
            106
        ],
        "interval should be based on how often you wanted to capture the True Value. Okay. So here's our interval. What do you notice interesting about this interval? Lower bound is negative. Hence. 443 very careful So instead of saying there isn't global warming will take a tiny step forward don't jump so far. The difference could be negative. But it could also be positive right hook 2.3 is the right ": [
            772.4,
            832.2,
            29
        ],
        "is a very slick thing by the way, I don't know if you felt how slick it was, but let me comment on its thickness. So you feel emotionally with two worlds, and we wanted to study them both, but the study was designed in such a way that the fingers on my hands paired up and create a single Universe are paired fingers and can collapse down to everything. ": [
            946.1,
            970.0,
            34
        ],
        "is known as paired data. So start with the paired data because this is easier to analyze and you're ready have the infrastructure in place. So this is what paired data tends to look like. You have a bunch of columns, you're measuring things about one population in the left and in the middle, you have the next population and because we have husbands and their wives This data is ": [
            280.3,
            304.5,
            10
        ],
        "it. I guess. Okay, and you go see what the high temperature was on January 1st 1970 many years ago. And then you check a more recent time 2016 use the same day. Okay, for each of those cities, you'll go calculate the difference in temperature that was deserved across this 46 year span and I chose the order here to take 2016 and subtract. The 1970 temperature you could ": [
            455.9,
            483.8,
            17
        ],
        "just plugging things into formulas for the most part. the first half of the class had a lot of complexity and it wasn't just simple formulas without her decision making okay. So let's do this is one of my favorite examples in the whole class. So some of you might know this guy. Mark Twain Samuel Clemens birth name so he wrote all these books that you had to read ": [
            2646.6,
            2672.5,
            94
        ],
        "know how to study the difference in two random variables here. They have to be called x one bar next to bar. So they're complicated cookies. But we could just think about for a moment the difference in two random variables. How do you subtract them you roughly get another T distribution? And since everything is approximation is going on all over the place. Anyway, hopefully you won't be bothered ": [
            2097.5,
            2128.8,
            74
        ],
        "letter words 100% of the title. The three letter words. This is a very hemingway-esque thing to do if you can take a bunch of letters, you know her from Twain. And you can take the Snodgrass letters and for each letter you could calculate a three-letter word percentage what percentage of the words in that letter three letters. Now that's a proportion. But what you going to do is ": [
            2813.4,
            2837.9,
            100
        ],
        "long are you sentences? How many words are in each sentence? Okay, if I just look at your words, how long are your words to use big words are small words? Okay, another one what percentage of all the words you use are three letter words. So Hemingway's famous for having lots of three letter words. The old man in the sea you read this the title is all three ": [
            2787.9,
            2813.4,
            99
        ],
        "long as you have a pretty big sample size, so I didn't even show you what the histogram of the differences in our 62 cities look like. Is 62 is a pretty big number. So most doesn't matter what it looks like now, how could you get your paired differences to be dependent on each other the differences? Okay, so here's some examples you're doing your married couple study and ": [
            1048.8,
            1077.0,
            38
        ],
        "look here. First of all, there's a lot of random just going into how people are chosen. So I'm guessing the differences when I go calculate them will be independent. Okay, here's a histogram showing the 36 different differences. This is how Mom and Dad compare. In these 36 families that you're looking at. So this looks roughly normal, right? Okay, so I feel pretty good about us. Go ahead ": [
            1410.9,
            1437.3,
            49
        ],
        "looking at ages, but you choose all of your people from the same church. Like a disco wrong. Well, maybe your church. Only lets people come in who are over 60. So I instantly know that all of the differences here. Have some relationship to each other. Cuz you're pulling from a consistent thing. Okay, if you only do before and after studies on college students. Guess what if I ": [
            1077.0,
            1120.4,
            39
        ],
        "nearest thing. I could 60 And I said we'd like to get .05 in both Tails or .025 and one so here's our number to which feels a lot like 1.99. Okay. So now we Feast our And we're ready to build our interval. Now who cares about the Centreville. It's got to could be useful to you somehow. So let's calculate it and see if we might be able ": [
            688.6,
            717.0,
            26
        ],
        "new center is at the difference of the old centers. This is believable, right? If the first thing is desperately trying to spit out me one and the second one is desperately trying to spit out Mewtwo and you subtract them. It's desperately trying to spit out the difference in those two ideas. Now if you want to figure out how spread out something is we learned how to find ": [
            2234.7,
            2258.6,
            79
        ],
        "next to Bar once too very so we need to understand what shape We're going to get if we look at the picture of all the differences. So imagine drawing samples. Imagine taking their averages imagine dropping them down. So we have our first. In the bottom left in bottom right pictures and subtract them. They know we have a. In the center and imagine repeating this process over and ": [
            2046.7,
            2073.2,
            72
        ],
        "now that what's going on here while more complicated still falls into the same infrastructure as before so that you don't get worried. Go ahead. Why didn't use this formula? For the for the standard error in the paired case rate question. The reason is as you move from this step right here. That is the square root of the variance difference good time for the batteries to die on ": [
            2342.6,
            2381.5,
            83
        ],
        "now we need to compare to our Alpha. I'm hoping we set that in advance. If you didn't set that in advance, there's now a temptation to be naughty. So you could set Alphas .05. If you wanted and that would cause you to reject right? You know you could set elephant as .01. This would cause you to keep the Knoll. So this is why you need to set ": [
            1629.7,
            1665.1,
            57
        ],
        "of gifted children. And what's different about those? Is there something paired up about them? So these are examples of what are called paired data and they're one of the two extremes that could happen that we're going to study. Okay. So are your Two Worlds paired up or are they independent? So if you're able to take one datum from your first population and it helps you make predictions. ": [
            203.9,
            231.1,
            7
        ],
        "of probabilistic structure. That is most of the time you're heading towards something that makes sense given with the date or saying so if your job is truth in life, and that's what you want. Sorry. Nothing in the masks that department gets you there. That's why I originally came to the max. Department in my life as far as a math major in undergrad cuz I thought I was ": [
            1838.9,
            1859.3,
            64
        ],
        "of temps on Earth. Across these years the average for our particular 62 cities for were thinking about the entire Earth. So, how's this work? So freezing after realizes the data repaired, so if you know temperature had a very high temperature on January 1st 1970 if the high temperature was a big number then you know, what's going to happen when you go 46 years in the future is ": [
            509.5,
            536.4,
            19
        ],
        "on 62 data points decide what's true and false in the world from a single study. You look across the totality of all the studies that exist on something. So if you're listening to the news and you see them cherry-picking results from single studies is always a terrible thing to do in life. If you want to know what to believe about global warming or climate change going to ": [
            896.4,
            916.9,
            32
        ],
        "over and feeling of a distribution where all these questions currently are. So I want to know what shape it was how spread out it was and where it's Center is. And as soon as I understand that I understand how X1 bar- x 2 bar can vary. And that can help me study that object and then I can form questions around it. The cool thing is that you ": [
            2073.2,
            2097.5,
            73
        ],
        "paired in a sense that every husband got paired with his wife, but more importantly what school is if I tell you the husband age is 24. You can have some information about the wife's age. You're not going to say 86, right? You could it's unlikely. Okay, if I tell you the husband is 81 you're not going to tell me the wife is 26 you see how information ": [
            304.5,
            331.1,
            11
        ],
        "put you all through a diet program? I know that almost all the differences are going to be negative because you're young bodies respond well to stimuli where's old people like me. It doesn't work as well. So you put me on a diet. I might gain weight helps be young. Anyhow, if you only pick cities in our study that followed the same latitude maybe what's going on is ": [
            1120.4,
            1151.4,
            40
        ],
        "run a one-sided test you could do that if you collected new data. Don't use my same data set again. To keep triangulating toward the truth. You just trying to lay toward whatever the date is that says if you keep doing that. So anyhow, I don't know what the answer is because this was one study and you need many many study is to decide on the truth of ": [
            1715.6,
            1739.4,
            60
        ],
        "so for example, the difference is that you're studying better be independent. Okay, there is a dependency in the paradis. But when you go subtract them and make the differences. That's been wiped away. And so now you're looking at well is the difference in the temperature in Rome? Unrelated to this other city that I randomly chose that you don't know where the cities from. So it is now ": [
            989.8,
            1019.4,
            36
        ],
        "something in life. So unfortunately, I'll leave you with. a feeling of Heidi's satisfaction If you want me to tell you the truth. Then you can come to my math classes. If you want to know how to take data and triangulate or the truth, then you can come to my stack classes. Now when you come to my math classes, I'll tell you that that's not truth either. Do ": [
            1739.4,
            1773.8,
            61
        ],
        "symmetric place which will be the negative version on T distributions. And you can change both ways because you have argued for a two-sided alternative. I don't know who is right. I don't know if all of you were right. In small parts a little bit of Truth everything and I should have both ways to get a P value here. Okay. So this p-values point 0 1 0 1 ": [
            1600.4,
            1627.7,
            56
        ],
        "test to see if there is a difference between parents the moms and the dads. Okay. Now, you know what curve you're going to be on T sub N - 1 It's going to help you do the analysis. You know, the T distribution is always centered at 0 and your house right out it is here. You can just go calculate things that what's interesting here is when you ": [
            1489.5,
            1512.9,
            52
        ],
        "than the Snodgrass or vice versa. That would be super exciting. Okay. The next thing is when you go collect your data. You're going to get averages in your two samples and you can subtract them. That's a difference of averages and it lives on some distribution. Okay, it's a t distribution where he decided we'd set up the degree of freedom is the minimum or the smaller of the ": [
            2944.2,
            2968.8,
            105
        ],
        "that and you can calculate what was going on in your sample. That's the statistic X bar or X1 bar if you want to keep track of what population working. You could also measure how spread out things are there at Esteban the standard deviation. And it's mimicking Sigma won the standard deviation in the population, which you'll never know. Okay. Now the only difference today is now that there's ": [
            1910.4,
            1934.5,
            67
        ],
        "that's what the dependence is. Okay. So there's actually a version of this formula over the sequel sign for when the data are dependent or paired involves something called covariance that you don't know yet. So if we knew that then we could use what's going on this infrastructure. We could recreate it. That's a very nice question. Have you taken stop before high school? Statistical physics they got here. ": [
            2407.6,
            2440.2,
            85
        ],
        "the global warming only affect certain latitude or something on Earth. Who knows. This is like dangerous things you can do when you're choosing the two populations that you're going to study the tie everything together. This complicated understanding how differences might be dependent on each other. Now, let's do another example. This one's from the educational research literature. I used to be obsessed with gifted children. I thought it ": [
            1151.4,
            1181.8,
            41
        ],
        "the horizontal axis for a t distribution take your observe difference subtract 0 here because that's what you're hypothesizing is going on and / a standard. So this is moving to the standardized t-distribution by subtracting what you think is going on Central and dividing by how spread out things are. Okay. So here's this number 2.72. You can drop it down on your T distribution. You can put the ": [
            1573.8,
            1600.4,
            55
        ],
        "the pointer. You see the step right here at the mess with the batteries or come back to life somehow as you move from here to here over this equal sign. It requires that the populations be independent. That is the two worlds are studying. But when we have paired up data the day directly dependent on each other if the husband age of 62, the wife is near 62, ": [
            2381.5,
            2407.6,
            84
        ],
        "the problems with the table and all the table people in the room or going to feel this when you take the exam is I couldn't build a table for every single possible DF value ever. Okay that we were infinitely many rows. So what happens is at some point they start they stopped counting by ones and they just sort of jump. Okay. So here I just chose the ": [
            668.7,
            688.6,
            25
        ],
        "the same thing over here on the right. First second population where everything has an index of 2 and what school is two sample sizes can be different. Play sometimes it's easier to draw data from one population than another. So you will have lopsided sample sizes. Totally find the infrastructure will handle this. Now. What school is you can draw a picture of what's going on? 4 x 1 ": [
            1934.5,
            1964.1,
            68
        ],
        "the smaller number of ends of 1 - 1 + 2 - 1 When I go next door at 9, they see the truth of this formula, which is horrible. And you don't want to see it right now. So usually at this level textbooks will be kind to you. This is a conservative approach. That's what this formula is doing here. The truth is one of the worst formulas ": [
            2153.5,
            2185.1,
            76
        ],
        "the spread out in this of a difference in two random variables. Okay, so it's always to find us the square root of the variance is the definition of standard deviation. But then we learned how to take the variance of the difference of two random variables as long as they were independent. It turned out to be the sum of the variances. Remember that slide from 3 weeks ago. ": [
            2258.6,
            2285.3,
            80
        ],
        "the study begins and after okay. So if the number starts really high like 203, you know that it's going to end relatively high but if the number starts very low that helps you understand that the post weight will also be pretty low. That's why this is paired data in the settings. You can always take the difference of the two columns and tell me how instead of worrying ": [
            353.4,
            378.7,
            13
        ],
        "the world falling apart. Sorry, we broke our Earth. They will go fix that. Does global warming or climate change spending on the line? Would you prefer actually exist? So you don't trust. The fake news the news scientific articles. I don't know. Don't trust anything. So you go run your own study. So you choose 62 random cities. Okay, just like turn the globe and put your finger on ": [
            423.9,
            455.9,
            16
        ],
        "them into one varying Universe which is much easier to understand than two things that are both very, so what we're going to do actually it's create the difference and said the same thing we did when we had paired data. So the idea shouldn't come it's so shocking this time. The only difference is this is going to be quite complicated. Okay, because x 1 bar once the very ": [
            2023.4,
            2046.7,
            71
        ],
        "these axioms down here, but the problem is what if the axioms down here aren't true. What if I can call the universe and say hey is the commutative law of algebra for real numbers really true. That's what I would have to do to decide on the truth of an axiom So Mad Max. Valid things that follow logically statistics creates things that harmonize with data through a pop ": [
            1811.4,
            1838.9,
            63
        ],
        "this is often difficult to check so we still have this randomization and 10% condition to most easily check that that is reasonably met also nearly normal. Okay, the universe of differences. Better be pretty nice. Now you can't see the universe of difference is so usually you look in your sample. And you say does that look roughly normal? Okay, and it's okay. If it isn't that normal as ": [
            1019.4,
            1048.8,
            37
        ],
        "to do with each other. And when you go collect today to you're not doing it in a way that creates Harmony where you compare things up with this looks like suddenly we have one population that has some meaning going on. That's me one and that's what we really want to study but we don't know if witches with the red X means so you draw a sample from ": [
            1888.8,
            1910.4,
            66
        ],
        "to use it. Okay. So here's our standard error. It tells you how this particular T distribution can vary and it's a t distribution that's helping us understand averages of differences. So now we are one level more complex than we used to be when I take an average of numbers anymore in the simple measurement. Thanks for taking averages of differences by 1.1. Earth has gotten hotter by 1.1 ": [
            717.0,
            744.7,
            27
        ],
        "too messy and the spread out and it's of the difference of the averages we figured it was this formula but going through that. I'm tough calculation on the previous slide. Hey, so there's no summarizes all of the confidence interval stuff when it comes to finding averages. When we get to the next chapter proportions, and then we will filled out most of its going on in life. Okay. ": [
            2569.0,
            2598.7,
            91
        ],
        "under this name during the Civil War. So what is Twain really the author of The Snodgrass letters? So you can try to decide this using statistics paired up with something known as author profile. Okay. So this Theory basically says if you look at how human beings right? it's quite consistent there certain things about people's writing styles that are quite consistent from one essay to the next one ": [
            2732.0,
            2763.4,
            97
        ],
        "wait for train your soul, which is how a mathematics really goes. Anyway, I'll just intuition everyone talks about I find that 99% of that time. It's just training and experience rather than you have a connection to the universe and know what's going to happen. I think all that's nonsense. But anyhow, these last two or different somehow than the first two husbands and their wives moms and dads ": [
            179.8,
            203.9,
            6
        ],
        "ways. I just don't know which is actually true. Okay. So anyhow here these data are paired. I wanted to show you that one way to no data are paired is if you have the same number of people in each of your two groups. Often that means your data repaired if those numbers are different than the data have to be independent. Okay, there's no way to pair up ": [
            1357.7,
            1384.7,
            47
        ],
        "we know how to study one column of data is very nice, right? All the infrastructure we have so far is built around studying one column of data hear the column is just the differences rather than individual measurements. So let's try problem and see how this all works. I love this example, cuz it tells you all about the real world in statistics and is very apropos given that ": [
            398.7,
            423.9,
            15
        ],
        "what we're sampling are differences in temperatures rather than individual ones. So we learned it the other day that we should be on N -1 where n is the number of data points? So there's the curve we're going to be on into our analysis and it will be a t distribution. And then we just have to break up the appropriate formula for confidence interval. Okay. So in this ": [
            563.6,
            584.4,
            21
        ],
        "works for both sides. You can say that the moms with higher IQs because you could argue that women give more of their genetic material to their kids. So if their kids are smart, And more it's coming from Mom and mom must be smart. But you could argue identically the dads give more genetic information. I don't know anything about this, but it's an argument that works for both ": [
            1332.8,
            1357.7,
            46
        ],
        "you survive from the Snodgrass. right hypotheses Oh, oh, we're running out of time. Maybe I'll write them for you. It's running at a time. So this is how you set of hypotheses. Usually when you have two different populations that are independent. Usually what you do is you say it be super boring of Mew EX the average three-letter word percentage in Twain letters - music by the ID ": [
            2894.7,
            2920.7,
            103
        ],
        "you think math is truth? Are you still there? Hey, I'm sorry to tell you math is not truth your tell MathWorks. You set down a set of axioms. You might remember this from geometry. You use those axioms to derive new things that are logically, correct? Based on the axioms. In mathematics should use the word valid to suggest that these facts up here follow from using invalid logic ": [
            1773.8,
            1811.4,
            62
        ],
        "your significance level before you begin the test, so you're not tempted. To choose it after you see the p-value. So as to get the results you want in life confirmation. I can confirm anything you believe. I just messing with the data enough, right? Anyhow, if you were chosen .05 in advance, you reject the null. So it does appear there is some difference between moms and dads their ": [
            1665.1,
            1693.9,
            58
        ]
    },
    "File Name": "Statistical Methods - A00 - Quarfoot, David James - Spring 2019-lecture_20.flac",
    "Full Transcript": "Listen to a podcast back everyone.  My voice can make it or not.  I was on a no speaking requirement yesterday.  So hopefully I saved up all my speaking and I just noticed something when you teach at 8 a.m. The batteries on the microphone never fail cuz I think they were placed in every night. So I don't have to switch my batteries out anymore.  I don't care too early to care about him scared me.  That's my brilliant observation for the day. Okay, here's where we are. I told you the truth last class.  That is there something called a t distribution and it's a more honest faithful representation of what you do when you have meetings and you want to build confidence intervals and run hypothesis test. So we're going to use that machinery and move forward but we going to afford into harder situations. Okay. So today we're going to work on two parameters instead of one so far. All you focused on is a single average in some population and then later we'll go to three or more.  Okay. So what's new today? Let's figure this out.  Well, some of our infrastructure is going to change but the cool thing is that some won't change and it's at similarity. That's very nice for us. So just a few details. So what's new about two populations for a sec now, they're Two Worlds. They're big they have lots of people.  And you don't know anything about either so you need to sample from both.  So here's some examples maybe care about men versus women and you want to measure this idea SAT score which only care about averages and you only care about UCSD cuz what else is there in life?  Okay, maybe height of aliens Planet X and Y. Okay. So here is really two different worlds literally and you want to measure Heights and some unit system. Then we have husbands and their wives assuming heterosexual marriages.  And then finally you could do IQ scores of moms and dads of gifted kids. Okay. So each of these has two populations some quantitative thing you want to measure and you're really interested in the averages of those two worlds and you be most excited if maybe they were equal.  Or perhaps one was different than the other night as you look at these.  Maybe something in your soul.  Look into your soul.  Did it feel a difference between these examples?  Hopefully it did.  If not, wait for train your soul, which is how a mathematics really goes. Anyway, I'll just intuition everyone talks about I find that 99% of that time. It's just training and experience rather than you have a connection to the universe and know what's going to happen. I think all that's nonsense. But anyhow, these last two or different somehow than the first two husbands and their wives moms and dads of gifted children.  And what's different about those? Is there something paired up about them?  So these are examples of what are called paired data and they're one of the two extremes that could happen that we're going to study.  Okay. So are your Two Worlds paired up or are they independent?  So if you're able to take one datum from your first population and it helps you make predictions.  About a datum in the second population and there's a perfect linkage between your worlds and you could even pair up your data and some nice way. Then this is called paired data down here at the bottom. It's however your two different worlds. There's no way to sort of leap across from one to the other.  And if I know the value of R in the first one, it doesn't help me make predictions over in the second one. This is independent data.  You really have two worlds have nothing to do with each other and you're just taking data from both and those are the two Extremes in which there's no linkage across the two universes Independence and there's a perfect start of one-to-one relationship where you can match up everyone in One population with the other which is known as paired data.  So start with the paired data because this is easier to analyze and you're ready have the infrastructure in place. So this is what paired data tends to look like. You have a bunch of columns, you're measuring things about one population in the left and in the middle, you have the next population and because we have husbands and their wives  This data is paired in a sense that every husband got paired with his wife, but more importantly what school is if I tell you the husband age is 24.  You can have some information about the wife's age. You're not going to say 86, right?  You could it's unlikely. Okay, if I tell you the husband is 81 you're not going to tell me the wife is 26 you see how information about one goes across to the other. It's a perfect cuz there's variability and everything. But as soon as you know, the first numbers bigger going to predict the second one is Big, although there are plenty of counter examples to this in life.  Okay pre and post weight. So these are measurements on a different human beings going through some weight loss study. And you can measure them before the study begins and after okay. So if the number starts really high like 203, you know that it's going to end relatively high but if the number starts very low that helps you understand that the post weight will also be pretty low.  That's why this is paired data in the settings. You can always take the difference of the two columns and tell me how instead of worrying about individual husbands and their wives you can just tell me this couple had a difference of age of two.  Which means in this case that the husband was two years older and this was -3, which means the wife is 3 years older or the husband was three years younger everyone think about it and was cool as you go from two columns of data down to one and we know how to study one column of data is very nice, right?  All the infrastructure we have so far is built around studying one column of data hear the column is just the differences rather than individual measurements. So let's try problem and see how this all works. I love this example, cuz it tells you all about the real world in statistics and is very apropos given that the world falling apart.  Sorry, we broke our Earth.  They will go fix that.  Does global warming or climate change spending on the line? Would you prefer actually exist?  So you don't trust.  The fake news the news scientific articles. I don't know. Don't trust anything. So you go run your own study. So you choose 62 random cities.  Okay, just like turn the globe and put your finger on it. I guess. Okay, and you go see what the high temperature was on January 1st 1970 many years ago. And then you check a more recent time 2016 use the same day.  Okay, for each of those cities, you'll go calculate the difference in temperature that was deserved across this 46 year span and I chose the order here to take 2016 and subtract.  The 1970 temperature you could do it in reverse if you wanted all the negative signs become positive and vice versa.  Okay. Now you have a big list of differences. In fact, there are 62 differences. It's the temperature changes and all your cities and you go find the average and you get one point one.  But there's some standard deviation of differences isn't always the same value find a 95% CI for the differences of temps on Earth.  Across these years the average for our particular 62 cities for were thinking about the entire Earth.  So, how's this work?  So freezing after realizes the data repaired, so if you know temperature had a very high temperature on January 1st 1970 if the high temperature was a big number then you know, what's going to happen when you go 46 years in the future is also going to be a big number probably cuz you're in the southern hemisphere, which is warm on January 1st.  Okay.  That's the thing. You have to decide when we start studying this data what curve we're going to be on to help us understand it. So here we have a list of 62 numbers.  And we're going to explore that list. So it's really just a one sample.  Study what we're sampling are differences in temperatures rather than individual ones. So we learned it the other day that we should be on N -1 where n is the number of data points?  So there's the curve we're going to be on into our analysis and it will be a t distribution.  And then we just have to break up the appropriate formula for confidence interval.  Okay. So in this case we do we always do take your best guess of what's going on for what you're trying to measure.  And Pat it.  Each way. So in this case, we need the t-distribution help adding and the standard error formula is going to be what it usually is. It's always a standard deviation over square root of n standard deviation. The thing we're measuring is not individual temperatures, but it's differences in temperatures.  in various cities  Luckily, we have all of these numbers cuz I gave them in the problem.  And so we can go plug everything in and see what's going on. Now. We need to go find this critical value this point on the horizontal axis for the T distribution has a certain amount of area Central. Okay, so you'll notice it was supposed to be on t61.  And I'm trying to get 95% of the area.  Because it's a 95% CI to be Central to it. Okay, so you end up taking that 95 Central Area take an extra two and a half on the left side, but you don't really care about its sweeping through all that to get to your T star value. So we get this number 1.999.  Feel so Tui.  Now one of the problems with the table and all the table people in the room or going to feel this when you take the exam is I couldn't build a table for every single possible DF value ever. Okay that we were infinitely many rows. So what happens is at some point they start they stopped counting by ones and they just sort of jump. Okay. So here I just chose the nearest thing. I could 60  And I said we'd like to get .05 in both Tails or .025 and one so here's our number to which feels a lot like 1.99.  Okay. So now we Feast our  And we're ready to build our interval. Now who cares about the Centreville. It's got to  could be useful to you somehow.  So let's calculate it and see if we might be able to use it. Okay. So here's our standard error. It tells you how this particular T distribution can vary and it's a t distribution that's helping us understand averages of differences. So now we are one level more complex than we used to be when I take an average of numbers anymore in the simple measurement. Thanks for taking averages of differences by 1.1.  Earth has gotten hotter by 1.1 degrees on average in our 62 cities.  But there's the rest of the earth. We didn't sample from and the plus or minus here is trying to be honest to that fact.  Okay, the .62 to here comes out of our standard error calculation, which is how much are simple very divided by the square root of N and this too has helped helping to decide how big the confidence interval should be based on how often you wanted to capture the True Value. Okay. So here's our interval.  What do you notice interesting about this interval?  Lower bound is negative. Hence.  443 very careful  So instead of saying there isn't global warming will take a tiny step forward don't jump so far.  The difference could be negative.  But it could also be positive right hook 2.3 is the right end of the info your noting that what is in the interval what number that's so important.  Pesos zero is in the Centreville.  So if zeros in the interval that says the difference in the temperatures across the Earth could be zero based on these data. It could also be negative or could be positive.  Okay. So the worst thing you can do is say this proves global warming doesn't exist because hypothesis test and confidence intervals. Don't prove anything is true or false. They triangulate you toward a belief system that harmonizes with the data that comes out of the universe.  Okay. So anyway, so zeros in the interval.  So you might want to keep believing that there's been no temperature change.  Turn off again. This doesn't prove anything true or false.  And also this is one study based on 62 data points decide what's true and false in the world from a single study. You look across the totality of all the studies that exist on something. So if you're listening to the news and you see them cherry-picking results from single studies is always a terrible thing to do in life.  If you want to know what to believe about global warming or climate change going to be in the 5,000 articles that have been produced about this not the one study I cherry-picked to demonstrate something to you.  Okay. Anyhow enough about that.  Whenever you run a test, you always have to make sure that you've met all the conditions that are necessary.  So here they are.  What's going on? This time is since we're doomed repairing up our data and looking at the differences. This is a very slick thing by the way, I don't know if you felt how slick it was, but let me comment on its thickness. So you feel emotionally with two worlds, and we wanted to study them both, but the study was designed in such a way that the fingers on my hands paired up and create a single Universe are paired fingers and can collapse down to everything. We already know that's very slick to reduce two things down to one. No new infrastructure was involved. You just have to wrap your mind around the fact you're working on differences. Okay. So if we're back in our old universe, but we're just studying differences then everything we needed to be true about the data and that old Universe just needs to be true about the difference is now so for example, the difference is that you're studying better be independent.  Okay, there is a dependency in the paradis. But when you go subtract them and make the differences.  That's been wiped away. And so now you're looking at well is the difference in the temperature in Rome?  Unrelated to this other city that I randomly chose that you don't know where the cities from. So it is  now this is often difficult to check so we still have this randomization and 10% condition to most easily check that that is reasonably met also nearly normal. Okay, the universe of differences.  Better be pretty nice.  Now you can't see the universe of difference is so usually you look in your sample. And you say does that look roughly normal? Okay, and it's okay. If it isn't that normal as long as you have a pretty big sample size, so I didn't even show you what the histogram of the differences in our 62 cities look like.  Is 62 is a pretty big number. So most doesn't matter what it looks like now, how could you get your paired differences to be dependent on each other the differences?  Okay, so here's some examples you're doing your married couple study and looking at ages, but you choose all of your people from the same church.  Like a disco wrong. Well, maybe your church.  Only lets people come in who are over 60.  So I instantly know that all of the differences here.  Have some relationship to each other.  Cuz you're pulling from a consistent thing. Okay, if you only do before and after studies on college students.  Guess what if I put you all through a diet program?  I know that almost all the differences are going to be negative because you're young bodies respond well to stimuli where's old people like me.  It doesn't work as well. So you put me on a diet. I might gain weight helps be young.  Anyhow, if you only pick cities in our study that followed the same latitude maybe what's going on is the global warming only affect certain latitude or something on Earth. Who knows. This is like dangerous things you can do when you're choosing the two populations that you're going to study the tie everything together.  This complicated understanding how differences might be dependent on each other. Now, let's do another example. This one's from the educational research literature. I used to be obsessed with gifted children.  I thought it all these fancy East Coast private schools average SAT score with a 1530 or 1550 out of 1600.  So people are obsessed with gifted kids. They feel like if you understand that Universe then maybe you could lift everyone up to it or something. I don't know why people get so obsessed. I just like  This world for some reason. Anyhow, here's a question. I love this.  If you look at the parents, assuming heterosexual parents of gifted kids will be a mom and a dad.  And you might wonder if the IQ of the mom and the dad.  Are the same?  or not  So first thing we're going to argue for both sides here.  Someone argue. This is very dangerous.  Why either the moms or the dads should have higher IQs than the other parent. You don't have to believe what you're saying.  It just has to be reasonable.  Danger  Go ahead.  Okay. So this is the historical cultural argument. The men will have the higher IQs because historically societies put resources more toward men than with it. Okay. I don't know if it's true or not. Thinking binaries. Anyway, it probably has some truth.  Or negative truth. I don't know. Okay, you can ready to argue the opposite.  Okay. So here's the women argument more women go to college these days. That's true. Actually somewhere between 51 and 54% of all college students are identified as female depending on the school you're at  what is a recent trend?  So have these women who have gone to college more off and had the chance to make babies yet.  Okay, so I don't know right?  Okay, here's an argument that works for both sides.  You can say that the moms with higher IQs because you could argue that women give more of their genetic material to their kids. So if their kids are smart,  And more it's coming from Mom and mom must be smart. But you could argue identically the dads give more genetic information. I don't know anything about this, but it's an argument that works for both ways.  I just don't know which is actually true.  Okay. So anyhow here these data are paired. I wanted to show you that one way to no data are paired is if you have the same number of people in each of your two groups.  Often that means your data repaired if those numbers are different than the data have to be independent.  Okay, there's no way to pair up an unequal number of things.  But it could happen that you're too independent worlds and you just happen to randomly choose the same sample sizes. Another way. You can know your data repaired is if there's a difference column listed on the page.  Although you could be really mean and try to trick students by putting a different column what I do that. Who knows?  Anyhow, so let's take a look here. First of all, there's a lot of random just going into how people are chosen. So I'm guessing the differences when I go calculate them will be independent. Okay, here's a histogram showing the 36 different differences. This is how Mom and Dad compare.  In these 36 families that you're looking at. So this looks roughly normal, right?  Okay, so I feel pretty good about us. Go ahead and going ahead and doing a study.  Now, what do you do when you set up a null and alternative hypothesis are?  Well what you care about the parameter of interest you can always labels Meuse MD. This is the average of  all of the differences  all of the parents of all of the gifted children, whatever that word means they that is argued about ferociously in the literature.  But if you could come up with the definition we could all agree upon and you could type talk to all parents ever and take all the differences ever and average them. That would be Mew but we don't have me of sub d  Okay, so this is what your nose going to look like.  And if we assume that's true, then we're ready to start doing some sort of hypothesis test to see if there is a difference between parents the moms and the dads.  Okay. Now, you know what curve you're going to be on T sub N - 1  It's going to help you do the analysis.  You know, the T distribution is always centered at 0 and your house right out it is here. You can just go calculate things that what's interesting here is when you find this sample error, this is supposed to be a standard deviation of the \u221a Aunt Sue have to be given the standard deviation of the differences. You can see the number 7.5 what's incredibly frustrating is  you can't find this number 7.5 using the 6.5 and the 3.5.  It's not possible.  So I have to give you a difference column if the problem is about pair data because I have to tell you the 7.5. It is possible to find the average of the differences in the sample. This is the 3.4 that's going to be the difference of the two averages.  So that is find out about if I just give you the left two columns, but 7.5 number isn't okay. So what are we doing here? We're going to go calculate the t-stat. That's a place on the horizontal axis for a t distribution take your observe difference subtract 0 here because that's what you're hypothesizing is going on and / a standard. So this is moving to the standardized t-distribution by subtracting what you think is going on Central and dividing by how spread out things are.  Okay. So here's this number 2.72. You can drop it down on your T distribution. You can put the symmetric place which will be the negative version on T distributions.  And you can change both ways because you have argued for a two-sided alternative.  I don't know who is right.  I don't know if all of you were right.  In small parts a little bit of Truth everything and I should have both ways to get a P value here.  Okay. So this p-values point 0 1 0 1  now we need to compare to our Alpha.  I'm hoping we set that in advance.  If you didn't set that in advance, there's now a temptation to be naughty.  So you could set Alphas .05.  If you wanted and that would cause you to reject right?  You know you could set elephant as .01.  This would cause you to keep the Knoll.  So this is why you need to set your significance level before you begin the test, so you're not tempted.  To choose it after you see the p-value. So as to get the results you want in life confirmation. I can confirm anything you believe. I just messing with the data enough, right?  Anyhow, if you were chosen .05 in advance, you reject the null.  So it does appear there is some difference between moms and dads their difference is not zero, but is there is a difference now because it's a two-sided alternative.  I just know that there's some difference. I don't know if the moms are supposedly smarter or the dads.  Now, it's cool. As you can go run a new study based on what you're seeing here. Like these data seem to suggest the moms have the higher IQs. So if you wanted to go run a one-sided test you could do that if you collected new data.  Don't use my same data set again.  To keep triangulating toward the truth. You just trying to lay toward whatever the date is that says if you keep doing that.  So anyhow, I don't know what the answer is because this was one study and you need many many study is to decide on the truth of something in life.  So unfortunately, I'll leave you with.  a feeling of  Heidi's satisfaction  If you want me to tell you the truth.  Then you can come to my math classes.  If you want to know how to take data and triangulate or the truth, then you can come to my stack classes.  Now when you come to my math classes, I'll tell you that that's not truth either.  Do you think math is truth? Are you still there?  Hey, I'm sorry to tell you math is not truth your tell MathWorks. You set down a set of axioms. You might remember this from geometry.  You use those axioms to derive new things that are logically, correct?  Based on the axioms.  In mathematics should use the word valid to suggest that these facts up here follow from using invalid logic these axioms down here, but the problem is what if the axioms down here aren't true.  What if I can call the universe and say hey is the commutative law of algebra for real numbers really true. That's what I would have to do to decide on the truth of an axiom So Mad Max. Valid things that follow logically statistics creates things that harmonize with data through a pop of probabilistic structure.  That is most of the time you're heading towards something that makes sense given with the date or saying so if your job is truth in life, and that's what you want. Sorry. Nothing in the masks that department gets you there. That's why I originally came to the max. Department in my life as far as a math major in undergrad cuz I thought I was getting the truths and that's what I told people know if it's still black and white. I love it, but now I realize all that was nonsense.  so now I do a lot of things that aren't truthy like English and  chamber music  I just feel it the truth and those sort of an emotive thing. OK it's time for non paired populations your Two Worlds. They really have nothing to do with each other. And when you go collect today to you're not doing it in a way that creates Harmony where you compare things up with this looks like suddenly we have one population that has some meaning going on. That's me one and that's what we really want to study but we don't know if witches with the red X means so you draw a sample from that and you can calculate what was going on in your sample. That's the statistic X bar or X1 bar if you want to keep track of what population working.  You could also measure how spread out things are there at Esteban the standard deviation.  And it's mimicking Sigma won the standard deviation in the population, which you'll never know.  Okay. Now the only difference today is now that there's the same thing over here on the right.  First second population where everything has an index of 2 and what school is two sample sizes can be different.  Play sometimes it's easier to draw data from one population than another.  So you will have lopsided sample sizes. Totally find the infrastructure will handle this. Now. What school is you can draw a picture of what's going on?  4 x 1 bar so this is actually random variable as you collect different samples, you would get different averages in your sample. And so there's a picture of what's going on for X1 bar. It's actually a t distribution and used to be normal back in the good old days.  Okay, it's centered somewhere.  The true value of Mew as when you collect a sample and you ask for the average the average wants to be near the truth.  That's how the universe works if it's a good sample, but there's some spread out in this and what's going on. That's the standard error is 1 / \u221a N1 and you also have the same idea over here just with the subscript 2 everywhere.  So the problem is how do we study two universes that are varying?  We just have to bring them into one varying Universe which is much easier to understand than two things that are both very, so what we're going to do actually it's create the difference and said the same thing we did when we had paired data.  So the idea shouldn't come it's so shocking this time. The only difference is this is going to be quite complicated. Okay, because x 1 bar once the very next to Bar once too very so we need to understand what shape  We're going to get if we look at the picture of all the differences. So imagine drawing samples. Imagine taking their averages imagine dropping them down. So we have our first. In the bottom left in bottom right pictures and subtract them. They know we have a. In the center and imagine repeating this process over and over and feeling of a distribution where all these questions currently are. So I want to know what shape it was how spread out it was and where it's Center is.  And as soon as I understand that I understand how X1 bar- x 2 bar can vary.  And that can help me study that object and then I can form questions around it.  The cool thing is that you know how to study the difference in two random variables here. They have to be called x one bar next to bar. So they're complicated cookies.  But we could just think about for a moment the difference in two random variables.  How do you subtract them you roughly get another T distribution? And since everything is approximation is going on all over the place. Anyway, hopefully you won't be bothered by the fact that I wrote roughly here.  Now one of the complicated things is which teachers tribution we know what's going on individually in each of our populations as we sample.  But when you subtract them, it's even more complicated. So in this class.  whenever we look at a difference of two d t distributions it again BT, but will the degree of Freedom will be the minimum of the smaller number of ends of 1 - 1 + 2 - 1  When I go next door at 9, they see the truth of this formula, which is horrible.  And you don't want to see it right now. So usually at this level textbooks will be kind to you. This is a conservative approach. That's what this formula is doing here.  The truth is one of the worst formulas and all of Statistics. It's just a long and messy. So hopefully we can all agree to be conservative for the moment on this thing.  Okay next thing.  The things we want to take the difference out or not. Just simple random variable. They're actually averages. Okay, so I'll call him X and Y instead of X1 and X2 for a moment case ox1 bar, which I'm not calling ex bars really a t Distribution Center didn't you want and we know what is standard error is it's the standard deviation divided by the square root of n  Okay, and the same thing over for what we were calling ex to borrow which of Kauai now just to make it easier.  Because I didn't the two things I want to subtract. So whenever you're to subtract 2 T distributions, the new center is at the difference of the old centers.  This is believable, right?  If the first thing is desperately trying to spit out me one and the second one is desperately trying to spit out Mewtwo and you subtract them. It's desperately trying to spit out the difference in those two ideas.  Now if you want to figure out how spread out something is we learned how to find the spread out in this of a difference in two random variables. Okay, so it's always to find us the square root of the variance is the definition of standard deviation.  But then we learned how to take the variance of the difference of two random variables as long as they were independent. It turned out to be the sum of the variances.  Remember that slide from 3 weeks ago.  Okay, it's just complicated here because the random variables are averages and their model by T distributions, which is irrelevant in this case. Okay, so if I take the variance of this first distribution  That is a need to square the standard deviation. I'll get S 1 squared / N1.  And then the variance of the second thing here. We need to square the standard deviation. So we get S 2 squared / N2. So what I'm working very hard right now it's doing this coming up a distribution.  Of the difference of the averages that come out of our two populations. It's a very complex object, but it's actually the easiest way to study these two populations. It's a sample from both and subtract what's going on with the individual averages in  Okay, so I wanted to show you now that what's going on here while more complicated still falls into the same infrastructure as before so that you don't get worried. Go ahead.  Why didn't use this formula?  For the for the standard error in the paired case rate question. The reason is as you move from this step right here.  That is the square root of the variance difference good time for the batteries to die on the pointer. You see the step right here at the mess with the batteries or come back to life somehow as you move from here to here over this equal sign. It requires that the populations be independent.  That is the two worlds are studying.  But when we have paired up data the day directly dependent on each other if the husband age of 62, the wife is near 62, that's what the dependence is. Okay. So there's actually a version of this formula over the sequel sign for when the data are dependent or paired involves something called covariance that you don't know yet. So if we knew that then we could use what's going on this infrastructure. We could recreate it.  That's a very nice question. Have you taken stop before high school?  Statistical physics they got here.  any good  I won't repeat the answer to that.  over the microphone  Hey, you never know.  Play some mix of good and bad in everything, right? Okay. So anyhow, I'm giving you a new more complicated infrastructure, but the cool thing is it fits everything we've been doing so far.  So when we just had one population and you sampled from that, you just got a big list of data.  And knows you can call this data values X if you want I can be the name so they had an average and you just had your confidence interval by using this kind of formula.  When we took a pair dataset and then took all the differences that made a long list of data. I wouldn't call it acts like cardi maybe for the differences and took you wanna build a confidence interval take the average of the differences in pad.  Okay, and finally if you can look at two different populations Do you want to build a c i take the individual averages in your samples and subtract those averages? That's your best guess on what's going on when you compare the two worlds and then pad it?  Switch to notice here. Is that everything looks so similar? It's always your best guess padded. The only things that really change our what's going on with the degree of Freedom. Now, the first two cases are all the same. So the first two cases are the same because in the engines making a long list of numbers.  MK watches and things in it. So your GF is in -1 and your standard error of some sort of standard deviation. It could be of the original data in the top line or could be the standard deviation of the differences in the middle line.  Okay in this bottom one here this the most complicated we decided the degree of Freedom would be the minimum.  Of the individual degrees of freedom minus one. So take whichever numbers less than that list.  And we did that out of convenience because the truth is too messy and the spread out and it's of the difference of the averages we figured it was this formula but going through that.  I'm tough calculation on the previous slide.  Hey, so there's no summarizes all of the confidence interval stuff when it comes to finding averages.  When we get to the next chapter proportions, and then we will filled out most of its going on in life.  Okay. So all you have to do from now on is first decide which of these three rows are in by reading the problem and saying while we're there two populations are one if there were two populations were the data collected in such a way that pair them up or not.  Hey. Then get you to one of these formulas and then you just need to use the appropriate pieces.  It's the hard work is really in the reading comprehension.  Easy stuff is putting stuff in the formulas that most students find the second half of the class easier than the first because the second half is mostly dictated by a small list of formulas. And as long as you have a good reading comprehension and can convert statements about the real world over into some statistical setting then it's just plugging things into formulas for the most part.  the first half of the class had a lot of complexity and it wasn't just simple formulas without her decision making  okay. So let's do this is one of my favorite examples in the whole class.  So some of you might know this guy.  Mark Twain Samuel Clemens birth name  so he wrote all these books that you had to read in high school if you're here in America.  Some sort of humorist. I guess might be the rest real name for him. So the interesting thing about Mark Twain is he lived during the Civil War by 1865 ish?  And people don't really know where he was during the Civil War hard to lose famous people during important times, but somehow we lost him not possible today social media client climate, but it was back then.  Now no one really knows where he was but with interesting the series of letters came out during the Civil War written by this very strange name quintus curtius. Snodgrass doesn't seem like a real name at all.  And the style of these letters feels Twain Ian.  So some people argue that the letters were written by Twain.  And maybe Twain was hiding out under this name during the Civil War.  So what is Twain really the author of The Snodgrass letters?  So you can try to decide this using statistics paired up with something known as author profile.  Okay. So this Theory basically says if you look at how human beings right?  it's quite consistent there certain things about people's writing styles that are quite consistent from one essay to the next one book to the next until you know, this you can pick up certain authors and instantly feel like you know what Stephen King's writing feels like or  JK Rowling, you've all read those books, right? Harry Potter stuff is a certain feel like kind of words that are used JRR Tolkien and you know when you're reading something and then some of these features that stay the same are how long are you sentences? How many words are in each sentence? Okay, if I just look at your words, how long are your words to use big words are small words?  Okay, another one what percentage of all the words you use are three letter words.  So Hemingway's famous for having lots of three letter words.  The old man in the sea you read this the title is all three letter words 100% of the title. The three letter words. This is a very hemingway-esque thing to do if you can take a bunch of letters, you know her from Twain.  And you can take the Snodgrass letters and for each letter you could calculate a three-letter word percentage what percentage of the words in that letter three letters.  Now that's a proportion. But what you going to do is average together all the proportions from all these different letters and that's a mean.  And you can do the same thing for Snodgrass.  Okay, so if these people really are the same.  Then three letter word percentages on average should be roughly the same.  And if the three-letter word percentages are much different.  Then author profile Theory says these probably aren't the same human being cuz human beings are very consistent.  So it's a cool way to use statistics to decide about some weird authorship question and like they've done this kind of stuff with Shakespeare. Also, this is why there's growing revolt against Shakespeare having written a bunch of these things that everyone says are from Shakespeare.  Okay, so let's start trying this problem. So here's my notation Mucinex for the tween things, you know are from Twain and you survive from the Snodgrass.  right hypotheses  Oh, oh, we're running out of time. Maybe I'll write them for you. It's running at a time. So this is how you set of hypotheses. Usually when you have two different populations that are independent. Usually what you do is you say it be super boring of Mew EX the average three-letter word percentage in Twain letters - music by the ID and Snodgrass is 0 if you like you can set this up as Mew x equals me. Why?  The reason you might set it up if the difference is because you end up studying differences in order to answer the problem. So it remind you of where you're going to that's all and here I could be excited about a two-sided alternative. As long as the twin thing is bigger than the Snodgrass or vice versa. That would be super exciting.  Okay. The next thing is when you go collect your data.  You're going to get averages in your two samples and you can subtract them. That's a difference of averages and it lives on some distribution.  Okay, it's a t distribution where he decided we'd set up the degree of freedom is the minimum or the smaller of the individual sample size is -1 case of the minimum of seven and nine the smaller number 7.  He says the curve all the analysis is going to happen on.  now I typed in a bunch of the data into r  And I got that the tween average 23.2% of tweens words or two letter words that are three letter words.  And 20.97 of the Snodgrass words are three letter words. Obviously, those aren't the same number but statistics far apart that they couldn't be the same, but we've got to stop perfect timing.  I'll let you guys read the rest of the slide for this example. Have a good day.  sandiego.edu "
}