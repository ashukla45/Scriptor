{
  "Blurbs": {
    "- 1 I know I can do that. I know that those two vectors span R2 they form a basis. So I will be able to write a v as a unique linear combination of those two vectors. Once I can do that then this thing here this coordinate Vector of a b in terms of that new bases. That's what we call X1, X2. Now let's push this a ": [
      2690.2,
      2715.6,
      104
    ],
    "2 + a - b / 2 by the way, it's very instructive in this example to look on a picture. So I don't have a lot of room here. Let's squeeze it in peso here stressing straight lines. So my standard basis vectors. Are here and here? And these new basis vectors in the basis be on put those in red they are here and here. The new basis ": [
      2788.3,
      2826.9,
      108
    ],
    "3 that means it's 2 * 81 + 3 * 82. I saw the coefficients of that Vector in terms of the standard basis E1 and E2. are two and three Careful here. It's really important that the basis vectors are ordered. Cuz the order you choose for the basis vectors. Although that doesn't change the dimension or the column space or anyting else and are examples of Racine. It ": [
      2542.2,
      2566.4,
      98
    ],
    "All right, so that's what I wanted to say about Dimension and rank and now for the remainder of this lecture or talk about section 4.4. I'd really the subject of section 4.4 is why do we care about a basis? Anyway, what's so great about a basis. I've described it as being a sort of minimal description on most efficient description of a Subspace, but it's more than that ": [
      2070.0,
      2094.5,
      81
    ],
    "Echelon form so we can tell which rows are pivotal. So which rows are pivotal. in this Matrix in there in the one that I've just arrived at the first and the second Rose are pivotal here. Okay, so I guess that means that we should take the first and second rows of a hazard basis vectors, right? Know why not? I'm sorry. I just heard mumbling. We switch some ": [
      1670.3,
      1701.4,
      65
    ],
    "I get by taking the old frame and rotating at 45 degrees. And also I've lengthen the vector. These aren't vectors of unit length. Is that why we haven't talked about life yet, but you can see that they're longer arrows. So expressing a vector in terms of the new basis means I have to turn my head 45\u00b0 and scale a little bit and that's exactly what this operation ": [
      2826.9,
      2849.7,
      109
    ],
    "I give you some variables. They might all be free or they might all be constrained but whatever happens the number of three variables plus the number of constraints is just the number of variables. Okay, so that's the rank nullity theorem rank facility is the number of columns. Now here's one more Subspace Associated to a matrix your textbooks talks about and that isn't going to be important in ": [
      1318.0,
      1342.7,
      51
    ],
    "Is that that is two times the first standard basis Vector plus three times the second standard basis vector. Okay, it's chewy OnePlus 3 e 2. Now if you want Annie to is a basis to standard basis. fart And that's what a basis does for you. Every point in your Subspace in your vector space can be coordinate eyes. In a unique way in terms of the basis. I ": [
      2189.0,
      2223.6,
      85
    ],
    "Let's just throw it away and we won't change the row space when we do that we can stay on the row space is the span of the first column in the third column. 1/3 for first row in third row of a and are those two linearly independent? Yeah. That's that's again the kind of thing. We have two vectors. You can check just by eyeballing. The second one ": [
      1555.8,
      1575.0,
      61
    ],
    "Listening to a podcast. Good morning. Happy Wednesday when I get straight to it today, so please find a seat. Quick administrative reminders you are next MyMathLab homework that is due this coming Tuesday. There's no class on Monday. Okay, but the homework is due on Tuesday. It will cover everything that we do up to and including this lecture next lecture. We're going to start talking about determinants and ": [
      2.0,
      33.6,
      0
    ],
    "Matrix. I've gone ahead and ask Matlab to do the row reduction for us. So there is its reduced row Echelon form. So we don't have to do any of the computational work in order to answer the question. I'm going to ask your so what I want to know is I want to find a basis for the column space and I want to find a basis for the ": [
      732.5,
      751.7,
      29
    ],
    "Okay now tell me something about it find a basis for it to compute the dimension. You are not always expected to verify from first principles that what I told you was true. If I tell you it's a vector space go ahead and believe me that it's a vector space, please. Thanks. Okay. So Dimension super important quantity, it's makes precise something that we've all been thinking about and ": [
      549.5,
      577.8,
      21
    ],
    "One word of caution the rank nullity theorem says that the rank plus the melody equals the number of columns. It doesn't equal the number of rows in typically in less than of rows into Columns of equal. So you should remember the rank as describing the number of pivotal columns. But remember that it also is the number of rows. So it's also the dimension of the row space. ": [
      2043.6,
      2066.3,
      80
    ],
    "RNA. We have a theorem that says Hey, I want to check if I have two vectors and are too if they form a basis. All I have to do is write down the court. They Matrix with those vectors as its columns and check if that is an invertible Matrix and so is this Matrix here 1-1 1-1 invertible. Another words are those two columns linearly independent. I could ": [
      2590.0,
      2614.8,
      100
    ],
    "Rose and the number of pivotal columns in a matrix. Those are the same number. They just count the number of pivotal once in the registration form. So the dimension of the row space and the dimension of the column space are the same animal. This is the rank of a the rank of accounts. Not only the number of pivotal columns, but also counts the number of pivotal Rose ": [
      2022.0,
      2042.6,
      79
    ],
    "What are you talkin about row reduction would be the usual way to do it because I already computed the inverse Matrix. I'm going to use it here because note that this says 1 1 1 - 1 * x 1 x 2 is equal to a b and the inverse Matrix is set up perfectly to solve this. Once we have it there for X1 X2 is equal to ": [
      2735.6,
      2757.5,
      106
    ],
    "a And the dimension of the null-space of a matrix a is called the nullity of a I'm not even sure your textbook uses that word. I think it's somewhere in the textbook but they usually just say dimension of the null space. It is a very common word. You'll see all over the place if you're doing anything else with linear algebra, so you should know it Noah T ": [
      690.6,
      709.2,
      27
    ],
    "a everything of the form a + BX + c x squared or a B and C are any coffee shops that we want. Now if you think about it what that says and we discuss this at the end of last lecture is that one x x squared? Those are polynomials there in the space P2 and they form a basis for the space Pizza. What will we run ": [
      2931.6,
      2955.5,
      113
    ],
    "a linearly independent set. So we have one nonzero Vector here. It's a basis for our space there for the dimension of the space is is what there's a basis of size one. So therefore the dimension of the null space of a is one which is defined to be the nullity. So there's are two numbers for this Matrix. This Matrix has Rank 3 and nullity 1. now we ": [
      1018.1,
      1049.8,
      40
    ],
    "a saddle to hear. If you're asked for a basis of the row space. I recommend you always use the pivotal role in the reduced row Echelon form if that's given to you. If you're asked for a basis of the column space, you must always use the pivotal columns in the original Matrix that you don't have a choice about from that information. Crystal, that's what they're only one ": [
      1848.9,
      1870.5,
      72
    ],
    "actually prove it that way at the end of this lecture after we talked about coordinates, but but that's an important when I wanted to make if you want to find a new bassist for the space once you know, how many basis vectors you're looking for. You don't need to verify that it's both linearly independent and expanding set either one of those together with the number of vectors ": [
      502.7,
      520.4,
      19
    ],
    "also, you know, let's remind ourselves about inverses. Let's calculate the inverse of that Matrix as a sidebar over here. We have our nice formula for two by two matrices. So what have to do is divide by this number the determinant which is 1 X - 1 - 1 x 1 so that gives me a -2 down there and then I have to reverse. The diagonal entries and ": [
      2614.8,
      2643.0,
      101
    ],
    "and It's clearly linearly independent same as before it we can just eyeball and see that it's not really independent, but actually better than that if you ever have a linearly independent set of vectors and all you do is you scale them by non-zero scalars. You're not going to change the linear Independence because that's not going to change whether all of those columns in The Matrix that you ": [
      276.6,
      298.8,
      10
    ],
    "and let's think back way way back to elementary school where you first encountered Cartesian coordinates. They are maybe that was middle school, but whenever you encounter. So Cartesian coordinates named after an ID account, which means Renee the mapmaker? Okay. They describe a way to give an address to every points on Earth for him. But in general to every point in the plane or in Space the last ": [
      2094.5,
      2125.7,
      82
    ],
    "and so on Down the Line. Novi - 3 equals 0 so look at this for a moment here. I've got a new linear combination of the vectors V1 through bien. with coefficients here I've got a linear combination of these basis vectors that gives the zero Factor. The basis vectors are linearly independent that exactly means that the only way you can get a linear combination of them equaling ": [
      2331.9,
      2362.7,
      90
    ],
    "and vectors that span the space and then they will automatically be linearly independent. You think about it those two statements. I just made get translated into the same fax machine over and over again, which is that if you have a square Matrix, if all the rows are pivotal than all the columns are pivotal and vice versa. And so that's a restatement of those facts and we can ": [
      481.6,
      502.7,
      18
    ],
    "are spanned by a certain finite set of vectors. They said that's the contacts that were in here right now and so for such a vector space Or Subspace of another Vector space a basis, which is a linearly independent spanning set with the resilience of those for any given space. Okay, but there's one common feature they all have which is that they all have the same number of ": [
      88.9,
      112.8,
      3
    ],
    "as an equation. That is not redundant. So we start with some system of equations, but it might be as we've seen that you can reduce it to a system of fewer equations. Those equations correspond to the pivotal Rose. The rank is that number of non-redundant equations. It's the actual amount of information that's there. If that's what the rank is, it's the number of equations that really describes ": [
      1262.7,
      1290.5,
      49
    ],
    "at least a few more to keep up pace. So if I give you a matrix & M by n Matrix 7 by 6 Matrix, so here's a five-by-five 5 by 4 Matrix. There are two numbers Associated to it that come from the two subspaces. We've been talking about Associated to it. So if I give you a matrix, there's two important subspaces. We've been dealing with the column ": [
      618.5,
      641.4,
      24
    ],
    "at the high like here, which is row operations. Don't mess up the row space. The row space of a is the same as the row space of the reduced row Echelon form of a and then one more thing I wanted to highlight here, which is okay. So I've got this new space the row space. That's a third one from Matrix. We have the concert of the null-space ": [
      1870.5,
      1893.1,
      73
    ],
    "basis One X x squared of the polynomial is okay. Well the first Vector here is a one and so the coefficient there is a one the second one X. It's coefficient is -2 and the third one. It's coefficient is 1 So if you're just thinking of the vector X - 1 squared if you have trouble thinking of that as a vector, you could instead say look. I'm ": [
      3011.6,
      3038.0,
      116
    ],
    "basis behind a script to be basis vectors be wants to be on for a vector space than every Vector in the space has a unique expansion in terms of the basic factors that is spanning set. So every Vector Envy can be written as a linear combination of the bees but not only can it be rain in a linear combination. There's only one linear combination is only one ": [
      2248.8,
      2272.9,
      87
    ],
    "being right will be enough information to verify that it's a basis. So that's dimension. Right. I stated that V isn't it out loud, at least that V is a vector space here. We actually did Pruitt in an earlier lecture for this example, but if you're talkin about what you might expect to see on an exam or homework, it may well say here is a vector space V. ": [
      520.4,
      549.5,
      20
    ],
    "by the bases. That's what's so important about a basis. They give us a way to coordinate eyes are Subspace to put coordinates on it. So let's let's formalize that if it lets out a little bit of notation, which is actually going to be super helpful and understanding this tricky Point we've had since we started talking about solving equations and spanning sets. So if V is a vector ": [
      2393.2,
      2417.3,
      92
    ],
    "can be considered as vectors. So how about the rows of the Matrix? Those are also vectors where Customs thinking of vectors as columns, but for our purposes right now we can talk about actually the rose are vectors as well. We can take linear combinations of the Rose. In fact, that's what we've been doing since day one taking linear combinations of the Rose is what we do when ": [
      1366.9,
      1387.0,
      53
    ],
    "can see from this by the way how we can figure out what those numbers are without going through this much work because the column space is you pointed out is spanned by the pivotal columns and they form a basis because the pivotal columns are linearly independent. That means that the rank the dimension of the column space, which is the number of elements in any basis is the ": [
      1049.8,
      1077.6,
      41
    ],
    "column vector and that's called the coordinate Vector a v in terms of the basis B. so for example if I have a vector in R to which I write as a column, Vector AV Then it's coordinate Vector in terms of the standard. Basis is a v that's exactly what it means as we noted on the previous slide up here. Okay that if I take the vector 2 ": [
      2515.2,
      2542.2,
      97
    ],
    "critical important point to remember those three columns are pivotal in the reduced row Echelon form of a and therefore those three columns columns 1 2 and 4 are pivotal in a those three columns of the column space of a the three columns that I highlighted in yellow. Those are not even in the column space of a there in the column space over there do stretch loan form ": [
      830.4,
      859.0,
      33
    ],
    "do that roast well because all the roads are supposed to be at the bottom. Okay, I know. I'm not quite in row Echelon form yet. I got to get rid of the one in the second row in the First Column. So I subtract the first row from the second using the zero I want there. 1 they're 3 1 and 4. I know this Matrix is in row ": [
      1634.1,
      1670.3,
      64
    ],
    "does determine what order you write the coefficients of the coordinate Vector. So if we have a vector in R2, we can always right in terms of the standard basis, but the standard basis is not the only basis are zillions of base's so here's another basis of our two. The ventures 1 1 + 1 - 1 we know it's a basis of our two because four bases of ": [
      2566.4,
      2590.0,
      99
    ],
    "equations. So the number of columns is the number of variables. Now what is the rank the rank is the number of pivotal columns, which is also the same as the number of pivotal Rose, of course that the rose correspond to equations. A pivotal role is one that is not a linear a scalar multiple of the others. There's not a linear combination of the others a pivotal role ": [
      1238.0,
      1262.7,
      48
    ],
    "fact what we see is that V is equal to the span of those two vectors. Okay. So now how would we find a basis for the Subspace? We need to find a spanning set. That is also linearly independent. We have a spanning set here. If it's linear independent, we're done. It's a basis and this is an example where we don't need to do any work. There are ": [
      162.9,
      193.2,
      6
    ],
    "find a basis and last day we talked about some ways to find basis for those faces. And therefore we can count the number of bases factors that tells us the dimension of those spaces. So we give those words that the dimension of this of the null space in the space names the dimension of the column space of a matrix a is called the rank of the Matrix ": [
      670.2,
      690.6,
      26
    ],
    "for the column space is the pivotal columns other words. The rank is the number of pivotal columns in The Matrix a how does that relate to the Roosevelt? Well, let's think about it for a moment. So then the dimension of the row space of a is the number of pivotal. Columns of a and the way we would calculate that is we go to the reduced row Echelon ": [
      1936.5,
      1963.8,
      76
    ],
    "for the null space each non pivotal column each free variable is going to give us By the way, can you guys see the difference between the yellow and the green up there? I really can't I'm color-blind, but I made a mistake for myself doing that. But hopefully it's not a problem for you guys. Try to avoid it in the future. Each non pivotal column is going to ": [
      1101.2,
      1123.6,
      43
    ],
    "form and we just count the number of pivotal ones. and the reduced row Echelon form of a Is a pivotal one in each pivotal column, but remember there's a pivotal one in each pivotal row and column. The number of pivotal ones is also equal to the number of pivotal Rose. in a day or the reduced row Echelon form of a okay, and oh, I'm sorry. So I ": [
      1963.8,
      1997.4,
      77
    ],
    "give us one of the columns that spans than l-space. It's not right to say that the pivotal in the nonpareil columns are a basis for the null space. They're not even in the null space but to each non pivotal column in a corresponds a basis vector. So that means the nullity of a is the number of non pivotal call UPS in The Matrix. So actually once you ": [
      1123.6,
      1145.6,
      44
    ],
    "give you a basis. The basis is a spanning set. So every Vector in the space is a linear combination of the basis vectors. That's true for any spanning set. What's special about a basis? What's special about the fact that it is a linearly independent Spanish that is that those components those coordinates will be unique have a question. So that's a statement here. If I give you a ": [
      2223.6,
      2248.8,
      86
    ],
    "going to find a basis? How many vectors would it have? So somebody tell me what is a basis for the column space of a the pivotal columns which are the pivotal columns in this example. Yes at the back. Columns 1 and 2 yes calls 1 and 2 are pivotal are the only pivotal columns. And for yes, 1 2 and 4 in a and end the British restaurant ": [
      776.8,
      806.4,
      31
    ],
    "have and scale them a little bit. So any Vector that could be expressed as a scalar as a linear combination of the two vectors up. There is also a linear combination of the two vectors down here just by changing the a I have to replace a with a / 2 + B with - be right, but it's still a spanning set. So I have another spending set ": [
      255.8,
      276.6,
      9
    ],
    "have the reduced row Echelon form of the Matrix or any any row Echelon form of the Matrix, you can quickly answer the question. What's the ranking? What's the nullity? These are just new words for number of pivotal columns versus number of non pivotal columns. And that's what I just wrote right here. So let's let's write it again. So the rank of a is equal to the number ": [
      1145.6,
      1171.6,
      45
    ],
    "here and I could use those columns as well. There's more freedom here. You're not changing the row space. So as long as you know, which columns which rows are pivotal at any given time you can use those Rose in any row equivalent form of the Matrix and they will form a basis for Aerospace. That's only true for the row space not for the column space. So that's ": [
      1827.9,
      1848.9,
      71
    ],
    "here. Does the new coordinates A + B / 2 + 8 - B / 2A. So if I started with the vector 1 0 then it's coordinate the first standard basis Vector its coordinates in the new bases are 1/2 0. 3 or 1/2 1/2 and so that first standard basis Vector its new coordinates are 1/2 1/2. And all that means is that if you want to express ": [
      2849.7,
      2876.8,
      110
    ],
    "if I go get into that more later in this lecture, but you know many of you had this reaction when were saying I've got these two vectors that you know, they don't split in R3, they don't spend all of our three question. So do they stand are too that's the question that many of you asked every time I just got people ask that question. It's a natural ": [
      577.8,
      595.3,
      22
    ],
    "in form of a those are pivotal Collins call him three is a scalar multiple of column to which you can actually see in the original Matrix. So it's not that at all. So those three form a basis write those those three factors that are highlighted in yellow there a basis for the column space, right? Wrong, you were all fooled. No, not of the reduced row Echelon form ": [
      806.4,
      830.4,
      32
    ],
    "is not a scalar multiple of the first so there is a basis for the row space. now let's systematize that like we did with the column space. So I'm going to do row operations in order to take this Matrix to reduced row Echelon form or actually, I'll just go to row Echelon form. Okay, I'm going to subtract 3 times the first row from the second. And as ": [
      1575.0,
      1606.9,
      62
    ],
    "is the dimension of the null space. Okay, so we can compute those for any Matrix because we know actually how to completely determined. The no space in the column space and in particular we know how to find basis for them. So let's do an example to illustrate this point again in to reinforce what we did last day. So here's a matrix is a particular 5 by 4 ": [
      709.2,
      732.5,
      28
    ],
    "it in terms of that basis. So I want to say here's my Vector a b. But I want to know what are its coordinates in terms of the basis B. In other words, I have to say I take the vector a be written in the standard basis and I have to be able to write it as a x 1 x 1 1. + x 2 * 1 ": [
      2667.6,
      2690.2,
      103
    ],
    "just going to fix a basis say this basis for the space of polynomials of degree at 2 and instead of thinking of PS2 polynomial something. I know how to manipulate and multiply and find roots of I'll think of it as an abstract vector and then write its coordinates in terms of this basis. It's really just the column Vector 1-2 one, which I know how to handle and ": [
      3038.0,
      3060.2,
      117
    ],
    "know how to deal with a next time. We'll start in the first 10 minutes of a Friday's lecture talking about what this coordinate. Can you see San Diego podcast? ": [
      3060.2,
      3070.3,
      118
    ],
    "little further and I'm going to find that X1 and X2. Of course. What I'm doing here is I'm going to solve a linear equation to solve. This is a vector equation A and B. I'm thinking of it as known parameters and I want to find the X1 and X2 that make this work. So how do I do that? No, we're just going to use the inverse Matrix. ": [
      2715.6,
      2735.6,
      105
    ],
    "look at an example here. Before we go any further. Here's a matrix a a 3 by 5 Matrix. And I would like to determine what the row space is what I should have written it down already here for you because by definition the row space is the span of the rows. So it's the span of those 3 reps. but this is a Subspace. It's a span of ": [
      1480.0,
      1504.8,
      58
    ],
    "look at the reduced row Echelon form to see what the reduced equations say about those. So the first equation there 1000 coefficients. Remember, there's the augmented zero on the right hand side for the homogeneous system that tells us that X1 is pinned down X1 must be zero. The second equation says x 2 - 2 X 3 equals 0 so we get x 2 is equal to 2 ": [
      916.2,
      937.3,
      36
    ],
    "me call this equation 1 + this equation to let me do raw thracian here. Let me subtract equation one from equation to that says that V - V is equal to what let me collect terms now everything that multiplies to be 1 is X1 - X2 X1 - y1. Xb1, everything that multiplies B2 is X2 - Y2. Those are not factors that are scalars * be too ": [
      2301.5,
      2331.9,
      89
    ],
    "members same number of elements. If there's one basis that has four vectors in it than all bases have exactly four vectors. So this number the number of vectors in any basis for a Subspace is called the dimension of the Subspace it so here's an example. We saw from a few lectures ago. So here's a vector space. This is a Subspace by the way of our three. Is ": [
      112.8,
      139.0,
      4
    ],
    "now. We got the row space now on the last slide. I introduced to size going to do some new notation some new terminology Rank and nullity rank was the dimension of the column space. Melody is the dimension of the null space. Maybe we should have had more words. Maybe I should have said the column rank is the dimension of the column space and I should have Ro ": [
      1893.1,
      1915.4,
      74
    ],
    "null space. Once we have the base's we can count up how many vectors are in each answer the question. What's the rank of a and what's the melody of a Kind? So let's do that. So first of all, The column space. Well, let's just the span of these four columns. But is that the right number of columns is is this a four-dimensional space or if I were ": [
      751.7,
      776.8,
      30
    ],
    "number of pivotal columns. So that's another way we can just describe. What is the rank of a matrix and then it really had some linear algebra meaning for us. The rank of a matrix is the number of pivotal columns in that Matrix. The nullity of the Matrix. Well, we see from this procedure that we're going to get in the spanning set that we know is a basis ": [
      1077.6,
      1101.2,
      42
    ],
    "of a which is typically a different Adam. Okay, so very important point so that here is a basis. these three form of Asus for the column space of a I know that means that I can tell you what the dimension of the column space is. It is 3 so therefore the rank of this Matrix is 3 No, I also want to find a basis for the null ": [
      859.0,
      888.6,
      34
    ],
    "of pivotal columns. And the nullity of a is equal to the number of non-committal columns. And so that gives us front right there up there and actually super important them. It's called the rank nullity theorem or sometimes just the rank theorem and it's the statement that for any Matrix. The rank on the melody they can depend on those particulars of the Matrix, but the sum of those ": [
      1171.6,
      1205.3,
      46
    ],
    "of the Rose row operations don't change the row space that change the column space but not the row space so I could just as well. You is as a basis the pivotal columns that I just arrived at. Okay, I could just as well use the pivotal columns in a row Echelon form. I could continue I could go one more step and do the reduced row Echelon form ": [
      1796.3,
      1827.9,
      70
    ],
    "of the transpose. The transpose turns the rows into columns in the columns into rows from Matrix. So another way to write what the row space is is to say, well the row space is the span of the Rose the rose of a are The Columns of a transpose. So the row space can equivalently be thought of as the column space of a transpose. So it just fits ": [
      1411.1,
      1436.8,
      55
    ],
    "other bases. for the same Subspace Here's one. Let me just take those two vectors and scale them like two to four. + 1 - 110 K that's another basis for this space now, it's actually easy to check that. That's the case those two vectors form a spanning set for the space because we'll all I did was to take the two vectors in the Spanish that I already ": [
      224.8,
      255.8,
      8
    ],
    "put minus signs in front of the off diagonal entries. So what I get is actually just 1/2 x 2 Matrix 1 1 1 - 1 That's the inverse they're all right. So anyway, that's a basis. So this Matrix is invertible. And that's a basis for our two. Now. I want to take the vector and arbitrary Vector Ava and I want to write it. I want to write ": [
      2643.0,
      2667.6,
      102
    ],
    "put together from them are pivotal, but here's another example maybe worth discussing Let's do let's include 112, but let's also do 2:02 How did I get that one there? We call these two vectors here B1 and B2. So this one over here in the in the first second example, I used to be one in - be to those are also a basis. How about here? I used ": [
      298.8,
      328.7,
      11
    ],
    "question know those pictures aren't even in our too but what they do span is a two-dimensional Subspace of R3, which looks like R2 and we will be more precise about what looks like means at the end of this lecture. But first now let me introduce some more terminology because we know we need more vocabulary in this course, right? We've only introduced one new word today. We need ": [
      595.3,
      618.5,
      23
    ],
    "rank is the dimension of the row space. I need to have a word for the dimension of the row space. Well, I don't need an extra word for it because remember what is the rank the rank is the dimension of the column space. That's just the number of basis elements in any basis for the column space and the nicest bases that we you know how to find ": [
      1915.4,
      1936.5,
      75
    ],
    "right into the framework that we've already been studying. This is what your textbook writes it slightly wrong because the column space of a transpose is still a collection of columns. Right. So we're taking the caught the rose of a we're turning them on their side to make them columns and then taking their span that gives us a space of columns. Where is the row space is a ": [
      1436.8,
      1457.1,
      56
    ],
    "rolls around. This is the point that I wanted to make with this example. So remember in the column space I said you look you do alterations. You get to Russia one form you figure out which columns in the rush rush on Farmer pivotal. I did to those columns that are pivotal in the original Matrix and then you have to use the ones in the original Matrix as ": [
      1701.4,
      1719.6,
      66
    ],
    "said no confidently. Why not? You're right, but why not? Yes. Very good the third with the second row is three times the first row. So there's there's a sort of in-your-face linear dependence there. Okay, so they are not linearly independent. So that means that we can certainly throw away the second row or there's no point of including it. So let's just go ahead and and do that. ": [
      1526.8,
      1555.8,
      60
    ],
    "same deal. They are not scaling multiples of each other. So what I've got is a basis of size 2 for a Subspace of V, but we know that every basis of V has two vectors in it by so actually there can't be anything left over if there were anything in ve that weren't in here. That would be a new Vector which is not in the span of ": [
      381.6,
      405.2,
      14
    ],
    "set of coefficients X-14 XM that makes this work. Why is that why is it unique? So that's the important word here unique. Why well, if we also had a different one in ostensibly different one. So have you know, the xm's are coefficients that make this work for a particular V suppose. I had some ostensibly other coefficients why one through why on that made it work. So let ": [
      2272.9,
      2301.5,
      88
    ],
    "should have started here. So dimension of the column space I started with here and this this is equal to the dimension of the row space down here. So let me reiterate that. Let's go backwards. The dimension of the row space of a is a size of a basis for the row space of a which is the number of pivotal Rose in a but the number of pivotal ": [
      1997.4,
      2022.0,
      78
    ],
    "some applications later the row space of the Matrix. So the column space remember the column space with the span of a columns. Now the columns are column vectors in r n r r Emma whatever letter word using as we've been talking about from the beginning. But remember we're also open to Vector spaces that have different forms to them. We've been talked about how make sure she's themselves ": [
      1342.7,
      1366.9,
      52
    ],
    "some vectors just as Subspace and as usual, we would like to have a basis for it would like to have a minimal description of it. So he's ever found a basis are the roads of that Matrix of a basis for the row space. And otherwise, I'm asking are the rows of that Matrix linearly independent. What do you think just looking at the Matrix? Are they? No, somebody ": [
      1504.8,
      1526.8,
      59
    ],
    "space and it has basis vectors V1 Serbian dating out remember, these are not necessarily the standard basis vectors of RN we could be talking about the Subspace the column space of some Matrix in the bees are the pivotal columns are not typically the standard basis vectors. We could be talking about a space V of polynomials and then those bees those are some particular polynomials. Okay, there's some ": [
      2417.3,
      2442.4,
      93
    ],
    "space in the null space. The column space is the span of the columns. Hey, that's a Subspace of the codomain for a and the no space is the solution set of the homogeneous system with a as coefficient Matrix. That's a Subspace of the domain. Well, those are two subspaces of of euclidean space is of RN and RM their subspaces. They have Dimension each of them. You can ": [
      641.4,
      670.2,
      25
    ],
    "space of Rose. So if you want to be really technically correct, you should also take the transpose back to make those columns back into Rose. Okay, but that's a bit of a notational point. It's not that important as long as we're consistent about these things. You're going to think of the roast basis to set up as a span of the rows of The Matrix. So let's just ": [
      1457.1,
      1480.0,
      57
    ],
    "space of a and as we saw last day that way to do that or a way to do that is to follow the procedure. We've been doing since day one of this course do row reduction in order to describe the solution set. So the null-space of a Is the set of vectors? Okay. It's going to be vectors in R4. Because the Matrix has four columns. And we ": [
      888.6,
      916.2,
      35
    ],
    "that Vector 1 0 as a linear combination of the vectors 1 1 + 1 - 1 you have to take a half times the first + 1/2 times the second. So that's coordinates. So let's finish with one more example here in the last 3 minutes. Just to stretch our minds a little bit. Let's look at the vector space of polynomials of degree 2. Okay, so that is ": [
      2876.8,
      2907.1,
      111
    ],
    "that in this example cuz there's only one free variable. So that means that what we mean is This non pivotal column here gives us this one here. Okay, which is the standard basis Vector of are what the number one. But anyway, when there's only one vector you don't need to do any work to see if it's linearly independent or not. Remember that any nonzero Vector form is ": [
      991.0,
      1018.1,
      39
    ],
    "that will be on the following homework set you are 4th lab assignment is due on February 23rd. Just coming up next Friday and just getting it out of there. So you're aware you are no you have another midterm coming up two weeks from tonight is midterm too, and there will be more detail announcements about seating assignments rooms Etc in the coming lectures. So let's get started on ": [
      33.6,
      62.9,
      1
    ],
    "the basis number of elements is constant so you could rephrase as suppose. I know that the space is and dimensional. Okay, and is to hear if you know, you have an n-dimensional space and you want to find a basis for it. It's good enough to find any set of n linearly independent vectors and they will automatically also spend this app. Similarly is good enough to find any ": [
      454.1,
      481.6,
      17
    ],
    "the constraints of the system. And the melody is the leftover information. It's the number of redundant equations and the statement is that if you have a bunch of equations and some unknowns, there might be fewer than the number of equations that really have the information there. But that the sum of the number of redundant equations and the number of non-redundant information. That's just the number of variables. ": [
      1290.5,
      1318.0,
      50
    ],
    "the inverse of that Matrix. x a b which is 1/2 1 1 1 - 1 a b which is A + B / 2A - B / 2 And there are the coordinates. Okay, so that's what the the coordinates of B in this new. Basis we start with a vector a b and the new coordinates of that Vector in this new bases are a + b / ": [
      2757.5,
      2788.3,
      107
    ],
    "the material for today. So last lecture we introduced a new word. It's not a new word, but we gave meaning to a word we've been using informally Dimension. So we saw that if I have any two. Vector spaces revive a vector space if I have any two bases of it. So for us in this room almost always the vector spaces and subspaces were considering are ones that ": [
      62.9,
      88.9,
      2
    ],
    "the same number of vectors in it for a Subspace. It's also true that that number actually allows you to figure out whether something is a basis very easily if I ever give you two vectors, so if I have a two dimensional Subspace and I ever give you two vectors that span the space, you know, they are linearly independent and form a basis because of this fact because ": [
      431.3,
      454.1,
      16
    ],
    "the vector two-three? Because if I drop a line down here, it's two units in the X Direction. And if I drop line over here is 3 units in the y direction, but what's really going on there? Is that here? I have the standard basis Vector E1 and here I have the standard basis Factory 2. There's anyone there Z2 and what describing that Vector has 2/3 really means. ": [
      2153.1,
      2185.8,
      84
    ],
    "these guys and so by problem for a on your midterm the set consisting of these two vectors. Plus this third Vector would be linearly independent which means that you would have a a linearly independent set Envy having three vectors in it, but that's impossible because we know that every bases has two vectors. So this example illustrates an important point. It's not just true that every bases has ": [
      405.2,
      431.3,
      15
    ],
    "they mucked up the columns. They didn't change the linear relationships between columns, but they changed the column space which is why when I'm trying to find the column space, I have to look at the pivotal columns in the original Matrix. But row operations don't mark up the row space. What is the row space at the space of linear combinations of the Rose row operations are linear combinations ": [
      1771.9,
      1796.3,
      69
    ],
    "thing with a plane for now, so you give an address to every point in defrost with any of the actress geometrically we imagined points not as just points, but as arrows emanating from the origin, that's why I've drawn here, but this Vector hear this Vector we described as the vector 2 3 Move that appear. Oops get us the vector 2 3 and why do we call it ": [
      2125.7,
      2153.1,
      83
    ],
    "this is a collection of vectors in R3 and it is a Subspace. We saw that its a Subspace by just noting that we can do this sort of usual trick of decomposing this arbitrary Vector in there in the form a type of some Vector the vector 1 1 2 plus b e x a vector 1 - 1 0 so everything in their looks like that. So in ": [
      139.0,
      162.9,
      5
    ],
    "to be one again. And then the second Vector here. That's B1 + B2. No. You shouldn't be able to say unless you read the textbook right away or lots of bases. But you what you can say from here, as you know, the span of those vectors these two vectors here. That's still contained in this Subspace V. If I have anything that is a linear combination of those ": [
      328.7,
      355.6,
      12
    ],
    "to say Vector space of polynomials of degree 2 at most the vector space the space of polynomials the set of polynomials of degree 2 is not a vector space just like we did with the example of polynomials of degree 3 0 polynomials and then there but if we allow polynomials of degree up to 2, then we're fine. Okay, and we can describe this explicitly as oops. as ": [
      2907.1,
      2931.6,
      112
    ],
    "two numbers the rank plus the nullity is something fixed for all matrices of a given size. So what is it the rank plus the melody is equal to The number of columns that's it. Okay. So here's another way to think about that. So the number of columns of a matrix taking back to lecture 1 The Columns of the Matrix correspond to the variables in our system of ": [
      1205.3,
      1238.0,
      47
    ],
    "two vectors and we can just look and see that neither is a scalar multiple of the other they're not parallel there for their linearly independent. And so these form of basis. for the and therefore the dimension of V is equal to 2 cuz there is a basis with two vectors. And therefore every basis for this Subspace will have two vectors in it. Now, let's look at some ": [
      193.2,
      224.8,
      7
    ],
    "two vectors following the same argument. We gave at the beginning of last lecture. It will be a linear combination of just B1 and B2 as well. Okay. So the span of these vectors is contained in the span. Of the ventures up there. So the Subspace spanned by these two vectors is contained in v. But also you can just check that these two vectors here are linearly independent ": [
      355.6,
      381.6,
      13
    ],
    "unique way of those pulling those three basis vectors. So let's figure out how well will remember how to multiply polynomials this is x squared minus 2x + 1 and we see that it's representative and uniquely as a linear combination of x squared x and one so looking at these coefficients hear what we see is that the coordinates of B in terms of the basis the so-called standard ": [
      2981.7,
      3011.6,
      115
    ],
    "up there says that they are spending set and as we discussed last day, they are linearly independent. So that's a basis for the polynomial space P2. So let's use that basis that hears a polynomial P polynomial is x - 1 squared. It's in the Spectra space P2. That means it has coordinates in terms of this basis B. We can express it as a linear combination and Uconnect ": [
      2955.5,
      2981.7,
      114
    ],
    "vectors in this Vector space that form a basis for the Spectra space. Then we can so that Vector space has a basis of size n think of an equal three here. If you have a basis of size 3 the dimension of your vector spaces 3 What does process of putting coordinates from the basis on your space does is it allows you to identify this abstract Vector space ": [
      2442.4,
      2467.6,
      94
    ],
    "was pointed out that actually just give the whole row of zeros here. Okay. So the next thing I should do is Eliminate the one well, actually there's a couple of different choices. I could make here. Let me do this instead. We know in the row reduction algorithm. If you ever get a Rosie Rose, you supposed to shuffle it to the bottom right doing row swaps. So let's ": [
      1606.9,
      1634.1,
      63
    ],
    "we do row operations, The row space of a matrix is the span of the rows of the Matrix. So we take the set of all linear combinations of the Rose. And we can write it in a slightly different way because remember there's this nice operation on matrices that turn them on their side or that rotate them around or reflect them across the main diet of the diagonal ": [
      1387.0,
      1411.1,
      54
    ],
    "were to just give you an exam Pearson Matrix a here's its reduced row Echelon form find the pivotal Rose. You can't do it. You can't figure out which were the pivotal Rose in a just by looking at the final for the reduced row Echelon form. Okay, so that's a problem except it's not a problem because we could just as well say hey. When I did row operations, ": [
      1745.2,
      1771.9,
      68
    ],
    "which has those coordinates as its coefficients is so this notation. I take V with square brackets around it and put a be down there says this is the coordinate Vector a v in terms of the basis B and it's just telling you those coefficients. There are the ones that describe the in terms of that basis and you take those coefficients and you string them together in a ": [
      2493.8,
      2515.2,
      96
    ],
    "with our three? Allows you to identify any n-dimensional Vector space with RN and here's how you do it. I take any Vector in my space V. I know that there's one unique way to express it as a linear combination of the given basis vectors. So this one has coordinates x 1 x 2 3 x n I'm going to now look at the associated Vector in r n ": [
      2467.6,
      2493.8,
      95
    ],
    "words the null space is the span. of the single vector 0210 now we saw last day why it's always true that using this procedure. We will produce not just a spanning set but an actual basis and that's because if you look at the entries corresponding to the free variables here, you'll get the standard basis vectors in the different vectors against pending set here. It's hard to see ": [
      963.9,
      991.0,
      38
    ],
    "x 3 x 3 is a free variable. It's a non-committal call him and x 4 x 4 actually the third equation there tells us that x40. and so that is a full description of the null space and we can do our usual trick a factoring out the free variable x 3 we see that everything else best looks like some free variable X the vector 02210 in other ": [
      937.3,
      963.9,
      37
    ],
    "your basis vectors. Here there's a danger because the first two column the first two rows of of this row Echelon form that we just arrived at those are pivotal, but those correspond to the first and third rows in the original Matrix and the only way to know that is to follow through the row reduction the row operations and see that we did a row swap. If I ": [
      1719.6,
      1745.2,
      67
    ],
    "zero is if all the coefficients are zero so because these are linearly independent, all those coefficients are zero. But that means that X1 equals. Y1 and X2 equals y 2 and x n equals wire. Okay, the only way you can find v as a linear combination of these is that one unique way every Vector has a unique set of coordinates. That's what these are called coordinates. Determined ": [
      2362.7,
      2393.2,
      91
    ]
  },
  "Full Transcript": "Listening to a podcast. Good morning. Happy Wednesday when I get straight to it today, so please find a seat.  Quick administrative reminders you are next MyMathLab homework that is due this coming Tuesday. There's no class on Monday. Okay, but the homework is due on Tuesday. It will cover everything that we do up to and including this lecture next lecture. We're going to start talking about determinants and that will be on the following homework set you are 4th lab assignment is due on February 23rd. Just coming up next Friday and just getting it out of there. So you're aware you are no you have another midterm coming up two weeks from tonight is midterm too, and there will be more detail announcements about seating assignments rooms Etc in the coming lectures.  So let's get started on the material for today.  So last lecture we introduced a new word. It's not a new word, but we gave meaning to a word we've been using informally Dimension. So we saw that if I have any two.  Vector spaces revive a vector space if I have any two bases of it. So for us in this room almost always the vector spaces and subspaces were considering are ones that are spanned by a certain finite set of vectors. They said that's the contacts that were in here right now and so for such a vector space  Or Subspace of another Vector space a basis, which is a linearly independent spanning set with the resilience of those for any given space. Okay, but there's one common feature they all have which is that they all have the same number of members same number of elements. If there's one basis that has four vectors in it than all bases have exactly four vectors. So this number the number of vectors in any basis for a Subspace is called the dimension of the Subspace it so here's an example. We saw from a few lectures ago. So here's a vector space. This is a Subspace by the way of our three.  Is this is a collection of vectors in R3 and it is a Subspace. We saw that its a Subspace by just noting that we can do this sort of usual trick of decomposing this arbitrary Vector in there in the form a type of some Vector the vector 1 1 2  plus b e x a vector 1 - 1 0 so everything in their looks like that. So in fact what we see is that V is equal to the span of those two vectors.  Okay. So now how would we find a basis for the Subspace? We need to find a spanning set. That is also linearly independent. We have a spanning set here. If it's linear independent, we're done. It's a basis and this is an example where we don't need to do any work. There are two vectors and we can just look and see that neither is a scalar multiple of the other they're not parallel there for their linearly independent. And so these form of basis.  for the and therefore  the dimension of V  is equal to 2 cuz there is a basis with two vectors.  And therefore every basis for this Subspace will have two vectors in it.  Now, let's look at some other bases.  for the same Subspace  Here's one. Let me just take those two vectors and scale them like two to four.  + 1 - 110  K that's another basis for this space now, it's actually easy to check that. That's the case those two vectors form a spanning set for the space because we'll all I did was to take the two vectors in the Spanish that I already have and scale them a little bit. So any Vector that could be expressed as a scalar as a linear combination of the two vectors up. There is also a linear combination of the two vectors down here just by changing the a I have to replace a with a / 2 + B with - be right, but it's still a spanning set. So I have another spending set and  It's clearly linearly independent same as before it we can just eyeball and see that it's not really independent, but actually better than that if you ever have a linearly independent set of vectors and all you do is you scale them by non-zero scalars. You're not going to change the linear Independence because that's not going to change whether all of those columns in The Matrix that you put together from them are pivotal, but here's another example  maybe worth discussing  Let's do let's include 112, but let's also do 2:02  How did I get that one there? We call these two vectors here B1 and B2.  So this one over here in the in the first second example, I used to be one in - be to those are also a basis. How about here? I used to be one again. And then the second Vector here. That's B1 + B2.  No.  You shouldn't be able to say unless you read the textbook right away or lots of bases. But you what you can say from here, as you know, the span of those vectors these two vectors here. That's still contained in this Subspace V. If I have anything that is a linear combination of those two vectors following the same argument. We gave at the beginning of last lecture. It will be a linear combination of just B1 and B2 as well. Okay. So the span of these vectors is contained in the span.  Of the ventures up there. So the Subspace spanned by these two vectors is contained in v.  But also you can just check that these two vectors here are linearly independent same deal. They are not scaling multiples of each other. So what I've got is a basis of size 2  for a Subspace of V, but we know that every basis of V has two vectors in it by so actually there can't be anything left over if there were anything in ve that weren't in here. That would be a new Vector which is not in the span of these guys and so by problem for a on your midterm the set consisting of these two vectors. Plus this third Vector would be linearly independent which means that you would have a a linearly independent set Envy having three vectors in it, but that's impossible because we know that every bases has two vectors. So this example illustrates an important point.  It's not just true that every bases has the same number of vectors in it for a Subspace. It's also true that that number actually allows you to figure out whether something is a basis very easily if I ever give you two vectors, so if I have a two dimensional Subspace and I ever give you two vectors that span the space, you know, they are linearly independent and form a basis because of this fact because the basis number of elements is constant so you could rephrase as suppose. I know that the space is and dimensional. Okay, and is to hear if you know, you have an n-dimensional space and you want to find a basis for it. It's good enough to find any set of n linearly independent vectors and they will automatically also spend this app.  Similarly is good enough to find any and vectors that span the space and then they will automatically be linearly independent. You think about it those two statements. I just made get translated into the same fax machine over and over again, which is that if you have a square Matrix, if all the rows are pivotal than all the columns are pivotal and vice versa. And so that's a restatement of those facts and we can actually prove it that way at the end of this lecture after we talked about coordinates, but but that's an important when I wanted to make if you want to find a new bassist for the space once you know, how many basis vectors you're looking for. You don't need to verify that it's both linearly independent and expanding set either one of those together with the number of vectors being right will be enough information to verify that it's a basis.  So that's dimension.  Right. I stated that V isn't it out loud, at least that V is a vector space here. We actually did Pruitt in an earlier lecture for this example, but if you're talkin about what you might expect to see on an exam or homework, it may well say here is a vector space V. Okay now tell me something about it find a basis for it to compute the dimension. You are not always expected to verify from first principles that what I told you was true. If I tell you it's a vector space go ahead and believe me that it's a vector space, please.  Thanks.  Okay. So Dimension super important quantity, it's makes precise something that we've all been thinking about and if I go get into that more later in this lecture, but you know many of you had this reaction when were saying I've got these two vectors that you know, they don't split in R3, they don't spend all of our three question. So do they stand are too that's the question that many of you asked every time I just got people ask that question. It's a natural question know those pictures aren't even in our too but what they do span is a two-dimensional Subspace of R3, which looks like R2 and we will be more precise about what looks like means at the end of this lecture.  But first now let me introduce some more terminology because we know we need more vocabulary in this course, right? We've only introduced one new word today. We need at least a few more to keep up pace. So if I give you a matrix & M by n Matrix 7 by 6 Matrix, so here's a five-by-five 5 by 4 Matrix. There are two numbers Associated to it that come from the two subspaces. We've been talking about Associated to it. So if I give you a matrix, there's two important subspaces. We've been dealing with the column space in the null space. The column space is the span of the columns. Hey, that's a Subspace of the codomain for a and the no space is the solution set of the homogeneous system with a as coefficient Matrix. That's a Subspace of the domain.  Well, those are two subspaces of of euclidean space is of RN and RM their subspaces. They have Dimension each of them. You can find a basis and last day we talked about some ways to find basis for those faces. And therefore we can count the number of bases factors that tells us the dimension of those spaces. So we give those words that the dimension of this of the null space in the space names the dimension of the column space of a matrix a is called the rank of the Matrix a  And the dimension of the null-space of a matrix a is called the nullity of a I'm not even sure your textbook uses that word. I think it's somewhere in the textbook but they usually just say dimension of the null space. It is a very common word. You'll see all over the place if you're doing anything else with linear algebra, so you should know it Noah T is the dimension of the null space.  Okay, so we can compute those for any Matrix because we know actually how to completely determined.  The no space in the column space and in particular we know how to find basis for them. So let's do an example to illustrate this point again in to reinforce what we did last day. So here's a matrix is a particular 5 by 4 Matrix. I've gone ahead and ask Matlab to do the row reduction for us. So there is its reduced row Echelon form. So we don't have to do any of the computational work in order to answer the question. I'm going to ask your so what I want to know is I want to find a basis for the column space and I want to find a basis for the null space. Once we have the base's we can count up how many vectors are in each answer the question. What's the rank of a and what's the melody of a Kind? So let's do that. So first of all,  The column space. Well, let's just the span of these four columns.  But is that the right number of columns is is this a four-dimensional space or if I were going to find a basis? How many vectors would it have? So somebody tell me what is a basis for the column space of a  the pivotal columns which are the pivotal columns in this example. Yes at the back.  Columns 1 and 2 yes calls 1 and 2 are pivotal are the only pivotal columns.  And for yes, 1 2 and 4 in a and end the British restaurant in form of a those are pivotal Collins call him three is a scalar multiple of column to which you can actually see in the original Matrix. So it's not that at all. So those three form a basis write those those three factors that are highlighted in yellow there a basis for the column space, right?  Wrong, you were all fooled. No, not of the reduced row Echelon form critical important point to remember those three columns are pivotal in the reduced row Echelon form of a and therefore those three columns columns 1 2 and 4 are pivotal in a those three columns of the column space of a the three columns that I highlighted in yellow. Those are not even in the column space of a there in the column space over there do stretch loan form of a which is typically a different Adam. Okay, so very important point so that here is a basis.  these three form of Asus  for the column space of a  I know that means that I can tell you what the dimension of the column space is. It is 3 so therefore the rank of this Matrix is 3  No, I also want to find a basis for the null space of a and as we saw last day that way to do that or a way to do that is to follow the procedure. We've been doing since day one of this course do row reduction in order to describe the solution set. So the null-space of a  Is the set of vectors? Okay. It's going to be vectors in R4.  Because the Matrix has four columns.  And we look at the reduced row Echelon form to see what the reduced equations say about those. So the first equation there 1000 coefficients. Remember, there's the augmented zero on the right hand side for the homogeneous system that tells us that X1 is pinned down X1 must be zero.  The second equation says x 2 - 2 X 3 equals 0 so we get x 2 is equal to 2 x 3 x 3 is a free variable. It's a non-committal call him and x 4 x 4 actually the third equation there tells us that x40.  and so that is a full description of the null space and we can do our usual trick a factoring out the free variable x 3 we see that everything else best looks like some free variable X the vector 02210  in other words the null space is the span.  of the single vector 0210  now we saw last day why it's always true that using this procedure. We will produce not just a spanning set but an actual basis and that's because if you look at the entries corresponding to the free variables here, you'll get the standard basis vectors in the different vectors against pending set here. It's hard to see that in this example cuz there's only one free variable. So that means that what we mean is  This non pivotal column here gives us this one here. Okay, which is the standard basis Vector of are what the number one.  But anyway, when there's only one vector you don't need to do any work to see if it's linearly independent or not. Remember that any nonzero Vector form is a linearly independent set. So we have one nonzero Vector here. It's a basis for our space there for the dimension of the space is  is what there's a basis of size one. So therefore the dimension of the null space of a is one which is defined to be the nullity.  So there's are two numbers for this Matrix. This Matrix has Rank 3 and nullity 1.  now we can see from this by the way how we can figure out what those numbers are without going through this much work because  the column space is you pointed out is spanned by the pivotal columns and they form a basis because the pivotal columns are linearly independent.  That means that the rank the dimension of the column space, which is the number of elements in any basis is the number of pivotal columns.  So that's another way we can just describe. What is the rank of a matrix and then it really had some linear algebra meaning for us. The rank of a matrix is the number of pivotal columns in that Matrix.  The nullity of the Matrix. Well, we see from this procedure that we're going to get in the spanning set that we know is a basis for the null space each non pivotal column each free variable is going to give us  By the way, can you guys see the difference between the yellow and the green up there? I really can't I'm color-blind, but I made a mistake for myself doing that. But hopefully it's not a problem for you guys. Try to avoid it in the future. Each non pivotal column is going to give us one of the columns that spans than l-space. It's not right to say that the pivotal in the nonpareil columns are a basis for the null space. They're not even in the null space but to each non pivotal column in a corresponds a basis vector.  So that means the nullity of a is the number of non pivotal call UPS in The Matrix. So actually once you have the reduced row Echelon form of the Matrix or any any row Echelon form of the Matrix, you can quickly answer the question. What's the ranking? What's the nullity? These are just new words for number of pivotal columns versus number of non pivotal columns.  And that's what I just wrote right here. So let's let's write it again. So the rank of a is equal to the number of pivotal columns.  And the nullity of a is equal to the number of non-committal columns.  And so that gives us front right there up there and actually super important them. It's called the rank nullity theorem or sometimes just the rank theorem and it's the statement that for any Matrix.  The rank on the melody they can depend on those particulars of the Matrix, but the sum of those two numbers the rank plus the nullity is something fixed for all matrices of a given size. So what is it the rank plus the melody is equal to  The number of columns that's it.  Okay.  So here's another way to think about that. So the number of columns of a matrix taking back to lecture 1 The Columns of the Matrix correspond to the variables in our system of equations. So the number of columns is the number of variables.  Now what is the rank the rank is the number of pivotal columns, which is also the same as the number of pivotal Rose, of course that the rose correspond to equations.  A pivotal role is one that is not a linear a scalar multiple of the others. There's not a linear combination of the others a pivotal role as an equation. That is not redundant.  So we start with some system of equations, but it might be as we've seen that you can reduce it to a system of fewer equations.  Those equations correspond to the pivotal Rose.  The rank is that number of non-redundant equations. It's the actual amount of information that's there.  If that's what the rank is, it's the number of equations that really describes the constraints of the system. And the melody is the leftover information. It's the number of redundant equations and the statement is that if you have a bunch of equations and some unknowns, there might be fewer than the number of equations that really have the information there.  But that the sum of the number of redundant equations and the number of non-redundant information. That's just the number of variables. I give you some variables. They might all be free or they might all be constrained but whatever happens the number of three variables plus the number of constraints is just the number of variables.  Okay, so that's the rank nullity theorem rank facility is the number of columns.  Now here's one more Subspace Associated to a matrix your textbooks talks about and that isn't going to be important in some applications later the row space of the Matrix. So the column space remember the column space with the span of a columns.  Now the columns are column vectors in r n r r Emma whatever letter word using as we've been talking about from the beginning. But remember we're also open to Vector spaces that have different forms to them. We've been talked about how make sure she's themselves can be considered as vectors. So how about the rows of the Matrix? Those are also vectors where Customs thinking of vectors as columns, but for our purposes right now we can talk about actually the rose are vectors as well. We can take linear combinations of the Rose. In fact, that's what we've been doing since day one taking linear combinations of the Rose is what we do when we do row operations,  The row space of a matrix is the span of the rows of the Matrix. So we take the set of all linear combinations of the Rose.  And we can write it in a slightly different way because remember there's this nice operation on matrices that turn them on their side or that rotate them around or reflect them across the main diet of the diagonal of the transpose. The transpose turns the rows into columns in the columns into rows from Matrix. So another way to write what the row space is is to say, well the row space is the span of the Rose the rose of a are The Columns of a transpose.  So the row space can equivalently be thought of as the column space of a transpose. So it just fits right into the framework that we've already been studying. This is what your textbook writes it slightly wrong because the column space of a transpose is still a collection of columns.  Right. So we're taking the caught the rose of a we're turning them on their side to make them columns and then taking their span that gives us a space of columns. Where is the row space is a space of Rose. So if you want to be really technically correct, you should also take the transpose back to make those columns back into Rose. Okay, but that's a bit of a notational point. It's not that important as long as we're consistent about these things. You're going to think of the roast basis to set up as a span of the rows of The Matrix.  So let's just look at an example here.  Before we go any further. Here's a matrix a a 3 by 5 Matrix.  And I would like to determine what the row space is what I should have written it down already here for you because by definition the row space is the span of the rows. So it's the span of those 3 reps.  but  this is a Subspace. It's a span of some vectors just as Subspace and as usual, we would like to have a basis for it would like to have a minimal description of it. So he's ever found a basis are the roads of that Matrix of a basis for the row space. And otherwise, I'm asking are the rows of that Matrix linearly independent.  What do you think just looking at the Matrix? Are they?  No, somebody said no confidently. Why not?  You're right, but why not?  Yes.  Very good the third with the second row is three times the first row. So there's there's a sort of in-your-face linear dependence there. Okay, so they are not linearly independent. So that means that we can certainly throw away the second row or there's no point of including it. So let's just go ahead and and do that. Let's just throw it away and we won't change the row space when we do that we can stay on the row space is the span of the first column in the third column.  1/3 for first row in third row of a and are those two linearly independent? Yeah. That's that's again the kind of thing. We have two vectors. You can check just by eyeballing. The second one is not a scalar multiple of the first so there is a basis for the row space.  now let's systematize that  like we did with the column space. So I'm going to do row operations in order to take this Matrix to reduced row Echelon form or actually, I'll just go to row Echelon form.  Okay, I'm going to subtract 3 times the first row from the second.  And as was pointed out that actually just give the whole row of zeros here.  Okay. So the next thing I should do is  Eliminate the one well, actually there's a couple of different choices. I could make here. Let me do this instead. We know in the row reduction algorithm. If you ever get a Rosie Rose, you supposed to shuffle it to the bottom right doing row swaps. So let's do that roast well because all the roads are supposed to be at the bottom.  Okay, I know.  I'm not quite in row Echelon form yet. I got to get rid of the one in the second row in the First Column. So I subtract the first row from the second using the zero I want there.  1 they're 3 1 and 4.  I know this Matrix is in row Echelon form so we can tell which rows are pivotal. So which rows are pivotal.  in this Matrix in there in the one that I've just arrived at  the first and the second Rose are pivotal here.  Okay, so I guess that means that we should take the first and second rows of a hazard basis vectors, right?  Know why not?  I'm sorry. I just heard mumbling.  We switch some rolls around. This is the point that I wanted to make with this example. So remember in the column space I said you look you do alterations. You get to Russia one form you figure out which columns in the rush rush on Farmer pivotal. I did to those columns that are pivotal in the original Matrix and then you have to use the ones in the original Matrix as your basis vectors.  Here there's a danger because the first two column the first two rows of of this row Echelon form that we just arrived at those are pivotal, but those correspond to the first and third rows in the original Matrix and the only way to know that is to follow through the row reduction the row operations and see that we did a row swap. If I were to just give you an exam Pearson Matrix a here's its reduced row Echelon form find the pivotal Rose. You can't do it. You can't figure out which were the pivotal Rose in a just by looking at the final for the reduced row Echelon form.  Okay, so that's a problem except it's not a problem because we could just as well say hey.  When I did row operations, they mucked up the columns. They didn't change the linear relationships between columns, but they changed the column space which is why when I'm trying to find the column space, I have to look at the pivotal columns in the original Matrix.  But row operations don't mark up the row space.  What is the row space at the space of linear combinations of the Rose row operations are linear combinations of the Rose row operations don't change the row space that change the column space but not the row space so I could just as well.  You is as a basis the pivotal columns that I just arrived at.  Okay, I could just as well use the pivotal columns in a row Echelon form. I could continue I could go one more step and do the reduced row Echelon form here and I could use those columns as well. There's more freedom here. You're not changing the row space. So as long as you know, which columns which rows are pivotal at any given time you can use those Rose in any row equivalent form of the Matrix and they will form a basis for Aerospace. That's only true for the row space not for the column space. So that's a saddle to hear. If you're asked for a basis of the row space. I recommend you always use the pivotal role in the reduced row Echelon form if that's given to you. If you're asked for a basis of the column space, you must always use the pivotal columns in the original Matrix that you don't have a choice about from that information.  Crystal, that's what they're only one at the high like here, which is row operations. Don't mess up the row space. The row space of a is the same as the row space of the reduced row Echelon form of a and then one more thing I wanted to highlight here, which is okay. So I've got this new space the row space.  That's a third one from Matrix. We have the concert of the null-space now. We got the row space now on the last slide. I introduced to size going to do some new notation some new terminology Rank and nullity rank was the dimension of the column space. Melody is the dimension of the null space. Maybe we should have had more words. Maybe I should have said the column rank is the dimension of the column space and I should have Ro rank is the dimension of the row space. I need to have a word for the dimension of the row space.  Well, I don't need an extra word for it because remember what is the rank the rank is the dimension of the column space. That's just the number of basis elements in any basis for the column space and the nicest bases that we you know how to find for the column space is the pivotal columns other words. The rank is the number of pivotal columns in The Matrix a how does that relate to the Roosevelt?  Well, let's think about it for a moment. So then the dimension of the row space of a is the number of pivotal.  Columns of a  and the way we would calculate that is we go to the reduced row Echelon form and we just count the number of pivotal ones.  and the reduced row Echelon form of a  Is a pivotal one in each pivotal column, but remember there's a pivotal one in each pivotal row and column.  The number of pivotal ones is also equal to the number of pivotal Rose.  in a day or the reduced row Echelon form of a  okay, and oh, I'm sorry. So I should have started here.  So dimension of the column space I started with here and this this is equal to the dimension of the row space down here. So let me reiterate that.  Let's go backwards. The dimension of the row space of a is a size of a basis for the row space of a which is the number of pivotal Rose in a but the number of pivotal Rose and the number of pivotal columns in a matrix. Those are the same number. They just count the number of pivotal once in the registration form. So the dimension of the row space and the dimension of the column space are the same animal. This is the rank of a the rank of accounts. Not only the number of pivotal columns, but also counts the number of pivotal Rose  One word of caution the rank nullity theorem says that the rank plus the melody equals the number of columns.  It doesn't equal the number of rows in typically in less than of rows into Columns of equal. So you should remember the rank as describing the number of pivotal columns. But remember that it also is the number of rows. So it's also the dimension of the row space.  All right, so that's what I wanted to say about Dimension and rank and now for the remainder of this lecture or talk about section 4.4.  I'd really the subject of section 4.4 is why do we care about a basis? Anyway, what's so great about a basis. I've described it as being a sort of minimal description on most efficient description of a Subspace, but it's more than that and let's think back way way back to elementary school where you first encountered Cartesian coordinates. They are maybe that was middle school, but whenever you encounter.  So Cartesian coordinates named after an ID account, which means Renee the mapmaker? Okay. They describe a way to give an address to every points on Earth for him. But in general to every point in the plane or in Space the last thing with a plane for now, so you give an address to every point in defrost with any of the actress geometrically we imagined points not as just points, but as arrows emanating from the origin, that's why I've drawn here, but this Vector hear this Vector we described as the vector 2 3  Move that appear. Oops  get us the vector 2 3 and why do we call it the vector two-three? Because if I drop a line down here, it's two units in the X Direction.  And if I drop line over here is 3 units in the y direction, but what's really going on there?  Is that here? I have the standard basis Vector E1 and here I have the standard basis Factory 2.  There's anyone there Z2 and what describing that Vector has 2/3 really means.  Is that that is two times the first standard basis Vector plus three times the second standard basis vector.  Okay, it's chewy OnePlus 3 e 2.  Now if you want Annie to is a basis to standard basis.  fart  And that's what a basis does for you.  Every point in your Subspace in your vector space can be coordinate eyes. In a unique way in terms of the basis. I give you a basis. The basis is a spanning set. So every Vector in the space is a linear combination of the basis vectors.  That's true for any spanning set. What's special about a basis? What's special about the fact that it is a linearly independent Spanish that is that those components those coordinates will be unique have a question.  So that's a statement here. If I give you a basis behind a script to be basis vectors be wants to be on for a vector space than every Vector in the space has a unique expansion in terms of the basic factors that is spanning set. So every Vector Envy can be written as a linear combination of the bees but not only can it be rain in a linear combination. There's only one linear combination is only one set of coefficients X-14 XM that makes this work. Why is that why is it unique? So that's the important word here unique.  Why well, if we also had a different one in ostensibly different one.  So have you know, the xm's are coefficients that make this work for a particular V suppose. I had some ostensibly other coefficients why one through why on that made it work. So let me call this equation 1 + this equation to let me do raw thracian here. Let me subtract equation one from equation to that says that V - V is equal to what let me collect terms now everything that multiplies to be 1 is X1 - X2 X1 - y1.  Xb1, everything that multiplies B2 is X2 - Y2.  Those are not factors that are scalars * be too and so on Down the Line.  Novi - 3 equals 0 so look at this for a moment here. I've got a new linear combination of the vectors V1 through bien.  with coefficients here  I've got a linear combination of these basis vectors that gives the zero Factor.  The basis vectors are linearly independent that exactly means that the only way you can get a linear combination of them equaling zero is if all the coefficients are zero so because these are linearly independent, all those coefficients are zero.  But that means that X1 equals. Y1 and X2 equals y 2 and x n equals wire.  Okay, the only way you can find v as a linear combination of these is that one unique way every Vector has a unique set of coordinates. That's what these are called coordinates.  Determined by the bases. That's what's so important about a basis. They give us a way to coordinate eyes are Subspace to put coordinates on it.  So let's let's formalize that if it lets out a little bit of notation, which is actually going to be super helpful and understanding this tricky Point we've had since we started talking about solving equations and spanning sets.  So if V is a vector space and it has basis vectors V1 Serbian dating out remember, these are not necessarily the standard basis vectors of RN we could be talking about the Subspace the column space of some Matrix in the bees are the pivotal columns are not typically the standard basis vectors. We could be talking about a space V of polynomials and then those bees those are some particular polynomials.  Okay, there's some vectors in this Vector space that form a basis for the Spectra space.  Then we can so that Vector space has a basis of size n think of an equal three here.  If you have a basis of size 3 the dimension of your vector spaces 3  What does process of putting coordinates from the basis on your space does is it allows you to identify this abstract Vector space with our three?  Allows you to identify any n-dimensional Vector space with RN and here's how you do it. I take any Vector in my space V. I know that there's one unique way to express it as a linear combination of the given basis vectors. So this one has coordinates x 1 x 2 3 x n  I'm going to now look at the associated Vector in r n which has those coordinates as its coefficients is so this notation. I take V with square brackets around it and put a be down there says this is the coordinate Vector a v in terms of the basis B and it's just telling you those coefficients. There are the ones that describe the in terms of that basis and you take those coefficients and you string them together in a column vector and that's called the coordinate Vector a v in terms of the basis B.  so for example if I have a vector in R to which I write as a column, Vector AV  Then it's coordinate Vector in terms of the standard. Basis is a v that's exactly what it means as we noted on the previous slide up here. Okay that if I take the vector 2 3 that means it's 2 * 81 + 3 * 82.  I saw the coefficients of that Vector in terms of the standard basis E1 and E2.  are two and three  Careful here. It's really important that the basis vectors are ordered. Cuz the order you choose for the basis vectors. Although that doesn't change the dimension or the column space or anyting else and are examples of Racine. It does determine what order you write the coefficients of the coordinate Vector. So if we have a vector in R2, we can always right in terms of the standard basis, but the standard basis is not the only basis are zillions of base's so here's another basis of our two.  The ventures 1 1 + 1 - 1 we know it's a basis of our two because four bases of RNA. We have a theorem that says Hey, I want to check if I have two vectors and are too if they form a basis. All I have to do is write down the court. They Matrix with those vectors as its columns and check if that is an invertible Matrix and so is this Matrix here 1-1 1-1 invertible.  Another words are those two columns linearly independent.  I could also, you know, let's remind ourselves about inverses. Let's calculate the inverse of that Matrix as a sidebar over here.  We have our nice formula for two by two matrices. So what have to do is divide by this number the determinant which is 1 X - 1 - 1 x 1 so that gives me a -2 down there and then I have to reverse.  The diagonal entries and put minus signs in front of the off diagonal entries.  So what I get is actually just 1/2 x 2 Matrix 1 1 1 - 1  That's the inverse they're all right. So anyway, that's a basis. So this Matrix is invertible. And that's a basis for our two. Now. I want to take the vector and arbitrary Vector Ava and I want to write it. I want to write it in terms of that basis. So I want to say here's my Vector a b.  But I want to know what are its coordinates in terms of the basis B.  In other words, I have to say I take the vector a be written in the standard basis and I have to be able to write it as a x 1 x 1 1.  + x 2 * 1 - 1 I know I can do that. I know that those two vectors span R2 they form a basis. So I will be able to write a v as a unique linear combination of those two vectors. Once I can do that then this thing here this coordinate Vector of a b in terms of that new bases. That's what we call X1, X2.  Now let's push this a little further and I'm going to find that X1 and X2. Of course. What I'm doing here is I'm going to solve a linear equation to solve. This is a vector equation A and B. I'm thinking of it as known parameters and I want to find the X1 and X2 that make this work. So how do I do that?  No, we're just going to use the inverse Matrix. What are you talkin about row reduction would be the usual way to do it because I already computed the inverse Matrix. I'm going to use it here because note that this says 1 1 1 - 1 * x 1 x 2 is equal to a b and the inverse Matrix is set up perfectly to solve this. Once we have it there for X1 X2 is equal to the inverse of that Matrix.  x a b which is 1/2 1 1 1 - 1 a b which is  A + B / 2A - B / 2  And there are the coordinates. Okay, so that's what the the coordinates of B in this new.  Basis we start with a vector a b and the new coordinates of that Vector in this new bases are a + b / 2 + a - b / 2 by the way, it's very instructive in this example to look on a picture. So I don't have a lot of room here. Let's squeeze it in peso here stressing straight lines.  So my standard basis vectors.  Are here and here?  And these new basis vectors in the basis be on put those in red they are here and here.  The new basis I get by taking the old frame and rotating at 45 degrees. And also I've lengthen the vector. These aren't vectors of unit length. Is that why we haven't talked about life yet, but you can see that they're longer arrows.  So expressing a vector in terms of the new basis means I have to turn my head 45\u00b0 and scale a little bit and that's exactly what this operation here. Does the new coordinates A + B / 2 + 8 - B / 2A. So if I started with the vector 1 0 then it's coordinate the first standard basis Vector its coordinates in the new bases are 1/2 0.  3 or 1/2 1/2  and so that first standard basis Vector its new coordinates are 1/2 1/2.  And all that means is that if you want to express that Vector 1 0 as a linear combination of the vectors 1 1 + 1 - 1 you have to take a half times the first + 1/2 times the second.  So that's coordinates. So let's finish with one more example here in the last 3 minutes.  Just to stretch our minds a little bit.  Let's look at the vector space of polynomials of degree 2.  Okay, so that is to say Vector space of polynomials of degree 2 at most the vector space the space of polynomials the set of polynomials of degree 2 is not a vector space just like we did with the example of polynomials of degree 3 0 polynomials and then there but if we allow polynomials of degree up to 2, then we're fine. Okay, and we can describe this explicitly as oops.  as a  everything of the form a + BX + c x squared or a B and C are any coffee shops that we want.  Now if you think about it what that says and we discuss this at the end of last lecture is that one x x squared? Those are polynomials there in the space P2 and they form a basis for the space Pizza. What will we run up there says that they are spending set and as we discussed last day, they are linearly independent. So that's a basis for the polynomial space P2. So let's use that basis that hears a polynomial P polynomial is x - 1 squared.  It's in the Spectra space P2. That means it has coordinates in terms of this basis B.  We can express it as a linear combination and Uconnect unique way of those pulling those three basis vectors. So let's figure out how well will remember how to multiply polynomials this is x squared minus 2x + 1 and we see that it's representative and uniquely as a linear combination of x squared x and one so looking at these coefficients hear what we see is that the coordinates of B in terms of the basis the so-called standard basis One X x squared of the polynomial is okay. Well the first Vector here is a one and so the coefficient there is a one the second one X. It's coefficient is -2 and the third one. It's coefficient is 1  So if you're just thinking of the vector X - 1 squared if you have trouble thinking of that as a vector, you could instead say look. I'm just going to fix a basis say this basis for the space of polynomials of degree at 2 and instead of thinking of PS2 polynomial something. I know how to manipulate and multiply and find roots of I'll think of it as an abstract vector and then write its coordinates in terms of this basis. It's really just the column Vector 1-2 one, which I know how to handle and know how to deal with a next time. We'll start in the first 10 minutes of a Friday's lecture talking about what this coordinate.  Can you see San Diego podcast? ",
  "Name": "math18_b00_wi18-02142018-1000",
  "File Name": "lecture_16.flac"
}