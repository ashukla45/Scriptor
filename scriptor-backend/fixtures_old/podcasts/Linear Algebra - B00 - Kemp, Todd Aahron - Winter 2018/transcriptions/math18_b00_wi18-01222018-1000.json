{
  "Blurbs": {
    "* a + add 3 * B. So the first person that gives -2 + 9 is 7 -2 * 2 is -4 - 3 is -7 - 2 * 0 + 3 * 1 is 3 + -2 + 3 * 2 - 2 + 6 is 4 So indeed, there is a linear combination. There is a linear relationship between these vectors - 2A + 3B is equal ": [
      683.2,
      718.1,
      26
    ],
    "- 21 there I've already got a zero here. What's up, - 7 - 21. Is there a problem? Yes, there's a problem. What's the problem? Are you telling me that? You telling me that -6 - 1 is not - 4. Thank you. Get Nutz. Let's fix that. I'm going to pretend that I made that are pedagogically for you to find you're not going to believe me, which ": [
      2017.7,
      2069.9,
      76
    ],
    "- 3/2 U + W. So there's V Express as a linear combination of you and W and similarly I could not see solve this one here. You say three you. Is equal to 2 - 2 V + 2W, which means that you is equal to -2/3 V + 2/3 W. I have solve each one of the variables as a linear combination of the others. I don't always ": [
      422.6,
      458.9,
      16
    ],
    "0 how I heard somebody say it clearly the answer is multiply each one of them by zero. Not them up 0 * 1 + 0 * 1 + 0 * 0 I can always make any collection of vectors A linear combination of the Zero by using 0 as the coefficient for every one of them that by the way, if you think about is the same thing as ": [
      530.8,
      554.0,
      20
    ],
    "3 x 3 equals 0 we want to solve that. And figure out what the solution set is if the solution set consists of only the zero Vector then those vectors are linearly independent if the solution set is a parametric solution that has infinitely many solutions. Then the vectors are not linearly independent vectors are linearly dependent. So now we go ahead and we solve doing Row reduction. Yeah, ": [
      1657.7,
      1688.0,
      63
    ],
    "Do I listen to a podcast? Hope you all had a good weekend. So let's get going our usual reminders. Today we're going to be doing the section 1.7 of the textbook linear Independence, which we've alluded to that topic and even use those words are few times with that besides the defining them if it is going to click today, I think from making sense of a lot of ": [
      2.0,
      32.5,
      0
    ],
    "I can't actually I can because I cooked it. I know the answer but just staring at them. It can be pretty hard to have three vectors to tell whether or not there's some linear relationship between the weather. You can express 1 as the new combination of the others. I happen to know that there is an in this case. Let's Notice what happens if we take - 2 ": [
      658.8,
      683.2,
      25
    ],
    "I've got this minus one there which is not zero. So if one of those vectors is is a linear combination of the others. Then there is a non-trivial linear combination of the four of them. That's not one of those coefficients is not zero in particular the minus one that's there. So that tells you that if one of the vectors as a linear combination of the others, then ": [
      1233.9,
      1256.0,
      47
    ],
    "Matrix equation ax equals 0. Is x equals 0 that's from the theremin the previous page the statements? That these three vectors are linearly independent. Okay, easy peasy. So let's do the second example. Answer these three vectors here in our for are they linearly independent or are they linearly dependent? Well, we already know the answer because I pulled out of thin air in the first slide that they ": [
      1918.5,
      1959.6,
      73
    ],
    "Now this moment in class, but probably not a good use of your time. It's due next Monday at 11:59 p.m. A week from tonight and it will cover the material we're doing This week. You also have Matlab homework. So it was originally due last Friday, but in order to accommodate all of the people from the waitlist that we let in on Friday who just shifted the deadline ": [
      100.4,
      122.4,
      4
    ],
    "V is a nonzero Vector, it is linearly independent or there's no way you can scale a nonzero vector by a nonzero number and get the zero Vector. You can't multiply two nonzero things and get zero. And I'm the real numbers anyway. But if you started with the zero Vector, then it's automatically linearly dependent just look at the first example, if you have any list of vectors that ": [
      2751.3,
      2774.8,
      101
    ],
    "W equals zero one more way to write this idea which is to say to say that this reflectors have a linear dependence between them means that I can take a non-trivial linear combination of them and get 0 now. This word trivial here is a word that has lots of uses in common parlance, but for us in this course in this context, it means something very specific and ": [
      484.0,
      509.1,
      18
    ],
    "X2 you 2 + x 303 For some coffee shops X1 X2 and X3 like this. It's okay if those X1 X2 and X3 are all 0 if X1 X2 X3 roll zero then that means that you for is the zero vector. So if I had given you the example the three Vector for vectors are my usual 3 + 0 vector. Okay is the zero Vector a linear ": [
      1168.1,
      1200.1,
      45
    ],
    "a -2 and a 3 there? In this form of the Matrix here. It's obvious. I hate to use that word cuz it's not always obvious until you see it. But now that you see it. I'm telling you. It's obvious that the third column is -2 times the first plus three times the second ride cuz I've only got ones and zeros there. So if I'm up for that ": [
      2249.2,
      2270.9,
      83
    ],
    "a collection of vectors is linearly dependent saying that a collection of vectors is linearly independent. which is the statement that no one vector can be expressed as linear combination of the others is the same thing as saying there is no non-trivial linear combination of all of them that gives you the zero vector. If that's the reverse of the positive statement in terms of linear dependence linear dependence ": [
      1379.5,
      1409.6,
      52
    ],
    "a non-trivial linear combination that zero and that's the equivalent to finding one of them being in the span of the others. Okay. So this now we sit in terms of language that we know how to handle if I want to prove that a set of vectors is linearly independent. I have to show that that vector equation that that homogeneous vector equation. Okay that has only the trivial ": [
      1512.3,
      1536.4,
      57
    ],
    "a plus there than these would be parallel. and therefore linearly independent linearly dependent So in the cases where you have only one vector only two vectors or if your list includes a zero Vector, it's easy to just look at them and see if there's any other dependent but if you have three or more vectors, there's really no easy way to do it is no easy way to ": [
      2932.9,
      2957.3,
      108
    ],
    "again. So in the first case there we found graphically that W is equal to 3/2 U + v o w was in the span of you envy by take the vectors u and v over there then W is in the span of those two, I can explicitly right as a linear combination of the two of them. But we also saw that I could write v as linear ": [
      821.2,
      842.7,
      31
    ],
    "already mostly done those. I hope you finish the first one a week ago, since you could have finished it you could have done it based on mr. We did in class last Friday not this past one, but the one before that so we've covered everything you need to do on those assignments. Hopefully MyMathLab is working. Well for most of you. I know if you had some technical ": [
      61.5,
      80.4,
      2
    ],
    "already. It's very easy to do as I'm sure you're aware having done lots of examples now. Right now I want to get rid of the one below that leading one the one in the third row and second column. So I'll subtract the second row from the third that's going to give me the desired 0 there and I'm subtracting a half from 2, which gives me 5/2 in ": [
      1769.2,
      1792.4,
      67
    ],
    "also write this in a different way. We could write for example, we could write this with multiply 3 by 2. Says 2 W is equal to 3 U + 2v and I could solve this relationship for any one of these three vectors as a linear combination of the other two went so I could for example I could write this one immediately as a v is equal to ": [
      396.9,
      422.6,
      15
    ],
    "and in a row since these are four dimensional vectors. Here's a B and C are the three vectors here blue red and green again. Are these vectors linearly dependent? Is there a linear dependence between them? Can you see one immediately? I mean you can't see it graphically, but can you look at those long enough and tell me that there's a linear dependence between them or not? Well, ": [
      630.6,
      658.8,
      24
    ],
    "and now I'm going to take the vector v. And as we know we're supposed to do I'm going to move it its tail up to the tip of 1.5 * B and indeed we get W. So that shows us graphically. that w is equal to 3/2 U + b o w is a linear combination of you and me and it is that linear combination of you and ": [
      331.6,
      363.3,
      13
    ],
    "at least one of those coefficients is non-zero. in general here the answer is that If you ever have a list of vectors that includes the zero Vector as one of those vectors, they are always automatically linearly dependent you put in the zero Vector that makes them linearly dependent because you can express that zero Vector as a linear combination of the others may remember the two competing equivalent ": [
      2550.1,
      2578.6,
      94
    ],
    "be a pivot in every column cuz there is only at most one pivot per row so there can be at most 3 pivots here. That's what what turned out in this case that might have been to there might have been one but that can be at most 3 Hibbetts. And so what we see is if you have a matrix which has more columns and rows, there's no ": [
      3076.5,
      3096.2,
      113
    ],
    "be dependent or independent for what? So this is a great example where mathematics is much better than natural language because we made things precisely the point that any question can be answered. So it's hard to understand what it would mean to say one vector is independent of what but our definition was one of our competing definitions was there's a non-trivial linear combination of that one vector. It ": [
      2627.1,
      2656.2,
      97
    ],
    "be exactly so these three vectors are linearly dependent. Which just means that there is a linear dependence between them and me and that you can express one of them as a linear combination of the others if I already know the vectors, I know how to handle the vectors u and v then I can get the vector W from them. Okay, as a linear combination know we could ": [
      363.3,
      396.9,
      14
    ],
    "because there are no non pivotal call upstairs a pivot in every color. Friends pivot every calling which means there's no free variables. I'm so there's a unique solution we could solve for it by pivoting the last row there and then doing row reduction or we could do back substitution, but we don't need to do that because the last equation says x 3 equals 0 and the second ": [
      1862.3,
      1886.8,
      71
    ],
    "but we'll make it mathematically connect with things. We've already done and easier to verify so here is an equivalent definition. Okay. So first of all this look up here again linear linear dependence. so this means free samples suppose that it's the last Vector you one. Let's take a concrete example expose his equal to 4. This means you for is equal to some linear combination x1u. 1 + ": [
      1128.3,
      1168.1,
      44
    ],
    "can / -7 to get a leading one and I could alternatively have swapped the second and third row to get a leading one there, but those will actually give me the same results. Because dividing 2 by -7 that second row gives me one and three there. Simile in the third row. I'm going to pay that by dividing through by minus one giving me a one and a ": [
      2097.5,
      2119.3,
      78
    ],
    "combination of those guys? Is there a resident it's a linear combination where I take 0 as the coefficients of these three vectors now that may sound like I contradicted what I said before but let's rewrite it like this. It says x1u 1 + X2 you 2 + x 3 you 3 - you for equal 0 So those coefficients X1 X2 X3, they could all be zero, but ": [
      1200.1,
      1233.9,
      46
    ],
    "combination of you and W and you as linear combination of V and W, so it's not necessarily unique. I can write one of them is when you come into some of the others, but in this case, I could choose any one of them and read his own your combination of all of the others that was the case down here as well and that happened because the coefficients ": [
      842.7,
      860.7,
      32
    ],
    "considered this case, but it was they give you the vectors 1 3 7. 206000 those three vectors are linearly independent or linearly dependent by show of hands little no thinking just looking linearly independent raise your hand. Someone scratch their head in the sort of meekly did that. Okay, are they linearly independent? Are they linearly dependent raise your hand? Okay, that's a vast majority of you. Why or ": [
      2402.5,
      2436.5,
      89
    ],
    "definition of linear dependence one is there's a nonlinear tribute non-trivial linear combination of all of them together to give zero and the other is at least one of them is a linear combination of the other ones here that second one doesn't need the word non-trivial because in the case when the zero Vector is among them that definitely is linearly dependent. That's it. A good Turkey Point to ": [
      2578.6,
      2602.1,
      95
    ],
    "did you have a question? Why are they linearly dependent? Yes. Okay, that that's a great explanation for typical hang up. So you're wrong, but it's a great explanation for why you were wrong and why it's convincing to think that that would be the answer. I'm glad you brought it up. So his answer was because zero if you want to get zero as a linear combination of the ": [
      2436.5,
      2471.2,
      90
    ],
    "different their equivalent statements. And the nice thing about the second way of saying it that linear dependence means that some non-trivial linear combination of them is 0 is it that fits right into our tools of row reduction are tools of solving linear systems in order to answer this question? Okay. So here is the theorem we just proved there's a therm that we just demonstrated their am just ": [
      1431.2,
      1460.0,
      54
    ],
    "do some concrete examples. There's a couple of examples So here are three vectors of already strung them together as The Columns of a matrix actors in R3 and I want to answer the question are they linearly independent? This is very much like the first example of the second example, we did on the first page. I gave you three factors that case there were an R4 I gave ": [
      1587.4,
      1610.2,
      60
    ],
    "express any one of them as linear combination of the other. So I have to choose the first one and say can I express it as a linear combination of the other two, I have to check all possibilities and some cents. In fact, we have the tools to do that as well inside a different language, but it is a trickier notion to wrap your brain around least I ": [
      941.7,
      963.5,
      36
    ],
    "eyeball it but there's an easy way to calculate it which is to do row reduction. Okay, so I was going to do one more example here but where I was just about out of time. So I'd rather spend one more moment. The one minute we have left cementing. Cementing what we've done actually, let's do this second example here cuz it's already done for us. So let's remind ": [
      2957.3,
      2980.0,
      109
    ],
    "first one by -2 and that second world by 3 and Adam that just means I get a -2 and a 3 in the slots is there is everywhere else when you take the Matrix to reduced row Echelon form. If you have any free variables, then those columns tell you how to reconstruct that column as a linear combination of the previous ones. So not only do we get ": [
      2270.9,
      2292.5,
      84
    ],
    "first to the only way you can do that is by multiplying each of them by zero and adding so the only linear combination of the first to give zero is a zero Vector. That is absolutely true what that tells us. Is that the first two vectors by themselves are linearly independent, but I didn't ask that question. I asked are those three vectors together linearly independent? the answer ": [
      2471.2,
      2496.4,
      91
    ],
    "for example if my two vectors were one two, three seven. and to 6 - 14 look at those and tell me are they linearly dependent or not? That's the same as the question look at those and tell me are they parallel or not? No, they're not parallel. Why are they not parallel because I can just see when I have only two vectors if I wanted to get ": [
      2883.4,
      2910.0,
      106
    ],
    "from 9:30 to 11. Alright, so let's get going on today's material. Talking about linear Independence, and actually this is one of the many cases of mathematics were an important definition of concept is actually introduced by its negative. Okay. So really the easier things understand for the start is linear dependence already been talking about it in a moment and let's start with a graphical example of their I've ": [
      186.8,
      221.7,
      8
    ],
    "front of its living supposed to be right there one. Remind us when I guess. So I can take a collection of nonzero not all zero coefficients and make a linear combination of these vectors with those coefficients and get the zero Vector that's another way of saying that you can express one of those vectors as a linear combination of the others. So this collection of three vectors is ": [
      745.7,
      770.0,
      28
    ],
    "given you three vectors use a blue vector v is a red vector and W's a green Vector over there, but just don't actually have colors. I'm just saying saying you can see the arrows there are different colors to differentiate them. and so the question is are those three vectors independent from each other and some sense or are they dependent on each other? So the precise question which ": [
      221.7,
      248.2,
      9
    ],
    "glitches that you've been working with us on Piazza and with the Pearson technical support people about all be resolved enough time for you to finish the meeting the homework tonight. And by the way, you have another homework set not raining here, but you have another homework set homework 3 on MyMathLab has now been posted you can look at it in the store right now. If you want. ": [
      80.4,
      100.4,
      3
    ],
    "have dependents - 2 * the First Column plus three times the second column equals 1/3 call. So we already know the answer what the answer is going to be but let's see how our methods give us the answer. We need to carry this Matrix to row Echelon form to answer this question. Technically. We need to take the augmented Matrix. And do row operations on. So, let's do ": [
      1959.6,
      1994.2,
      74
    ],
    "includes a zero Vector is linearly dependent particular that list is just the zero Vector. It's linearly dependent. Okay, so we're just testing our understanding of the definition of here on these kind of met examples looks like it one more here. What if there are only two vectors because I've got two vectors V1 and V2. What is it mean to say? They are linearly independent. Let's go back ": [
      2774.8,
      2798.6,
      102
    ],
    "independent. Okay, so that's the statement. I just translated the first statement which is stated in terms of vector equations into the corresponding statement for Matrix equations. The Columns of a matrix a are linearly independent. If and only if the Matrix equation ax equals 0 has only the trivial solution x equals 0 and that is a statement. We now know how to verify using row reduction. So let's ": [
      1560.2,
      1587.4,
      59
    ],
    "is good. Okay, that's correct now and then in the third row in to get rid that once I subtract the first row from the third one, so I get a zero there I get to -3 is -1 + 4 - 7 is -3 Okay. Now they're a bunch of things I could do for my next step. The standard thing is to Pivot that second row there. I ": [
      2069.9,
      2097.5,
      77
    ],
    "is that if I have a non linear combination, I ate a non-trivial linear combination of these four vectors that gives me the zero Vector. Well, it's non-trivial. So there's some confusion in there. Let's say it's why to that's not zero then I could divide through by that and rearrange the equation to say you to is this linear combination of the others. so in other words saying that ": [
      1354.1,
      1379.5,
      51
    ],
    "is the statement that one of the vectors is a linear combination of the others, but this little calculation down here the scheme shows you that oh, that's the same thing saying that one of them is linear combination of the others is just the same statement as a statement that some non-trivial linear combination of them is 0. Hey, those are equivalent statements, even though mathematically they look somewhat ": [
      1409.6,
      1431.2,
      53
    ],
    "is zero. So that's the question here. So is it true? That some non linear combination non-trivial linear combination of that one vector, which means x1v that's its is equal to zero. for some non-zero X1 that's the question. Can I multiply x1v buy some nonzero number X1 and get 0 Yes, why how which which Vector explanation which number X when should I use? Okay, so maybe that vector ": [
      2656.2,
      2694.5,
      98
    ],
    "it in the homogeneous case, which of the two legs of the dichotomy is it does this have exactly one solution or does it have infinitely many solutions? Somebody from this side of the road tell me. Yes, it's one solution and that one solution is. Is 0000000 is a solution? So if the reduced ride if a row Echelon form tells you that the only one you know what ": [
      1816.3,
      1841.5,
      69
    ],
    "it's over here. So is this Matrix? Does this Matrix as the coefficient Matrix here? Does it represent a system with only one solution or with infinitely many solutions? Infinitely many because this is not mention Matrix. This is the coefficient Matrix because that third of that fourth column there. That 4th column there. Has no pivot. Has no leading entry. Therefore. There's a free variable. therefore there's a non-trivial ": [
      3005.1,
      3040.2,
      111
    ],
    "keep in mind as we go forward. Okay, next example. What if I just give you a list of one vector cancer? Here's my my one vector v. I don't care what it is. Is that set of vectors linearly independent or linearly dependent? I see people biting their lips, which is the right answer because what does that even mean? You're saying in your head, how can one vector ": [
      2602.1,
      2627.1,
      96
    ],
    "linearly dependent? I heard some indiscernible mumbling. So let's try again by a hand. Tell me what's the answer and why yes. is a free variable in column Street, and so Very good. I'll say everything you just said we already know this is Tim is consistent cuz it's homogeneous. They're always consistent. There's a free variable therefore there infinitely many solutions Employment Solutions means that there are non-trivial solution ": [
      2179.8,
      2225.0,
      81
    ],
    "made 0 with linear combination with trivial coefficient. We're looking for non-trivial linear combination, but that's great that you said that because that's the first mistake that everybody always makes thank you for making it for everybody else. So they don't have to know. Yes. Okay, see if you said because only one vector has to be in the span of the others and I'm going to turn that around ": [
      1039.8,
      1062.2,
      40
    ],
    "means true statements. Okay, here is the true statement that we just demonstrated. Hey, if I have vectors you once were you when they are linearly independent linearly independent meaning by definition, they're not linearly dependent meaning that no, one of those Vector as a linear combination of the others that happens. If and only if the vector equation x 21 + X2, you two plus all the way up ": [
      1460.0,
      1487.5,
      55
    ],
    "my two arms representing two vectors in three dimensional space and my head representing the third sticking up here. So let's answer the question graphically is my head in the span of my arms. Is it a linear combination of these two, so we've already answered that question many times the answer is no unless I had a neck injury. Okay, the answer is no because the span of these ": [
      985.8,
      1009.1,
      38
    ],
    "necessarily be able to do that with every one of the variables in a case like this. In this case. I can every one of these variables is linearly dependent on the other two. Let me write it one more way. It's going to be relevant to us. Let's take this relationship right here. And let's write it like this. That's right at 3 you + 2 V - 2 ": [
      458.9,
      484.0,
      17
    ],
    "not in the span of these two. Okay. Well actually I mean for the same graphical reason that's true. In this case the the plane the span of these two vectors is this playing here that my head and that are Marin and this arm is sticking out of that plane. Similarly, I have to show that this Vector is not in the span of these two. Okay, and again ": [
      1080.8,
      1101.4,
      42
    ],
    "not independent from each other if I know two of them I can get the third just by taking a linear combination. So that's linear dependence. So let's formalize that Just rewriting exactly same thing. I just said. A collection of vectors in some space so we're in some space. Maybe it's r505. I could be vectors of height 505 but all the factors in the same Space Adventures of ": [
      770.0,
      797.4,
      29
    ],
    "of equation. But that's kind of a silly solution in the question is is there a non-trivial linear combination? So the 0 linear combination of vectors is called the trivial linear combination. And the question is is there a non-trivial one and if you have a linear dependence like this where you have one vector is a linear combination of the other two, it gives you a non-trivial linear combination ": [
      577.7,
      600.2,
      22
    ],
    "of this linear combination. We're all nonzero so I could just divide through by the coefficient in front of be for example, in order to write be as linear combination of A and C, even though it was C is in a combination of A and B. Okay, so that's a linear dependence a set of vectors is linearly dependent. If at least one of them may be more than ": [
      860.7,
      884.0,
      33
    ],
    "often very hard to work with that is it can be at least philosophically easier to answer these vectors are linearly dependent because it just means I've got to find some linear combination of them some non-trivial in combination of them. But if I want to show that a set of vectors is linearly independent, it means I have to show a universal statement that there's no way I can ": [
      916.6,
      941.7,
      35
    ],
    "okay. I guess I'm not super excited about doing reduction either but it's you know, it's it's a necessary tool and this one isn't going to take very long. So we want to solve that system. I'd Falls couple things I could do. I want to get zeros below the leading one. I could swap the second and third row, but that doesn't really make any difference cuz I'm going ": [
      1688.0,
      1709.8,
      64
    ],
    "one below the below the second-leading entry there. Well, there's a couple of ways things I could do. I could pivot in order to get a one leading one in the second row. Let's go ahead and do that I suppose. That means that I get a - 1/2 here. By the way, if you see me making a miracle error, please pointed out. I may well have made one ": [
      1734.9,
      1769.2,
      66
    ],
    "one but at least one of them can be expressed as a linear combination of all the others. Now if that just is not possible. Then we call the vectors linearly independent. So linearly independent vectors are vectors for which you cannot express any one of them as a linear combination of the others. That's a negative definition linear. Independence means they are not linearly dependent and negative definitions are ": [
      884.0,
      916.6,
      34
    ],
    "other than the zero solution and that is exactly the same statement is saying that these vectors are linearly dependent not linearly independent now, we already knew that but actually look look what happened here. So I told you at the beginning - 2 * the first Factor plus three times the second is equal to the Third. We can pick that off of the reduced row Echelon form. Is ": [
      2225.0,
      2249.2,
      82
    ],
    "ourselves what we need to do here. I wanted to check if these four vectors are linearly independent or not. The way I answered that is I put them together in a coefficient Matrix and I checked to see if the system ax equals 0 has only the trivial solution or has non-trivial Solutions. So I've already use Matlab to compute the reduced row Echelon form of that Matrix and ": [
      2980.0,
      3005.1,
      110
    ],
    "say the B2 is a scalar multiple. If you want. I have a word for that when I have two vectors that are scalar multiples of each other. They are called. anyone I've heard a few people say it very quietly. Someone say it louder. Okay, maybe not louder anyone want to raise their hand until I guess they're called parallel. I have parallel vectors, they are linearly dependent. So ": [
      2857.8,
      2883.4,
      105
    ],
    "saying that any homogeneous system has a solution is 0 solution you think of those three vectors is The Columns of the coefficient Matrix. That's what we're saying. You can always take a linear combination of them that is Multiplied that matrix by X1 X2 X3 can always find one in this case X1 X2 X3 zero such that the solution such as you get 0 on the other side ": [
      554.0,
      577.7,
      21
    ],
    "see on the grid what the coordinates are you has coordinates a 0 2 V has coordinates looks like 1 2 3 4 5 - 2 + W has coordinates 5 + 151. Okay. So the question is is w a linear combination of u and v I heard someone say yes pretty confidently over on the side of the road. Could you tell me why? The person disappeared would ": [
      271.2,
      301.0,
      11
    ],
    "slightly. It's hard to say this I think is what you meant. All we've shown is that this Vector my head is not in the span of these two for the definition of written up their linear. Independence is no one vector can be in linear combination of the others. So, I've only done one third of the work now I have to show that this Vector over here is ": [
      1062.2,
      1080.8,
      41
    ],
    "solution remember last day when we talked about homogeneous systems of equations. We said the nice thing about them is that they have a dichotomy for their solution sets instead of a trichotomy. They always have a solution 0 is always a solution. It might be the only solution or there might be many. In the special case where there's just one solution. That means those column vectors are linearly ": [
      1536.4,
      1560.2,
      58
    ],
    "solution. And therefore these vectors are linearly dependent. No for the last 10 seconds here. Did we need to go through computations in this example know? Here we had four vectors in R3. When we string them together in the coefficient matrix, it's a matrix with four columns. But only three rows and the question where the seeking to answer is is there a pivot in every column? The can't ": [
      3040.2,
      3076.5,
      112
    ],
    "someone like to tell me why W as a linear combination of u and v. Yes. You could take a V and add 1.5 times you and get W. That's exactly right. Okay, so let's actually do that graphically. So I'm going to scale up. I'll do the these ones in Black. I'm going to scale-up you to 3/2 times its current height. So there's one point five times you ": [
      301.0,
      331.6,
      12
    ],
    "step and take it to reduced row Echelon form. Which only takes one more step. I just need to get rid of the three above the second-leading one, which means I multiply the second row by -3 and add give me the desired zero there and giving me a -2 he Okay. So now we answer the question as to which we already know. Are these vectors linearly independent or ": [
      2150.1,
      2179.8,
      80
    ],
    "that entry. Throw 1 - 1/2 + 120 Okay. Now if I wanted to actually solve this system completely I would have to do a couple more steps to get it to reduced row Echelon form. But I've already got it in row Echelon form. And remember when you're in row Echelon form you have enough information to answer the question, which of the three legs of the trichotomy. Is ": [
      1792.4,
      1816.3,
      68
    ],
    "that is no there linearly dependent because I can take the following linear combination of all three I can take I can take zero X the first Let's let's write it down I can take. 0 times the first + 0 * II + 300 + 776 * 1/3 and that gives me the zero vector. and the point is that those three coefficients. They're not all 02. This was ": [
      2496.4,
      2529.2,
      92
    ],
    "that point we we made early on in the lecture that just because when you're expressing one of the vectors is linear combination of the others if you can do so, but only with a zero coefficients that doesn't mean the vectors are linearly independent because it's having a non-trivial in a combination of all of them put together. That's the important point. This is a non-trivial linear combination because ": [
      2529.2,
      2550.1,
      93
    ],
    "that this time. All right, so I need to looks like I might have a bunch of work to do but it's actually going to go with real quick here. So I need to get a zero in the second row below the leading entry in the first row. If I subtract twice the first row from the second give me those are there and I - 4 there Anna ": [
      1994.2,
      2017.7,
      75
    ],
    "that what we know there's a unique solution because there is a pivot in every row because there's no roads. There was at the bottom to give us an inconsistency. I'm sorry that tells me that it's consistent. So there's a pivot in every road that that does tell me the same thing here, but only because the number of rows equals the number of columns in this case is ": [
      1841.5,
      1862.3,
      70
    ],
    "the logic it's complicated. So you need to run through it a dozen times before you can suss out what the definition of saying we called twisting the definitions. Yes. Exactly. So the thank you for saying that exactly the way I was going to so the answer is no if the key is not the zero Vector but yes, if the is zero vector. So in other words if ": [
      2720.1,
      2751.3,
      100
    ],
    "the midterm. And one final quick reminder her quick information my office hour. Tomorrow morning is shifted a little bit shifted up to 9:30. So I'll be there from 9:30 to 11 not later as usual return to the normal hours that have already changed it on the Google Calendar, but just in case you wanted to come after 11, I won't be there this time, but I'll be there ": [
      163.3,
      186.8,
      7
    ],
    "the non Cyril one. Then I can solve the one we did this example with four vectors A few minutes ago is equal to 8 - x 2 / x 1 x V2 That says that V1 is a scalar multiple of V2. If I done it the other way if I assume that X2 was nonzero than V2 would be - X1 or X2 X V want. That would ": [
      2832.7,
      2857.8,
      104
    ],
    "the questions that we've had in the last few lectures and the next lecture on Wednesday. We can talk about linear Transformations. We're going to add another level of different language and different ideas to approach the same certain Concepts and use the tools that we've been developing to understand. Some reminders your first to MyMathLab homework assignments are due tonight at 11:50 or by 11:59 p.m. So hopefully you're ": [
      32.5,
      61.5,
      1
    ],
    "the same height collection of vectors. You want you two up to you en pesos some list of columns is called linearly dependent if you can find one of them that is in the span of the others that is if you can find one of those vectors that is a linear combination of the other two. So I'm going to go back to the previous life for a second ": [
      797.4,
      821.2,
      30
    ],
    "the second one as of scalar multiple the first I know what coefficient I need to use. I need you to write so does that work for all of them to * 1 is too? Yep 6 * 2 is 332 * 3 + 60 + 2 * 7 is -14 know it's + 14. So these two are not parallel and therefore they are linearly independent if there's been ": [
      2910.0,
      2932.9,
      107
    ],
    "the zero vector? And at least one of those coefficients is not zero, that's what this statement means here. At least one of those coefficients is non-zero. Meaning that there's a non-trivial linear combination. So let's say suppose that it's why to is not zero. Well, then I can divide through by Y2. I can divided by a nonzero number. So this one says y 1 / y to x ": [
      1293.0,
      1319.8,
      49
    ],
    "there is a non-trivial linear combination of all of them. That is the zero Vector even if all the coefficients but that one or zero, it doesn't matter. Okay, no on the other hand. I suppose all we knew. Was that someone are combination maybe a different one? Maybe I'll call it. Y1 you 1 + Y2. You 2 + y 3 you 3 + y 4 U 4 is ": [
      1256.0,
      1293.0,
      48
    ],
    "think so just why I want to do lots of examples I also want to get to to a slight variation of this definition. It means the same thing your textbook defines us in a slightly different way, but I think this is more intuitive the way that it's to find here. So for example, let's take the example of my favorite example that I keep demonstrating in the room ": [
      963.5,
      985.8,
      37
    ],
    "this plane the span of these two vectors. This was clearly sticking out of it. Okay, so I have at least demonstrated are Justified graphically that those three vectors are linearly independent. Cuz no one of those three factors can be expressed as a linear combination of the other two. But let's rewrite this in a slightly different way. Which is actually going to make it sound harder to verify ": [
      1101.4,
      1128.3,
      43
    ],
    "three there and look the second third and fourth Rose. They're all equal. so in order to get rid of the ones below the second-leading one now, I'm going to subtract the second row from the third and from the fourth, but when I do that I just get all zeros down there. Okay. I know this Matrix is in row Echelon form. Let's go ahead and do one more ": [
      2119.3,
      2150.1,
      79
    ],
    "to C. I could rearrange this if I like noticed that all of those coefficients are nonzero. So if I read it in the same way I get. - 2A + 3B - C equals 0 there is a non-trivial linear combination of them that give 0 and in this case like the last one you can have all nonzero coefficients highlighted the sea because it's really a 1 in ": [
      718.1,
      745.7,
      27
    ],
    "to X and you and equal 0 has only the trivial solution x 1 equals x 2 equals x equals 0 Hey, that's what linearly independent vectors are that's what linear Independence means. It means that the only way that I can get a linear combination of those vectors equal 0 is if it's the trivial linear combination. Otherwise, it would mean their linearly dependent it would mean that there's ": [
      1487.5,
      1512.3,
      56
    ],
    "to answer the question that these vectors were linearly dependent but the reduced row Echelon form Witnesses a linear dependence between them. and these coefficients tell us how okay. Great. Now there's one more thing. I wanted to point out here, which is that it was a waste of energy to carry all of the zeros in the right-hand column around if I had just erase them from consideration. Nothing ": [
      2292.5,
      2330.2,
      85
    ],
    "to change okay, but in the case of the homogeneous system in particular, when were answering a question about linear dependence, there's no reason to write the zeros over and over. We just carry the coefficient Matrix to row Echelon form to answer the question. If we want to know an exact linear dependence between the variables between the the vectors the columns. Okay, so that's more or less the ": [
      2353.2,
      2379.5,
      87
    ],
    "to have to get rid of that one. That's currently in the second row anyway. So I'm going to subtract the first row from the second. If I just made a zero there a -2 there retains the one there and of course, it doesn't do anything to the right hand side. Okay. And I've already got the zero down below. So now I want to get rid of the ": [
      1709.8,
      1734.9,
      65
    ],
    "to the definition to say they are linearly independent. So they're linearly or actually, let's do the easy one to work with they are linearly dependent. if and only if There's some linear combination of them. That's zero-sum non-trivial linear combination. So I can take some that some corporations extra next to not both zero that gives me 0 for those two. Well, let's say suppose that this one is ": [
      2798.6,
      2832.7,
      103
    ],
    "to tonight by 11:59 p.m. That's for everybody. So if you wanted extra time to work on it, you got it this time, but the next medal of homework is still due this coming Friday. That is 5 days from today at 11:59 p.m. And two more reminders first, your first midterm in this class is next week. And this is week 3 right now next week is week for ": [
      122.4,
      144.4,
      5
    ],
    "two vectors is this plane here and my head is sticking up out of that plant. So my head is not in the span of these two vectors down here. Does that mean that these three vectors are linearly independent from the definition there? That statement. Know why not? Oh, but if we had all zeros is coefficients that doesn't tell us anything because every set of vectors can be ": [
      1009.1,
      1039.8,
      39
    ],
    "u 1 + u 2 + y 3 / y to X U 3 + y 4 / Y 2 X you for equals 0 and now I can solve for you, too. So you two is equal to - y 1 / y to X you one. minus y 3 / Y 2 x u 3 - y 4 / y to X you for So what I've shown ": [
      1319.8,
      1354.1,
      50
    ],
    "v there was the was the vector this one? Hey, so let me pick any number. I'll pick the number one. Is 1 * inspector equal to the zero vector? Your your train of thought is getting a little lost because I've negated statements for X. Right and that's a great example of why these things are important to think about a lot the language gets complicated and the state ": [
      2694.5,
      2720.1,
      99
    ],
    "was not going to say x 2 - 1/2 0 is 0 and so on and we know that the unique solution since there was a unique one is zero. So once we're here, we're done. We now have unique solution. and therefore this implies that X1 X2 X3 is equal to 000. So what we've got is that Matrix there has the property that the only solution of the ": [
      1886.8,
      1918.5,
      72
    ],
    "way those columns can be linearly independent if you have columns in R3, if there's more than three of them, they must be linearly dependent. So let's continue with Can you see San Diego? ": [
      3096.2,
      3112.3,
      114
    ],
    "we can Now quickly answer is let's what is Vector w? is w a linear combination of u and v or not now just to be clear. This is not a relief three-dimensional projection, right? You might look at that in an interpretive. So he's drawing three dimensional vectors but on the board, but I'm not in this case. Those are three vectors in the plane. In fact, you can ": [
      248.2,
      271.2,
      10
    ],
    "we have the Theron from the last page and explanation. We just gave that's do the first example there. I want to figure out if The Columns of that first Matrix there 1 1 0 2 0 1 0 1 2 if those are linearly independent or not. The theorem says they're linearly independent if and only if The Matrix equation that Matrix x yuno x 1 x 2 x ": [
      1633.7,
      1657.7,
      62
    ],
    "which means that you can take a linear combination of those three vectors. In which some maybe not all but some of the coefficients are not zero this case. All three of the coefficients are not zero, but all that matters is if you can take a linear combination so that some of them are non-zero then we say that the vectors are linearly dependent be hard to draw it ": [
      600.2,
      630.6,
      23
    ],
    "whole story on linear Independence. That's how you determine whether vectors are linearly independent. So let's look at some specific meta examples now to understand this now that we have the mechanical way to do it. Okay, there's some cases where we don't need to do much. So for example suppose I give you a list of vectors and one of them is the zero Vector. We actually really already ": [
      2379.5,
      2402.5,
      88
    ],
    "would have changed when you're solving a homogeneous system. There's no reason to write the augmented, cuz it's never going to change row operations don't change the zeros right now. Be careful if you're going to do that because it's only going to work in the case of a homogeneous system. If you have an in homogeneous system, you need to carry those corporations around coz row operations are going ": [
      2330.2,
      2353.2,
      86
    ],
    "you three vectors actually. I asked you are they linearly dependent? I asked you is one of them Olivia combination of the others and just staring at them. We were never going to get anywhere unless I happen to tell you that I cook them out to have this particular linear dependence. Hey, but now we have the tools that we can answer the question in a routine way. So ": [
      1610.2,
      1633.7,
      61
    ],
    "your first week midterm is Wednesday evening of next week. I'll give you more detailed reminders about that as we go it's going to cover everything that we do up until Friday of this week. And so that is all of chapter one will be on midterm 1 we're going to finish what we'll do in chapter 1 by this Friday and that's the cutoff date for material covered on ": [
      144.4,
      163.3,
      6
    ],
    "your textbook uses the language this way so I could take any set of vectors at all. A set of three vectors for example and I can always make some linear combination of them 0 right? How do I if I took these three vectors in the room, right the standard vectors that point in the three unit directions? I could make a linear combination of these is equal to ": [
      509.1,
      530.8,
      19
    ]
  },
  "Full Transcript": "Do I listen to a podcast?  Hope you all had a good weekend.  So let's get going our usual reminders.  Today we're going to be doing the section 1.7 of the textbook linear Independence, which we've alluded to that topic and even use those words are few times with that besides the defining them if it is going to click today, I think from making sense of a lot of the questions that we've had in the last few lectures and the next lecture on Wednesday. We can talk about linear Transformations. We're going to add another level of different language and different ideas to approach the same certain Concepts and use the tools that we've been developing to understand.  Some reminders your first to MyMathLab homework assignments are due tonight at 11:50 or by 11:59 p.m. So hopefully you're already mostly done those. I hope you finish the first one a week ago, since you could have finished it you could have done it based on mr. We did in class last Friday not this past one, but the one before that so we've covered everything you need to do on those assignments. Hopefully MyMathLab is working. Well for most of you. I know if you had some technical glitches that you've been working with us on Piazza and with the Pearson technical support people about all be resolved enough time for you to finish the meeting the homework tonight. And by the way, you have another homework set not raining here, but you have another homework set homework 3 on MyMathLab has now been posted you can look at it in the store right now. If you want. Now this moment in class, but probably not a good use of your time. It's due next Monday at 11:59 p.m. A week from tonight and it will cover the material we're doing  This week. You also have Matlab homework. So it was originally due last Friday, but in order to accommodate all of the people from the waitlist that we let in on Friday who just shifted the deadline to tonight by 11:59 p.m. That's for everybody. So if you wanted extra time to work on it, you got it this time, but the next medal of homework is still due this coming Friday. That is 5 days from today at 11:59 p.m.  And two more reminders first, your first midterm in this class is next week. And this is week 3 right now next week is week for your first week midterm is Wednesday evening of next week. I'll give you more detailed reminders about that as we go it's going to cover everything that we do up until Friday of this week. And so that is all of chapter one will be on midterm 1 we're going to finish what we'll do in chapter 1 by this Friday and that's the cutoff date for material covered on the midterm.  And one final quick reminder her quick information my office hour. Tomorrow morning is shifted a little bit shifted up to 9:30. So I'll be there from 9:30 to 11 not later as usual return to the normal hours that have already changed it on the Google Calendar, but just in case you wanted to come after 11, I won't be there this time, but I'll be there from 9:30 to 11.  Alright, so let's get going on today's material.  Talking about linear Independence, and actually this is one of the many cases of mathematics were an important definition of concept is actually introduced by its negative. Okay. So really the easier things understand for the start is linear dependence already been talking about it in a moment and let's start with a graphical example of their I've given you three vectors use a blue vector v is a red vector and W's a green Vector over there, but just don't actually have colors. I'm just saying saying you can see the arrows there are different colors to differentiate them.  and so the question is  are those three vectors independent from each other and some sense or are they dependent on each other? So the precise question which we can Now quickly answer is  let's what is Vector w?  is w a linear combination of u and v  or not now just to be clear. This is not a relief three-dimensional projection, right? You might look at that in an interpretive. So he's drawing three dimensional vectors but on the board, but I'm not in this case. Those are three vectors in the plane. In fact, you can see on the grid what the coordinates are you has coordinates a 0 2 V has coordinates looks like 1 2 3 4 5 - 2 + W has coordinates 5 + 151. Okay. So the question is is w a linear combination of u and v  I heard someone say yes pretty confidently over on the side of the road. Could you tell me why?  The person disappeared would someone like to tell me why W as a linear combination of u and v. Yes.  You could take a V and add 1.5 times you and get W. That's exactly right. Okay, so let's actually do that graphically.  So I'm going to scale up. I'll do the these ones in Black. I'm going to scale-up you to 3/2 times its current height. So there's one point five times you and now I'm going to take the vector v.  And as we know we're supposed to do I'm going to move it its tail up to the tip of 1.5 * B and indeed we get W. So that shows us graphically.  that  w  is equal to 3/2 U + b o w is a linear combination of you and me and it is that linear combination of you and be exactly so these three vectors are linearly dependent.  Which just means that there is a linear dependence between them and me and that you can express one of them as a linear combination of the others if I already know the vectors, I know how to handle the vectors u and v then I can get the vector W from them. Okay, as a linear combination know we could also write this in a different way. We could write for example, we could write this with multiply 3 by 2. Says 2 W is equal to 3 U + 2v  and I could solve this relationship for any one of these three vectors as a linear combination of the other two went so I could for example  I could write this one immediately as a v is equal to - 3/2 U + W. So there's V Express as a linear combination of you and W and similarly I could not see solve this one here. You say three you.  Is equal to 2 - 2 V + 2W, which means that you is equal to -2/3 V + 2/3 W. I have solve each one of the variables as a linear combination of the others. I don't always necessarily be able to do that with every one of the variables in a case like this. In this case. I can every one of these variables is linearly dependent on the other two.  Let me write it one more way. It's going to be relevant to us. Let's take this relationship right here. And let's write it like this. That's right at 3 you  + 2 V - 2 W equals zero one more way to write this idea which is to say  to say that this reflectors have a linear dependence between them means that I can take a non-trivial linear combination of them and get 0 now. This word trivial here is a word that has lots of uses in common parlance, but for us in this course in this context, it means something very specific and your textbook uses the language this way so I could take any set of vectors at all.  A set of three vectors for example and I can always make some linear combination of them 0 right? How do I if I took these three vectors in the room, right the standard vectors that point in the three unit directions?  I could make a linear combination of these is equal to 0 how  I heard somebody say it clearly the answer is multiply each one of them by zero. Not them up 0 * 1 + 0 * 1 + 0 * 0 I can always make any collection of vectors A linear combination of the Zero by using 0 as the coefficient for every one of them that by the way, if you think about is the same thing as saying that any homogeneous system has a solution is 0 solution you think of those three vectors is The Columns of the coefficient Matrix. That's what we're saying. You can always take a linear combination of them that is Multiplied that matrix by X1 X2 X3 can always find one in this case X1 X2 X3 zero such that the solution such as you get 0 on the other side of equation.  But that's kind of a silly solution in the question is is there a non-trivial linear combination? So the 0 linear combination of vectors is called the trivial linear combination. And the question is is there a non-trivial one and if you have a linear dependence like this where you have one vector is a linear combination of the other two, it gives you a non-trivial linear combination which means that you can take a linear combination of those three vectors.  In which some maybe not all but some of the coefficients are not zero this case. All three of the coefficients are not zero, but all that matters is if you can take a linear combination so that some of them are non-zero then we say that the vectors are linearly dependent be hard to draw it and in a row since these are four dimensional vectors. Here's a B and C are the three vectors here blue red and green again.  Are these vectors linearly dependent? Is there a linear dependence between them? Can you see one immediately? I mean you can't see it graphically, but can you look at those long enough and tell me that there's a linear dependence between them or not?  Well, I can't actually I can because I cooked it. I know the answer but just staring at them. It can be pretty hard to have three vectors to tell whether or not there's some linear relationship between the weather. You can express 1 as the new combination of the others. I happen to know that there is an in this case. Let's  Notice what happens if we take - 2 * a + add 3 * B.  So the first person that gives -2 + 9 is 7  -2 * 2 is -4 - 3 is -7 - 2 * 0 + 3 * 1 is 3 + -2 + 3 * 2 - 2 + 6 is 4  So indeed, there is a linear combination. There is a linear relationship between these vectors - 2A + 3B is equal to C.  I could rearrange this if I like noticed that all of those coefficients are nonzero. So if I read it in the same way I get.  - 2A + 3B - C equals 0 there is a non-trivial linear combination of them that give 0 and in this case like the last one you can have all nonzero coefficients highlighted the sea because it's really a 1 in front of its living supposed to be right there one.  Remind us when I guess.  So I can take a collection of nonzero not all zero coefficients and make a linear combination of these vectors with those coefficients and get the zero Vector that's another way of saying that you can express one of those vectors as a linear combination of the others. So this collection of three vectors is not independent from each other if I know two of them I can get the third just by taking a linear combination. So that's linear dependence. So let's formalize that  Just rewriting exactly same thing. I just said.  A collection of vectors in some space so we're in some space. Maybe it's r505. I could be vectors of height 505 but all the factors in the same Space Adventures of the same height collection of vectors. You want you two up to you en pesos some list of columns is called linearly dependent if you can find one of them that is in the span of the others that is if you can find one of those vectors that is a linear combination of the other two.  So I'm going to go back to the previous life for a second again. So in the first case there we found graphically that W is equal to 3/2 U + v o w was in the span of you envy by take the vectors u and v over there then W is in the span of those two, I can explicitly right as a linear combination of the two of them. But we also saw that I could write v as linear combination of you and W and you as linear combination of V and W, so it's not necessarily unique. I can write one of them is when you come into some of the others, but in this case, I could choose any one of them and read his own your combination of all of the others that was the case down here as well and that happened because the coefficients of this linear combination. We're all nonzero so I could just divide through by the coefficient in front of be for example, in order to write be as linear combination of A and C, even though it was C is in a combination of A and B.  Okay, so that's a linear dependence a set of vectors is linearly dependent. If at least one of them may be more than one but at least one of them can be expressed as a linear combination of all the others.  Now if that just is not possible.  Then we call the vectors linearly independent.  So linearly independent vectors are vectors for which you cannot express any one of them as a linear combination of the others.  That's a negative definition linear. Independence means they are not linearly dependent and negative definitions are often very hard to work with that is it can be at least philosophically easier to answer these vectors are linearly dependent because it just means I've got to find some linear combination of them some non-trivial in combination of them. But if I want to show that a set of vectors is linearly independent, it means I have to show a universal statement that there's no way I can express any one of them as linear combination of the other. So I have to choose the first one and say can I express it as a linear combination of the other two, I have to check all possibilities and some cents. In fact, we have the tools to do that as well inside a different language, but it is a trickier notion to wrap your brain around least I think so just why I want to do lots of examples  I also want to get to to a slight variation of this definition. It means the same thing your textbook defines us in a slightly different way, but I think this is more intuitive the way that it's to find here. So for example, let's take the example of  my favorite example that I keep demonstrating in the room my two arms representing two vectors in three dimensional space and my head representing the third sticking up here. So let's answer the question graphically is my head in the span of my arms. Is it a linear combination of these two, so we've already answered that question many times the answer is no unless I had a neck injury. Okay, the answer is no because the span of these two vectors is this plane here and my head is sticking up out of that plant. So my head is not in the span of these two vectors down here.  Does that mean that these three vectors are linearly independent from the definition there?  That statement.  Know why not?  Oh, but if we had all zeros is coefficients that doesn't tell us anything because every set of vectors can be made 0 with linear combination with trivial coefficient. We're looking for non-trivial linear combination, but that's great that you said that because that's the first mistake that everybody always makes thank you for making it for everybody else. So they don't have to know. Yes.  Okay, see if you said because only one vector has to be in the span of the others and I'm going to turn that around slightly. It's hard to say this I think is what you meant. All we've shown is that this Vector my head is not in the span of these two for the definition of written up their linear. Independence is no one vector can be in linear combination of the others. So, I've only done one third of the work now I have to show that this Vector over here is not in the span of these two.  Okay. Well actually I mean for the same graphical reason that's true. In this case the the plane the span of these two vectors is this playing here that my head and that are Marin and this arm is sticking out of that plane.  Similarly, I have to show that this Vector is not in the span of these two.  Okay, and again this plane the span of these two vectors. This was clearly sticking out of it.  Okay, so I have at least demonstrated are Justified graphically that those three vectors are linearly independent. Cuz no one of those three factors can be expressed as a linear combination of the other two.  But let's rewrite this in a slightly different way.  Which is actually going to make it sound harder to verify but we'll make it mathematically connect with things. We've already done and easier to verify so here is an equivalent definition.  Okay. So first of all this look up here again linear linear dependence.  so this means  free samples suppose that it's the last Vector you one. Let's take a concrete example expose his equal to 4.  This means you for is equal to some linear combination x1u. 1 + X2 you 2 + x 303  For some coffee shops X1 X2 and X3 like this. It's okay if those X1 X2 and X3 are all 0 if X1 X2 X3 roll zero then that means that you for is the zero vector.  So if I had given you the example the three Vector for vectors are my usual 3 + 0 vector.  Okay is the zero Vector a linear combination of those guys?  Is there a resident it's a linear combination where I take 0 as the coefficients of these three vectors now that may sound like I contradicted what I said before but let's rewrite it like this.  It says x1u 1 + X2 you 2 + x 3 you 3 - you for equal 0  So those coefficients X1 X2 X3, they could all be zero, but I've got this minus one there which is not zero. So if one of those vectors is is a linear combination of the others. Then there is a non-trivial linear combination of the four of them. That's not one of those coefficients is not zero in particular the minus one that's there.  So that tells you that if one of the vectors as a linear combination of the others, then there is a non-trivial linear combination of all of them. That is the zero Vector even if all the coefficients but that one or zero, it doesn't matter.  Okay, no on the other hand.  I suppose all we knew.  Was that someone are combination maybe a different one? Maybe I'll call it. Y1 you 1 + Y2.  You 2 + y 3 you 3 + y 4 U 4 is the zero vector?  And at least one of those coefficients is not zero, that's what this statement means here. At least one of those coefficients is non-zero. Meaning that there's a non-trivial linear combination. So let's say suppose that it's why to is not zero.  Well, then I can divide through by Y2. I can divided by a nonzero number. So this one says y 1 / y to x u 1 + u 2 + y 3 / y to X U 3 + y 4 / Y 2  X you for equals 0 and now I can solve for you, too.  So you two is equal to - y 1 / y to X you one.  minus y 3 / Y 2 x u 3 - y 4 / y to X you for  So what I've shown is that if I have a non linear combination, I ate a non-trivial linear combination of these four vectors that gives me the zero Vector. Well, it's non-trivial. So there's some confusion in there. Let's say it's why to that's not zero then I could divide through by that and rearrange the equation to say you to is this linear combination of the others.  so in other words  saying that a collection of vectors is linearly dependent saying that a collection of vectors is linearly independent.  which is the statement that  no one vector can be expressed as linear combination of the others is the same thing as saying there is no non-trivial linear combination of all of them that gives you the zero vector.  If that's the reverse of the positive statement in terms of linear dependence linear dependence is the statement that one of the vectors is a linear combination of the others, but this little calculation down here the scheme shows you that oh, that's the same thing saying that one of them is linear combination of the others is just the same statement as a statement that some non-trivial linear combination of them is 0. Hey, those are equivalent statements, even though mathematically they look somewhat different their equivalent statements.  And the nice thing about the second way of saying it that linear dependence means that some non-trivial linear combination of them is 0 is it that fits right into our tools of row reduction are tools of solving linear systems in order to answer this question? Okay. So here is the theorem  we just proved there's a therm that we just demonstrated their am just means true statements. Okay, here is the true statement that we just demonstrated.  Hey, if I have vectors you once were you when they are linearly independent linearly independent meaning by definition, they're not linearly dependent meaning that no, one of those Vector as a linear combination of the others that happens. If and only if the vector equation x 21 + X2, you two plus all the way up to X and you and equal 0 has only the trivial solution x 1 equals x 2 equals x equals 0  Hey, that's what linearly independent vectors are that's what linear Independence means. It means that the only way that I can get a linear combination of those vectors equal 0 is if it's the trivial linear combination.  Otherwise, it would mean their linearly dependent it would mean that there's a non-trivial linear combination that zero and that's the equivalent to finding one of them being in the span of the others.  Okay. So this now we sit in terms of language that we know how to handle if I want to prove that a set of vectors is linearly independent. I have to show that that vector equation that that homogeneous vector equation. Okay that has only the trivial solution remember last day when we talked about homogeneous systems of equations. We said the nice thing about them is that they have a dichotomy for their solution sets instead of a trichotomy. They always have a solution 0 is always a solution. It might be the only solution or there might be many.  In the special case where there's just one solution. That means those column vectors are linearly independent.  Okay, so that's the statement. I just translated the first statement which is stated in terms of vector equations into the corresponding statement for Matrix equations. The Columns of a matrix a are linearly independent. If and only if the Matrix equation ax equals 0 has only the trivial solution x equals 0  and that is a statement. We now know how to verify using row reduction. So let's do some concrete examples. There's a couple of examples  So here are three vectors of already strung them together as The Columns of a matrix actors in R3 and I want to answer the question are they linearly independent? This is very much like the first example of the second example, we did on the first page. I gave you three factors that case there were an R4 I gave you three vectors actually.  I asked you are they linearly dependent? I asked you is one of them Olivia combination of the others and just staring at them. We were never going to get anywhere unless I happen to tell you that I cook them out to have this particular linear dependence. Hey, but now we have the tools that we can answer the question in a routine way. So we have the Theron from the last page and explanation. We just gave that's do the first example there. I want to figure out if The Columns of that first Matrix there 1 1 0 2 0 1 0 1 2 if those are linearly independent or not. The theorem says they're linearly independent if and only if  The Matrix equation  that Matrix x yuno x 1 x 2 x 3 x 3 equals 0  we want to solve that.  And figure out what the solution set is if the solution set consists of only the zero Vector then those vectors are linearly independent if the solution set is a parametric solution that has infinitely many solutions. Then the vectors are not linearly independent vectors are linearly dependent. So now we go ahead and we solve doing  Row reduction. Yeah, okay. I guess I'm not super excited about doing reduction either but it's you know, it's it's a necessary tool and this one isn't going to take very long.  So we want to solve that system.  I'd Falls couple things I could do. I want to get zeros below the leading one. I could swap the second and third row, but that doesn't really make any difference cuz I'm going to have to get rid of that one. That's currently in the second row anyway.  So I'm going to subtract the first row from the second.  If I just made a zero there a -2 there retains the one there and of course, it doesn't do anything to the right hand side.  Okay.  And I've already got the zero down below. So now I want to get rid of the one below the below the second-leading entry there.  Well, there's a couple of ways things I could do. I could pivot in order to get a one leading one in the second row. Let's go ahead and do that I suppose.  That means that I get a - 1/2 here.  By the way, if you see me making a miracle error, please pointed out. I may well have made one already. It's very easy to do as I'm sure you're aware having done lots of examples now.  Right now I want to get rid of the one below that leading one the one in the third row and second column. So I'll subtract the second row from the third that's going to give me the desired 0 there and I'm subtracting a half from 2, which gives me 5/2 in that entry. Throw 1 - 1/2 + 120  Okay. Now if I wanted to actually solve this system completely I would have to do a couple more steps to get it to reduced row Echelon form. But I've already got it in row Echelon form. And remember when you're in row Echelon form you have enough information to answer the question, which of the three legs of the trichotomy. Is it in the homogeneous case, which of the two legs of the dichotomy is it does this have exactly one solution or does it have infinitely many solutions?  Somebody from this side of the road tell me.  Yes, it's one solution and that one solution is.  Is 0000000 is a solution? So if the reduced ride if a row Echelon form tells you that the only one you know what that what we know there's a unique solution because there is a pivot in every row because there's no roads. There was at the bottom to give us an inconsistency. I'm sorry that tells me that it's consistent. So there's a pivot in every road that that does tell me the same thing here, but only because the number of rows equals the number of columns in this case is because there are no non pivotal call upstairs a pivot in every color.  Friends pivot every calling which means there's no free variables.  I'm so there's a unique solution we could solve for it by pivoting the last row there and then doing row reduction or we could do back substitution, but we don't need to do that because the last equation says x 3 equals 0 and the second was not going to say x 2 - 1/2 0 is 0 and so on and we know that the unique solution since there was a unique one is zero.  So once we're here, we're done. We now have unique solution.  and therefore  this implies that X1 X2 X3 is equal to 000. So what we've got is  that Matrix there has the property that the only solution of the Matrix equation ax equals 0.  Is x equals 0 that's from the theremin the previous page the statements?  That these three vectors are linearly independent.  Okay, easy peasy. So let's do the second example. Answer these three vectors here in our for are they linearly independent or are they linearly dependent? Well, we already know the answer because I pulled out of thin air in the first slide that they have dependents - 2 * the First Column plus three times the second column equals 1/3 call. So we already know the answer what the answer is going to be but let's see how our methods give us the answer. We need to carry this Matrix to row Echelon form to answer this question. Technically. We need to take the augmented Matrix.  And do row operations on. So, let's do that this time.  All right, so I need to looks like I might have a bunch of work to do but it's actually going to go with real quick here. So I need to get a zero in the second row below the leading entry in the first row.  If I subtract twice the first row from the second give me those are there and I - 4 there  Anna - 21 there  I've already got a zero here.  What's up, - 7 - 21.  Is there a problem?  Yes, there's a problem. What's the problem?  Are you telling me that?  You telling me that -6 - 1 is not - 4.  Thank you.  Get Nutz.  Let's fix that.  I'm going to pretend that I made that are pedagogically for you to find you're not going to believe me, which is good. Okay, that's correct now and then in the third row in to get rid that once I subtract the first row from the third one, so I get a zero there I get to -3 is -1 + 4 - 7 is -3  Okay. Now they're a bunch of things I could do for my next step.  The standard thing is to Pivot that second row there. I can / -7 to get a leading one and I could alternatively have swapped the second and third row to get a leading one there, but those will actually give me the same results.  Because dividing 2 by -7 that second row gives me one and three there.  Simile in the third row. I'm going to pay that by dividing through by minus one giving me a one and a three there and look the second third and fourth Rose. They're all equal.  so in order to get rid of the ones below the second-leading one now, I'm going to subtract the second row from the third and from the fourth, but when I do that  I just get all zeros down there.  Okay. I know this Matrix is in row Echelon form.  Let's go ahead and do one more step and take it to reduced row Echelon form.  Which only takes one more step. I just need to get rid of the three above the second-leading one, which means I multiply the second row by -3 and add give me the desired zero there and giving me a -2 he  Okay. So now we answer the question as to which we already know.  Are these vectors linearly independent or linearly dependent?  I heard some indiscernible mumbling. So let's try again by a hand. Tell me what's the answer and why yes.  is a free variable in column Street, and so  Very good. I'll say everything you just said we already know this is Tim is consistent cuz it's homogeneous. They're always consistent. There's a free variable therefore there infinitely many solutions Employment Solutions means that there are non-trivial solution other than the zero solution and that is exactly the same statement is saying that these vectors are linearly dependent not linearly independent now, we already knew that but actually look look what happened here. So I told you at the beginning - 2 * the first Factor plus three times the second is equal to the Third.  We can pick that off of the reduced row Echelon form.  Is a -2 and a 3 there?  In this form of the Matrix here. It's obvious. I hate to use that word cuz it's not always obvious until you see it. But now that you see it. I'm telling you. It's obvious that the third column is -2 times the first plus three times the second ride cuz I've only got ones and zeros there. So if I'm up for that first one by -2 and that second world by 3 and Adam that just means I get a -2 and a 3 in the slots is there is everywhere else when you take the Matrix to reduced row Echelon form. If you have any free variables, then those columns tell you how to reconstruct that column as a linear combination of the previous ones.  So not only do we get to answer the question that these vectors were linearly dependent but the reduced row Echelon form Witnesses a linear dependence between them.  and these coefficients tell us how  okay.  Great. Now there's one more thing. I wanted to point out here, which is that it was a waste of energy to carry all of the zeros in the right-hand column around if I had just erase them from consideration.  Nothing would have changed when you're solving a homogeneous system. There's no reason to write the augmented, cuz it's never going to change row operations don't change the zeros right now. Be careful if you're going to do that because it's only going to work in the case of a homogeneous system. If you have an in homogeneous system, you need to carry those corporations around coz row operations are going to change okay, but in the case of the homogeneous system in particular, when were answering a question about linear dependence, there's no reason to write the zeros over and over. We just carry the coefficient Matrix to row Echelon form to answer the question. If we want to know an exact linear dependence between the variables between the the vectors the columns.  Okay, so that's more or less the whole story on linear Independence. That's how you determine whether vectors are linearly independent. So let's look at some specific meta examples now to understand this now that we have the mechanical way to do it. Okay, there's some cases where we don't need to do much.  So for example suppose I give you a list of vectors and one of them is the zero Vector. We actually really already considered this case, but it was they give you the vectors 1 3 7.  206000 those three vectors are linearly independent or linearly dependent by show of hands little no thinking just looking linearly independent raise your hand.  Someone scratch their head in the sort of meekly did that. Okay, are they linearly independent? Are they linearly dependent raise your hand? Okay, that's a vast majority of you. Why or did you have a question?  Why are they linearly dependent?  Yes.  Okay, that that's a great explanation for typical hang up. So you're wrong, but it's a great explanation for why you were wrong and why it's convincing to think that that would be the answer. I'm glad you brought it up. So his answer was because zero if you want to get zero as a linear combination of the first to the only way you can do that is by multiplying each of them by zero and adding so the only linear combination of the first to give zero is a zero Vector. That is absolutely true what that tells us. Is that the first two vectors by themselves are linearly independent, but I didn't ask that question. I asked are those three vectors together linearly independent?  the answer that is no there linearly dependent because I can take the following linear combination of all three I can take I can take zero X the first  Let's let's write it down I can take.  0 times the first  + 0 * II + 300 + 776 * 1/3  and that gives me the zero vector.  and the point is  that those three coefficients. They're not all 02. This was that point we we made early on in the lecture that just because when you're expressing one of the vectors is linear combination of the others if you can do so, but only with a zero coefficients that doesn't mean the vectors are linearly independent because it's having a non-trivial in a combination of all of them put together. That's the important point. This is a non-trivial linear combination because at least one of those coefficients is non-zero.  in general here the answer is that  If you ever have a list of vectors that includes the zero Vector as one of those vectors, they are always automatically linearly dependent you put in the zero Vector that makes them linearly dependent because you can express that zero Vector as a linear combination of the others may remember the two competing equivalent definition of linear dependence one is there's a nonlinear tribute non-trivial linear combination of all of them together to give zero and the other is at least one of them is a linear combination of the other ones here that second one doesn't need the word non-trivial because in the case when the zero Vector is among them that definitely is linearly dependent.  That's it. A good Turkey Point to keep in mind as we go forward. Okay, next example. What if I just give you a list of one vector cancer? Here's my my one vector v. I don't care what it is.  Is that set of vectors linearly independent or linearly dependent?  I see people biting their lips, which is the right answer because what does that even mean? You're saying in your head, how can one vector be dependent or independent for what? So this is a great example where mathematics is much better than natural language because we made things precisely the point that any question can be answered. So it's hard to understand what it would mean to say one vector is independent of what but our definition was one of our competing definitions was there's a non-trivial linear combination of that one vector. It is zero. So that's the question here.  So is it true?  That some non linear combination non-trivial linear combination of that one vector, which means x1v that's its is equal to zero.  for some non-zero  X1 that's the question. Can I multiply x1v buy some nonzero number X1 and get 0  Yes, why how which which Vector explanation which number X when should I use?  Okay, so maybe that vector v there was the was the vector this one?  Hey, so let me pick any number. I'll pick the number one.  Is 1 * inspector equal to the zero vector?  Your your train of thought is getting a little lost because I've negated statements for X. Right and that's a great example of why these things are important to think about a lot the language gets complicated and the state the logic it's complicated. So you need to run through it a dozen times before you can suss out what the definition of saying we called twisting the definitions. Yes.  Exactly. So the thank you for saying that exactly the way I was going to so the answer is no if the key is not the zero Vector but yes, if the is zero vector.  So in other words if V is a nonzero Vector, it is linearly independent or there's no way you can scale a nonzero vector by a nonzero number and get the zero Vector. You can't multiply two nonzero things and get zero.  And I'm the real numbers anyway.  But if you started with the zero Vector, then it's automatically linearly dependent just look at the first example, if you have any list of vectors that includes a zero Vector is linearly dependent particular that list is just the zero Vector. It's linearly dependent.  Okay, so we're just testing our understanding of the definition of here on these kind of met examples looks like it one more here. What if there are only two vectors because I've got two vectors V1 and V2.  What is it mean to say? They are linearly independent. Let's go back to the definition to say they are linearly independent. So they're linearly or actually, let's do the easy one to work with they are linearly dependent.  if and only if  There's some linear combination of them.  That's zero-sum non-trivial linear combination.  So I can take some that some corporations extra next to not both zero that gives me 0 for those two.  Well, let's say suppose that this one is the non Cyril one. Then I can solve the one we did this example with four vectors A few minutes ago is equal to 8 - x 2 / x 1 x V2  That says that V1 is a scalar multiple of V2.  If I done it the other way if I assume that X2 was nonzero than V2 would be - X1 or X2 X V want.  That would say the B2 is a scalar multiple. If you want. I have a word for that when I have two vectors that are scalar multiples of each other. They are called.  anyone  I've heard a few people say it very quietly. Someone say it louder.  Okay, maybe not louder anyone want to raise their hand until I guess they're called parallel.  I have parallel vectors, they are linearly dependent. So for example if my two vectors were one two, three seven.  and to 6 - 14  look at those and tell me are they linearly dependent or not?  That's the same as the question look at those and tell me are they parallel or not?  No, they're not parallel. Why are they not parallel because I can just see when I have only two vectors if I wanted to get the second one as of scalar multiple the first I know what coefficient I need to use. I need you to write so does that work for all of them to * 1 is too? Yep 6 * 2 is 332 * 3 + 60 + 2 * 7 is -14 know it's + 14. So these two are not parallel and therefore they are linearly independent if there's been a plus there than these would be parallel.  and therefore linearly independent linearly dependent  So in the cases where you have only one vector only two vectors or if your list includes a zero Vector, it's easy to just look at them and see if there's any other dependent but if you have three or more vectors, there's really no easy way to do it is no easy way to eyeball it but there's an easy way to calculate it which is to do row reduction. Okay, so I was going to do one more example here but where I was just about out of time. So I'd rather spend one more moment. The one minute we have left cementing.  Cementing what we've done actually, let's do this second example here cuz it's already done for us. So let's remind ourselves what we need to do here. I wanted to check if these four vectors are linearly independent or not. The way I answered that is I put them together in a coefficient Matrix and I checked to see if the system ax equals 0 has only the trivial solution or has non-trivial Solutions. So I've already use Matlab to compute the reduced row Echelon form of that Matrix and it's over here. So is this Matrix? Does this Matrix as the coefficient Matrix here? Does it represent a system with only one solution or with infinitely many solutions?  Infinitely many because this is not mention Matrix. This is the coefficient Matrix because that third of that fourth column there.  That 4th column there.  Has no pivot.  Has no leading entry. Therefore. There's a free variable.  therefore  there's a non-trivial solution.  And therefore these vectors are linearly dependent.  No for the last 10 seconds here. Did we need to go through computations in this example know?  Here we had four vectors in R3.  When we string them together in the coefficient matrix, it's a matrix with four columns. But only three rows and the question where the seeking to answer is is there a pivot in every column?  The can't be a pivot in every column cuz there is only at most one pivot per row so there can be at most 3 pivots here. That's what what turned out in this case that might have been to there might have been one but that can be at most 3 Hibbetts. And so what we see is if you have a matrix which has more columns and rows, there's no way those columns can be linearly independent if you have columns in R3, if there's more than three of them, they must be linearly dependent. So let's continue with  Can you see San Diego? ",
  "Name": "math18_b00_wi18-01222018-1000",
  "File Name": "lecture_6.flac"
}