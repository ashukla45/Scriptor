{
  "Blurbs": {
    "* B inverse by definition is the identity. So I got that da is equal to be inverse. That hasn't fully solved. 4D yet, but now I can repeat the same calculation. So I multiply on both sides by a and verse. And on this side, I'll note that that. Besos by using associativity of matrix multiplication that turns into d x d identity, which is D. I know I ": [
      1469.7,
      1506.0,
      59
    ],
    "3, but there's some is not in the set upon Him is a degree 3, that means the set of polynomials of degree 3 is not a vector space. It's not closed under the vector operations. not a vector space But we can modify it a little bit. So let's talk about P sub. Sorry, that's the notation that your textbook uses. soapy subtree Is the set of polynomials? of ": [
      2695.2,
      2735.4,
      108
    ],
    "And I'm subtracting the first one the second so I get a minus C there at eight doesn't change. Okay. Now that's just the first steps before I go any further. I know. Remember when we're finding the inverse of a matrix. The first thing we're doing is making sure that it makes sense to find the inverse which means we need to check to make sure that the Matrix ": [
      683.2,
      703.2,
      28
    ],
    "And if we actually did Robert option here how many steps would it take? Well, if you look back at your book and we discuss this a little book bed if you have a an N by n system. Okay with a single augmented column then the number of floss it takes to take it to Rohit reduced row Echelon form is about one-third and Cubed here. We're actually finding ": [
      1003.2,
      1024.9,
      41
    ],
    "Anderson a But a inverse times a by definition of a inverse is the identity Matrix. And therefore I just get see over there. so C is equal to a the thing that we didn't know a inverse inverse C is actually equal today. So there we have it. So any invertible Matrix its inverse. Is its own it's the inverse of its inverse is itself a ever invertible. Matrix ": [
      1305.4,
      1335.1,
      53
    ],
    "Can I use that term informally now, we're going to use it. Formally I'm going to give a formal abstract definition of what it means and show you several examples that are some familiar and some not. So first, I want to be able to still a little informal but tell you the idea of vector space. What is it? It is a collection of objects. And this is the ": [
      1766.1,
      1789.4,
      72
    ],
    "Do I listen to a podcast next time we're moving on to section 4.2 some specific examples connecting those two two things. We've already been doing and two quick reminders. This Friday. You have a Matlab assignment to Matlab assignment 3 is due this coming Friday, February 9th at 11:59 p.m. And also your fourth MyMathLab homework is due a week from today Monday, February 12th at 11:59 p.m. On ": [
      2.0,
      35.4,
      0
    ],
    "I guess we should also technically say and A and C are nonzero, but actually if you backtrack and look at the special cases where where one of the ANC is zero, then you would have done different row operations, but you would have actually been able to do row swaps in order to get it into the same form. So we're at the end of the day. It's going ": [
      783.2,
      801.9,
      32
    ],
    "I have two vectors, it's called them. A-1 B-1 and see one as the components and the next Vector A2 B2 C2. So the objects are lists of three numbers. Okay, and the operation of plus I tell you is defined or I put a colon before the equal sign means I'm defining this to be equal to a 1 + b181 + A2 B1 + B2 and C1 plus ": [
      1854.7,
      1886.7,
      76
    ],
    "Matrix system of equations would take the Matrix a and we put another Square Matrix to the right of it. Not just a column for the whole identity Matrix to the right of it and then we do row operations on back end by to animatrix. And we carry it to register Echelon form that whole big augmented Matrix again. The dotted line in the middle. There is just for ": [
      286.2,
      307.1,
      11
    ],
    "Now let's move on to chapter for so this is a huge shift and topics right now. It's like we're going to be starting the course again. We're going to be coming back next day already. We've already seen but it's a it's a big shift not just in topic, but also in thought process and I want to preface this by saying you're going to want to review what ": [
      1662.0,
      1685.9,
      67
    ],
    "P hear that one has degree 3 power. The highest power is 3. Where is this polynomial Q it has degree 2? Hey its highest power has degree to. Soapy so kieu is not in this new set piece piece of equals 3 down here. Where is pee is in this set? Sop is in here Q is not in here. Okay. So here's the question. So I'll give you ": [
      2538.9,
      2570.1,
      103
    ],
    "So that gives me a - to hear - 1/2 here positive one here and positive 3 has there and that's the inverse of a matrix. How many flops die do how many athletic operations? Why did 1 2 3 to calculate the determinant and then then I had to take that number and divide each of those buy it. So it did form or Flop. So this took 7 ": [
      952.2,
      978.8,
      39
    ],
    "Test all the properties. Okay, great. So we need to check if the addition is. Commutative associative addition distributes over addition and if we do that going to see that all of those properties Holt. but we have to be careful and go back to the very beginning of the definition. We had to have for to be a vector space. It has to be a set. With an addition ": [
      2598.8,
      2624.5,
      105
    ],
    "That's the the byline here. That's the the moral of the story. So we're going to go with that and now we're going to talk about some examples of vector spaces that are different at least on their surface then ones that we've been working with. All right, so far in this past, we've been working with spaces of vectors which are list of real numbers of some finite height ": [
      2243.2,
      2265.3,
      92
    ],
    "That's your job. That's why it's going to be useful to review over and over what we do here. So want to talk about Vector spaces. I've already used that term many times informally when I talked about the domain and codomain if a linear transformation when I took what are vectors living in RN, I've sometimes referred to RN as the vector space the space where the vectors live. ": [
      1744.8,
      1765.4,
      71
    ],
    "We saw that Having a left inverse a cyst. That's e x a is the identity tells you that solutions to equations x equals b r unique when they exist and having a right inverse cd68 x equals a identity tells you there's always a solution but it might not be unique. So if you wants to have a unique solution if you want to solve ax equals B, 4X ": [
      124.3,
      148.4,
      4
    ],
    "We're going to use row reduction. So let's do that with a generic two-by-two Matrix ABCD or reduction here. And this is like a nightmare version of all of those questions with an h and right now I have all four parameters unknown here so they could get quite messy and the two by two cases tractable enough that we can actually do it. I'm going to do a trick ": [
      547.6,
      570.5,
      23
    ],
    "a are linearly independent, all the columns are linearly independent or equivalently the rose have are all pivotal. That means that the columns span all of our end. And for a square Matrix just because pivotal Rose and pivotal columns go hand-in-hand for square Matrix those two are equivalent again. So for a square matrix, it's rows and columns are linearly independent. If and only if they spend all of ": [
      235.5,
      263.2,
      9
    ],
    "a distinguished member. We call the zero vector. And it has two operations to find Onnit addition and scalar multiplication. And I have to define those on whatever said in that means that I take any two elements of the vector space and it must return a new element of the vector space one way to say that is that the vector space is closed under addition. Okay, so that ": [
      2056.4,
      2080.7,
      84
    ],
    "a distinguished one called the zero Vector. There's an operation Edition the on the vectors. There's no operations scalar multiplication to any veterans Skillet by any real number those operations produce vectors that are back in the same set you started with this Vector space and those operations satisfy all of the properties that Edition scalar multiplication are supposed to satisfy from your intuition from real arithmetic from grad school. ": [
      2218.5,
      2243.2,
      91
    ],
    "a matrix that had a row of zeros in it. What happens if you get an inverse that has a row of zeros in it? You you step away from the desk come back erase and start again because you made a mistake the end of a row of zeros in it. Because if it did it would have to be invertible matrices are invertible. If and only if they ": [
      348.2,
      371.8,
      14
    ],
    "a new element of that set, which I call U + V. No, I mean you might be saying come on Camp. I know how to do this. I've done this a thousand times like yeah, you've done it a thousand times in the case of RN, right? So that's a good example RN is a vector space and it's a vector space. Let's do our three here. So if ": [
      1833.8,
      1854.7,
      75
    ],
    "a that just gives you a again but this highlights an important point, which is if I already know that a is invertible then I should do this procedure to find its inverse. But what if I don't know that it's invertible. I need to check that the Matrix is invertible on the way I do that is to see if it has a pivot in every row or every ": [
      392.0,
      414.9,
      16
    ],
    "add these two up p.m. X + Q of x. is equal to x cubed minus 2x plus minus X cubed which is equal to -2X. -2X is a polynomial. Does it have degrees three? Now that's a degree 1 polynomial. This is not in this set piece of equals 3. Oh, yeah, sorry. Secure our two polynomials P&R they're both in this set the set of polynomials of degree ": [
      2657.2,
      2695.2,
      107
    ],
    "an abstract structure and I'm placing some axioms down but it satisfies and in principle, you're supposed to drive everything you want to know about the set from those axioms in practice. We get used to applying them and we often hide them in the background. So we don't have to do is a formal proof using those axioms every time and in fact, you'll see all the vector spaces ": [
      2180.6,
      2200.9,
      89
    ],
    "and only if the linear transformation is one to one and onto So an equivalent question here is given two linear Transformations that are both one-to-one and onto if I take their composition, is it one to one and onto? Well, maybe that doesn't make it any clearer for you. Maybe it makes it less clear, but I want you to think about that as we as we do this ": [
      1361.7,
      1382.7,
      55
    ],
    "and produces a third one. And the second one is called scalar multiplication, which is a rule that takes one of the objects in your set one of these vectors. Any real number Lambda and calculates their scalar product calculates their Skillet, you know, how do I do the scalar multiplication? I have Lambda and I'm supposed to x one of the vectors. And I know for RN I know ": [
      1931.4,
      1958.9,
      79
    ],
    "and scalar multiplication option and it has to be closed under those operations given two vectors. There's some has to be a vector. So let's for example take We saw that P. Is in there. Let's take a new one. Let's call our of x minus X cubed minus X cubed is a degree 3 polynomial. And so that one is in the set piece of equals 3. Now let's ": [
      2624.5,
      2657.2,
      106
    ],
    "and scalar multiplication the way we usually know how to do those operations. So it back let's just let's just do an example. Let's take two of them. That's a a 1 x cubed + B One X squared plus C One X Plus D1. Let's add that to a 2x cubed + a + b 2 x squared plus C 2x + D2 So, how do I add those ": [
      2863.6,
      2892.9,
      114
    ],
    "and then add a third then I get the same result if I add the second and the third. With the first in front like that. Okay Edition is supposed to be Associative and also the scalar multiplication is distributive over addition that if I scale the sum of two vectors, that's the same thing as scaling the vectors and adding them up after work. These kind of properties. Okay, ": [
      2128.1,
      2156.2,
      87
    ],
    "as real numbers if you generate in Excel or in Matlab, if you generate a random Matrix, then it's going to be invertible with probability one you do that and not let go ahead and ask and generate a thousand random 3 by 3 matrices and then ask Matlab to find the inverses of all of them. All 1,000 will be invertible being non invertible is a special property. Now, ": [
      482.1,
      503.8,
      20
    ],
    "at the second one and say let's factor that that's x + 1 squared. That's true. But let's not do that. Well, maybe I'll do that and I'll cross it out right now. That's not to say that that's false. That is true. But that's not relevant for us right now because that involves multiplying polynomials and polynomials are things you can multiply together, but we're not going to right ": [
      2326.5,
      2348.4,
      95
    ],
    "because the answer is yes, and if you untwist the definitions of one to one and onto you will see that it must be true that both of those conditions are preserved undertaking compositions. Okay, but for now we can do the same sort of calculation. We still just above so let's call this thing d. I'm assuming that it exists even do this calculation, but then we'll see at ": [
      1382.7,
      1408.1,
      56
    ],
    "by 2 matrices. Okay, but for two by two sure we can use it. How about this Matrix down here one to one? Can we calculate the inverse of that one? No, we're not. Because the determinant is zero because the two columns are parallel. I heard both answers and those are both good answers not invertible. Okay, if you want the determinant is 2-2 there and we will see ": [
      1118.4,
      1145.7,
      46
    ],
    "call him. But that means when row reduction it means doing Road auction on a alone so really should I go ahead and do that row reduction on a alone to see that it's invertible and if it is then start again doing this. No, I don't think so. I think you should always start by assuming that a is invertible not assuming by presuming that a is invertible and ": [
      414.9,
      439.3,
      17
    ],
    "cancel some of the terms and have only a few of the terms left, but those will have a lower degree or else they would have been high degree to start with Okay. So let's actually write out explicitly what this means. We're taking polynomials a polynomial of degree 3 looks like this a x cubed + b x squared + BX + d Any degree 3 polynomial looks like ": [
      2766.4,
      2788.1,
      110
    ],
    "closed under scalar multiplication. We need to be able to multiply the polynomial by zero. Right, but you can't take something in there and * 0 it's not going to be in there anymore. Take a look at the zero polynomial which has degree zero. So they set upon a male's of degree less than or equal to 3 is a vector space and it's a vector space under addition ": [
      2840.1,
      2863.6,
      113
    ],
    "coefficient down there that a D minus BC is non-zero. Okay, so this must be nonzero in order for the Matrix to be invertible. And that is that number there that number has a special name that she may have heard of and we'll get into in a couple of weeks. That number is called the determinant of the Matrix a all square matrices have determinants. We'll get to that ": [
      724.7,
      752.3,
      30
    ],
    "columns in that case are going to be the reduced row Echelon form of a and the thing you're left with on the right is the inverse of a Now let me comment by the way. Someone posted a good question on Piazza this morning where they did they did this with a matrix that okay. Well, I got that the inverse was equal to and then the inverse was ": [
      325.4,
      348.2,
      13
    ],
    "day to understand exactly how to always do the translation. But as you're going through always remember that the operations are always going to look like the ones we've seen an RN because they're always isomorphic to the ones we've seen so Vector spaces always look like RN for us. So we'll continue with that on one. ": [
      3053.9,
      3072.0,
      120
    ],
    "definition like taking calculus you define a function is differentiable. If and you get it certified abstract definition of what that means and then lots of examples of differentiable functions that have calculate the derivative. So I'm giving you an abstract definition. This is what a vector space is it is this kind of object and then it will show lots of examples of things that may not match that ": [
      1789.4,
      1812.4,
      73
    ],
    "definition. A vector space is a set of objects. He will call those objects and vectors. And what makes it a vector space is that it has two operations defined on it. What does that mean? You have an operation to find on it? So I have this set and the operations are given any two elements of that set, which I'll call you in a v i can produce ": [
      1812.4,
      1833.8,
      74
    ],
    "degree Less than or equal to 3. Okay. And this one is a vector space. It's so that that thing we did on the last slide where we added a polynomial of degree 3 to another one of degree 3 and we got a new polynomial its degree wasn't three anymore. But his degree was lower than three. You can never get higher degree by adding polynomials together. You could ": [
      2735.4,
      2766.4,
      109
    ],
    "done half the work and you continue that's a little wasteful for the stuff on the right. There's no reason to carry around the stuff on the right if you just checking if it's invertible, but the reality is that It's a safe bet that any random Matrix is invertible. Okay, if I actually give you a random Matrix, like I choose all the numbers randomly not as integers, but ": [
      459.9,
      482.1,
      19
    ],
    "down the inverse of an arbitrary two-by-two Matrix the way I do it is I take the diagonal entries and I swap them and I put my two signs in front of the Archie diagonal entries and then I divide the whole thing by the determinant by a D minus PC and that's a very, patiently efficient way to compute the inverse here. Let's think about how many steps does ": [
      850.1,
      871.5,
      35
    ],
    "equals be over a ax equals a inverse P. You need to have the sea on both sides and then we call it a inverse Ace age of the power of -1. It's only possible if a is square to get that to happen as we saw and that's just because of these equivalent statements down here doesn't mean that every Square Matrix is invertible. That's definitely not true. But ": [
      148.4,
      170.3,
      5
    ],
    "equation C over a equals 1 solve for C. What do you do? I heard someone say / a inverse but I want to but that's true. But let's think of it as what it really means which is x a Okay, so therefore and I want to be very nauseatingly pedantic here. So we make sure we understand all the things we're doing. So if I X a on ": [
      1253.3,
      1280.7,
      51
    ],
    "every invertible Matrix is square. And we saw various equivalent conditions to check if a matrix is invertible. It's invertible. If and only if it's reduced row Echelon form is the identity Matrix, which is the same thing as saying that all rows and columns are pivotal, but because it's a square Matrix, you only need to check one of those right if if every row is pivotal that means ": [
      170.3,
      195.6,
      6
    ],
    "find it? It's a non invertible Matrix know you couldn't because this thing is actually a Okay. Why is that? Well, let's just check. So let's go. Let's let's not let's pretend we don't know that that's true. But let's call this thing see what does it mean that a inverse inverse is see, whatever that is. That means that c x a inverse. Is the identity Matrix that's what ": [
      1199.4,
      1228.9,
      49
    ],
    "first. I'm going to use associativity of matrix multiplication and strip off the bee. I want to solve for D here. So the first thing I'm going to do is move the be over to the other side. So I'll X by B inverse. I know that b is invertible so I get the inverse there. but over here I'm going to use associativity of matrix multiplication again. And B ": [
      1434.4,
      1469.7,
      58
    ],
    "flops to calculate the determinant whereas to see if it's invertible using row operations takes less than Okay, great. So let's now talk about a few more properties of inverses that you're going to use. You should be aware of their homework. So we already mentioned this one. So if I find the inverse of a matrix, what is its inverse? Is it invertible? Could you take the inverse and ": [
      1170.8,
      1199.4,
      48
    ],
    "flops. That's what it's going to take for any Square Matrix are going to do seven flops unless you count the actual action of moving the the so it could be up to 12 flops. If your computer account has a flop the action of swapping the one in the four and put it in the gating those numbers, but it's it's a small number of flops floating Point operations. ": [
      978.8,
      1001.4,
      40
    ],
    "going to make you do it but it is true here. That's that all those properties will hold so the space of polynomials is a vector space can taking it upon him as an atom skill multiplying a polynomial all those operations work the weight Vector operations are supposed to work. There's a new set P sub equals 3 and this is the set of polynomials. of degree 3 This ": [
      2503.8,
      2538.9,
      102
    ],
    "good. That definition wouldn't give you a vector space here because they're certain properties that these these operations have to satisfy which will get to on the next line. But for now just want to say we have a set of objects abstract set of objects. And I'm going to Define two operations on it. One of them is Edition, which is some rule which takes two of the objects ": [
      1911.6,
      1931.4,
      78
    ],
    "have a particular element in it that has special properties because we always have that zero Vector around the zero vector and all our calculations has played a critical role, right? We talked about homogeneous equations with a 0 on the right and then 0 is a solution 0 is the additive identity write 0 + any Vector is 0 so a vector space is a set of objects with ": [
      2034.6,
      2056.4,
      83
    ],
    "have a pivot in every row and every column But if you get that the inverse isn't invertible. There's no way it could be an inverse in the first place. Why is that we'll get to that in two slides in case you didn't read ahead already because the inverse of a matrix is always invertible and its inverse is the original Matrix to take the reciprocal of 1 over ": [
      371.8,
      392.0,
      15
    ],
    "have found. That D is equal to that which is almost what you might have expected, but there's a wrinkle. I asked you what's the inverse of 8 * b + the answer is B inverse X and verse about real numbers if I ask you? What's the reciprocal of a x b you'll tell me it's one of her baby and it's pressed you say. Oh, well, that's one ": [
      1506.0,
      1528.3,
      60
    ],
    "hours are this week. All right, so I would like to get started with what we're doing today, but getting started me is reviewing. So here's everything we did last day just as a reminder that we talked about Matrix inverses, which are things that sometimes exist is so if we have a matrix a it's called invertible if it has a two-sided inverse that is if there is a ": [
      76.3,
      102.4,
      2
    ],
    "how that's defined. I told you it's defined by scaling all of the entries. That's the definition of scalar multiplication for the vector space RN. But the key fact here, is that a vector space could consist of other things kind of back to this? What is a vector so concretely at the beginning we said, we'll just Define vectors to be these things list of real numbers of effects ": [
      1958.9,
      1984.8,
      80
    ],
    "if you've seen already that this condition for invertibility having the determinant non-zero that is always equivalent will get two determinants for higher size matrices later. And the determinant is zero exactly when the Matrix is not invertible. Okay, but that's not a good copy tationil tool because just calculating that one determinant that's most of the work for a 10 by 10 matrix. It takes more than 15 million ": [
      1145.7,
      1170.8,
      47
    ],
    "in your back pocket. All right. I think that's everything that I want to talk about with invertible matrices for now. We will of course be coming back to them over and over it may be working with them on your homework. Okay to cement those things for sure and on your Matlab assignment cuz Matlab, of course since All Night Live does reduction can easily find inverses of matrices. ": [
      1638.7,
      1659.9,
      66
    ],
    "into. AC DC and then C 0 and the second Road turns into a c a d 0 a another reason that I did that is when I subtract. Row 1 from Row 2 I'm going to get that 0 that I wanted to cuz I arranged it so that those two will match so I get a zero there. And now over here I get a D minus BC. ": [
      644.4,
      681.8,
      27
    ],
    "inverse. So I got to do all that work again, and the answer is actually The inverse of the transpose is the same as the transpose of the inverse. Invert taking inverse and taking transpose those operations commute with each other. So if I tell you what the inverse of a transpose is, then I've already told you what the transpose of a and versus and vice-versa facts to have ": [
      1611.5,
      1638.7,
      65
    ],
    "is invertible. And the inverse you get back the original Matrix. Here's another important property. What if I take 2 inverse matrices or if I take two invertible matrices is their product invertible. Well, let's think about this in terms of linear transformations. Linear transformations of a I can make a multiplication by 8 as a linear transformation. And remember we talked about last day that a is invertible. If ": [
      1335.1,
      1361.7,
      54
    ],
    "is invertible. So I need to check that all the rows and columns are pivotal. So we already assumed that A and C are nonzero. So that one 1 entry of the Matrix over there a time. See that's not zero. But what about in the second row? I need to see that the second row of the coefficient Matrix has a pivot in it. That's only true if that ": [
      703.2,
      724.7,
      29
    ],
    "it lets let's write that as Z of x. That's just x cubed minus 2x + 0 which is just X cubed minus 2x which is p so the zero polynomial is the thing that if I add it to another polynomial I get that same polynomial back. Nothing changed. That's just like the zero Vector it is the zero Vector in this Vector space. If I were really going ": [
      2454.0,
      2478.2,
      100
    ],
    "it means on the other side as well as we know these are square matrices. So in that case, it's sufficient to just check it on one side. So let's check in on this side say so we want to find Cena. Let's solve for C in this equation. How do I solve for C? Think think of these is real numbers for a moment. If I give you the ": [
      1228.9,
      1253.3,
      50
    ],
    "it take Ok, well, let's actually do an example here. So we'll ride this went down. So here's a matrix 1 2 3 4 Is it invertible? I heard some people whispering. Yes, why is it invertible? Cuz the determinate is not zero, that's a good answer. That's correct. But there are at least at least one other answer that you could give which is also good. although what all ": [
      871.5,
      903.6,
      36
    ],
    "know that it's Square then it's invertible. If and only if it has n pivots a pivot for each row and each column. Okay, that's the same thing as it's reduced row Echelon form being the identity Matrix and then taking that same language and converting it into equivalent Notions that we've been developing. The same statement tells you that a is invertible. If and only if The Columns of ": [
      214.0,
      235.5,
      8
    ],
    "later for a square matrix. It's pretty easy to compute it. Okay, it's just what you get when you multiply the diagonal entries and subtract from that the product of the Auntie diagonal entries. Okay. So what we see here is a is an invertible Matrix if it's two by two if and only if that determinants a D minus BC is non-zero. If that thing is non-zero then well, ": [
      752.3,
      783.2,
      31
    ],
    "length. But what's important about that what makes them vectors why we call them vectors and R and a vector space is that it has these two operations you can add them and you can scanner multiply them. Peyton will see you in a few minutes examples that are not RN not explicitly anyway, or you can do this these operations as well. And it makes sense to a vector ": [
      1984.8,
      2006.9,
      81
    ],
    "let's talk about that message to buy 2 case how many people know or know of the formula for the inverse of a 2 by 2 Matrix? Oh not very many of you but a bunch of you ask last day, but that's okay. I want I want you to see it if you haven't already. So, how are we going to find the inverse of a generic two-by-two Matrix? ": [
      528.3,
      547.6,
      22
    ],
    "math class for most of you. And you're you're all going to get it no problem, but it's going to take a little bit of effort and it's going to take a few passes through before it really sticks. And that's just how it goes. Mathematicians. Love to do things abstractly mathematicians love to use strange symbols. Right? And so you're just going to have to roll with it and ": [
      1704.9,
      1728.5,
      69
    ],
    "matrix see so if i x c x a I get the identity Matrix and If I multiply 8 * Z, I got the identity Matrix and we saw an example when we started. Where is it possible to hook up one of these to happen, but the other can fail, okay, because matrix multiplication really does not commute in general. So we want it to be a two-sided inverse. ": [
      102.4,
      124.3,
      3
    ],
    "multiply the first row by - c / a If that's going to give me fractions, so instead what I'm going to do. Is I'm going to multiply the first row by a story by sea and multiply the second row by a now that's not strictly allowed. Right? I am I'm allowed to divide. I'm not allowed to multiply at the difference between multiplying and dividing is just that ": [
      593.1,
      621.3,
      25
    ],
    "my set of objects. Okay, it's the set of polynomials like for example. P of X is X cubed minus 2X And Q of X is equal to x squared plus 2X + 1. + let's called Z of X is just the polynomial which is 0 constant polynomial. Those are three examples of polynomials. If you're working with polynomials and remembering from high school, you're probably inclined to look ": [
      2293.7,
      2326.5,
      94
    ],
    "now. We're not going to take him up on his things. You can multiply we're going to think of polynomials as vectors. Can you used to a vector being a list of numbers and we'll see how that serves still make sense in this context, but right now the objects are polynomials and to call them vectors means that I need to have a few things. I need to tell ": [
      2348.4,
      2367.7,
      96
    ],
    "of her 8 * 104 be the product of the reciprocals and that's true here as well. Except we have to keep in mind we have to always remember that matrix multiplication is not generally commutative. And in fact, if you want to find the inverse of the product AV you have to take the inverse is in the other order always. If you multiply a inverse x v inverse ": [
      1528.3,
      1549.1,
      61
    ],
    "our end, yeah, that's not true for rectangular makes these but it is Truth or Square matrices and its equivalent to The Matrix being invertible know all that is to say those are conditions. We can check any one of them to see if the Matrix is invertible if we actually want to find the inverse as we saw last time, what we do is we solve this multi augmented ": [
      263.2,
      286.2,
      10
    ],
    "polit the set of polynomials is closed. Similarly. I know how to scale a polynomial I can take two x p a tax that means two times x cubed minus 2x which means just two x cubed minus 4X and that's still a polynomial. So these things are closed under addition on the scale of multiplication operations. Similarly if I take p An ad 02 it's at the zero polynomial ": [
      2422.8,
      2454.0,
      99
    ],
    "polynomials with what we did down here. We did exactly the same thing. Actually all we're doing Is we're taking the thing we saw before our for a list of four numbers and we're riding them in a different way instead of writing them as a one-time is the standard basis Vector C1 plus ancient necklace. Let's write it that way. So this one is a 1 + a 2 ": [
      2964.2,
      2988.2,
      117
    ],
    "said doing row operations to calculate the inverse take about two-thirds and Cubed flops. So that's about 666 flops, which is a lot for a human computer but 666 flops. Where is the formula that uses determinants to calculate the inverse of a 10 by 10 matrix takes more than a hundred million flops. Really bad algorithm cuz it's really not a computational useful tool for anything other than 2 ": [
      1091.0,
      1118.4,
      45
    ],
    "seat. That's the definition of the addition. I give you these two objects are real numbers three, and I Define there some to be that thing. I could have been giving you some weird definition. Like I actually let's make it a 1 * a 2 and just be one and then see 1 ^ C 2-3. I could have given you a different definition but not every definition is ": [
      1886.7,
      1911.6,
      77
    ],
    "so I'll do X cubed minus 2x plus x squared plus 2X + 1 and now I'll use the properties of addition of real numbers to write this as X cubed. Plus x squared minus 2x + 2x gives me 0 there plus one. Now. That's a new polynomial. This is in this set. That is a polynomial and so I have given you a definition of addition under which ": [
      2393.9,
      2422.8,
      98
    ],
    "some fix tight. Let's work with a new Vector space. Now that is not of that form at least it's not presented in that form, but it's something you've already seen and worked with objects of art is human work with I'm going to call it p-block board bold p and this is the set of all polynomial functions. So I'll just say all polynomials. in a single variable That's ": [
      2265.3,
      2293.7,
      93
    ],
    "some of the two vectors has to be in that same set of objects. Okay, and then all of these things together the vectors together with those operations, they must satisfy all whole blank of properties and I'm not going to write them down here. But if you open your textbooks to page 192, they're all listed there. There's about 15 properties, but they all satisfy you do not have ": [
      2080.7,
      2103.1,
      85
    ],
    "space is a set of objects that has two operations addition and scalar multiplication to find on it. Now. It's a little more involved than that, right? You can't just have any operations that you want. You have to have the operations play nicely together. So V is a vector space means that V is a set. And already it can't be any old set or rather. You have to ": [
      2006.9,
      2034.6,
      82
    ],
    "supposed for the moment. So this is Mirror Universe. Now look at that are for. Vectors in R4 look like A-1 B-1 C1 D1 and how do I add two of those A2 B2 C2 and D2? I add them by adding the like coefficients. That's exactly copied over from three sides of except with four components instead of 3. I don't want you to compare what we did with ": [
      2927.6,
      2964.2,
      116
    ],
    "that resulting thing is not the inverse of a b. It's the inverse of ba which might not be the same as a b. Okay, so that's a useful property that you'll need to use and remember on your homework for example, and there's one more I want to do down here and I'm not going to do the calculation because it turns out to look exactly like the things ": [
      1549.1,
      1569.3,
      62
    ],
    "that where a b c and d are real numbers. No to be clear here. This is what the set of set P3 is polynomials of degree less than or equal to 3. If I wanted to describe piece of equals 3 from the last slide in the same terms, I would have exactly the same description. Except that the important condition would be that a cannot be 0 but ": [
      2788.1,
      2822.3,
      111
    ],
    "the end that the calculation shows that it exists that this Matrix is invertible. So I want to solve for D there somehow was that mean to solve for D? What what is what is the actual statement here? What does it mean that D is a v inverse this means that d x a v Is the identity. So I'm going to do the same thing. I did before ": [
      1408.1,
      1434.4,
      57
    ],
    "the inverse Matrix. So we have to do that end times except we don't do all the operations end times. We're only we're doing it all in parallel. And if you counted up properly it turns out to be about two-thirds and Cubed. So in this case and is 2 in cubed is eight. Right. So 2/3 of n cubed. Is about 6. Text Lee fewer flops than then here, ": [
      1024.9,
      1049.1,
      42
    ],
    "the inverse of a 10 x 10 matrix as well through a 3/4 by 4 any size you want there is a formula for it if you took math 102 or math 100 the abstract algebra classes after this you would eventually see how it works involves a lot of determinants. So there is a Formula that you can use but for example of a 10 by 10 case I ": [
      1071.0,
      1091.0,
      44
    ],
    "the right, but I'm not playing the place where it's going to work out. I get CA inverse x a is equal to Identity times a no identity x a is just a matrix does and then over here. I'm going to use the associative array of matrix multiplication to say well if I multiply Co Universe by a that's the same thing as multiplying see by the product of ": [
      1280.7,
      1305.4,
      52
    ],
    "the rows and columns are pivotal it with a two-by-two matrix. It's easy to check look at the two columns. Are they parallel know you can't multiply the first go and buy something to get the second column. So that means that the columns are linearly independent, which means that they're both pivotal which means that Matrix is invertible one way or another it's an invertible Matrix and stuff. I ": [
      903.6,
      923.0,
      37
    ],
    "then you'll do your first steps the first part of the road auction algorithm until you get this Matrix in row Echelon form and then you'll be able to check. Is it going to give you the identity Matrix in the end? If it isn't if you get a rope zeros for the first part then you stopped with a okay sexy not invertible. If it is that you've already ": [
      439.3,
      459.9,
      18
    ],
    "there is an N by n Matrix that means there are and pivots but there can only be one pivot per column as well to actually all the columns are pivotal to and vice-versa for a square Matrix. Every column pivotal is the same thing as every row pivotal that's not true for rectangular matrices, but it is true for square matrices. So if you got a matrix and you ": [
      195.6,
      214.0,
      7
    ],
    "there is one more thing. I wanted to mention which is that my office hours. Are shifted this week? so my office hour will be Wednesday and Friday 1 p.m. To 3 p.m. This week's of my usual office hour is Friday at 1 p.m. And I'm going to actually have to ship my Tuesday offer. Absurd Wednesday. I won't be on campus tomorrow. Okay, so that's why my office ": [
      35.4,
      76.3,
      1
    ],
    "there's lots of non invertible matrices around but they form a much smaller set of matrices. Okay. So generically matrices Square matrices are invertible. All right. So this is how you find the inverse of a matrix with row reduction. There is one for a special case that many of you have already seen probably where you don't need to do row reduction because you can remember a formula. So ": [
      503.8,
      528.3,
      21
    ],
    "things like you + 0 or 0 + you is equal to you for every Vector you Okay, those are the properties or some of the properties that make a vector space a vector space and there's a there's many more. But again they all are in are things that you're familiar with already just have to formalize them as mathematicians. We would call these things axioms. I'm giving you ": [
      2156.2,
      2180.6,
      88
    ],
    "this set Pete piece of equals 3. And I'll Define on it addition scalar multiplication the way it's defined up above for polynomials. I know how to add and multiply polynomials. Does that make this set piece of equals 3 into a vector space. Is it a vector space or not? So before we answer question, what do we need to do to figure out if it's true? I'm sorry. ": [
      2570.1,
      2597.5,
      104
    ],
    "times the standard basis Factory 1 + B1 + B2 Time to Standard next basis Vector E2 plus C1 plus C. Two times the standard I suspect early 3 + 81 + D2 Time to Standard basis Factory for right where you want is the vector 1000 inches of actor 0 1 0 0 and so forth compare. What we just did. here with what we did over here. All ": [
      2988.2,
      3023.1,
      118
    ],
    "to boil down to just that condition a D minus PC has to be nonzero. Okay, I did not kiss. If we if we continue with the row reduction algorithm will be able to convert that Matrix to reduced row Echelon form. So the next thing we're going to do is divide through by a D minus BC. I'm going to pay that now we have no choice and then ": [
      801.9,
      821.1,
      33
    ],
    "to do that. I take the transpose and then I put a transpose next to the identity and I carry it to the reduced row Echelon form get the identity on the left and a inverse transpose on the right or I transport a transpose inverse on the right. But what if I already told you what a inverse was I want a relationship between a transpose inverse and a ": [
      1590.9,
      1611.5,
      64
    ],
    "to memorize those properties because you already know those properties those properties say addition and scalar multiplication work the way your intuition tells you they should from all your experience with arithmetic it tells you things like all right a few of them down it tells you things like U + V is equal to V + UV Edition has to be commutative and that if I add two vectors ": [
      2103.1,
      2128.1,
      86
    ],
    "to verify that the set of polynomials is a vector space. What I would need to do is now check that the definitions, you know for addition and scalar multiplication of polynomials satisfy all of those properties listed on page 192 of your textbook, which would be unbelievably boring but also very easy things usually go hand-in-hand by the way things that are easy are usually boring So I'm not ": [
      2478.2,
      2503.8,
      101
    ],
    "unless you unless you are careful it unless you don't count the swapping. It's about equivalent. So doing the operations take about the same amount of time here as calculating the determinant I using the formula. So you can do one or the other and it's easy to remember this formula. But this is the only case where a formula makes sense to be clear. There is a formula for ": [
      1049.1,
      1071.0,
      43
    ],
    "up? Well, I take the coefficients in front of the X cubes and add them. I take the coffee stands in front of the x squared and add them. Texaco officiants in front of the exes and add them I take the coffee stands in front of the 0 is an atom. That's how I add polynomials by adding up the like degree coefficients. I just want to put here ": [
      2892.9,
      2927.6,
      115
    ],
    "want to compute the inverse I could use this formula. So the determinant determinant debt summons called is equal to 1 * 4 - 2 * 3 - 2 so I have to divided by -2 and then I swap the 4 and the one and I put minus signs in front of the two in the three. Okay, then I actually have to I supposed to do that division. ": [
      923.0,
      952.2,
      38
    ],
    "we already did here but this is just something that you should know. And you can look how it works in the textbook if I take the transpose of a matrix right? Remember that means to start turn it on its side turn the rows into columns. then What if I asked you to find the inverse of a transpose? That's what we're doing here. Well, I I know how ": [
      1569.3,
      1590.9,
      63
    ],
    "we do for more steps of row reduction or we're going to get his the following formula for the inverse of this two-by-two Matrix. So you have to divide through by that determinants buy a D minus PC. And then what happens is that the two diagonal entries they get swapped and the off diagonal entries they get negated. Celestial It's relatively easy to remember if I want to write ": [
      821.1,
      850.1,
      34
    ],
    "we do in this half of this lecture and in tomorrow's lecture several times, you're going to want to watch this podcast again, you going to want to read the textbook several times and do lots of exercises because this is a real shift in thinking from things you've been doing so far. We're moving from concrete to abstract for the first time that you'll ever do that in a ": [
      1685.9,
      1704.9,
      68
    ],
    "we're going to use as few symbols as possible and I'm going to help you interpret them. But you're going to get used to them as we go the part of what we're going to do right now is exactly the same as things we've been doing all along. It's going to look very familiar but strange at the same time. Okay, I'm figuring out how it all fits together. ": [
      1728.5,
      1744.8,
      70
    ],
    "we've done is renamed you want equal to X cubed E2 equal to x squared III equal to x + 84 equal to what? and that's really all abstract Vector spaces are about it's always going to boil down to taking the same thing. We've already done in RN. And renaming the standard basis vectors as something new now. It's a slightly more complicated than that will have language next ": [
      3023.1,
      3053.9,
      119
    ],
    "when you divide you remember that you never divide by zero, but when you multiply in you might end up multiplying by zero. Supposed to be in a there. And so when we do this, we're going to explicitly assume that A and C are not zero because that wouldn't be an allowed Ro operation. Okay, so when I do that, I'm going to get that the first road turns ": [
      621.3,
      644.4,
      26
    ],
    "where that will allow me to avoid doing fractional arithmetic. So the first row operations I'm going to do to get the first coefficients to match that when I subtract I'll get zero without having to divide 2 in pivot. In other words. I want to get a zero where the sea is now when I'm doing row reduction, so the way I would have to do that is to ": [
      570.5,
      593.1,
      24
    ],
    "will work with in this class are more or less of the variety that you've already been working with like RN or things that you've already seen inside our end so you don't need to worry too much about this level of abstraction, but you do need to be aware of it lurking in the background. Okay. So a vector space is a set of objects with colon doctors is ": [
      2200.9,
      2218.5,
      90
    ],
    "you can't have the coefficient of x cubed to be zero or else it would be a degree. I would have to agree to or 1 or 0. So this thing is not a vector space with where you insist at the a not b 0 and there are a million ways to see that we saw that last slide cuz it wasn't closed under addition. But also it's not ": [
      2822.3,
      2840.1,
      112
    ],
    "you what the zero polynomial is. The zero polynomial is going to be the polynomial which is always zero that function which is just wanted to tell you how to add polynomials and how to scale or multiply a polynomial by a real number, but you already know how to do that. What's P + Q X? I know how to add functions. I just add their values right? It's ": [
      2367.7,
      2393.9,
      97
    ],
    "your convenience. Once you're doing this, it's just a you know, 4 by 8 Matrix, you're doing the same row operations. You would do no matter what to get to reduced row Echelon form, but you if you know that a is invertible then what's going to happen is you're going to get the identity Matrix on the right cuz they're the right on the left to the left four ": [
      307.1,
      325.4,
      12
    ]
  },
  "Full Transcript": "Do I listen to a podcast next time we're moving on to section 4.2 some specific examples connecting those two two things. We've already been doing and two quick reminders.  This Friday. You have a Matlab assignment to Matlab assignment 3 is due this coming Friday, February 9th at 11:59 p.m. And also your fourth MyMathLab homework is due a week from today Monday, February 12th at 11:59 p.m. On there is one more thing. I wanted to mention which is that my office hours.  Are shifted this week?  so my office hour  will be  Wednesday and Friday  1 p.m. To 3 p.m. This week's of my usual office hour is Friday at 1 p.m. And I'm going to actually have to ship my Tuesday offer. Absurd Wednesday. I won't be on campus tomorrow. Okay, so that's why my office hours are this week.  All right, so I would like to get started with what we're doing today, but getting started me is reviewing. So here's everything we did last day just as a reminder that we talked about Matrix inverses, which are things that sometimes exist is so if we have a matrix a it's called invertible if it has a two-sided inverse that is if there is a matrix see so if i x c x a I get the identity Matrix and If I multiply 8 * Z, I got the identity Matrix and we saw an example when we started. Where is it possible to hook up one of these to happen, but the other can fail, okay, because matrix multiplication really does not commute in general. So we want it to be a two-sided inverse. We saw that  Having a left inverse a cyst. That's e x a is the identity tells you that solutions to equations x equals b r unique when they exist and having a right inverse cd68 x equals a identity tells you there's always a solution but it might not be unique. So if you wants to have a unique solution if you want to solve ax equals B, 4X equals be over a ax equals a inverse P. You need to have the sea on both sides and then we call it a inverse Ace age of the power of -1. It's only possible if a is square to get that to happen as we saw and that's just because of these equivalent statements down here doesn't mean that every Square Matrix is invertible. That's definitely not true. But every invertible Matrix is square.  And we saw various equivalent conditions to check if a matrix is invertible. It's invertible. If and only if it's reduced row Echelon form is the identity Matrix, which is the same thing as saying that all rows and columns are pivotal, but because it's a square Matrix, you only need to check one of those right if if every row is pivotal that means there is an N by n Matrix that means there are and pivots but there can only be one pivot per column as well to actually all the columns are pivotal to and vice-versa for a square Matrix. Every column pivotal is the same thing as every row pivotal that's not true for rectangular matrices, but it is true for square matrices. So if you got a matrix and you know that it's Square then it's invertible. If and only if it has n pivots a pivot for each row and each column. Okay, that's the same thing as it's reduced row Echelon form being the identity Matrix and then taking that same language and converting it into equivalent Notions that we've been developing.  The same statement tells you that a is invertible. If and only if The Columns of a are linearly independent, all the columns are linearly independent or equivalently the rose have are all pivotal. That means that the columns span all of our end.  And for a square Matrix just because pivotal Rose and pivotal columns go hand-in-hand for square Matrix those two are equivalent again. So for a square matrix, it's rows and columns are linearly independent. If and only if they spend all of our end, yeah, that's not true for rectangular makes these but it is Truth or Square matrices and its equivalent to The Matrix being invertible know all that is to say those are conditions. We can check any one of them to see if the Matrix is invertible if we actually want to find the inverse as we saw last time, what we do is we solve this multi augmented Matrix system of equations would take the Matrix a and we put another Square Matrix to the right of it. Not just a column for the whole identity Matrix to the right of it and then we do row operations on back end by to animatrix.  And we carry it to register Echelon form that whole big augmented Matrix again. The dotted line in the middle. There is just for your convenience. Once you're doing this, it's just a you know, 4 by 8 Matrix, you're doing the same row operations. You would do no matter what to get to reduced row Echelon form, but you if you know that a is invertible then what's going to happen is you're going to get the identity Matrix on the right cuz they're the right on the left to the left four columns in that case are going to be the reduced row Echelon form of a and the thing you're left with on the right is the inverse of a  Now let me comment by the way. Someone posted a good question on Piazza this morning where they did they did this with a matrix that okay. Well, I got that the inverse was equal to and then the inverse was a matrix that had a row of zeros in it.  What happens if you get an inverse that has a row of zeros in it?  You you step away from the desk come back erase and start again because you made a mistake the end of a row of zeros in it. Because if it did it would have to be invertible matrices are invertible. If and only if they have a pivot in every row and every column  But if you get that the inverse isn't invertible. There's no way it could be an inverse in the first place. Why is that we'll get to that in two slides in case you didn't read ahead already because the inverse of a matrix is always invertible and its inverse is the original Matrix to take the reciprocal of 1 over a that just gives you a again but this highlights an important point, which is if I already know that a is invertible then I should do this procedure to find its inverse. But what if I don't know that it's invertible. I need to check that the Matrix is invertible on the way I do that is to see if it has a pivot in every row or every call him.  But that means when row reduction it means doing Road auction on a alone so really should I go ahead and do that row reduction on a alone to see that it's invertible and if it is then start again doing this. No, I don't think so. I think you should always start by assuming that a is invertible not assuming by presuming that a is invertible and then you'll do your first steps the first part of the road auction algorithm until you get this Matrix in row Echelon form and then you'll be able to check. Is it going to give you the identity Matrix in the end? If it isn't if you get a rope zeros for the first part then you stopped with a okay sexy not invertible. If it is that you've already done half the work and you continue that's a little wasteful for the stuff on the right. There's no reason to carry around the stuff on the right if you just checking if it's invertible, but the reality is that  It's a safe bet that any random Matrix is invertible. Okay, if I actually give you a random Matrix, like I choose all the numbers randomly not as integers, but as real numbers if you generate in Excel or in Matlab, if you generate a random Matrix, then it's going to be invertible with probability one you do that and not let go ahead and ask and generate a thousand random 3 by 3 matrices and then ask Matlab to find the inverses of all of them. All 1,000 will be invertible being non invertible is a special property. Now, there's lots of non invertible matrices around but they form a much smaller set of matrices. Okay. So generically matrices Square matrices are invertible.  All right. So this is how you find the inverse of a matrix with row reduction. There is one for a special case that many of you have already seen probably where you don't need to do row reduction because you can remember a formula. So let's talk about that message to buy 2 case how many people know or know of the formula for the inverse of a 2 by 2 Matrix?  Oh not very many of you but a bunch of you ask last day, but that's okay. I want I want you to see it if you haven't already.  So, how are we going to find the inverse of a generic two-by-two Matrix? We're going to use row reduction. So let's do that with a generic two-by-two Matrix ABCD or reduction here. And this is like a nightmare version of all of those questions with an h and right now I have all four parameters unknown here so they could get quite messy and the two by two cases tractable enough that we can actually do it. I'm going to do a trick where that will allow me to avoid doing fractional arithmetic. So the first row operations I'm going to do to get the first coefficients to match that when I subtract I'll get zero without having to divide 2 in pivot. In other words. I want to get a zero where the sea is now when I'm doing row reduction, so the way I would have to do that is to multiply the first row by - c / a  If that's going to give me fractions, so instead what I'm going to do.  Is I'm going to multiply the first row by a story by sea and multiply the second row by a now that's not strictly allowed. Right? I am I'm allowed to divide. I'm not allowed to multiply at the difference between multiplying and dividing is just that when you divide you remember that you never divide by zero, but when you multiply in you might end up multiplying by zero. Supposed to be in a there.  And so when we do this, we're going to explicitly assume that A and C are not zero because that wouldn't be an allowed Ro operation.  Okay, so when I do that, I'm going to get that the first road turns into.  AC DC  and then C 0 and the second Road turns into a c a d 0 a another reason that I did that is when I subtract.  Row 1 from Row 2  I'm going to get that 0 that I wanted to cuz I arranged it so that those two will match so I get a zero there.  And now over here I get a D minus BC.  And I'm subtracting the first one the second so I get a minus C there at eight doesn't change.  Okay. Now that's just the first steps before I go any further. I know. Remember when we're finding the inverse of a matrix. The first thing we're doing is making sure that it makes sense to find the inverse which means we need to check to make sure that the Matrix is invertible. So I need to check that all the rows and columns are pivotal. So we already assumed that A and C are nonzero. So that one 1 entry of the Matrix over there a time. See that's not zero. But what about in the second row? I need to see that the second row of the coefficient Matrix has a pivot in it. That's only true if that coefficient down there that a D minus BC is non-zero.  Okay, so this must be nonzero in order for the Matrix to be invertible.  And that is that number there that number has a special name that she may have heard of and we'll get into in a couple of weeks. That number is called the determinant of the Matrix a  all square matrices have determinants. We'll get to that later for a square matrix. It's pretty easy to compute it. Okay, it's just what you get when you multiply the diagonal entries and subtract from that the product of the Auntie diagonal entries.  Okay. So what we see here is  a is an invertible Matrix if it's two by two if and only if that determinants a D minus BC is non-zero.  If that thing is non-zero then well, I guess we should also technically say and A and C are nonzero, but actually if you backtrack and look at the special cases where where one of the ANC is zero, then you would have done different row operations, but you would have actually been able to do row swaps in order to get it into the same form. So we're at the end of the day. It's going to boil down to just that condition a D minus PC has to be nonzero.  Okay, I did not kiss. If we if we continue with the row reduction algorithm will be able to convert that Matrix to reduced row Echelon form. So the next thing we're going to do is divide through by a D minus BC. I'm going to pay that now we have no choice and then we do for more steps of row reduction or we're going to get his the following formula for the inverse of this two-by-two Matrix. So you have to divide through by that determinants buy a D minus PC.  And then what happens is that the two diagonal entries they get swapped and the off diagonal entries they get negated.  Celestial It's relatively easy to remember if I want to write down the inverse of an arbitrary two-by-two Matrix the way I do it is I take the diagonal entries and I swap them and I put my two signs in front of the Archie diagonal entries and then I divide the whole thing by the determinant by a D minus PC and that's a very, patiently efficient way to compute the inverse here. Let's think about how many steps does it take Ok, well, let's actually do an example here. So we'll ride this went down. So here's a matrix 1 2 3 4  Is it invertible?  I heard some people whispering. Yes, why is it invertible?  Cuz the determinate is not zero, that's a good answer. That's correct. But there are at least at least one other answer that you could give which is also good.  although what  all the rows and columns are pivotal it with a two-by-two matrix. It's easy to check look at the two columns. Are they parallel know you can't multiply the first go and buy something to get the second column. So that means that the columns are linearly independent, which means that they're both pivotal which means that Matrix is invertible one way or another it's an invertible Matrix and stuff. I want to compute the inverse I could use this formula. So the determinant  determinant debt summons called is equal to 1 * 4 - 2 * 3 - 2 so I have to divided by -2 and then I swap the 4 and the one  and I put minus signs in front of the two in the three.  Okay, then I actually have to I supposed to do that division. So that gives me a - to hear - 1/2 here positive one here and positive 3 has there and that's the inverse of a matrix. How many flops die do how many athletic operations? Why did  1 2 3 to calculate the determinant  and then then I had to take that number and divide each of those buy it. So it did form or Flop. So this took 7 flops. That's what it's going to take for any Square Matrix are going to do seven flops unless you count the actual action of moving the the so it could be up to 12 flops. If your computer account has a flop the action of swapping the one in the four and put it in the gating those numbers, but it's it's a small number of flops floating Point operations.  And if we actually did Robert option here how many steps would it take? Well, if you look back at your book and we discuss this a little book bed if you have a an N by n system.  Okay with a single augmented column then the number of floss it takes to take it to Rohit reduced row Echelon form is about one-third and Cubed here. We're actually finding the inverse Matrix. So we have to do that end times except we don't do all the operations end times. We're only we're doing it all in parallel. And if you counted up properly it turns out to be about two-thirds and Cubed. So in this case and is 2 in cubed is eight.  Right. So 2/3 of n cubed.  Is about 6.  Text Lee fewer flops than then here, unless you unless you are careful it unless you don't count the swapping. It's about equivalent. So doing the operations take about the same amount of time here as calculating the determinant I using the formula.  So you can do one or the other and it's easy to remember this formula.  But this is the only case where a formula makes sense to be clear. There is a formula for the inverse of a 10 x 10 matrix as well through a 3/4 by 4 any size you want there is a formula for it if you took math 102 or math 100 the abstract algebra classes after this you would eventually see how it works involves a lot of determinants. So there is a Formula that you can use but for example of a 10 by 10 case I said doing row operations to calculate the inverse take about two-thirds and Cubed flops. So that's about 666 flops, which is a lot for a human computer but 666 flops. Where is the formula that uses determinants to calculate the inverse of a 10 by 10 matrix takes more than a hundred million flops.  Really bad algorithm cuz it's really not a computational useful tool for anything other than 2 by 2 matrices. Okay, but for two by two sure we can use it. How about this Matrix down here one to one? Can we calculate the inverse of that one?  No, we're not.  Because the determinant is zero because the two columns are parallel. I heard both answers and those are both good answers not invertible.  Okay, if you want the determinant is 2-2 there and we will see if you've seen already that this condition for invertibility having the determinant non-zero that is always equivalent will get two determinants for higher size matrices later. And the determinant is zero exactly when the Matrix is not invertible. Okay, but that's not a good copy tationil tool because just calculating that one determinant that's most of the work for a 10 by 10 matrix. It takes more than 15 million flops to calculate the determinant whereas to see if it's invertible using row operations takes less than  Okay, great.  So let's now talk about a few more properties of inverses that you're going to use. You should be aware of their homework. So we already mentioned this one. So if I find the inverse of a matrix, what is its inverse? Is it invertible? Could you take the inverse and find it? It's a non invertible Matrix know you couldn't because this thing is actually a  Okay. Why is that? Well, let's just check. So let's go. Let's let's not let's pretend we don't know that that's true. But let's call this thing see what does it mean that a inverse inverse is see, whatever that is. That means that c x a inverse.  Is the identity Matrix that's what it means on the other side as well as we know these are square matrices. So in that case, it's sufficient to just check it on one side. So let's check in on this side say  so we want to find Cena. Let's solve for C in this equation. How do I solve for C?  Think think of these is real numbers for a moment. If I give you the equation C over a equals 1 solve for C. What do you do?  I heard someone say / a inverse but I want to but that's true. But let's think of it as what it really means which is x a  Okay, so therefore and I want to be very nauseatingly pedantic here. So we make sure we understand all the things we're doing. So if I X a on the right, but I'm not playing the place where it's going to work out. I get CA inverse x a is equal to Identity times a no identity x a is just a matrix does and then over here. I'm going to use the associative array of matrix multiplication to say well if I multiply Co Universe by a that's the same thing as multiplying see by the product of Anderson a  But a inverse times a by definition of a inverse is the identity Matrix.  And therefore I just get see over there.  so  C is equal to a the thing that we didn't know a inverse inverse C is actually equal today. So there we have it. So any invertible Matrix its inverse.  Is its own it's the inverse of its inverse is itself a ever invertible. Matrix is invertible. And the inverse you get back the original Matrix. Here's another important property. What if I take 2 inverse matrices or if I take two invertible matrices is their product invertible.  Well, let's think about this in terms of linear transformations.  Linear transformations of a I can make a multiplication by 8 as a linear transformation. And remember we talked about last day that a is invertible. If and only if the linear transformation is one to one and onto  So an equivalent question here is given two linear Transformations that are both one-to-one and onto if I take their composition, is it one to one and onto?  Well, maybe that doesn't make it any clearer for you. Maybe it makes it less clear, but I want you to think about that as we as we do this because the answer is yes, and if you untwist the definitions of one to one and onto you will see that it must be true that both of those conditions are preserved undertaking compositions.  Okay, but for now we can do the same sort of calculation. We still just above so let's call this thing d.  I'm assuming that it exists even do this calculation, but then we'll see at the end that the calculation shows that it exists that this Matrix is invertible.  So I want to solve for D there somehow was that mean to solve for D? What what is what is the actual statement here? What does it mean that D is a v inverse this means that d x a v  Is the identity.  So I'm going to do the same thing. I did before first. I'm going to use associativity of matrix multiplication and strip off the bee.  I want to solve for D here. So the first thing I'm going to do is move the be over to the other side. So I'll X  by B inverse. I know that b is invertible so I get the inverse there.  but over here  I'm going to use associativity of matrix multiplication again.  And B * B inverse by definition is the identity.  So I got that da is equal to be inverse.  That hasn't fully solved.  4D yet, but now I can repeat the same calculation.  So I multiply on both sides by a and verse.  And on this side, I'll note that that.  Besos by using associativity of matrix multiplication that turns into d x d identity, which is D. I know I have found.  That D is equal to that which is almost what you might have expected, but there's a wrinkle.  I asked you what's the inverse of 8 * b + the answer is B inverse X and verse about real numbers if I ask you? What's the reciprocal of a x b you'll tell me it's one of her baby and it's pressed you say. Oh, well, that's one of her 8 * 104 be the product of the reciprocals and that's true here as well. Except we have to keep in mind we have to always remember that matrix multiplication is not generally commutative. And in fact, if you want to find the inverse of the product AV you have to take the inverse is in the other order always.  If you multiply a inverse x v inverse that resulting thing is not the inverse of a b. It's the inverse of ba which might not be the same as a b.  Okay, so that's a useful property that you'll need to use and remember on your homework for example, and there's one more I want to do down here and I'm not going to do the calculation because it turns out to look exactly like the things we already did here but this is just something that you should know. And you can look how it works in the textbook if I take the transpose of a matrix right? Remember that means to start turn it on its side turn the rows into columns.  then  What if I asked you to find the inverse of a transpose? That's what we're doing here. Well, I I know how to do that. I take the transpose and then I put a transpose next to the identity and I carry it to the reduced row Echelon form get the identity on the left and a inverse transpose on the right or I transport a transpose inverse on the right. But what if I already told you what a inverse was I want a relationship between a transpose inverse and a inverse. So I got to do all that work again, and the answer is actually  The inverse of the transpose is the same as the transpose of the inverse.  Invert taking inverse and taking transpose those operations commute with each other. So if I tell you what the inverse of a transpose is, then I've already told you what the transpose of a and versus and vice-versa facts to have in your back pocket.  All right. I think that's everything that I want to talk about with invertible matrices for now. We will of course be coming back to them over and over it may be working with them on your homework. Okay to cement those things for sure and on your Matlab assignment cuz Matlab, of course since All Night Live does reduction can easily find inverses of matrices.  Now let's move on to chapter for so this is a huge shift and topics right now. It's like we're going to be starting the course again. We're going to be coming back next day already. We've already seen but it's a it's a big shift not just in topic, but also in thought process and I want to preface this by saying you're going to want to review what we do in this half of this lecture and in tomorrow's lecture several times, you're going to want to watch this podcast again, you going to want to read the textbook several times and do lots of exercises because this is a real shift in thinking from things you've been doing so far. We're moving from concrete to abstract for the first time that you'll ever do that in a math class for most of you.  And you're you're all going to get it no problem, but it's going to take a little bit of effort and it's going to take a few passes through before it really sticks. And that's just how it goes. Mathematicians. Love to do things abstractly mathematicians love to use strange symbols. Right? And so you're just going to have to roll with it and we're going to use as few symbols as possible and I'm going to help you interpret them. But you're going to get used to them as we go the part of what we're going to do right now is exactly the same as things we've been doing all along. It's going to look very familiar but strange at the same time. Okay, I'm figuring out how it all fits together. That's your job. That's why it's going to be useful to review over and over what we do here. So want to talk about Vector spaces. I've already used that term many times informally when I talked about the domain and codomain if a linear transformation when I took what are vectors living in RN, I've sometimes referred to RN as the vector space the space where the vectors live.  Can I use that term informally now, we're going to use it. Formally I'm going to give a formal abstract definition of what it means and show you several examples that are some familiar and some not.  So first, I want to be able to still a little informal but tell you the idea of vector space. What is it? It is a collection of objects. And this is the definition like taking calculus you define a function is differentiable. If and you get it certified abstract definition of what that means and then lots of examples of differentiable functions that have calculate the derivative. So I'm giving you an abstract definition. This is what a vector space is it is this kind of object and then it will show lots of examples of things that may not match that definition. A vector space is a set of objects. He will call those objects and vectors.  And what makes it a vector space is that it has two operations defined on it. What does that mean? You have an operation to find on it? So I have this set and the operations are given any two elements of that set, which I'll call you in a v i can produce a new element of that set, which I call U + V.  No, I mean you might be saying come on Camp. I know how to do this. I've done this a thousand times like yeah, you've done it a thousand times in the case of RN, right? So that's a good example RN is a vector space and it's a vector space. Let's do our three here. So if I have two vectors, it's called them.  A-1 B-1 and see one as the components and the next Vector A2 B2 C2. So the objects are lists of three numbers. Okay, and the operation of plus I tell you is defined or I put a colon before the equal sign means I'm defining this to be equal to a 1 + b181 + A2 B1 + B2 and C1 plus seat. That's the definition of the addition. I give you these two objects are real numbers three, and I Define there some to be that thing.  I could have been giving you some weird definition. Like I actually let's make it a 1 * a 2 and just be one and then see 1 ^ C 2-3. I could have given you a different definition but not every definition is good. That definition wouldn't give you a vector space here because they're certain properties that these these operations have to satisfy which will get to on the next line. But for now just want to say we have a set of objects abstract set of objects. And I'm going to Define two operations on it. One of them is Edition, which is some rule which takes two of the objects and produces a third one.  And the second one is called scalar multiplication, which is a rule that takes one of the objects in your set one of these vectors.  Any real number Lambda and calculates their scalar product calculates their Skillet, you know, how do I do the scalar multiplication? I have Lambda and I'm supposed to x one of the vectors.  And I know for RN I know how that's defined. I told you it's defined by scaling all of the entries.  That's the definition of scalar multiplication for the vector space RN.  But the key fact here, is that a vector space could consist of other things kind of back to this? What is a vector so concretely at the beginning we said, we'll just Define vectors to be these things list of real numbers of effects length.  But what's important about that what makes them vectors why we call them vectors and R and a vector space is that it has these two operations you can add them and you can scanner multiply them.  Peyton will see you in a few minutes examples that are not RN not explicitly anyway, or you can do this these operations as well. And it makes sense to a vector space is a set of objects that has two operations addition and scalar multiplication to find on it. Now. It's a little more involved than that, right? You can't just have any operations that you want.  You have to have the operations play nicely together. So V is a vector space means that V is a set.  And already it can't be any old set or rather. You have to have a particular element in it that has special properties because we always have that zero Vector around the zero vector and all our calculations has played a critical role, right? We talked about homogeneous equations with a 0 on the right and then 0 is a solution 0 is the additive identity write 0 + any Vector is 0 so a vector space is a set of objects with a distinguished member. We call the zero vector.  And it has two operations to find Onnit addition and scalar multiplication.  And I have to define those on whatever said in that means that I take any two elements of the vector space and it must return a new element of the vector space one way to say that is that the vector space is closed under addition. Okay, so that some of the two vectors has to be in that same set of objects. Okay, and then all of these things together the vectors together with those operations, they must satisfy all whole blank of properties and I'm not going to write them down here. But if you open your textbooks to page 192, they're all listed there. There's about 15 properties, but they all satisfy you do not have to memorize those properties because you already know those properties those properties say addition and scalar multiplication work the way your intuition tells you they should from all your experience with arithmetic it tells you things like all right a few of them down it tells you things like  U + V is equal to V + UV Edition has to be commutative and that if I add two vectors and then add a third  then I get the same result if I add the second and the third.  With the first in front like that. Okay Edition is supposed to be  Associative and also the scalar multiplication is distributive over addition that if I scale the sum of two vectors, that's the same thing as scaling the vectors and adding them up after work.  These kind of properties. Okay, things like you + 0 or 0 + you is equal to you for every Vector you  Okay, those are the properties or some of the properties that make a vector space a vector space and there's a there's many more. But again they all are in are things that you're familiar with already just have to formalize them as mathematicians. We would call these things axioms. I'm giving you an abstract structure and I'm placing some axioms down but it satisfies and in principle, you're supposed to drive everything you want to know about the set from those axioms in practice. We get used to applying them and we often hide them in the background. So we don't have to do is a formal proof using those axioms every time and in fact, you'll see all the vector spaces will work with in this class are more or less of the variety that you've already been working with like RN or things that you've already seen inside our end so you don't need to worry too much about this level of abstraction, but you do need to be aware of it lurking in the background.  Okay. So a vector space is a set of objects with colon doctors is a distinguished one called the zero Vector. There's an operation Edition the on the vectors. There's no operations scalar multiplication to any veterans Skillet by any real number those operations produce vectors that are back in the same set you started with this Vector space and those operations satisfy all of the properties that Edition scalar multiplication are supposed to satisfy from your intuition from real arithmetic from grad school. That's the the byline here. That's the the moral of the story. So we're going to go with that and now we're going to talk about some examples of vector spaces that are different at least on their surface then ones that we've been working with. All right, so far in this past, we've been working with spaces of vectors which are list of real numbers of some finite height some fix tight. Let's work with a new Vector space. Now that is not of that form at least it's not presented in that form, but it's something you've already seen and worked with  objects of art is human work with I'm going to call it p-block board bold p  and this is the set of all polynomial functions. So I'll just say all polynomials.  in a single variable  That's my set of objects. Okay, it's the set of polynomials like for example.  P of X is X cubed minus 2X  And Q of X is equal to x squared plus 2X + 1. + let's called Z of X is just the polynomial which is 0 constant polynomial. Those are three examples of polynomials.  If you're working with polynomials and remembering from high school, you're probably inclined to look at the second one and say let's factor that that's x + 1 squared. That's true. But let's not do that. Well, maybe I'll do that and I'll cross it out right now.  That's not to say that that's false. That is true. But that's not relevant for us right now because that involves multiplying polynomials and polynomials are things you can multiply together, but we're not going to right now. We're not going to take him up on his things. You can multiply we're going to think of polynomials as vectors.  Can you used to a vector being a list of numbers and we'll see how that serves still make sense in this context, but right now the objects are polynomials and to call them vectors means that I need to have a few things. I need to tell you what the zero polynomial is. The zero polynomial is going to be the polynomial which is always zero that function which is just wanted to tell you how to add polynomials and how to scale or multiply a polynomial by a real number, but you already know how to do that.  What's P + Q X? I know how to add functions. I just add their values right? It's so I'll do X cubed minus 2x plus x squared plus 2X + 1 and now I'll use the properties of addition of real numbers to write this as X cubed.  Plus x squared minus 2x + 2x gives me 0 there plus one. Now. That's a new polynomial. This is in this set. That is a polynomial and so I have given you a definition of addition under which polit the set of polynomials is closed. Similarly. I know how to scale a polynomial  I can take two x p a tax that means two times x cubed minus 2x which means just two x cubed minus 4X and that's still a polynomial.  So these things are closed under addition on the scale of multiplication operations. Similarly if I take p  An ad 02 it's at the zero polynomial it lets let's write that as Z of x.  That's just x cubed minus 2x + 0 which is just X cubed minus 2x which is p so the zero polynomial is the thing that if I add it to another polynomial I get that same polynomial back. Nothing changed. That's just like the zero Vector it is the zero Vector in this Vector space. If I were really going to verify that the set of polynomials is a vector space. What I would need to do is now check that the definitions, you know for addition and scalar multiplication of polynomials satisfy all of those properties listed on page 192 of your textbook, which would be unbelievably boring but also very easy things usually go hand-in-hand by the way things that are easy are usually boring  So I'm not going to make you do it but it is true here. That's that all those properties will hold so the space of polynomials is a vector space can taking it upon him as an atom skill multiplying a polynomial all those operations work the weight Vector operations are supposed to work.  There's a new set P sub equals 3 and this is the set of polynomials.  of degree  3  This P hear that one has degree 3 power. The highest power is 3.  Where is this polynomial Q it has degree 2?  Hey its highest power has degree to.  Soapy so kieu is not in this new set piece piece of equals 3 down here. Where is pee is in this set?  Sop is in here Q is not in here. Okay. So here's the question. So I'll give you this set Pete piece of equals 3.  And I'll Define on it addition scalar multiplication the way it's defined up above for polynomials. I know how to add and multiply polynomials. Does that make this set piece of equals 3 into a vector space. Is it a vector space or not?  So before we answer question, what do we need to do to figure out if it's true?  I'm sorry.  Test all the properties. Okay, great. So we need to check if the addition is.  Commutative associative addition distributes over addition and if we do that going to see that all of those properties Holt.  but  we have to be careful and go back to the very beginning of the definition. We had to have for to be a vector space. It has to be a set.  With an addition and scalar multiplication option and it has to be closed under those operations given two vectors. There's some has to be a vector. So let's for example take  We saw that P.  Is in there.  Let's take a new one. Let's call our of x minus X cubed minus X cubed is a degree 3 polynomial.  And so that one is in the set piece of equals 3.  Now let's add these two up p.m. X + Q of x.  is equal to  x cubed minus 2x plus minus X cubed which is equal to -2X.  -2X is a polynomial. Does it have degrees three?  Now that's a degree 1 polynomial. This is not in this set piece of equals 3.  Oh, yeah, sorry.  Secure our two polynomials P&R they're both in this set the set of polynomials of degree 3, but there's some is not in the set upon Him is a degree 3, that means the set of polynomials of degree 3 is not a vector space. It's not closed under the vector operations.  not a vector space  But we can modify it a little bit.  So let's talk about P sub. Sorry, that's the notation that your textbook uses.  soapy subtree  Is the set of polynomials?  of degree  Less than or equal to 3.  Okay.  And this one is a vector space.  It's so that that thing we did on the last slide where we added a polynomial of degree 3 to another one of degree 3 and we got a new polynomial its degree wasn't three anymore. But his degree was lower than three. You can never get higher degree by adding polynomials together. You could cancel some of the terms and have only a few of the terms left, but those will have a lower degree or else they would have been high degree to start with Okay. So let's actually write out explicitly what this means. We're taking polynomials a polynomial of degree 3 looks like this a x cubed + b x squared + BX + d  Any degree 3 polynomial looks like that where a b c and d are real numbers.  No to be clear here. This is what the set of set P3 is polynomials of degree less than or equal to 3.  If I wanted to describe piece of equals 3 from the last slide in the same terms, I would have exactly the same description.  Except that the important condition would be that a cannot be 0 but you can't have the coefficient of x cubed to be zero or else it would be a degree. I would have to agree to or 1 or 0.  So this thing is not a vector space with where you insist at the a not b 0 and there are a million ways to see that we saw that last slide cuz it wasn't closed under addition. But also it's not closed under scalar multiplication. We need to be able to multiply the polynomial by zero.  Right, but you can't take something in there and * 0 it's not going to be in there anymore.  Take a look at the zero polynomial which has degree zero.  So they set upon a male's of degree less than or equal to 3 is a vector space and it's a vector space under addition and scalar multiplication the way we usually know how to do those operations. So it back let's just let's just do an example. Let's take two of them. That's a a 1 x cubed + B One X squared plus C One X Plus D1. Let's add that to  a 2x cubed + a + b 2 x squared plus C 2x + D2  So, how do I add those up? Well, I take the coefficients in front of the X cubes and add them.  I take the coffee stands in front of the x squared and add them.  Texaco officiants in front of the exes and add them  I take the coffee stands in front of the  0 is an atom. That's how I add polynomials by adding up the like degree coefficients.  I just want to put here supposed for the moment. So this is Mirror Universe. Now look at that are for.  Vectors in R4 look like A-1 B-1 C1 D1 and how do I add two of those A2 B2 C2 and D2?  I add them by adding the like coefficients.  That's exactly copied over from three sides of except with four components instead of 3. I don't want you to compare what we did with polynomials with what we did down here. We did exactly the same thing. Actually all we're doing  Is we're taking the thing we saw before our for a list of four numbers and we're riding them in a different way instead of writing them as a one-time is the standard basis Vector C1 plus ancient necklace. Let's write it that way. So this one is a 1 + a 2 times the standard basis Factory 1 + B1 + B2 Time to Standard next basis Vector E2 plus C1 plus C. Two times the standard I suspect early 3 + 81 + D2 Time to Standard basis Factory for right where you want is the vector 1000 inches of actor 0 1 0 0 and so forth compare.  What we just did.  here  with what we did over here.  All we've done is renamed you want equal to X cubed E2 equal to x squared III equal to x + 84 equal to what?  and that's really all abstract Vector spaces are about it's always going to boil down to  taking the same thing. We've already done in RN.  And renaming the standard basis vectors as something new now. It's a slightly more complicated than that will have language next day to understand exactly how to always do the translation. But as you're going through always remember that the operations are always going to look like the ones we've seen an RN because they're always isomorphic to the ones we've seen so Vector spaces always look like RN for us. So we'll continue with that on one. ",
  "Name": "math18_b00_wi18-02052018-1000",
  "File Name": "lecture_12.flac"
}