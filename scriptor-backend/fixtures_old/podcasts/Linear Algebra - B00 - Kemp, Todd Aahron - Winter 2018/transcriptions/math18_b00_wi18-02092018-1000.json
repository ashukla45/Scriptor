{
  "Blurbs": {
    "1 + X2 V2 Plus xnvn. equal 0 the only way that could have happened is if all of the coefficients the X ends r0 okay, that's what linear dependence means or linear Independence means the only way to get zero as a linear combination is with the trivial. So let's look an example to submit that this is something you've seen before but you might need new language or ": [
      1458.7,
      1488.4,
      53
    ],
    "2 by 2 matrices and he messed it up three times. He didn't get it right until the 4th attempt. Now I found this funny at the time but it's not that surprising because he was not manually multiplying matrices very often. He was working on some other esoteric things and wanted to give a concrete example for the crowd and hadn't practiced. If you don't practice, you might be ": [
      159.3,
      184.5,
      7
    ],
    "4 there's no one in the First Column first row of 0 in the second minus 210. and then x 5 is a -3 in the first row then a 0 then a 2 and a 0 and 1. so that is a perfectly good description of the solution set is the set of all vectors of the form some free variable X that perspective plus some through some other ": [
      490.2,
      519.1,
      20
    ],
    "5 equals 0 so we subtract everything on the other side of me get the X1 is equal to 2 x 2 + x 4. -3 x 5 x 3 + 2 x 4 - 2 x 5 equals 0 so we subtract from the other side when we get the x 3 is equal to -2 x 4 + 2 x 5. So there is no one perfectly good ": [
      438.2,
      465.3,
      18
    ],
    "All right. So that's the notion of basis a basis is a minimal spanning set the linearly independent set of vectors that spans you're given Subspace and for all of our end if you're looking for a basis of RN that connect to a zillion other things that we already know how to check which always boil down to row reduction one way or another we know how to check ": [
      2372.4,
      2392.5,
      86
    ],
    "Do I listen to a podcast? I understand I agree. I often get confused as well when I'm learning new things and new language. And the only thing I can say is you're doing the right things. You're talking on Piazza. You're coming to office hours. Keep it up and you're going to get it. Okay, it's just going to take more grinding. We are going to be moving into ": [
      2.0,
      27.6,
      0
    ],
    "Great know to be clear. They still are a spanning set. They include those two vectors. That we already saw was a spanning set. That was a basis. In fact, and then we threw in a third Vector that was a linear combination of those that's never going to be a basis. If you have a basis already throwing any more vectors in the space is going to kill it ": [
      2876.5,
      2897.4,
      102
    ],
    "I can describe that plane as the span of my arms and my head gets a set of linear combinations of my two arms on my head. But it's also just equal to the span of my two arms. Or just equal to the span of my left arm in my head. Or just equal to the span of my right arm on my head. Okay. So those are three ": [
      1884.9,
      1907.4,
      68
    ],
    "I'll give you some plans for the origin in R3 a basis for that Subspace is a collection of vectors with two properties. They span. The Subspace they said they are at the kind of vectors we can use to describe it as a set that spans it. So if it is the sign of those vectors, but also we don't want to have any extra ones around that we ": [
      1998.1,
      2030.1,
      73
    ],
    "Matlab assignment is due tonight by 11:59 p.m. A scope by then. And please make sure double check that you've uploaded all parts of what you want to upload there have been some uploading mishaps and we want to make sure that everything that you want the greater to see gets uploaded properly and your fourth MyMathLab homework is due on Monday this coming Monday by 11:59 p.m. It covers ": [
      70.1,
      96.8,
      3
    ],
    "Matrix food is a linear transformation is the null-space of that Matrix and the Subspace of the codomain is the column space of Matrix as a reminder of what those things are the no space. Of a is defined to be the solution set of the homogeneous system that a represents so it's the set of X in the domain on this case. It's Matrix is 3 by 5. That ": [
      251.9,
      283.9,
      11
    ],
    "Okay. So here's a question that I want to answer together as a means of testing some of the concepts that we've been discussing for the last few weeks. So we described the no space the last lecture in today, but no spaces to find to be the solution set of the homogeneous system for that Matrix. Why the homogeneous system, let's look at other systems like the ones we've ": [
      930.6,
      956.0,
      36
    ],
    "Subspace in which the set that spans. It is linearly independent. And that is what a basis is. So if I give you a Subspace of some Vector space so you for your intuition purposes right now, it's fine always to think of your big Vector spaces are in and the Subspace is going to be some smaller dimensional Subspace inside their like a plane in R3 something like that. ": [
      1972.9,
      1998.1,
      72
    ],
    "The Columns of a I don't want to write those down. So I'll call them A1 A2 A3 A4 and A5. And by definition the column space is the span of those five calls. That's it. That's so that's easy to write down here at the columns have to take this man is really not much more I can say than that. No, I know what these subspaces are. So ": [
      587.3,
      622.0,
      23
    ],
    "Vector space of all polynomials. So here's the question are these vectors linearly dependent or are they linearly independent? So the question is is there a non-trivial linear combination of these guys that gives the zero polynomial? Yes. Yes, who said? Yes. Would you like to explain why? Okay, you want to give them names? Let's give them names yet V1 V2 V3 and you're telling me that one of ": [
      1512.5,
      1554.8,
      55
    ],
    "X1. Maybe I'll write it like this. The vector x 1 through 10 is not the zero vector. But gives the zero Factor has the same definition as before linear dependence means that there is a linear dependence relation between them. There's some non turn a trivia linear combination of vectors that gives you the zero Vector equivalently since one of those confessions at least is non-zero, you can divide ": [
      1370.5,
      1400.7,
      50
    ],
    "a Subspace in a vector space is the span of some collection of vectors and the null-space of a matrix is always going to have the form the span of some collection of vectors to set up linear combinations of some collection of vectors. So that's one more time goes through that computation that we've already done dozens of times. This is something we've been doing literally since the first ": [
      339.2,
      360.3,
      14
    ],
    "a basis is a linearly independent spending set. So what I need to do is check. are these linearly independent I know when I have two vectors in RN, how do I check if they're linearly independent? I got a lot of people saying row reduction that's good. That's always the best General answer but if there's only two of them it's easy to eyeball, right because for two vectors ": [
      2747.8,
      2778.8,
      98
    ],
    "a basis. If and only if the associated Matrix with those columns is an invertible Matrix great. So that's the basis of RN. What about a basis of a Subspace of our I'm so here here is a Subspace of R3. I've described it up there. It's like the last example we did of a Subspace last time before we got to, space and null space. So here's a Subspace ": [
      2579.6,
      2602.1,
      92
    ],
    "a e3 that says V1 is equal to V 2 + 2 V 3 in other words the 1 - V2 - 2 V 3 equals 0 there is a non-trivial linear combination of those three vectors that gives you all. So those three vectors in the vector space of polynomials are linearly dependent. Yes, yes. You think what's her? They are okay. This is a very good question. So ": [
      1587.8,
      1632.7,
      57
    ],
    "a reiteration of what we said approved on the left side. If you're looking for a basis of RN every bases of RNA has exactly and vectors. Okay, because the Matrix the composed of those columns must be a square Matrix for it to be invertible for it to have a pivot at in every row and every column. And in particular the kind of set of those vectors is ": [
      2558.9,
      2579.6,
      91
    ],
    "and pick off the answer from there and I have asked Matlab to do that for us. Here is the reduced row Echelon form of that Matrix a so from here, we can write down the solution set. The solution set to the equation ax equals 0. Okay. Looks like X 1X 2x 3x 4X 5. Well, we look and see that there are some free variables here. Okay. The ": [
      380.4,
      407.3,
      16
    ],
    "are scalar valued functions that you think about the polynomial which is the function which takes exit maps 2x + 1 sqrt. That's V1. That is not a scalar number. It is a function and it is an abstract Vector in this space in this is a point that is super important that we go over and that we understand because the question you just asked the question on almost ": [
      1659.8,
      1682.4,
      59
    ],
    "are the most famous mathematicians of the 20th and 21st century and I was jet-lagged and exhausted in his lecture was on something extremely sophisticated an esoteric and I was totally lost for the whole lecture until we got about 45 minutes into an hour-long lecture. And he said, okay now let's demonstrate this that he was just doing with an example and the example literally just involves multiplying to ": [
      138.4,
      159.3,
      6
    ],
    "augmented Matrix that has those columns romantic with a column you and I'm solving that system or I'm checking to see if that system is consistent to see if you is in the span of those pictures. So I have to go through a bunch of reproduction again. Well, actually no I don't have to do it that way. That's just reversing the workout he did. what I'm really asking ": [
      673.7,
      695.3,
      26
    ],
    "basis with someone from this side of the road like to explain why it's not a basis. Answers know what someone from the middle of the room like to explain why it's a base. Not a basis. Yes. When you add the first two vectors, you get the third one, correct? That means that those three vectors are linearly dependent right this plus this equals this know they're linearly dependent. ": [
      2848.5,
      2874.7,
      101
    ],
    "be Let's do it over here. It's going to have three components on the first component. is this row X component Lies by that, So let's see if we can can do it real quick here. I got 3 * -3 - 9. + 6 * -2 - 12 What's -1 * -1 + 1? plus something * 200 + -7 * 4 * -28 Right. Now let's add those ": [
      721.6,
      765.6,
      28
    ],
    "been solving. So here's a question the Matrix equation ax equals be so we've got our Matrix a I give you that Matrix give me some Vector B, which is not the zero vector and let's look at the solution set to ax equals B that we know how to find that we find it by row reduction. The question for you. Is is that a Subspace? Hey, is that ": [
      956.0,
      978.3,
      37
    ],
    "being a basis because any more vectors by definition of basis will be a linear combination of the ones you already had their know. How about this third set down here set of two vectors. It doesn't have too many. Is it a basis? No, I heard a lot of people saying no, that's correct. It's not a basis. In fact, it's even worse. This Vector here is not in ": [
      2897.4,
      2920.3,
      103
    ],
    "bit. So let's go ahead and vote how many people think that this thing is a Subspace. Nobody how many people think it's not a Subspace. Most of you how many people don't know what a Subspace is? Nobody raised their hands but I bet Oh, I thought you in one hand was at the back. Thank you for your honesty, sir. Okay, and I bet that answer applied to ": [
      1052.0,
      1075.3,
      39
    ],
    "can stop. That was great. Thank you. Yeah, those two steps of reproduction were enough to get the Matrix to row Echelon form. And once it's in Russia landform, we can tell that every row and every column here is pivotal. So this one is this is an invertible Matrix and the answer is yes, all columns and all rows pivotal. Awesome. Okay. So this down here. This is just ": [
      2524.2,
      2558.9,
      90
    ],
    "column vectors and putting them together in a matrix. If I take the columns of a matrix and I asked does that set of columns span all of RN? What do I need to check in The Matrix? I'm sorry. But every row is pivotal, so if I want a set of vectors in RN to be a spanning set for RN, I need to check that every row is ": [
      2210.4,
      2233.2,
      80
    ],
    "combination of those columns. But it's a linear combination in a unique way is exactly one linear combination of those factors that gives you your given Vector you wanted which again is the restatement of the fact that if you're trying to solve the system ax equals B, if you want there to be a unique solution that Matrix a better have every column pivotal. Otherwise, I'll be free variables. ": [
      2347.1,
      2369.9,
      85
    ],
    "computing proving with the simple computations put it together in the right way. But that thing is a Subspace the key feature here was that if I take two solutions of the homogeneous system and add them up that gives me a solution of the homogeneous system and that's just because matrix multiplication distribute silver edition ax + 80 y is equal to a x x + y example of ": [
      307.0,
      339.2,
      13
    ],
    "continue. Basically, I'm going to start with reminder of what we did at the very end of the last lecture, but was slightly New Perspective so last time. We talked about know what we talked about subspaces in general and then for any particular Matrix, we Define two important subspaces a Subspace of the domain and a Subspace of the codomain. Okay, the Subspace of the domain Associated to that ": [
      226.2,
      251.9,
      10
    ],
    "dependence if you're looking for one between some polynomials the numbers you're looking for have to be just scalar numbers not polynomials. Morale is polynomials are not scale their functions. And those are the abstract pictures of this space. I hope that that clarified things a bit. But if it didn't then go back and do more examples from the book. This is a critical point that we need to ": [
      1751.8,
      1775.0,
      63
    ],
    "different descriptions of That Subspace four of them three of them. I can pick any two of those factors and they will span the same space. So there's no reason to include all three so what was going on there in that example, the three vectors are in the space and they span the space but Any one of those vectors is a linear combination of the other two. So ": [
      1907.4,
      1933.0,
      69
    ],
    "don't need in that description. So we want that the set of those vectors. Is linearly independent? So it's a linearly independent spanning set for the Subspace or if you want to use it so catchy phrasing. It's a minimal spanning set. That is we don't have any extra ones hanging around that weren't really need it. So that's what a basis is. It's a set of vector a basis ": [
      2030.1,
      2065.6,
      74
    ],
    "everybody's mind the first time second time and their time they see that's what those aren't vectors. The other question is wait a minute Xbox one square that's not a linear thing. So how can that be in this course on a linear algebra another very common question, and thought natural thing to think. These are abstract basic objects. The vectors polynomials themselves. Okay, but you're absolutely right that it's ": [
      1682.4,
      1706.0,
      60
    ],
    "everything that we're doing up to today's lecture possible that a little bit of what is on that homework will leak into Monday's lecture. But just in the sense that I might do a few more examples on Monday, all of the concepts will have been covered within this lecture. I do want to say one more quick thing that I heard from some of the TA is that in ": [
      96.8,
      115.3,
      4
    ],
    "for a Subspace is a set of vectors that span the Subspace. But also are linearly independent. So for example And the preeminent example is if your Subspace is is the whole Vector space are and we've been working with since the beginning then the standard basis vectors are a basis. Okay, that's why they're called basis vectors. So those standard basis vectors the ones that have a one in ": [
      2065.6,
      2094.0,
      75
    ],
    "form explicitly. This collection of vectors is the span of those two vectors the two vectors I've written over there. Okay, so for free we got that that set of vectors there is a spanning set of this Subspace. The question is is it a basis? So if I have a spending sat, how do I check if it's a basis? What's the other thing? I need to check? Somebody ": [
      2697.4,
      2721.5,
      96
    ],
    "free variable x 1 0 - 210 + another free variable x - 30201 in other words This is the span of those three vectors. I'll just call those vectors for now. I'll call them. I'll call V1 V2 and V3. Does the three vectors in R5? And what we have just identified. Is that the null space? Of the Matrix a the solution set of the Virginia system is ": [
      519.1,
      556.3,
      21
    ],
    "from this side of the room. You quiet folks over here if I have a spending set by definition. What does it mean for it to be a basis? What was the definition we give to slides ago of a basis a basis is a spanning set. That is. That is linear combinations. Well, that's what Hispanics that means to use the wrong word supposed to be linearly. Independence So ": [
      2721.5,
      2747.8,
      97
    ],
    "getting there. So now I want to talk about generalizing some of the Notions. From RN to General Electric spaces and subspaces. So going back to what we did and week later half of week 2 of this class. We talked about the notion of linear Independence and linear dependence and we talked about that for Colon doctors in RN but the ideas that we develop their had nothing in ": [
      1235.3,
      1262.8,
      46
    ],
    "if I want to test membership if I have a particular vector v there and I want to check to see if he is in the column space of a what I'm asking is is V. in here and the only way to answer that is to do row reduction. I have to take the augmented Matrix with columns a1485 augmented with v through row reduction. So it takes work ": [
      860.9,
      884.0,
      33
    ],
    "if a given set of vectors is a basis for RN. It's so here. This one here. Is this collection of vectors A basis for RN? How do we check? Row reduction pencil, let's do a little bit of production. Shall we? Actually, I was thinking of asking for a volunteer or anyone like to come up here and do the rod Road option for us. Anyone brave enough to ": [
      2392.5,
      2426.2,
      87
    ],
    "in a matrix. And you see if that Matrix is invertible not in particular that tells you something about the size of a basis of RN. Invertible matrices must be square. And that's just because if you want to have every row and every column pivotal that you can't have any more Rose than calling for any more columns and rows. So what we see here is that every basis ": [
      2298.7,
      2323.3,
      83
    ],
    "in it. Right so I could say hey, here's to polynomials x squared + x cubed like it's a well aren't those linearly dependent because X cubed is equal to x times x squared that X is just a number so that gives me that those two are parallel. No, they're not parallel. I didn't * a number I X another polynomial there. Okay, so when you find a linear ": [
      1728.4,
      1751.8,
      62
    ],
    "is linear combination of RN, but they're also linearly independent. Now, these are column vectors and we know how to check if column vectors are linearly independent. How do we check that? row reduction we check it by row reduction. We need to check that the The Matrix with those vectors as columns Is what we need to check. To see that those vectors are linearly independent. What's the what's ": [
      2116.0,
      2150.0,
      77
    ],
    "just as bad at matrix multiplication as alencon Fields medalist. Okay, and I want you to be better than Ellen Kang was that day? I multiply matrices. So even though it's better to leave computations to the computers. You need to know how they work. So you need to be Adept enough at its understand how it works. There's lots of examples in your homework for that night might be ": [
      184.5,
      204.7,
      8
    ],
    "lecture we want to solve this system the system of equation. Who is coefficient Matrix is a? Now that means that if we're going to solve it by writing down the augmented Matrix, we augment the system with zeros in the element in column, but since row operations don't affect those zeros, it's wasteful to even write them down. So we're just going to carry a reduced row Echelon form ": [
      360.3,
      380.4,
      15
    ],
    "linear Independence means that they are parallel that they are not parallel are these two vectors parallel know because if I wanted to get the second as a multiple of the first then looking at the first component that multiple half of you want but One X the first factor is not the second. So these are yes, these are linearly independent and therefore this is a basis. It's a ": [
      2778.8,
      2801.4,
      99
    ],
    "made it look like that three was a fight but it's not sorry about that. So this First Column is a one and that's a -3 there. Thanks for pointing out that that wasn't very clear. So I think what I wrote was right, so I got -48 there and that means that no matter what the other entries are. This is not the zero vector. So that means that ": [
      795.6,
      818.8,
      30
    ],
    "many of you in that. Yeah, you've seen the definition but you really don't understand yet. And that's totally fine. It just means that you need to be reviewing what we're doing in these lectures a few more times. So please do that. This thing is not a Subspace. In fact the answer to all three of these questions is no with someone like to explain to me why one ": [
      1075.3,
      1097.9,
      40
    ],
    "means that the domain is vectors an R5 and it's set of vectors in R5 for which a x x equals 0 that's enough space. Text me actually move that so I have a little room to compute it. So we want to we want to figure out what is the null space for this Matrix. And the point is that that thing which we saw explicitly last day of ": [
      283.9,
      307.0,
      12
    ],
    "no non-trivial linear combination equaling zero. There is no non-trivial. linear combination How does bacteria sequence era we know that there is the trivia linear combination 8.0. You can always take all coefficients equal to 0 and add them up and go get the zero factor for any factors. What linear Independence means is that? That's the only way to get zero here in other words? If you have x1v ": [
      1425.6,
      1458.7,
      52
    ],
    "now let's ask some questions about them. So I've given a couple of vectors up there the vector you which is a vector in the domain the vector in r v and the vector v which is a vector in the rain. I felt sorry in the codomain and we'll see if it's in the in the in the domain when are five. Is it in the null space? How ": [
      622.0,
      648.1,
      24
    ],
    "of RN has n vectors in it. Here's one basis of our at the standard basis, but there are zillions of base's out there. You just take any invertible Matrix its columns form a basis of RN meaning that they expand all of our end and those vectors are linearly independent and what the linear Independence does for you as it says that not only is every Vector a linear ": [
      2323.3,
      2347.1,
      84
    ],
    "of any Vector space. Every Subspace is the span of some particular set of vectors or many many particulars. the question is Is every set of vectors that spans the Subspace just as good as any other? or are there more efficient and less efficient ways to describe it and the answer is well, there are there are maximally efficient ways to describe it which is to say I can ": [
      1827.2,
      1861.1,
      66
    ],
    "of set of vectors I can get which ones I want to throw away any that are linear combinations of the others. Now we have this definition that we've been working with a long time doctors are called linearly dependent if at least one of them is a linear combination of the others. So we want is to rule that out and we want to have a description of a ": [
      1953.0,
      1972.9,
      71
    ],
    "of the questions has the answer no Yes. Okay, so you're saying that x equal 0 is not a solution of x equals B. That's correct. So no zero is not NW because a * 0 is equal to 0 not equal to b b is not zero. The only way the question answer to question one could be us is if p is the zero vector. It turns out ": [
      1097.9,
      1129.4,
      41
    ],
    "of those columns. It's slightly used. There's there's a something slightly better that you can do. Okay, that's being a little inefficient. This is a perfectly good answer that. It's a span of those 5 columns turns out that we don't need all five of those columns though. We're going to get to explain why so this is a perfectly fine answer but it's maybe not the most efficient answer. ": [
      908.5,
      929.3,
      35
    ],
    "of vectors in the space. Okay, so I think we're going to we're going to stop there for today. We will continue next day talking about Bayseas for a few minutes before moving on to the notion of Dimension. Have a great weekend. Make sure you get your Matlab homework completely uploaded in the end on time this evening. Play know the anti-slavery flag on ovary swelling and it's for ": [
      2989.3,
      3231.7,
      107
    ],
    "of vectors of archery. Its a Subspace consisting of vectors of the form a + b a - b into a the first question. Is that even a Subspace? Okay. Well, we could go ahead and check directly from the definition that it's is closed under scalar multiplication and addition and contains the zero vector or we can observe the following fact, which is that if we do our usual ": [
      2602.1,
      2626.9,
      93
    ],
    "one position is there is everywhere else. They do spend all of our in every Vector an RN is a linear combination of those guys. Okay in the sort of court and Court obvious way that the vector X1 X2 X3 Etc is presented as x 1 x e 1 + x 2 * 82 + x 3 x III down the line. So they do Spanish that every Vector ": [
      2094.0,
      2116.0,
      76
    ],
    "particular to do with RN the only required that we lived in a vector space. They only required that we knew how to add and scalar multiply two vectors. So I'm going to write down the definitions again and they're exactly the same definitions as before. It's just that we need to keep in mind that now are vectors might not be column vectors there general doctors in a vector ": [
      1262.8,
      1285.3,
      47
    ],
    "pivotal. So to check that a set of vectors in RN is a spanning set for our annual check to check that the Matrix with those is its Collins has every road pivotal to check that it's linearly independent set. You need to check that every column is pivotal. So in other words If I have some vectors V1 up to the end. That's a bassist. for RN that's going ": [
      2233.2,
      2273.2,
      81
    ],
    "prove that the homogeneous solution set is a Subspace. But in this case, we don't get 0 + 0 we get b + B which is to be which is not speak just like above their 4 x + y is not in w o w is maximally not a Subspace. It doesn't contain zero. It's never closed under scalar multiplication unless this killer is one and it's never closed ": [
      1183.7,
      1208.5,
      44
    ],
    "same as be unless via. Is there a no. Nonzero Vector is twice itself. So that means that 2x is not in W and similarly with Edition that's works exactly the same way if I have two solutions If X and Y are solutions. Then a x x + y is equal to x + a y what just like we saw for the when genius case that's how we ": [
      1156.7,
      1183.7,
      43
    ],
    "second column is non pivotal. As is the fourth column in the fifth column. That means that the variables x 2. X4 and X5 are free variables. The other variables will be expressed as linear combinations of those variables in the solution set and those near combinations are displayed for us right there. The first equation translating says x 1 - 2 x 2 - x 4 + 3 x ": [
      407.3,
      438.2,
      17
    ],
    "second mother will take you be have to be zero. So the only Vector in the Subspace W that has zeros in the second two components must have a zero in the first component to 0 + 0. Is this Vector hear the first standard basis Vector of our three is not in W. So if we go back to the definition hear of a of a basis critical word ": [
      2945.8,
      2968.5,
      105
    ],
    "some more concrete stuff using the language. We've been developing in the next few lectures, but we have to continue with the same sort of ideas that we've been working on for a little while longer. So today we're going to talk a little more about null space and column space just to cement those with another example or two and we'll does all fit into what we do for ": [
      27.6,
      46.7,
      1
    ],
    "sometimes remove some of the vectors that I'm using to describe what spans the space and still get the same Subspace. So for example, if I were to take my favorite example of the plane passing through these two vectors my arms in space here and suppose that I have a serious neck injury in my head is in the plane as well. So I have those three vectors now. ": [
      1861.1,
      1884.9,
      67
    ],
    "sort of decomposition trick and factor out the A's and the bees than this set of vectors can be described as the set of all vectors of the form a x 1 1/2 + B * 1 - 1 1 i-110. Thank you. Did you want to come down here? Maybe you do and you probably do a better job that I'm doing right now. Okay, there we go. Thank ": [
      2626.9,
      2658.0,
      94
    ],
    "space. So if I have a collection of vectors V1 Savion in some Vector space could be the vector space of polynomials could be the vector space of matrices. It could be some Subspace of one of those or some Subspace of RN we call them a linearly dependent if one of them at least one of them. Is a scalar multiple is a linear combination. of the others exactly ": [
      1285.3,
      1324.2,
      48
    ],
    "spanning set and I just checked it. It's okay now, let's look down here. Here is another set of vectors. Is it a basis of w or not? Let's send spend 15 seconds and take about 15 seconds. Okay. Flash about how many people think that is the basis. One confident guy also, maybe too many people think that it's not a basis almost everybody. That's correct. It's not a ": [
      2801.4,
      2848.5,
      100
    ],
    "that Vector in the null space, that's easy to check you just plug and chug you multiply 8 by you and see if they're on the other hand for the column space. I'm asking is the vector v in the column space. So it's easy to write down what the column space is. You just write it done. So it's by definition is the span of those five calls. But ": [
      839.1,
      860.9,
      32
    ],
    "that the answer to all three of the questions is no is W closed under scalar multiplication. Well, let's just check. So if if x is in W, which means that 8 * x equals B Then let's look at 2 x 8 x 2 x is equal to 2 x a x which is equal to X is equal to be that's equal to to be that's not the ": [
      1129.4,
      1156.7,
      42
    ],
    "that you're using Matlab to do all the computations and that's a choice you can make but you're going to have to demonstrate that, you know how to multiply matrices on the midterm for example, so just make sure that you're doing enough of those computations by hand that you can begrudgingly do it when you need to. That's my advice. All right, and with that I would like to ": [
      204.7,
      226.2,
      9
    ],
    "the answer here is no. You is not enough space. That's much easier than doing row reduction. So the moral of the story here is if you want to figure out what the roast what the null space is for Matrix that takes work you have to do row reduction. But if you want to test membership if you have a vector and you on an answer the question, is ": [
      818.8,
      839.1,
      31
    ],
    "the key feature? Every column is pivotal. And if we want to check that that means we need to carry the Matrix to reduced Russia Arturo Echelon form and check that we indeed have a leading entry and every column. Well, this Matrix is already in reduced row Echelon form. It's the identity Matrix. So we have a pivot in every column and therefore those pictures of linearly independent. So ": [
      2150.0,
      2180.8,
      78
    ],
    "the most important ocean. So, how do I describe a Subspace will so far every Subspace that we have encountered was either explicitly given as or could be described as the span of some set of vectors. So that's a nice efficient way to describe some spaces and we will see actually at the end of this lecture or the beginning of next lecture, but that's always true. Every Subspace ": [
      1801.4,
      1827.2,
      65
    ],
    "the question is wait a minute. Those aren't the vectors. Those are just scalars. They aren't scalars. They are scalar valued functions. They are polynomials. So for each fixed X, those are just three numbers. So for each fix tax, those three numbers are linearly dependent because they're one-by-one vectors and one by one of actors that can be at most one linearly independent one, but those aren't scalars. Those ": [
      1632.7,
      1659.8,
      58
    ],
    "the rest of the lecture. And then we're moving on to section 4.3 linear Independence and bases of subspaces. And on Monday, we will continue a section of 4.5 and 4.6 on Dimension and rank. We've already used the word Dimension informally Lots in this room. And on Monday, we will finally be able to explicitly say what we mean by it. A few bits of administered via your third ": [
      46.7,
      70.1,
      2
    ],
    "the same definition as before linear dependence means that one of them is in the span of the others. And we saw and the same proof we gave in that lecture. We saw the that can be stated equivalently as there is a non-trivial linear combination of them equaling $0 to say there are X1 X2. oops up to xn nonzero coefficients that is not always a real corporations. So ": [
      1324.2,
      1370.5,
      49
    ],
    "the span of those three vectors. That's what I wrote auction algorithm does for us it produces a set of vectors. That span the null space. All right now. I have some questions that I want to ask you before we answer questions. Let's let's talk about the column space as well. So remember that the column space. In the column space is equal to by definition the span of ": [
      556.3,
      587.3,
      22
    ],
    "there is you and the null-space of a that's asking. Is a times you equal to zero? And that is an easy thing to answer by direct computation. I just take the Matrix a and I X the column you and I don't want to go to that computation right now, but we can we can do the first entry of that. Okay, so anytime is you is going to ": [
      695.3,
      721.6,
      27
    ],
    "there that I want to highlight with this example is vectors in H. Vectors to form a basis they have to be in the Subspace to start with doesn't even make sense to ask if a vector that's not in the Subspace can be in a spanning set for it because it will take you outside the Subspace. So this one is not a basis. It's not even a set ": [
      2968.5,
      2989.3,
      106
    ],
    "there was no reason to included in a description of the space as banned by such and such factors because it was already in the span of the other two. So that means if you want to be more efficient, what we want is to say, you know, if I'm looking for a set of vectors that spans a certain Subspace like a plain. I want the most efficient size ": [
      1933.0,
      1953.0,
      70
    ],
    "thing a Subspace a question? We need to if it if the answer is yes, it must be the answer to all three of these questions is yes, so I'm going to give you one minute to Talk Amongst yourselves and see if you can figure out whether you think this thing is a Subspace or not. Go ahead. talk talk All right, I hear the talking dying down a ": [
      978.3,
      1052.0,
      38
    ],
    "those things to themselves to playing the anti-slavery flag for every climb and the slave. To the comedian flashing farm-raised disposal is not peaceful. sandiego.edu ": [
      3231.7,
      3311.4,
      108
    ],
    "through by it and isolate that variable at one of the vectors is going to be a linear combination of the others. I'm so then we have the negative of this property as well. We call vectors those vectors in this Vector space linearly independent if they are not linearly dependent and then just reversing the second definition taking the negation of the second definition. That means that there is ": [
      1400.7,
      1425.6,
      51
    ],
    "to happen. If and only if the Matrix. Whose columns are those vectors has every row and every column pivotal? In terms of what we did last week. What does that say about the Matrix? It says that it's invertible. So that's another way to check here. So if you want to see if your column vectors are given an RN or a basis for RN you put them together ": [
      2273.2,
      2298.7,
      82
    ],
    "to test membership. If that's the moral Sol testing membership in the know space is easy, but describing it is hard describing the column space is easy, but testing membership in it is hard. Describing the column space is as easy as it can get it's just a matter of copying what was above right? There's The Columns of a just copy them down and say hey, it's the span ": [
      884.0,
      908.5,
      34
    ],
    "try anyone dumb enough to try. I see some people trying to volunteer their their friends. So I think that means that you just volunteered. Yeah. Next time you'll think twice before trying to get your head friend to raise his hand. Okay, why don't you take us through the rubber ducks in here? You don't have to right here. I'll hold this right? You don't have to write the ": [
      2426.2,
      2455.6,
      88
    ],
    "under addition ever. Okay, great. So the homogeneous solution set is really special and one way we can talk about it being special is that it's a Subspace that it's the only solution set of any system of equations. That is a Subspace. Great. No, I would like to move on to section 4.3. So now I understand no spaces and column spaces and subspaces and general little better. We're ": [
      1208.5,
      1235.3,
      45
    ],
    "understand. In the calculus of critical point. This is an important point that we need to understand. Okay, so that's linear dependence and linear Independence in an abstract Vector space now. I want to talk about. Efficiently describing subspaces, if that's the byline that I'm giving here for this new notion. We're going to introduce now, which is one of the most important oceans and all of linear algebra. Probably ": [
      1775.0,
      1801.4,
      64
    ],
    "up. -9 - 12 is -21 + 1 is -20 - 28 is -48 no, I don't need to go any further to answer this question. Whatever this Vector eight times. Did I make a mistake? It looks like I did. Yeah, what did I write - 900? No. No, it shouldn't. Yeah, but I understand why you said that I underline the vector a and that underlined of it ": [
      765.6,
      795.6,
      29
    ],
    "w. Okay, and we can check that. I mean the way we would check that of course is row reduction usually but we can actually just see look the third component of any vector. The Subspace W that's equal to 2 a so if to a has-been equal 0 that means a has to be zero, but the second component is a minus B. So they is 0 that will ": [
      2920.3,
      2945.8,
      104
    ],
    "way to write down the solution satin sort of parametric form and then we know that it's probably easier to understand what that says if we factor out the free variables. So that says let's back. Everything that x 2 x gives me a two and a one there's no x2 in the third component or the 4th or the 5th. Okay. Now that's factor out the free variable x ": [
      465.3,
      490.2,
      19
    ],
    "we have a linearly independent standing set therefore it forms the basis for RN I'm thinking of all sorts of other words and descriptions that we've learned are connected. So here if we're talking about a basis for RN. Okay, then we need to have a set of vectors that spans are in and that also is linearly independent. Now, I can check both of those things by taking the ": [
      2180.8,
      2210.4,
      79
    ],
    "would we answer that question? Row reduction. Okay, that's a perfectly good answer. So what that means is what I'm asking is is the vector up there you in the Subspace the null-space of a which I can describe it described him perfectly as the span of those three vectors. So if I'm going to ask answer that question in general, what I typically do is I take the new ": [
      648.1,
      673.7,
      25
    ],
    "yesterday's sections. Some of you guys were doing Matrix inverse, which is a great thing to have you right now and in the process, it seems like Many of you were pretty Rusty on even how to multiply matrices. So I wanted to tell you a short anecdote about that. The first time that I went to Paris in 2004, I attended a lecture of the fields medalist alencon, what ": [
      115.3,
      138.4,
      5
    ],
    "you don't have to write the operations. Just so tell us what's the first thing you're going to do. I'm going to double the first row and then added to the third row perfect. rewrite at first okay right now, what's the next step? I'll add together those the bottom of the bottom to thank you. So that'll be like a102. I mean, so we were another okay so you ": [
      2455.6,
      2524.2,
      89
    ],
    "you might need a new level of abstraction to applied in cases where the vectors are not calling back anymore. So for example, here are three polynomials. X + 1 squared x squared + x + 1/2 of the three polynomials in the vector space of polynomials. They're also in the vector space P2 of polynomials of degree less than or equal to 2 as a Subspace of the big ": [
      1488.4,
      1512.5,
      54
    ],
    "you need to be careful. And think about these things not as numbers when you just plug in some value of x and in particular, it's really important that when you find If you're trying to see that these things are linearly linearly independent you want to find a linear combination of them that gives hero that linear combination has to have just numbers and it can't have an X ": [
      1706.0,
      1728.4,
      61
    ],
    "you one- V to Y -1 x V2 -2 V 3 equals 0 that's cracked. Let's just work that out if I take x + 1 squared. I can I know how to how to expand out polynomials that's x squared plus 2X + 1. And that is x squared + 2 * x + 1/2. And look what that says. I've got here the one. Hear V2 and hear ": [
      1554.8,
      1587.8,
      56
    ],
    "you. I think that's correct. Maybe you really should come down here. so I have a so 80 x 1 1/2 and B * 1 - 1 0 I am pretty sure that's right. Okay, great. Thank you. I totally did all those mistakes just to show you your pedagogically that no, I really screwed up. Sorry about that. That's correct. Okay, so it's a set of vectors of that ": [
      2658.0,
      2697.4,
      95
    ]
  },
  "Full Transcript": "Do I listen to a podcast? I understand I agree. I often get confused as well when I'm learning new things and new language. And the only thing I can say is you're doing the right things. You're talking on Piazza. You're coming to office hours. Keep it up and you're going to get it. Okay, it's just going to take more grinding.  We are going to be moving into some more concrete stuff using the language. We've been developing in the next few lectures, but we have to continue with the same sort of ideas that we've been working on for a little while longer. So today we're going to talk a little more about null space and column space just to cement those with another example or two and we'll does all fit into what we do for the rest of the lecture. And then we're moving on to section 4.3 linear Independence and bases of subspaces. And on Monday, we will continue a section of 4.5 and 4.6 on Dimension and rank. We've already used the word Dimension informally Lots in this room. And on Monday, we will finally be able to explicitly say what we mean by it.  A few bits of administered via your third Matlab assignment is due tonight by 11:59 p.m. A scope by then. And please make sure double check that you've uploaded all parts of what you want to upload there have been some uploading mishaps and we want to make sure that everything that you want the greater to see gets uploaded properly and your fourth MyMathLab homework is due on Monday this coming Monday by 11:59 p.m. It covers everything that we're doing up to today's lecture possible that a little bit of what is on that homework will leak into Monday's lecture. But just in the sense that I might do a few more examples on Monday, all of the concepts will have been covered within this lecture. I do want to say one more quick thing that I heard from some of the TA is that in yesterday's sections. Some of you guys were doing Matrix inverse, which is a great thing to have you right now and in the process, it seems like  Many of you were pretty Rusty on even how to multiply matrices. So I wanted to tell you a short anecdote about that. The first time that I went to Paris in 2004, I attended a lecture of the fields medalist alencon, what are the most famous mathematicians of the 20th and 21st century and I was jet-lagged and exhausted in his lecture was on something extremely sophisticated an esoteric and I was totally lost for the whole lecture until we got about 45 minutes into an hour-long lecture. And he said, okay now let's demonstrate this that he was just doing with an example and the example literally just involves multiplying to 2 by 2 matrices and he messed it up three times. He didn't get it right until the 4th attempt.  Now I found this funny at the time but it's not that surprising because he was not manually multiplying matrices very often. He was working on some other esoteric things and wanted to give a concrete example for the crowd and hadn't practiced.  If you don't practice, you might be just as bad at matrix multiplication as alencon Fields medalist. Okay, and I want you to be better than Ellen Kang was that day? I multiply matrices. So even though it's better to leave computations to the computers. You need to know how they work. So you need to be Adept enough at its understand how it works. There's lots of examples in your homework for that night might be that you're using Matlab to do all the computations and that's a choice you can make but you're going to have to demonstrate that, you know how to multiply matrices on the midterm for example, so just make sure that you're doing enough of those computations by hand that you can begrudgingly do it when you need to. That's my advice.  All right, and with that I would like to continue. Basically, I'm going to start with reminder of what we did at the very end of the last lecture, but was slightly New Perspective so last time.  We talked about know what we talked about subspaces in general and then for any particular Matrix, we Define two important subspaces a Subspace of the domain and a Subspace of the codomain. Okay, the Subspace of the domain Associated to that Matrix food is a linear transformation is the null-space of that Matrix and the Subspace of the codomain is the column space of Matrix as a reminder of what those things are the no space.  Of a is defined to be the solution set of the homogeneous system that a represents so it's the set of X in the domain on this case.  It's Matrix is 3 by 5. That means that the domain is vectors an R5 and it's set of vectors in R5 for which a x x equals 0 that's enough space.  Text me actually move that so I have a little room to compute it. So we want to we want to figure out what is the null space for this Matrix.  And the point is that that thing which we saw explicitly last day of computing proving with the simple computations put it together in the right way. But that thing is a Subspace the key feature here was that if I take two solutions of the homogeneous system and add them up that gives me a solution of the homogeneous system and that's just because matrix multiplication distribute silver edition ax + 80 y is equal to a x x + y example of a Subspace in a vector space is the span of some collection of vectors and the null-space of a matrix is always going to have the form the span of some collection of vectors to set up linear combinations of some collection of vectors. So that's one more time goes through that computation that we've already done dozens of times. This is something we've been doing literally since the first lecture we want to solve this system the system of equation.  Who is coefficient Matrix is a?  Now that means that if we're going to solve it by writing down the augmented Matrix, we augment the system with zeros in the element in column, but since row operations don't affect those zeros, it's wasteful to even write them down. So we're just going to carry a reduced row Echelon form and pick off the answer from there and I have asked Matlab to do that for us. Here is the reduced row Echelon form of that Matrix a so from here, we can write down the solution set.  The solution set to the equation ax equals 0. Okay. Looks like X 1X 2x 3x 4X 5. Well, we look and see that there are some free variables here. Okay. The second column is non pivotal.  As is the fourth column in the fifth column. That means that the variables x 2.  X4 and X5 are free variables. The other variables will be expressed as linear combinations of those variables in the solution set and those near combinations are displayed for us right there. The first equation translating says x 1 - 2 x 2 - x 4 + 3 x 5 equals 0 so we subtract everything on the other side of me get the X1 is equal to 2 x 2 + x 4.  -3 x 5 x 3 + 2 x 4 - 2 x 5 equals 0 so we subtract from the other side when we get the x 3 is equal to -2 x 4 + 2 x 5.  So there is no one perfectly good way to write down the solution satin sort of parametric form and then we know that it's probably easier to understand what that says if we factor out the free variables.  So that says let's back. Everything that x 2 x gives me a two and a one there's no x2 in the third component or the 4th or the 5th.  Okay. Now that's factor out the free variable x 4 there's no one in the First Column first row of 0 in the second minus 210.  and then x 5  is a -3 in the first row then a 0 then a 2 and a 0 and 1.  so that is a perfectly good description of the solution set is the set of all vectors of the form some free variable X that perspective plus some through some other free variable x 1 0 - 210 + another free variable x - 30201 in other words  This is the span of those three vectors. I'll just call those vectors for now. I'll call them.  I'll call V1 V2 and V3. Does the three vectors in R5?  And what we have just identified.  Is that the null space?  Of the Matrix a the solution set of the Virginia system is the span of those three vectors. That's what I wrote auction algorithm does for us it produces a set of vectors.  That span the null space.  All right now.  I have some questions that I want to ask you before we answer questions. Let's let's talk about the column space as well. So remember that the column space.  In the column space is equal to by definition the span of The Columns of a I don't want to write those down. So I'll call them A1 A2 A3 A4 and A5.  And by definition the column space is the span of those five calls.  That's it. That's so that's easy to write down here at the columns have to take this man is really not much more I can say than that.  No, I know what these subspaces are. So now let's ask some questions about them. So I've given a couple of vectors up there the vector you which is a vector in the domain the vector in r v and the vector v which is a vector in the rain. I felt sorry in the codomain and we'll see if it's in the in the in the domain when are five. Is it in the null space?  How would we answer that question?  Row reduction. Okay, that's a perfectly good answer. So what that means is what I'm asking is is the vector up there you in the Subspace the null-space of a which I can describe it described him perfectly as the span of those three vectors. So if I'm going to ask answer that question in general, what I typically do is I take the new augmented Matrix that has those columns romantic with a column you and I'm solving that system or I'm checking to see if that system is consistent to see if you is in the span of those pictures. So I have to go through a bunch of reproduction again. Well, actually no I don't have to do it that way. That's just reversing the workout he did.  what I'm really asking there is you and the null-space of a  that's asking.  Is a times you equal to zero?  And that is an easy thing to answer by direct computation. I just take the Matrix a and I X the column you  and I don't want to go to that computation right now, but we can we can do the first entry of that. Okay, so anytime is you is going to be  Let's do it over here.  It's going to have three components on the first component.  is  this row X component Lies by that, So let's see if we can can do it real quick here.  I got 3 * -3 - 9.  + 6 * -2 - 12  What's -1 * -1 + 1?  plus something * 200 + -7 * 4 * -28  Right. Now let's add those up. -9 - 12 is -21 + 1 is -20 - 28 is  -48  no, I don't need to go any further to answer this question. Whatever this Vector eight times. Did I make a mistake? It looks like I did.  Yeah, what did I write - 900? No. No, it shouldn't. Yeah, but I understand why you said that I underline the vector a and that underlined of it made it look like that three was a fight but it's not sorry about that. So this First Column is a one and that's a -3 there. Thanks for pointing out that that wasn't very clear. So I think what I wrote was right, so I got -48 there and that means that no matter what the other entries are. This is not the zero vector.  So that means that the answer here is no.  You is not enough space. That's much easier than doing row reduction. So the moral of the story here is if you want to figure out what the roast what the null space is for Matrix that takes work you have to do row reduction. But if you want to test membership if you have a vector and you on an answer the question, is that Vector in the null space, that's easy to check you just plug and chug you multiply 8 by you and see if they're on the other hand for the column space. I'm asking is the vector v in the column space. So it's easy to write down what the column space is. You just write it done. So it's by definition is the span of those five calls.  But if I want to test membership if I have a particular vector v there and I want to check to see if he is in the column space of a what I'm asking is is V.  in here  and the only way to answer that is to do row reduction. I have to take the augmented Matrix with columns a1485 augmented with v through row reduction. So it takes work to test membership.  If that's the moral Sol testing membership in the know space is easy, but describing it is hard describing the column space is easy, but testing membership in it is hard.  Describing the column space is as easy as it can get it's just a matter of copying what was above right? There's The Columns of a just copy them down and say hey, it's the span of those columns. It's slightly used. There's there's a something slightly better that you can do. Okay, that's being a little inefficient. This is a perfectly good answer that. It's a span of those 5 columns turns out that we don't need all five of those columns though. We're going to get to explain why so this is a perfectly fine answer but it's maybe not the most efficient answer.  Okay. So here's a question that I want to answer together as a means of testing some of the concepts that we've been discussing for the last few weeks.  So we described the no space the last lecture in today, but no spaces to find to be the solution set of the homogeneous system for that Matrix.  Why the homogeneous system, let's look at other systems like the ones we've been solving. So here's a question the Matrix equation ax equals be so we've got our Matrix a I give you that Matrix give me some Vector B, which is not the zero vector and let's look at the solution set to ax equals B that we know how to find that we find it by row reduction. The question for you. Is is that a Subspace?  Hey, is that thing a Subspace a question? We need to if it if the answer is yes, it must be the answer to all three of these questions is yes, so I'm going to give you one minute to Talk Amongst yourselves and see if you can figure out whether you think this thing is a Subspace or not. Go ahead.  talk talk  All right, I hear the talking dying down a bit. So let's go ahead and vote how many people think that this thing is a Subspace.  Nobody how many people think it's not a Subspace.  Most of you how many people don't know what a Subspace is?  Nobody raised their hands but I bet Oh, I thought you in one hand was at the back. Thank you for your honesty, sir. Okay, and I bet that answer applied to many of you in that. Yeah, you've seen the definition but you really don't understand yet. And that's totally fine. It just means that you need to be reviewing what we're doing in these lectures a few more times. So please do that. This thing is not a Subspace. In fact the answer to all three of these questions is no with someone like to explain to me why one of the questions has the answer no  Yes.  Okay, so you're saying that x equal 0 is not a solution of x equals B. That's correct. So no zero is not NW because a * 0 is equal to 0 not equal to b b is not zero. The only way the question answer to question one could be us is if p is the zero vector.  It turns out that the answer to all three of the questions is no is W closed under scalar multiplication. Well, let's just check. So if if x is in W, which means that  8 * x equals B  Then let's look at 2 x 8 x 2 x is equal to 2 x a x which is equal to X is equal to be that's equal to to be that's not the same as be unless via. Is there a no. Nonzero Vector is twice itself.  So that means that 2x is not in W and similarly with Edition that's works exactly the same way if I have two solutions If X and Y are solutions.  Then a x x + y is equal to x + a y what just like we saw for the when genius case that's how we prove that the homogeneous solution set is a Subspace. But in this case, we don't get 0 + 0 we get b + B which is to be  which is not speak just like above their 4 x + y is not in w o w is maximally not a Subspace. It doesn't contain zero. It's never closed under scalar multiplication unless this killer is one and it's never closed under addition ever.  Okay, great. So the homogeneous solution set is really special and one way we can talk about it being special is that it's a Subspace that it's the only solution set of any system of equations. That is a Subspace.  Great.  No, I would like to move on to section 4.3. So now I understand no spaces and column spaces and subspaces and general little better. We're getting there. So now I want to talk about generalizing some of the Notions.  From RN to General Electric spaces and subspaces. So going back to what we did and week later half of week 2 of this class. We talked about the notion of linear Independence and linear dependence and we talked about that for  Colon doctors in RN but the ideas that we develop their had nothing in particular to do with RN the only required that we lived in a vector space. They only required that we knew how to add and scalar multiply two vectors. So I'm going to write down the definitions again and they're exactly the same definitions as before. It's just that we need to keep in mind that now are vectors might not be column vectors there general doctors in a vector space. So if I have a collection of vectors V1 Savion in some Vector space could be the vector space of polynomials could be the vector space of matrices. It could be some Subspace of one of those or some Subspace of RN  we call them a linearly dependent if  one of them at least one of them.  Is a scalar multiple is a linear combination.  of the others  exactly the same definition as before linear dependence means that one of them is in the span of the others.  And we saw and the same proof we gave in that lecture. We saw the that can be stated equivalently as  there is  a non-trivial  linear combination  of them  equaling $0 to say there are X1 X2.  oops  up to xn  nonzero coefficients  that is not always a real corporations. So X1. Maybe I'll write it like this.  The vector x 1 through 10 is not the zero vector.  But gives the zero Factor has the same definition as before linear dependence means that there is a linear dependence relation between them. There's some non turn a trivia linear combination of vectors that gives you the zero Vector equivalently since one of those confessions at least is non-zero, you can divide through by it and isolate that variable at one of the vectors is going to be a linear combination of the others.  I'm so then we have the negative of this property as well. We call vectors those vectors in this Vector space linearly independent if they are not linearly dependent and then just reversing the second definition taking the negation of the second definition. That means that there is no non-trivial linear combination equaling zero.  There is no non-trivial.  linear combination  How does bacteria sequence era we know that there is the trivia linear combination 8.0. You can always take all coefficients equal to 0 and add them up and go get the zero factor for any factors.  What linear Independence means is that? That's the only way to get zero here in other words?  If you have x1v 1 + X2 V2 Plus xnvn.  equal 0 the only way that could have happened is if all of the coefficients the X ends  r0  okay, that's what linear dependence means or linear Independence means the only way to get zero as a linear combination is with the trivial.  So let's look an example to submit that this is something you've seen before but you might need new language or you might need a new level of abstraction to applied in cases where the vectors are not calling back anymore. So for example, here are three polynomials.  X + 1 squared x squared + x + 1/2 of the three polynomials in the vector space of polynomials. They're also in the vector space P2 of polynomials of degree less than or equal to 2 as a Subspace of the big Vector space of all polynomials. So here's the question are these vectors linearly dependent or are they linearly independent?  So the question is is there a non-trivial linear combination of these guys that gives the zero polynomial? Yes. Yes, who said? Yes.  Would you like to explain why?  Okay, you want to give them names? Let's give them names yet V1 V2 V3 and you're telling me that one of you one- V to Y -1 x V2  -2 V 3 equals 0 that's cracked. Let's just work that out if I take x + 1 squared.  I can I know how to how to expand out polynomials that's x squared plus 2X + 1.  And that is x squared + 2 * x + 1/2.  And look what that says. I've got here the one.  Hear V2 and hear a e3 that says V1 is equal to V 2 + 2 V 3 in other words the 1 - V2 - 2 V 3 equals 0 there is a non-trivial linear combination of those three vectors that gives you all. So those three vectors in the vector space of polynomials are linearly dependent.  Yes, yes.  You think what's her?  They are okay. This is a very good question. So the question is wait a minute. Those aren't the vectors. Those are just scalars.  They aren't scalars. They are scalar valued functions. They are polynomials. So for each fixed X, those are just three numbers. So for each fix tax, those three numbers are linearly dependent because they're one-by-one vectors and one by one of actors that can be at most one linearly independent one, but those aren't scalars. Those are scalar valued functions that you think about the polynomial which is the function which takes exit maps 2x + 1 sqrt. That's V1. That is not a scalar number. It is a function and it is an abstract Vector in this space in this is a point that is super important that we go over and that we understand because the question you just asked the question on almost everybody's mind the first time second time and their time they see that's what those aren't vectors. The other question is wait a minute Xbox one square that's not a linear thing. So how can that be in this course on a linear algebra another very common question, and thought natural thing to think.  These are abstract basic objects. The vectors polynomials themselves. Okay, but you're absolutely right that it's you need to be careful.  And think about these things not as numbers when you just plug in some value of x and in particular, it's really important that when you find If you're trying to see that these things are linearly linearly independent you want to find a linear combination of them that gives hero that linear combination has to have just numbers and it can't have an X in it.  Right so I could say hey, here's to polynomials x squared + x cubed like it's a well aren't those linearly dependent because X cubed is equal to x times x squared that X is just a number so that gives me that those two are parallel. No, they're not parallel. I didn't * a number I X another polynomial there.  Okay, so when you find a linear dependence if you're looking for one between some polynomials the numbers you're looking for have to be just scalar numbers not polynomials. Morale is polynomials are not scale their functions. And those are the abstract pictures of this space.  I hope that that clarified things a bit. But if it didn't then go back and do more examples from the book. This is a critical point that we need to understand. In the calculus of critical point. This is an important point that we need to understand.  Okay, so that's linear dependence and linear Independence in an abstract Vector space now.  I want to talk about.  Efficiently describing subspaces, if that's the byline that I'm giving here for this new notion. We're going to introduce now, which is one of the most important oceans and all of linear algebra. Probably the most important ocean.  So, how do I describe a Subspace will so far every Subspace that we have encountered was either explicitly given as or could be described as the span of some set of vectors. So that's a nice efficient way to describe some spaces and we will see actually at the end of this lecture or the beginning of next lecture, but that's always true. Every Subspace of any Vector space. Every Subspace is the span of some particular set of vectors or many many particulars.  the question is  Is every set of vectors that spans the Subspace just as good as any other?  or are there more efficient and less efficient ways to describe it and the answer is well, there are there are maximally efficient ways to describe it which is to say  I can sometimes remove some of the vectors that I'm using to describe what spans the space and still get the same Subspace. So for example, if I were to take my favorite example of the plane passing through these two vectors my arms in space here and suppose that I have a serious neck injury in my head is in the plane as well.  So I have those three vectors now. I can describe that plane as the span of my arms and my head gets a set of linear combinations of my two arms on my head.  But it's also just equal to the span of my two arms.  Or just equal to the span of my left arm in my head.  Or just equal to the span of my right arm on my head. Okay. So those are three different descriptions of That Subspace four of them three of them. I can pick any two of those factors and they will span the same space. So there's no reason to include all three  so what was going on there in that example, the three vectors are in the space and they span the space but  Any one of those vectors is a linear combination of the other two.  So there was no reason to included in a description of the space as banned by such and such factors because it was already in the span of the other two.  So that means if you want to be more efficient, what we want is to say, you know, if I'm looking for a set of vectors that spans a certain Subspace like a plain. I want the most efficient size of set of vectors I can get which ones I want to throw away any that are linear combinations of the others.  Now we have this definition that we've been working with a long time doctors are called linearly dependent if at least one of them is a linear combination of the others. So we want is to rule that out and we want to have a description of a Subspace in which the set that spans. It is linearly independent.  And that is what a basis is. So if I give you a Subspace of some Vector space so you for your intuition purposes right now, it's fine always to think of your big Vector spaces are in and the Subspace is going to be some smaller dimensional Subspace inside their like a plane in R3 something like that. I'll give you some plans for the origin in R3 a basis for that Subspace is a collection of vectors with two properties.  They span.  The Subspace they said they are at the kind of vectors we can use to describe it as a set that spans it. So if it is the sign of those vectors, but also we don't want to have any extra ones around that we don't need in that description. So we want that the set of those vectors.  Is linearly independent?  So it's a linearly independent spanning set for the Subspace or if you want to use it so catchy phrasing. It's a minimal spanning set. That is we don't have any extra ones hanging around that weren't really need it.  So that's what a basis is. It's a set of vector a basis for a Subspace is a set of vectors that span the Subspace.  But also are linearly independent. So for example  And the preeminent example is if your Subspace is is the whole Vector space are and we've been working with since the beginning then the standard basis vectors are a basis.  Okay, that's why they're called basis vectors.  So those standard basis vectors the ones that have a one in one position is there is everywhere else. They do spend all of our in every Vector an RN is a linear combination of those guys. Okay in the sort of court and Court obvious way that the vector X1 X2 X3 Etc is presented as x 1 x e 1 + x 2 * 82 + x 3 x III down the line. So they do Spanish that every Vector is linear combination of RN, but they're also linearly independent. Now, these are column vectors and we know how to check if column vectors are linearly independent. How do we check that?  row reduction  we check it by row reduction.  We need to check that the  The Matrix with those vectors as columns  Is what we need to check.  To see that those vectors are linearly independent. What's the what's the key feature?  Every column is pivotal.  And if we want to check that that means we need to carry the Matrix to reduced Russia Arturo Echelon form and check that we indeed have a leading entry and every column. Well, this Matrix is already in reduced row Echelon form. It's the identity Matrix. So we have a pivot in every column and therefore those pictures of linearly independent. So we have a linearly independent standing set therefore it forms the basis for RN  I'm thinking of all sorts of other words and descriptions that we've learned are connected. So here if we're talking about a basis for RN. Okay, then we need to have a set of vectors that spans are in and that also is linearly independent. Now, I can check both of those things by taking the column vectors and putting them together in a matrix. If I take the columns of a matrix and I asked does that set of columns span all of RN? What do I need to check in The Matrix?  I'm sorry.  But every row is pivotal, so if I want a set of vectors in RN to be a spanning set for RN, I need to check that every row is pivotal.  So to check that a set of vectors in RN is a spanning set for our annual check to check that the Matrix with those is its Collins has every road pivotal to check that it's linearly independent set. You need to check that every column is pivotal. So in other words  If I have some vectors V1 up to the end.  That's a bassist.  for RN  that's going to happen. If and only if the Matrix.  Whose columns are those vectors has every row and every column pivotal?  In terms of what we did last week. What does that say about the Matrix? It says that it's invertible.  So that's another way to check here. So if you want to see if your column vectors are given an RN or a basis for RN you put them together in a matrix. And you see if that Matrix is invertible not in particular that tells you something about the size of a basis of RN.  Invertible matrices must be square.  And that's just because if you want to have every row and every column pivotal that you can't have any more Rose than calling for any more columns and rows.  So what we see here is that every basis of RN has n vectors in it. Here's one basis of our at the standard basis, but there are zillions of base's out there. You just take any invertible Matrix its columns form a basis of RN meaning that they expand all of our end and those vectors are linearly independent and what the linear Independence does for you as it says that not only is every Vector a linear combination of those columns.  But it's a linear combination in a unique way is exactly one linear combination of those factors that gives you your given Vector you wanted which again is the restatement of the fact that if you're trying to solve the system ax equals B, if you want there to be a unique solution that Matrix a better have every column pivotal. Otherwise, I'll be free variables.  All right. So that's the notion of basis a basis is a minimal spanning set the linearly independent set of vectors that spans you're given Subspace and for all of our end if you're looking for a basis of RN that connect to a zillion other things that we already know how to check which always boil down to row reduction one way or another we know how to check if a given set of vectors is a basis for RN.  It's so here. This one here. Is this collection of vectors A basis for RN?  How do we check?  Row reduction pencil, let's do a little bit of production. Shall we?  Actually, I was thinking of asking for a volunteer or anyone like to come up here and do the rod Road option for us.  Anyone brave enough to try anyone dumb enough to try.  I see some people trying to volunteer their their friends. So I think that means that you just volunteered. Yeah.  Next time you'll think twice before trying to get your head friend to raise his hand.  Okay, why don't you take us through the rubber ducks in here?  You don't have to right here. I'll hold this right? You don't have to write the you don't have to write the operations. Just  so tell us what's the first thing you're going to do. I'm going to double the first row and then added to the third row perfect.  rewrite at first  okay right now, what's the next step?  I'll add together those the bottom of the bottom to thank you.  So that'll be like a102.  I mean, so we were another okay so you can stop.  That was great. Thank you. Yeah, those two steps of reproduction were enough to get the Matrix to row Echelon form. And once it's in Russia landform, we can tell that every row and every column here is pivotal. So this one is this is an invertible Matrix and the answer is yes, all columns and all rows pivotal.  Awesome. Okay. So this down here. This is just a reiteration of what we said approved on the left side. If you're looking for a basis of RN every bases of RNA has exactly and vectors.  Okay, because the Matrix the composed of those columns must be a square Matrix for it to be invertible for it to have a pivot at in every row and every column.  And in particular the kind of set of those vectors is a basis. If and only if the associated Matrix with those columns is an invertible Matrix great. So that's the basis of RN.  What about a basis of a Subspace of our I'm so here here is a Subspace of R3. I've described it up there. It's like the last example we did of a Subspace last time before we got to, space and null space. So here's a Subspace of vectors of archery. Its a Subspace consisting of vectors of the form a + b a - b into a the first question. Is that even a Subspace? Okay. Well, we could go ahead and check directly from the definition that it's is closed under scalar multiplication and addition and contains the zero vector or we can observe the following fact, which is that if we do our usual sort of decomposition trick and factor out the A's and the bees than this set of vectors can be described as the set of all vectors of the form a x 1 1/2  + B * 1 - 1 1  i-110. Thank you.  Did you want to come down here? Maybe you do and you probably do a better job that I'm doing right now. Okay, there we go. Thank you. I think that's correct.  Maybe you really should come down here.  so  I have a  so 80 x 1 1/2  and B * 1 - 1 0  I am pretty sure that's right.  Okay, great. Thank you. I totally did all those mistakes just to show you your pedagogically that no, I really screwed up. Sorry about that.  That's correct. Okay, so it's a set of vectors of that form explicitly. This collection of vectors is the span of those two vectors the two vectors I've written over there.  Okay, so for free we got that that set of vectors there is a spanning set of this Subspace.  The question is is it a basis? So if I have a spending sat, how do I check if it's a basis? What's the other thing? I need to check?  Somebody from this side of the room. You quiet folks over here if I have a spending set by definition. What does it mean for it to be a basis?  What was the definition we give to slides ago of a basis a basis is a spanning set. That is.  That is linear combinations. Well, that's what Hispanics that means to use the wrong word supposed to be linearly.  Independence  So a basis is a linearly independent spending set. So what I need to do is check.  are these  linearly independent  I know when I have two vectors in RN, how do I check if they're linearly independent?  I got a lot of people saying row reduction that's good. That's always the best General answer but if there's only two of them it's easy to eyeball, right because for two vectors linear Independence means that they are parallel that they are not parallel are these two vectors parallel know because if I wanted to get the second as a multiple of the first then looking at the first component that multiple half of you want but One X the first factor is not the second. So these are yes, these are linearly independent and therefore this is a basis. It's a spanning set and I just checked it. It's okay now, let's look down here.  Here is another set of vectors.  Is it a basis of w or not?  Let's send spend 15 seconds and take about 15 seconds.  Okay.  Flash about how many people think that is the basis.  One confident guy also, maybe too many people think that it's not a basis almost everybody. That's correct. It's not a basis with someone from this side of the road like to explain why it's not a basis.  Answers know what someone from the middle of the room like to explain why it's a base. Not a basis. Yes.  When you add the first two vectors, you get the third one, correct? That means that those three vectors are linearly dependent right this plus this equals this know they're linearly dependent.  Great know to be clear. They still are a spanning set. They include those two vectors.  That we already saw was a spanning set. That was a basis. In fact, and then we threw in a third Vector that was a linear combination of those that's never going to be a basis. If you have a basis already throwing any more vectors in the space is going to kill it being a basis because any more vectors by definition of basis will be a linear combination of the ones you already had their know. How about this third set down here set of two vectors. It doesn't have too many. Is it a basis?  No, I heard a lot of people saying no, that's correct. It's not a basis. In fact, it's even worse. This Vector here is not in w.  Okay, and we can check that. I mean the way we would check that of course is row reduction usually but we can actually just see look the third component of any vector.  The Subspace W that's equal to 2 a so if to a has-been equal 0 that means a has to be zero, but the second component is a minus B. So they is 0 that will second mother will take you be have to be zero. So the only Vector in the Subspace W that has zeros in the second two components must have a zero in the first component to 0 + 0. Is this Vector hear the first standard basis Vector of our three is not in W. So if we go back to the definition hear of a of a basis critical word there that I want to highlight with this example is vectors in H.  Vectors to form a basis they have to be in the Subspace to start with doesn't even make sense to ask if a vector that's not in the Subspace can be in a spanning set for it because it will take you outside the Subspace. So this one is not a basis. It's not even a set of vectors in the space.  Okay, so  I think we're going to we're going to stop there for today. We will continue next day talking about Bayseas for a few minutes before moving on to the notion of Dimension. Have a great weekend. Make sure you get your Matlab homework completely uploaded in the end on time this evening.  Play know the anti-slavery flag on ovary swelling and it's for those things to themselves to playing the anti-slavery flag for every climb and the slave.  To the comedian flashing farm-raised disposal is not peaceful.  sandiego.edu ",
  "Name": "math18_b00_wi18-02092018-1000",
  "File Name": "lecture_14.flac"
}