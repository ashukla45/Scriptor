{
    "Blurbs": {
        "1 so we had three different years we cared about so we have to and the DFE is always defined to be and minus k So we had nine different data points are 9 rows in the The Volcano dataframe and here I'm subtracting the number of groups. So I gave us to 6. So, can you see where these appear in the F Formula? Well, hopefully you remember back ": [
            1511.6,
            1535.2,
            55
        ],
        "50 different Muse me one through me or 50. Well the most boring thing General isis's patterns, which is that they're all the same. Play alternative it gets interesting though. It just says that's some at least one of these Muse of eyes is different from the others. NFL you generalize a not equal to sign to a big list of things something is different. So it's a little strange. ": [
            103.1,
            130.5,
            4
        ],
        "But in the end you decide something interesting is going on and move to the alternative. It happens about 5% of the time or whatever your Alpha is. So if you're going to go run 20 tests. One of them is just going to buy random chance scream at you. Go to the alternative go to the alternative something cools happening when there's really nothing happening. Okay, if I ask ": [
            396.1,
            419.4,
            15
        ],
        "Cuz this road residuals or the same thing as error terms. So this is like a Nero and that's like an MS call him and they meet at MSE. How do I find either of these? You have an idea. Let's hear it. You just said the words some and square. Hey, I got to call him that does it for me. This, right here is those summations you see ": [
            2875.9,
            2915.7,
            87
        ],
        "Etna eruptions in these various years volcanologist recorded the below data on the direction of Earth's magnetic field. Do these data support the idea that the direction has changed over time? Those blows your mind the first time you hear about it. You mean the direction of Earth's magnetic field is not constant. Or may not be constant. Well, that's what this problem is designed to figure out now. This ": [
            1088.9,
            1120.7,
            42
        ],
        "How spread out there in Wyoming and we want to sort of wait them by how often they show up. And then we sort of take some average. Now this will seem utterly mysterious the first time you see it and the derivation of where all this comes from is super complicated like 181b 281 be complicated if you want to go there. I think it's valuable at this level ": [
            1001.9,
            1030.7,
            39
        ],
        "Listen to a podcast. Hey, y'all. Welcome back, Happy Thanksgiving week. We are going to have class on Wednesday. I'm required by the school to hold class on Wednesday. If you have some plans to take you away from class on Wednesday, I understand you don't need to send me an email to ask permission. You can watch the podcast if you need to that's fine with me. If you ": [
            1.9,
            31.8,
            0
        ],
        "Now. How did we actually do some calculations in these settings? So in the first setting we noticed that the teachers tribution could help us so we calculated it was called the stat take what's going on in your sample X bar. subtract the center of the universe you're expecting to get something near Mew not if you assume the null hypothesis and then / how spread out things are ": [
            130.5,
            154.5,
            5
        ],
        "Okay, so X bar you can see here is the mean of all the data. So take all the data and forget where it came from and just dump it into a big pot. And find the average pay that sort of the overall average of all your data now hex I bar is the average in the ice population or the ice sample here. Okay, so tells you like ": [
            876.4,
            897.0,
            34
        ],
        "Okay. So here the A's will be the 1669 and then you have the B's and C's you don't even have to list them all group together. Like I did the computer will figure it out, but it's easiest to do that. Okay, so you take that in and I have this dataframe and then you just want to go run an anova now. There's many different ways in our ": [
            1344.4,
            1365.4,
            48
        ],
        "They must always look like that except for extreme cases. So here you can see like I drew some different ones for different degrees of freedom in minitab. Okay. So if you ever want to find a P value on one of these things first, you put down your F value or your ex that and then you're always going to shade to the right. You notice that the null ": [
            1655.6,
            1677.0,
            60
        ],
        "a day. You have a problem. This is part of a huge study that involves 50 thousand women. So women's health studies where this comes from. Okay. So now we have a qualitative into groups. And then the quantitative thing you're measuring about them is how much they exercise so he's person themselves. Did their average exercise and then you're averaging together the averages? Okay, so here's the number. Mets ": [
            2243.3,
            2273.8,
            75
        ],
        "a large National survey, not random Okay, so we're a little worried about that. What about 10% There are more than 500,000 women. A few more. I don't know. It's like waiting for you to say yes or something. There's not a trick question a couple more. So we're maybe a little worried cuz we don't know how they were sampled. Maybe I chose my 50000 best female friends. You ": [
            2472.8,
            2510.6,
            81
        ],
        "a little bit off each other. But it's not enough. You'll be like hey something crazy is going on. This is just an artifact of how the statistical infrastructure works. That's really counterintuitive for people. Definitely want that day. Thanks for your data. What's the ideal with coffee? Do people who drink different amounts of coffee? Tend to exercise different amounts. So here we go. They did cups of coffee ": [
            2143.3,
            2189.2,
            72
        ],
        "a super clever idea. Let me tell you about it. Here's my super clever idea. If there's four means going on. For example, I'll just compare them all one by one. Seems reasonable, right? I'll compare me one damn you to maybe the t-test will say they're the same. Maybe you'll say it's different and someone you can keep doing this, right. That seems like a good idea. The only ": [
            312.4,
            340.3,
            12
        ],
        "about this on an exam, like I presented it a different way and you'll see some of those examples coming out but let's go to Socrative. Please enter Network. Researchers doing an F test on the F distribution. Will that make sense? Third degree of Freedom around the group number is 7 and the degrees of freedom are on the error idea is 112 how many groups? Boom 6 2/3 ": [
            1760.1,
            1821.1,
            64
        ],
        "after tribution and then shade right? We get an incredibly small P value. It must mean that. One of these means is different which suggests that somehow coffee consumption does affect exercise. I don't know how it does. It just does. It's a little strange. It appears that met levels are not the same across the different coffee consumption categories into which they divided things for some reason. Oh my ": [
            2968.8,
            3007.9,
            90
        ],
        "along. We've already dealt with means from one population and we learned how to deal with hypotheses. Okay it be super boring if what we were studying with just equal to some value. I'll call this when you not be some constant see if you want. And sometimes you might use an alternative. It's two-sided AR thing we're studying is not you not and then we moved on to two ": [
            55.4,
            79.7,
            2
        ],
        "and alternative hypotheses always look the same for these problems. The Knoll is very boring. All of the means are equal. The alternative is also always the same at least something is different. So there isn't one and two-sided Alternatives anymore like there was back in the day. They're all equal something different and because of that very forced structure to how these look it forces us to always actually ": [
            1677.0,
            1705.9,
            61
        ],
        "and it turned out that number gozanti 7 - 1 then we dealt with the harder situation the other day of what if they're two populations. So we ended up working with their difference is because it could turn two separate worlds into one world could then be started the world of differences? And here you subtract 0 because that's the Bourne hypothesized value about the difference between these two ": [
            154.5,
            180.6,
            6
        ],
        "ask around this. Are not actually calculating anything. It's mostly like, how do you set the South? How do you finish it? Can you talk to me a little about like Connections In The Middle? It feels a little like the middle is missing out of it. That's how I always feel like the middle is all computer. I can't even imagine doing this before computers. I'm the only one ": [
            2306.5,
            2343.4,
            77
        ],
        "at this. Now this F statistic is admittedly quite complicated. We can do all the theory behind it, but I can show you how to use it. So turns out it's the ratio of two things MSG. You're probably eating that before and MSE will talk about with these meeting and that's a number that you were supposed to look up on this curve the F distribution now, you'll notice ": [
            236.4,
            260.0,
            9
        ],
        "basically ca1 and 1000 event a lot once a week basically. So for example today is one in a thousand event student couldn't take the exam at 8 a.m. Because well, they live in Tijuana and they commute across the border every single day to UCSD got shut down because of Migrant Caravan. That sounds like a one in a thousand event. Right? But if you have a thousand students ": [
            445.9,
            470.5,
            17
        ],
        "can do all of this sort of laborious stuff that I hate. So why can't I use my clever idea? There's just one problem with running lots and lots of tests. When you run lots and lots of tests. Things are going to show up statistically significant or interesting even though they're not a small percentage of the time. Resisting called a type 1 error. Nothing interesting is going on. ": [
            367.2,
            396.1,
            14
        ],
        "consumed now, that's normally a quantitative variable. And average exercise per week measured in these weird Mets that you see on the treadmill video is like what is that? I'm going to ignore that and put calories. Which is really kilocalories. So everything so silly. Okay. So those are the two variables. That doesn't make sense. Okay, in order to do this study, you have to have little bins. There ": [
            2189.2,
            2216.8,
            73
        ],
        "data expression is I need you to tell me a quantitative variable first. That is something that feels numeric and then put this little till 2 here and say I want to split it out a partition it or think about it based on what year it is. So this is the categorical variable right here. It tells you what group or what population you're part of. So what does ": [
            1387.0,
            1410.8,
            50
        ],
        "data. And finally, this is a new one for us. The spreads in each group are roughly equal. So this is called homoscedasticity homo meaning same skied a stick meaning spread out in this so you want them to be roughly spread out similarly other ways to deal with the situation when they're not but those are super complicated and we'll just deal with the easier situations for now. Okay, ": [
            623.2,
            651.9,
            24
        ],
        "does anyone know on Earth? Like what what an m-80 is? Okay, I don't either good. We're all in the same place. Are there some spread out in this? Okay, 12,000 people don't drink any coffee in their sample. Basically, or they can have one cup set of parameters and hypotheses. So give this a go. As you're doing this one thing you'll notice is most of the questions you ": [
            2273.8,
            2306.5,
            76
        ],
        "don't know my life don't judge me. Okay, what else we got to do someone else tell me about a different condition. Go ahead. Good, so I don't know like women's met averages at the gym like that could be crazy. Not normal, but look at how big these samples are 12000. I feel good. Last one. Go ahead. You were going to decide for us. I would definitely say ": [
            2510.6,
            2546.1,
            82
        ],
        "don't really know the difference cuz Sports that's not really my thing. Okay, so you might say like do certain positions in baseball have higher batting averages than other positions. Most people in the room would probably know that pitchers suck at batting. I mean, I know nothing about sports and I know that so if I know something then you guys definitely know it when it comes to that ": [
            703.6,
            729.1,
            27
        ],
        "dots. So the first thing has to do with what our first thing always is Independence, but he was more complicated you have each of these groups these different populations. You need the dots inside each group to be independent of each other. They shouldn't be influencing and helping you predict each other. But furthermore if you look across different groups, you need to make sure that a data point ": [
            577.4,
            600.1,
            22
        ],
        "equal. Something is awry is our alternative here. We've got a problem. Next thing discuss the conditions for doing inference and whether they are met so I want someone to talk to us about these. You can take any of the conditioned to like and tell me how you feel about them. Go ahead. Independence So how do you know these women were chosen randomly? you just hoping part of ": [
            2424.6,
            2472.8,
            80
        ],
        "everyone in the room to flip a quarter 10 times one of you strange people will get all heads. And you'll be like this point is definitely broken. So you can't just start doing something a bunch of times because when Randomness is involved you start seeing weird things pop up. I told my parents every time I drive home from school that now that I teach 800 students, I ": [
            419.4,
            445.9,
            16
        ],
        "field in our three years. Hey, let's just those are some numbers. I don't know if they are. Now. When you write these Nolan Alternatives the easy way the noise. I was just going to be there or they all have to be equal. Okay. Now if there's like 50 different averages don't write them all down just say it's not all the Muse are equal just use words and ": [
            1278.8,
            1301.1,
            45
        ],
        "five. B45 different groups and you have to really be careful about actually tell me what you're measuring the average weekly met level in women and are different categories. And hear the Nola sort of boring. You can see me. I've already moved away from saying they're all equal in math notation, and I'm just doing it in words. That's totally fine. If you like the word approach. They're all ": [
            2399.8,
            2424.6,
            79
        ],
        "for later in life. So let's try a little example and you'll see one of my favorite examples in the whole course. It's like on the top 10 Oh everytime. I see it. It's so exciting. Things are so sexy. When lava hardens it reveals the direction of Earth's magnetic field, that's because there's iron in lava and the iron gets pulled by magnetism. Taking 3 lava samples from Mount ": [
            1059.7,
            1088.9,
            41
        ],
        "get to F value? Divide someone said okay, I can divide the MSG and the MSE if you'd like, I could 5.2 now the last column is a P value the probability of getting something bigger than your F statistic. So you would have to go write a line of code in R to do this take the place by point to on the horizontal axis situated on the appropriate ": [
            2940.1,
            2968.8,
            89
        ],
        "go crazy you seen the end minus one that comes up in the standard deviation formula using the K - 1 that's the group degree of freedom, and I seen the end minus k Tobira Freedom around the residual to the are terms. So you've just seen a lot. Okay. So there you go. Hopefully put those numbers in and if you want to add them together to do the ": [
            2810.1,
            2834.0,
            85
        ],
        "goodness. We're out of time. I'll see you later. ": [
            3007.9,
            3011.9,
            91
        ],
        "guessing. This is the frustrating thing about a novas. It says something interesting is going on, but it doesn't tell you what lake did we ever decide? What year in the volcanologist study was the weird? You're no. Just the Earth's magnetic field has changed. hair straightener 1 If Anova suggest something is different, then we will be able to find it if we start using pairwise comparisons. There's a ": [
            2034.8,
            2095.8,
            69
        ],
        "had a problem cuz I don't know the answer to that. I was going to say global warming cuz someone in the class told me that's always the answer. Okay. Now this p-value you can actually figure out what this is. What you have to do is take the F value and you have to look that up on a curve and shade an area. It's the equivalent of when ": [
            1601.7,
            1625.5,
            58
        ],
        "has to be some qualitative variable is stepping separating things like what state do you live in so you can see what they did to hear. They broke coffee drinkers into different groups in Bend them are officially a week. That's me to pick up today. Now you're up to like 14 to 21 cups a week. Starbucks Bill starting to get big greater than or equal to 4 cups ": [
            2216.8,
            2243.3,
            74
        ],
        "hear the alternative don't give me any all the possibilities or maybe new one is different than Mewtwo and maybe Mewtwo's different just a like some of this new I at least one is different some people use the phrase at least one. You can also just say some if you want it's up to you. Now you saw the calculations were horrible. If you want to find the apps ": [
            1301.1,
            1325.2,
            46
        ],
        "here is less than what's in your soul. Which means we should have banned in the null hypothesis these data do not suggest that there's equinus between all those different years and the Earth's magnetic field. What would make earth magnetic field change? Circulation of magma underneath the mantle how do you know that? Oh, thank God someone in the room. There's something about geology. Otherwise, otherwise, we would have ": [
            1564.0,
            1601.7,
            57
        ],
        "in group 2 doesn't help you decide anything about 1. Now you just sort of randomly choose people to fill everything. This is totally fine. Next the data in each group need to be nearly normal. Well, it's okay. If they're not nearly normal, as long as we have this large sample size thing that we always talk about but that's the starting place. You want to have nice pretty ": [
            600.1,
            623.2,
            23
        ],
        "in the room. I think he was born before computers really took off. 2018 most of you were born in 98 in the 90s somewhere around there computer started being real thing in like Junior They weren't in my in they weren't like actual living rooms until 95. 94 something like that may be a lots and lots of muse. So I just say let me send some one through ": [
            2343.4,
            2399.8,
            78
        ],
        "in those formulas? I didn't tell you that but that's what it is. Okay. So here's the MSG. For example, it has this piece right here the first thing and has that horrible nightmare. I hope you'll nightmare is the sum of squares at the sum of squares of something. It doesn't matter. So you just divide the two and that's how you get the next thing. How do I ": [
            2915.7,
            2940.1,
            88
        ],
        "is a pretty limited data set. This is what the real world actually looks like you're thinking about sample sizes of like 400 or 200 your n equals 3. Okay, they cut some dirt out of the ground that was part of the 1669 eruption and they measured the angle and then they repeated the process two more times and then they did it for the next year and then ": [
            1120.7,
            1143.3,
            43
        ],
        "it take to dataframe and it sucks away all the A's and it works with them and does stuff and it sucks up the bees and does stuff in the seas and then it does all the calculations that it needs to. Okay, and then I store the result of what's coming out of that into something. It does not be called results that I chose that and then if ": [
            1410.8,
            1429.3,
            51
        ],
        "kind of stuff. So the pictures aren't even on really the list here. Okay. So what do we got? So first of all, you want to check that these box plots for the data that made them up or nearly normal. Well one way to just write a check that is to look at the box plots. And if it looks well balanced for the line in the middle is ": [
            729.1,
            746.1,
            28
        ],
        "like to come join me here and spend time with me on Wednesday. I would love that cuz I always like seeing you guys. Okay, here we go. Not appear in a class like math 11. It's a more sophisticated techniques that people like y'all might actually need one day. So I took me a long time to realize that this idea just generalized is something we've been doing all ": [
            31.8,
            55.4,
            1
        ],
        "look at the sample standard deviations. So that's a measure of spread this more susceptible to outliers another SKU effects, but you have decided are these numbers roughly the same? What do you think? 1% said yes, one person said no. Define does it matter we're going to move on anyway, so often if the numbers are a little different, I'll just say continue. Anyway, even though you've noted you ": [
            768.8,
            802.5,
            30
        ],
        "not that many people in Wyoming so or in our sample, so who really cares? So these are the size of the samples now does might not reflect the sizes of those States you might draw the same size from everyone. Okay, so it does like a weighted average of how far each state is from the overall and it's telling you the mean the average square cuz you want ": [
            946.4,
            972.6,
            37
        ],
        "of the room can instantly use formulas. So here's the expression for the degree of Freedom around the group idea number of groups - 1 Siri range and add one I need to change the problems or 6 is an answer. Silly me will make it harder next time same question. How many total data points make up this huge data set? Okay, so here you just have to know ": [
            1821.1,
            1873.9,
            65
        ],
        "of this table is about the group's okay the years which regrouping on and splitting things into groups based on so I was I think about this role as a group idea. And I think about the next one residuals another word for that is error. So this won't this Rose about errors so that I know is MSG in MSE. Okay, so you going to be to buy those ": [
            1459.2,
            1481.7,
            53
        ],
        "on number of groups comes first, and then the error term is next. Okay, so this I don't know people are just obob za51 boo-boos. What command in R. Would you expect would find the area that you care about? Tricky tricky. Let's see how this goes. Okay, if you chosen PRC we're currently trying to find an area. That's a probability. That's what the p means. Okay, so that's ": [
            1932.8,
            1993.1,
            67
        ],
        "only one population and you say one sample sample from it and you're doing things on the T distribution says call the T Test then we have to sample and this is known as a Nova or analysis of variance. This was just a generalization. Now the first thing you might ask I think it's quite natural is star really need some new complicated architecture for this situation. I've got ": [
            282.9,
            312.4,
            11
        ],
        "out an F table. I'll because it's big and complicated now. You have two degrees of freedom. And you have a place along the horizontal axis to worry about so there's at least three things that are sort of varying. It's the most things we've ever had and it's very hard to make tables like that you end up making lots of tables actually. Okay, so I if there's something ": [
            1736.2,
            1760.1,
            63
        ],
        "populations and to be super boring if they were the same and you might start getting excited if they different somehow either greater than or less than that could be exciting to you. Now. What are we going to do when we have more than two populations and we want to study this idea. For example in my care about average IQ in the 50 different states. That would be ": [
            79.7,
            103.1,
            3
        ],
        "print out of an anova But you can't read the screen. Sorry. See if you can fill it all in. Okay, someone tell me how to get the First Column. What do I do? glad The group subtract 1/4 which row is it? Coffee row K. How do I get the residual bro? Take the end total and subtract. subtract the number of groups now your mind is going to ": [
            2575.2,
            2810.1,
            84
        ],
        "problem is that this requires a lot of tests. And as the number of means gets really high. The number of tests is basically quadratic and nature. So if you have 50 different states and you'd like to start comparing them one against each other suddenly you're doing 2500 comparison. Now I know what you're going to say to that. Hey, I got this fancy thing called a computer it ": [
            340.3,
            367.2,
            13
        ],
        "question that EA's will get wrong. You got to dig into the 80s or 90s for the TA start making mistakes. So you probably saw on the explanation when you read it. Amazingly it is possible for the Anova to suggest a difference in present. But when you do all pairwise comparisons, they're unable to detect the difference sensing corruption and present in the government that being unable to identify ": [
            2095.8,
            2120.0,
            70
        ],
        "roughly in the middle of the box, and it's probably normal. Okay, now equal spreads you need the heights of these boxes to be roughly the same height of those boxes IQR interquartile range. That's one way of measuring spread. So if there are roughly the same you're good. So that's how you can do it from this picture. They can also do it from a summary here. You can ": [
            746.1,
            768.8,
            29
        ],
        "same number. You're averaging together. Okay. So all these differences here will be near zero. If the null hypothesis really is true. Okay. Now when you calculate this difference, like how far is California from the average IQ? You want to wait it based on how many people are in California or in your sample? Okay, Wyoming. Sure, Wyoming might have a much different IQ than America but there's really ": [
            919.8,
            946.4,
            36
        ],
        "shade to the right. Okay. So if you had the ability to calculate MSG in NYC by yourself, then you can go find the F stat by yourself and then you could go drop in on some curve by yourself and you could change to the right. using r at some point you either have to go to the F table. or the computer Now I'm not going to print ": [
            1705.9,
            1736.2,
            62
        ],
        "should stop at this point because you don't really know what to do if you stop but it's hard to decide how close is close enough for jazz if they say. I want to check out those conditions. Then you want to calculate the F stat now, usually a computer does this but I will show you what all these things me. So first MSG stands for me and squared ": [
            802.5,
            823.9,
            31
        ],
        "so there you go. That's what you need. Now, how do you actually check all these conditions? So sometimes pictures will help you. Sometimes it's how things are set up. So I was checking dependents who are typical randomization in less than 10% Don't dig too deep into your populations and choose people randomly. There's nothing new there. Now this last these last two you can't it through the same ": [
            651.9,
            678.5,
            25
        ],
        "so we see some sort of weird averages going on and we're not dividing by K, which is the number of groups or doing some K - 1 you seen that before when we were dealing with like standard deviation. Okay, so that should feel a little familiar. And what are you doing an estimate of the variability? We see in the K different sample means one for each group. ": [
            852.5,
            874.8,
            33
        ],
        "sum total, bro, you can do that. You notice it just adds up to something. It has a 10-1 if you want to check. Okay, now you probably did the next one through subtraction. Nothing magical there. If I give you something called the total column, then you can probably add things up to get there. How do I find the mean squared error? hopeless No. MSC is right here. ": [
            2834.0,
            2875.9,
            86
        ],
        "that directly. Okay, roughly equal great. I don't have any like particular way to do that. You just look at the numbers and decide. And you decided so there we got we're going to keep going. Let's see. You said all those words? Okay, good. We'll move on past those words now. Here's an example of what you might see on exam. I love this. What's the computer broke? partial ": [
            2546.1,
            2575.2,
            83
        ],
        "that so usually this is the point where you go and you type your data into R. I want to show you how our best likes you to put this data in so they want you to make a little dataframe here. We're one column is just all the angle measurements and the second column is an indicator variable that helps you keep track of what year you're talking about. ": [
            1325.2,
            1344.4,
            47
        ],
        "that there are two parameters that are deciding which F distribution. So this is your first distribution that is a two parameter family or two index family has two different degrees of freedom. Play the T distribution just has one so we'll talk about all of that as we go to the class. And here's the language that people out in the world used to refer to all this there's ": [
            260.0,
            282.9,
            10
        ],
        "the average IQ in each of the 50 states in your samples. How you going to turn that into one pretty number? Well, so it turns out that the thing that's going to help us in this setting is called the F statistic named after sir. Ronald Fisher one of the top three statisticians of all time. She look back in history and how to vote. Oh my goodness. Look ": [
            208.1,
            236.4,
            8
        ],
        "the expression. The degree of Freedom around the error idea number of observations minus number of groups. So just rearranged. 112 + 8 what salary info on 1,200 people there split across five states you run an anova? Which curve defined area on? This notation means the F distribution. For the degrees of freedom are 5 + 1200. Can you do that order? Let's see. What are the world decided ": [
            1873.9,
            1932.8,
            66
        ],
        "the following year so it helps when the volcano erupts because it creates data. First thing Define variables and write hypothesis for this problem. So give this a go and see how you do. Hopefully wrote some Greek letters on the page. Hope there's no X bars anywhere is I don't care about that yet. So let me see you one two and three be the angle of Earth's magnetic ": [
            1143.3,
            1278.8,
            44
        ],
        "the particular source. See, this is weird. The way the anovaworks. Is it sort of accumulate evidence for strangeness going on by looking at everything that's happening and all these little strangeness is can add up to a huge strangeness and it says oh my goodness something crazy here, but if you go back and you try to sort of look at every little thing They can all just be ": [
            2120.0,
            2143.3,
            71
        ],
        "to have some sense of like what these are sort of measuring and be able to use them. Now it's not obvious right now that this ratio is of any value. Okay, I just like put some weird symbols all over the page. Like why did they follow any kind of distribution? a question Okay, why does it help us decide anything about hypothesis test good question. So that's something ": [
            1030.7,
            1059.7,
            40
        ],
        "to make things positive and this is across all the different groups here. Bottom MSE mean squared error. So apparently we need to divide it by this thing the combined measure of the variability of all the groups. Okay. So how much do these groups vary within themselves are variances? Basically, they're going to take the variance that's going on in Group. I how spread out or IQs in, California ": [
            972.6,
            1000.7,
            38
        ],
        "to run an anova believe it or not. So here is one of the ways if you know a different way it's going to give you basically the same results. So first thing a OVI want to do an analysis of variance. Now, you tell me the date of frame call him so our date of volcano and has the two columns angle and year. So what comes before this ": [
            1365.4,
            1387.0,
            49
        ],
        "to the F Formula. Here it is. Right there, right. There's K - 1 and there's an - k So those things are useful. Okay, finally the p-value. So this helps you decide about the hypotheses. Do you want to abandon age not or do you want to keep it so you have some Alpha in your soul? I don't know what it is, but I'm guessing that our p-value ": [
            1535.2,
            1564.0,
            56
        ],
        "two? You can go check 45/3 that's about 15. So the computer doing things right? I trust it. Next thing here are the degrees of freedom in this problem. And we saw earlier that these expressions. What part of our formulas for MSG nmsc? Okay. So the first one here is called the DFG the degree of Freedom around the group number and it's always going to be K - ": [
            1481.7,
            1511.6,
            54
        ],
        "visualization. So here's a nicer visualization than what I showed you on the previous slide with Twisted individual data points side by side boxplots. So here what's going on is we've looked at four different positions in baseball. outfielder infielder designated hitter and catch her those with the letters stand for the bottom and what we're measuring about them is on-base percentage, which is roughly like batting average, but I ": [
            678.5,
            703.6,
            26
        ],
        "we found T statistics and Z statistics and look them up on normal distributions and T distributions. So let's introduce you to the family. Now this is a frustrating family. First of all, it only exists to the right of zero and there infinitely many members of this family and they look lots of different ways, but in general they tend to sort of go up and come back down. ": [
            1625.5,
            1653.8,
            59
        ],
        "weird outlier mean that you're setting now the conditions to run an anova example of what your data might look like if you had an anova. Okay, so first of all there three different population going on. And you're measuring something in them that the quantitative variable. Here's just called outcome. Okay, and your data from each of your different populations in your sample just look like a bunch of ": [
            551.2,
            577.4,
            21
        ],
        "well, what's the average IQ in Texas and will subtract the average American IQ? So tells you how far is Texas away from sword of the overall average of what's going on. Now if the null hypothesis is true in Texas looks like California looks like Wyoming looks like Idaho. Okay, and when you bring them all together and call them America, they look just like everything. It's all the ": [
            897.0,
            919.8,
            35
        ],
        "which is really nice. But it's a little. It's a bad taste in your mouth as we're going to see the problem is if you decide to move to the alternative hypothesis just said that one of the new eyes is different from the others. but it doesn't tell you which one or even how many it just says something is a foul with all of your means. I told ": [
            495.3,
            528.0,
            19
        ],
        "why B&C or false all the a people got too excited and didn't remember that. Are always goes from the very left place up to where you care about. So that's why I have to do lower tail gets false. Oh silly are if an anova suggest a move to the alternative, then we will have identified the mean that is different than the rest. Hey, we're 25% above random ": [
            1993.1,
            2034.8,
            68
        ],
        "with dinner crosses groups here. So here's the formula for MSG. And it's not totally ridiculous when you sit down and look slowly think about what he's trying to do. Okay, so first of all, You can see the notation over here pay is the number of groups. That was four and a baseball example. It was three in the picture on the previous slide where the three populations. Okay, ": [
            823.9,
            852.5,
            32
        ],
        "worlds if they're equal their difference is 0 and we decided the degree of Freedom here should be some men expression the minimum of the two sample size is each decreased by one. So what are we going to do when we have three or more populations sadly? I can't do some clever step or I just subtract them and create one idea because now there's maybe 50 different numbers ": [
            180.6,
            208.1,
            7
        ],
        "you see these things and then you have to deal with them. So. One of these silly little tests is going to show a significant difference just because of weird random noise screaming at you that something exciting is going on when in fact nothing might be going on. So the whole thing about a Nova, is it one test instead of case weird tests? So it's a single test, ": [
            470.5,
            495.3,
            18
        ],
        "you someone in here had won the lottery. He like oh great, but it doesn't really help you at. All. Right someone in the room is super rich who Could That Be So, Now if you run an F test in it says Hey something interesting is going on. Sometimes people will then move to individual T tests and try to sort out which one it is, which is the ": [
            528.0,
            551.2,
            20
        ],
        "you type summary of results, it'll print out a helpful little table here. Now the things you care about most in this table is this number right here for the current discussion. That's the ratio of MSG intimacy. Number and that should be a place along a horizontal axis for some f distribution. No MSG, and imma see you're also right here in the table. Okay. So the first row ": [
            1429.3,
            1459.2,
            52
        ]
    },
    "File Name": "Statistical Methods - A00 - Quarfoot, David James - Fall 2018-lecture_22.flac",
    "Full Transcript": "Listen to a podcast.  Hey, y'all. Welcome back, Happy Thanksgiving week.  We are going to have class on Wednesday. I'm required by the school to hold class on Wednesday.  If you have some plans to take you away from class on Wednesday, I understand you don't need to send me an email to ask permission. You can watch the podcast if you need to that's fine with me. If you like to come join me here and spend time with me on Wednesday. I would love that cuz I always like seeing you guys. Okay, here we go. Not appear in a class like math 11. It's a more sophisticated techniques that people like y'all might actually need one day. So I took me a long time to realize that this idea just generalized is something we've been doing all along. We've already dealt with means from one population and we learned how to deal with hypotheses. Okay it be super boring if what we were studying with just equal to some value. I'll call this when you not be some constant see if you want.  And sometimes you might use an alternative. It's two-sided AR thing we're studying is not you not and then we moved on to two populations and to be super boring if they were the same and you might start getting excited if they different somehow either greater than or less than that could be exciting to you. Now. What are we going to do when we have more than two populations and we want to study this idea. For example in my care about average IQ in the 50 different states. That would be 50 different Muse me one through me or 50. Well the most boring thing General isis's patterns, which is that they're all the same.  Play alternative it gets interesting though. It just says that's some at least one of these Muse of eyes is different from the others.  NFL you generalize a not equal to sign to a big list of things something is different.  So it's a little strange. Now. How did we actually do some calculations in these settings? So in the first setting we noticed that the teachers tribution could help us so we calculated it was called the stat take what's going on in your sample X bar.  subtract the center of the universe you're expecting to get something near Mew not if you assume the null hypothesis and then / how spread out things are and it turned out that number gozanti 7 - 1  then we dealt with the harder situation the other day of what if they're two populations. So we ended up working with their difference is because it could turn two separate worlds into one world could then be started the world of differences?  And here you subtract 0 because that's the Bourne hypothesized value about the difference between these two worlds if they're equal their difference is 0 and we decided the degree of Freedom here should be some men expression the minimum of the two sample size is each decreased by one.  So what are we going to do when we have three or more populations sadly? I can't do some clever step or I just subtract them and create one idea because now there's maybe 50 different numbers the average IQ in each of the 50 states in your samples.  How you going to turn that into one pretty number? Well, so it turns out that the thing that's going to help us in this setting is called the F statistic named after sir. Ronald Fisher one of the top three statisticians of all time. She look back in history and how to vote.  Oh my goodness. Look at this. Now this F statistic is admittedly quite complicated. We can do all the theory behind it, but I can show you how to use it. So turns out it's the ratio of two things MSG. You're probably eating that before and MSE will talk about with these meeting and that's a number that you were supposed to look up on this curve the F distribution now, you'll notice that there are two parameters that are deciding which F distribution. So this is your first distribution that is a two parameter family or two index family has two different degrees of freedom.  Play the T distribution just has one so we'll talk about all of that as we go to the class. And here's the language that people out in the world used to refer to all this there's only one population and you say one sample sample from it and you're doing things on the T distribution says call the T Test then we have to sample and this is known as a Nova or analysis of variance.  This was just a generalization.  Now the first thing you might ask I think it's quite natural is star really need some new complicated architecture for this situation. I've got a super clever idea. Let me tell you about it. Here's my super clever idea. If there's four means going on. For example, I'll just compare them all one by one.  Seems reasonable, right?  I'll compare me one damn you to maybe the t-test will say they're the same. Maybe you'll say it's different and someone you can keep doing this, right.  That seems like a good idea. The only problem is that this requires a lot of tests. And as the number of means gets really high. The number of tests is basically quadratic and nature. So if you have 50 different states and you'd like to start comparing them one against each other suddenly you're doing 2500 comparison.  Now I know what you're going to say to that. Hey, I got this fancy thing called a computer it can do all of this sort of laborious stuff that I hate. So why can't I use my clever idea?  There's just one problem with running lots and lots of tests.  When you run lots and lots of tests.  Things are going to show up statistically significant or interesting even though they're not a small percentage of the time.  Resisting called a type 1 error. Nothing interesting is going on. But in the end you decide something interesting is going on and move to the alternative. It happens about 5% of the time or whatever your Alpha is. So if you're going to go run 20 tests.  One of them is just going to buy random chance scream at you. Go to the alternative go to the alternative something cools happening when there's really nothing happening.  Okay, if I ask everyone in the room to flip a quarter 10 times one of you strange people will get all heads.  And you'll be like this point is definitely broken.  So you can't just start doing something a bunch of times because when Randomness is involved you start seeing weird things pop up. I told my parents every time I drive home from school that now that I teach 800 students, I basically ca1 and 1000 event a lot once a week basically. So for example today is one in a thousand event student couldn't take the exam at 8 a.m. Because well, they live in Tijuana and they commute across the border every single day to UCSD got shut down because of Migrant Caravan.  That sounds like a one in a thousand event. Right? But if you have a thousand students you see these things and then you have to deal with them. So.  One of these silly little tests is going to show a significant difference just because of weird random noise screaming at you that something exciting is going on when in fact nothing might be going on. So the whole thing about a Nova, is it one test instead of case weird tests?  So it's a single test, which is really nice.  But it's a little.  It's a bad taste in your mouth as we're going to see the problem is if you decide to move to the alternative hypothesis just said that one of the new eyes is different from the others.  but it doesn't tell you which one or even how many  it just says something is a foul with all of your means.  I told you someone in here had won the lottery.  He like oh great, but it doesn't really help you at. All. Right someone in the room is super rich who Could That Be So,  Now if you run an F test in it says Hey something interesting is going on. Sometimes people will then move to individual T tests and try to sort out which one it is, which is the weird outlier mean that you're setting now the conditions to run an anova example of what your data might look like if you had an anova. Okay, so first of all there three different population going on.  And you're measuring something in them that the quantitative variable. Here's just called outcome.  Okay, and your data from each of your different populations in your sample just look like a bunch of dots.  So the first thing has to do with what our first thing always is Independence, but he was more complicated you have each of these groups these different populations. You need the dots inside each group to be independent of each other. They shouldn't be influencing and helping you predict each other. But furthermore if you look across different groups, you need to make sure that a data point in group 2 doesn't help you decide anything about 1.  Now you just sort of randomly choose people to fill everything. This is totally fine.  Next the data in each group need to be nearly normal.  Well, it's okay. If they're not nearly normal, as long as we have this large sample size thing that we always talk about but that's the starting place. You want to have nice pretty data. And finally, this is a new one for us. The spreads in each group are roughly equal.  So this is called homoscedasticity homo meaning same skied a stick meaning spread out in this so you want them to be roughly spread out similarly other ways to deal with the situation when they're not but those are super complicated and we'll just deal with the easier situations for now.  Okay, so there you go. That's what you need.  Now, how do you actually check all these conditions?  So sometimes pictures will help you. Sometimes it's how things are set up. So I was checking dependents who are typical randomization in less than 10% Don't dig too deep into your populations and choose people randomly. There's nothing new there. Now this last these last two you can't it through the same visualization. So here's a nicer visualization than what I showed you on the previous slide with Twisted individual data points side by side boxplots. So here what's going on is we've looked at four different positions in baseball.  outfielder infielder designated hitter and catch her those with the letters stand for the bottom and what we're measuring about them is on-base percentage, which is roughly like batting average, but I don't really know the difference cuz Sports  that's not really my thing. Okay, so you might say like do certain positions in baseball have higher batting averages than other positions.  Most people in the room would probably know that pitchers suck at batting.  I mean, I know nothing about sports and I know that so if I know something then you guys definitely know it when it comes to that kind of stuff. So the pictures aren't even on really the list here. Okay. So what do we got? So first of all, you want to check that these box plots for the data that made them up or nearly normal. Well one way to just write a check that is to look at the box plots. And if it looks well balanced for the line in the middle is roughly in the middle of the box, and it's probably normal.  Okay, now equal spreads you need the heights of these boxes to be roughly the same height of those boxes IQR interquartile range. That's one way of measuring spread. So if there are roughly the same you're good.  So that's how you can do it from this picture. They can also do it from a summary here. You can look at the sample standard deviations. So that's a measure of spread this more susceptible to outliers another SKU effects, but you have decided are these numbers roughly the same?  What do you think?  1% said yes, one person said no.  Define does it matter we're going to move on anyway, so often if the numbers are a little different, I'll just say continue. Anyway, even though you've noted you should stop at this point because you don't really know what to do if you stop but it's hard to decide how close is close enough for jazz if they say.  I want to check out those conditions. Then you want to calculate the F stat now, usually a computer does this but I will show you what all these things me. So first MSG stands for me and squared with dinner crosses groups here.  So here's the formula for MSG.  And it's not totally ridiculous when you sit down and look slowly think about what he's trying to do. Okay, so first of all,  You can see the notation over here pay is the number of groups. That was four and a baseball example. It was three in the picture on the previous slide where the three populations.  Okay, so we see some sort of weird averages going on and we're not dividing by K, which is the number of groups or doing some K - 1 you seen that before when we were dealing with like standard deviation. Okay, so that should feel a little familiar.  And what are you doing an estimate of the variability? We see in the K different sample means one for each group.  Okay, so X bar you can see here is the mean of all the data. So take all the data and forget where it came from and just dump it into a big pot.  And find the average pay that sort of the overall average of all your data now hex I bar is the average in the ice population or the ice sample here.  Okay, so tells you like well, what's the average IQ in Texas and will subtract the average American IQ?  So tells you how far is Texas away from sword of the overall average of what's going on. Now if the null hypothesis is true in Texas looks like California looks like Wyoming looks like Idaho. Okay, and when you bring them all together and call them America, they look just like everything. It's all the same number. You're averaging together. Okay. So all these differences here will be near zero.  If the null hypothesis really is true.  Okay. Now when you calculate this difference, like how far is California from the average IQ? You want to wait it based on how many people are in California or in your sample? Okay, Wyoming. Sure, Wyoming might have a much different IQ than America but there's really not that many people in Wyoming so or in our sample, so who really cares?  So these are the size of the samples now does might not reflect the sizes of those States you might draw the same size from everyone. Okay, so it does like a weighted average of how far each state is from the overall and it's telling you the mean the average square cuz you want to make things positive and this is across all the different groups here.  Bottom MSE mean squared error. So apparently we need to divide it by this thing the combined measure of the variability of all the groups. Okay. So how much do these groups vary within themselves are variances? Basically, they're going to take the variance that's going on in Group. I how spread out or IQs in, California  How spread out there in Wyoming and we want to sort of wait them by how often they show up.  And then we sort of take some average.  Now this will seem utterly mysterious the first time you see it and the derivation of where all this comes from is super complicated like 181b 281 be complicated if you want to go there. I think it's valuable at this level to have some sense of like what these are sort of measuring and be able to use them.  Now it's not obvious right now that this ratio is of any value.  Okay, I just like put some weird symbols all over the page. Like why did they follow any kind of distribution?  a question  Okay, why does it help us decide anything about hypothesis test good question. So that's something for later in life. So let's try a little example and you'll see one of my favorite examples in the whole course. It's like on the top 10  Oh everytime. I see it. It's so exciting.  Things are so sexy.  When lava hardens it reveals the direction of Earth's magnetic field, that's because there's iron in lava and the iron gets pulled by magnetism.  Taking 3 lava samples from Mount Etna eruptions in these various years volcanologist recorded the below data on the direction of Earth's magnetic field.  Do these data support the idea that the direction has changed over time?  Those blows your mind the first time you hear about it. You mean the direction of Earth's magnetic field is not constant.  Or may not be constant.  Well, that's what this problem is designed to figure out now. This is a pretty limited data set. This is what the real world actually looks like you're thinking about sample sizes of like 400 or 200 your n equals 3. Okay, they cut some dirt out of the ground that was part of the 1669 eruption and they measured the angle and then they repeated the process two more times and then they did it for the next year and then the following year so it helps when the volcano erupts because it creates data.  First thing Define variables and write hypothesis for this problem. So give this a go and see how you do.  Hopefully wrote some Greek letters on the page.  Hope there's no X bars anywhere is I don't care about that yet. So let me see you one two and three be the angle of Earth's magnetic field in our three years.  Hey, let's just those are some numbers. I don't know if they are. Now. When you write these Nolan Alternatives the easy way the noise. I was just going to be there or they all have to be equal. Okay. Now if there's like 50 different averages don't write them all down just say it's not all the Muse are equal just use words and hear the alternative don't give me any all the possibilities or maybe new one is different than Mewtwo and maybe Mewtwo's different just a like some of this new I at least one is different some people use the phrase at least one. You can also just say some if you want it's up to you.  Now you saw the calculations were horrible.  If you want to find the apps that so usually this is the point where you go and you type your data into R. I want to show you how our best likes you to put this data in so they want you to make a little dataframe here. We're one column is just all the angle measurements and the second column is an indicator variable that helps you keep track of what year you're talking about. Okay. So here the A's will be the 1669 and then you have the B's and C's you don't even have to list them all group together. Like I did the computer will figure it out, but it's easiest to do that.  Okay, so you take that in and I have this dataframe and then you just want to go run an anova now. There's many different ways in our to run an anova believe it or not. So here is one of the ways if you know a different way it's going to give you basically the same results. So first thing a OVI want to do an analysis of variance. Now, you tell me the date of frame call him so our date of volcano and has the two columns angle and year. So what comes before this data expression is I need you to tell me a quantitative variable first.  That is something that feels numeric and then put this little till 2 here and say I want to split it out a partition it or think about it based on what year it is. So this is the categorical variable right here. It tells you what group or what population you're part of.  So what does it take to dataframe and it sucks away all the A's and it works with them and does stuff and it sucks up the bees and does stuff in the seas and then it does all the calculations that it needs to.  Okay, and then I store the result of what's coming out of that into something. It does not be called results that I chose that and then if you type summary of results, it'll print out a helpful little table here.  Now the things you care about most in this table is this number right here for the current discussion. That's the ratio of MSG intimacy. Number and that should be a place along a horizontal axis for some f distribution.  No MSG, and imma see you're also right here in the table.  Okay. So the first row of this table is about the group's okay the years which regrouping on and splitting things into groups based on so I was I think about this role as a group idea.  And I think about the next one residuals another word for that is error. So this won't this Rose about errors so that I know is MSG in MSE.  Okay, so you going to be to buy those two? You can go check 45/3 that's about 15. So the computer doing things right? I trust it.  Next thing here are the degrees of freedom in this problem.  And we saw earlier that these expressions.  What part of our formulas for MSG nmsc? Okay. So the first one here is called the DFG the degree of Freedom around the group number and it's always going to be K - 1 so we had three different years we cared about so we have to and the DFE is always defined to be and minus k  So we had nine different data points are 9 rows in the The Volcano dataframe and here I'm subtracting the number of groups. So I gave us to 6.  So, can you see where these appear in the F Formula?  Well, hopefully you remember back to the F Formula.  Here it is.  Right there, right. There's K - 1 and there's an - k  So those things are useful.  Okay, finally the p-value. So this helps you decide about the hypotheses. Do you want to abandon age not or do you want to keep it so you have some Alpha in your soul? I don't know what it is, but I'm guessing that our p-value here is less than what's in your soul.  Which means we should have banned in the null hypothesis these data do not suggest that there's equinus between all those different years and the Earth's magnetic field.  What would make earth magnetic field change?  Circulation of magma underneath the mantle how do you know that?  Oh, thank God someone in the room. There's something about geology.  Otherwise, otherwise, we would have had a problem cuz I don't know the answer to that.  I was going to say global warming cuz someone in the class told me that's always the answer.  Okay.  Now this p-value you can actually figure out what this is. What you have to do is take the F value and you have to look that up on a curve and shade an area.  It's the equivalent of when we found T statistics and Z statistics and look them up on normal distributions and T distributions. So let's introduce you to the family.  Now this is a frustrating family.  First of all, it only exists to the right of zero and there infinitely many members of this family and they look lots of different ways, but in general they tend to sort of go up and come back down.  They must always look like that except for extreme cases. So here you can see like I drew some different ones for different degrees of freedom in minitab. Okay. So if you ever want to find a P value on one of these things first, you put down your F value or your ex that and then you're always going to shade to the right.  You notice that the null and alternative hypotheses always look the same for these problems. The Knoll is very boring. All of the means are equal. The alternative is also always the same at least something is different. So there isn't one and two-sided Alternatives anymore like there was back in the day.  They're all equal something different and because of that very forced structure to how these look it forces us to always actually shade to the right.  Okay.  So if you had the ability to calculate MSG in NYC by yourself, then you can go find the F stat by yourself and then you could go drop in on some curve by yourself and you could change to the right.  using r  at some point you either have to go to the F table.  or the computer  Now I'm not going to print out an F table.  I'll because it's big and complicated now. You have two degrees of freedom.  And you have a place along the horizontal axis to worry about so there's at least three things that are sort of varying. It's the most things we've ever had and it's very hard to make tables like that you end up making lots of tables actually.  Okay, so I if there's something about this on an exam, like I presented it a different way and you'll see some of those examples coming out but let's go to Socrative.  Please enter Network.  Researchers doing an F test on the F distribution. Will that make sense?  Third degree of Freedom around the group number is 7 and the degrees of freedom are on the error idea is 112 how many groups?  Boom 6 2/3 of the room can instantly use formulas. So here's the expression for the degree of Freedom around the group idea number of groups - 1  Siri range and add one  I need to change the problems or 6 is an answer.  Silly me will make it harder next time same question. How many total data points make up this huge data set?  Okay, so here you just have to know the expression.  The degree of Freedom around the error idea number of observations minus number of groups. So just rearranged.  112 + 8  what salary info on 1,200 people there split across five states you run an anova?  Which curve defined area on?  This notation means the F distribution.  For the degrees of freedom are 5 + 1200.  Can you do that order? Let's see. What are the world decided on number of groups comes first, and then the error term is next.  Okay, so this I don't know people are just obob za51 boo-boos.  What command in R. Would you expect would find the area that you care about?  Tricky tricky. Let's see how this goes.  Okay, if you chosen PRC we're currently trying to find an area. That's a probability. That's what the p means. Okay, so that's why B&C or false all the a people got too excited and didn't remember that.  Are always goes from the very left place up to where you care about. So that's why I have to do lower tail gets false. Oh silly are if an anova suggest a move to the alternative, then we will have identified the mean that is different than the rest.  Hey, we're 25% above random guessing. This is the frustrating thing about a novas. It says something interesting is going on, but it doesn't tell you what lake did we ever decide? What year in the volcanologist study was the weird?  You're no.  Just the Earth's magnetic field has changed.  hair straightener 1  If Anova suggest something is different, then we will be able to find it if we start using pairwise comparisons.  There's a question that EA's will get wrong. You got to dig into the 80s or 90s for the TA start making mistakes.  So you probably saw on the explanation when you read it.  Amazingly it is possible for the Anova to suggest a difference in present. But when you do all pairwise comparisons, they're unable to detect the difference sensing corruption and present in the government that being unable to identify the particular source.  See, this is weird. The way the anovaworks. Is it sort of accumulate evidence for strangeness going on by looking at everything that's happening and all these little strangeness is can add up to a huge strangeness and it says oh my goodness something crazy here, but if you go back and you try to sort of look at every little thing  They can all just be a little bit off each other.  But it's not enough. You'll be like hey something crazy is going on.  This is just an artifact of how the statistical infrastructure works. That's really counterintuitive for people.  Definitely want that day.  Thanks for your data.  What's the ideal with coffee?  Do people who drink different amounts of coffee?  Tend to exercise different amounts.  So here we go. They did cups of coffee consumed now, that's normally a quantitative variable.  And average exercise per week measured in these weird Mets that you see on the treadmill video is like what is that? I'm going to ignore that and put calories.  Which is really kilocalories. So everything so silly. Okay. So those are the two variables.  That doesn't make sense. Okay, in order to do this study, you have to have little bins. There has to be some qualitative variable is stepping separating things like what state do you live in so you can see what they did to hear. They broke coffee drinkers into different groups in Bend them are officially a week. That's me to pick up today. Now you're up to like 14 to 21 cups a week.  Starbucks Bill starting to get big greater than or equal to 4 cups a day. You have a problem.  This is part of a huge study that involves 50 thousand women. So women's health studies where this comes from. Okay. So now we have a qualitative into groups. And then the quantitative thing you're measuring about them is how much they exercise so he's person themselves.  Did their average exercise and then you're averaging together the averages? Okay, so here's the number.  Mets does anyone know on Earth? Like what what an m-80 is?  Okay, I don't either good. We're all in the same place.  Are there some spread out in this? Okay, 12,000 people don't drink any coffee in their sample. Basically, or they can have one cup set of parameters and hypotheses. So give this a go.  As you're doing this one thing you'll notice is most of the questions you ask around this.  Are not actually calculating anything. It's mostly like, how do you set the South? How do you finish it? Can you talk to me a little about like Connections In The Middle?  It feels a little like the middle is missing out of it. That's how I always feel like the middle is all computer.  I can't even imagine doing this before computers.  I'm the only one in the room. I think he was born before computers really took off.  2018 most of you were born in 98  in the 90s  somewhere around there computer started being real thing in like  Junior  They weren't in my in they weren't like actual living rooms until 95.  94  something like that may be a lots and lots of muse. So I just say let me send some one through five.  B45 different groups and you have to really be careful about actually tell me what you're measuring the average weekly met level in women and are different categories.  And hear the Nola sort of boring. You can see me. I've already moved away from saying they're all equal in math notation, and I'm just doing it in words. That's totally fine. If you like the word approach. They're all equal. Something is awry is our alternative here. We've got a problem.  Next thing discuss the conditions for doing inference and whether they are met so I want someone to talk to us about these.  You can take any of the conditioned to like and tell me how you feel about them.  Go ahead.  Independence  So how do you know these women were chosen randomly?  you just hoping  part of a large National survey, not random  Okay, so we're a little worried about that. What about 10%  There are more than 500,000 women.  A few more. I don't know. It's like waiting for you to say yes or something. There's not a trick question a couple more. So we're maybe a little worried cuz we don't know how they were sampled. Maybe I chose my 50000 best female friends.  You don't know my life don't judge me.  Okay, what else we got to do someone else tell me about a different condition. Go ahead.  Good, so I don't know like women's met averages at the gym like that could be crazy. Not normal, but look at how big these samples are 12000. I feel good. Last one. Go ahead.  You were going to decide for us.  I would definitely say that directly. Okay, roughly equal great. I don't have any like particular way to do that. You just look at the numbers and decide.  And you decided so there we got we're going to keep going.  Let's see. You said all those words?  Okay, good. We'll move on past those words now. Here's an example of what you might see on exam. I love this. What's the computer broke?  partial print out of an anova  But you can't read the screen. Sorry.  See if you can fill it all in.  Okay, someone tell me how to get the First Column. What do I do?  glad  The group subtract 1/4 which row is it? Coffee row K. How do I get the residual bro?  Take the end total and subtract.  subtract the number of groups  now your mind is going to go crazy you seen the end minus one that comes up in the standard deviation formula using the K - 1 that's the group degree of freedom, and I seen the end minus k  Tobira Freedom around the residual to the are terms. So you've just seen a lot. Okay. So there you go. Hopefully put those numbers in  and if you want to add them together to do the sum total, bro, you can do that.  You notice it just adds up to something.  It has a 10-1 if you want to check.  Okay, now you probably did the next one through subtraction.  Nothing magical there. If I give you something called the total column, then you can probably add things up to get there.  How do I find the mean squared error?  hopeless  No.  MSC is right here. Cuz this road residuals or the same thing as error terms. So this is like a Nero and that's like an MS call him and they meet at MSE.  How do I find either of these?  You have an idea. Let's hear it.  You just said the words some and square. Hey, I got to call him that does it for me.  This, right here is those summations you see in those formulas? I didn't tell you that but that's what it is. Okay. So here's the MSG. For example, it has this piece right here the first thing and has that horrible nightmare.  I hope you'll nightmare is the sum of squares at the sum of squares of something. It doesn't matter.  So you just divide the two and that's how you get the next thing.  How do I get to F value?  Divide someone said okay, I can divide the MSG and the MSE if you'd like, I could 5.2 now the last column is a P value the probability of getting something bigger than your F statistic. So you would have to go write a line of code in R to do this take the place by point to on the horizontal axis situated on the appropriate after tribution and then shade right?  We get an incredibly small P value. It must mean that.  One of these means is different which suggests that somehow coffee consumption does affect exercise.  I don't know how it does.  It just does.  It's a little strange. It appears that met levels are not the same across the different coffee consumption categories into which they divided things for some reason.  Oh my goodness. We're out of time.  I'll see you later. "
}