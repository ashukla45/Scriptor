{
    "Blurbs": {
        "14 to 21 cups a week. Starbucks Bill starting to get big greater than or equal to 4 cups a day. You have a problem. This is part of a huge study that involves 50 thousand women. So women's health studies where this comes from. Okay. So now we have a qualitative into groups. And then the quantitative thing you're measuring about them is how much they exercise so each ": [
            2233.6, 
            2260.7, 
            74
        ], 
        "But look at how big these samples are 12000. I feel good. Last one. Go ahead. You were going to decide for us. Okay, roughly equal great. I don't have any like particular way to do that. You just look at the numbers and decide and you decided so there we got we're going to keep going. Let's see. You said all those words? Okay, good. We'll move on past ": [
            2530.8, 
            2562.0, 
            82
        ], 
        "F distribution. Will that make sense? Third degree of Freedom around the group number is seven and the degree of Freedom are on the error idea is 112 how many groups? Boom 6 2/3 of the room can instantly use formulas. So here's the expression for the degree of Freedom around the group idea number of groups - 1 to rearrange and add one. I need to change the problems ": [
            1781.8, 
            1833.4, 
            64
        ], 
        "Hey, I got to call him that does it for me. This, right here. Is those summations you see in those formulas? I didn't tell you that but that's what it is. Okay. So here's the MSG for example, is this piece right here? The first thing and I had that horrible nightmare that horrible nightmare is the sum of squares at the sum of squares of something. It doesn't ": [
            2905.7, 
            2930.3, 
            87
        ], 
        "Hey, y'all. Welcome back, Happy Thanksgiving week. We are going to have class on Wednesday. I'm required by the school to hold class on Wednesday. If you have some plans to take you away from class on Wednesday, I understand you don't need to send me an email to ask permission. You can watch the podcast if you need to that's fine with me. If you'd like to come join ": [
            3.6, 
            29.0, 
            0
        ], 
        "I at least one is different if you want. It's up to you. Now you saw the calculations were horrible. If you want to find the F stat so usually this is the point where you go and you type your data into R. And I want to show you how our best likes you to put this data in so they want you to make a little dataframe here ": [
            1307.0, 
            1332.9, 
            46
        ], 
        "I see it. It's so exciting. Things are so sexy. When lava hardens it reveals the direction of Earth's magnetic field, that's because there's iron in lava and the iron gets pulled by magnetism. Taking 3 lava samples from Mount Etna eruptions in these various years volcanologist recorded the below data on the direction of Earth's magnetic field. Do these data support the idea that the direction has changed over ": [
            1065.3, 
            1098.7, 
            41
        ], 
        "I was just going to be there or they all have to be equal. Okay. Now if there's any different averages don't write them all down just say it's not all them years are equal just use words and hear the alternative don't give me any all the possibilities or maybe me one is different than Mewtwo and maybe Mewtwo is different than just a like some of this new ": [
            1285.4, 
            1307.0, 
            45
        ], 
        "Now when you calculate this difference, like how far is California from the average IQ? You want to wait it based on how many people are in California or in your sample? Okay, Wyoming. Sure, Wyoming might have a much different IQ than America but there's really not that many people in Wyoming so or in our sample, so who really cares? These are the size of the samples now, ": [
            926.8, 
            953.5, 
            36
        ], 
        "Okay, so you take that in and I have the state of frame and then you just want to go run an anova now. There's many different ways in our to run an anova believe it or not. So here is one of the ways if you know a different way it's going to give you basically the same results. So first thing aov I want to do an analysis ": [
            1354.3, 
            1372.5, 
            48
        ], 
        "Okay. So there you go. Hopefully put those numbers in and if you want to add them together to do the sum total, bro, you can do that. You notice I just adds up to something. It adds up 10-1 if you want to check. Okay, now you probably did the next one through subtraction. Nothing magical there. If I give you something called the total column, then you would ": [
            2822.2, 
            2848.8, 
            85
        ], 
        "a P value on one of these things first, you put down your F value or your ex that and then you're always going to shade to the right. You notice that the null and alternative hypotheses always look the same for these problems. The Knoll is very boring. All of the means are equal. The alternative is also always the same at least something is different. So there isn't ": [
            1662.4, 
            1687.7, 
            60
        ], 
        "all the calculations that it needs to. Okay, and then I store the result of what's coming out of that into something. It does not be called results, but I chose that and then if you type summary of results, it'll print out a helpful little table here. Now the temperature about most in this table is this number right here for the current discussion. That's the ratio of MSG ": [
            1415.2, 
            1438.5, 
            51
        ], 
        "all the theory behind if I can show you how to use it. So the ratio of two things MSG, you're probably eating that before and Emma's he will talk about with these meeting and that's a number that you were supposed to look up on this curve the F distribution now, you'll notice that there are two parameters that are deciding which F distribution. So this is your first ": [
            237.8, 
            262.0, 
            9
        ], 
        "an anova? Which curve defined area on? This notation means the F distribution. For the degrees of freedom are 5 + 1200. Can you do that order? Let's see. What are the world decided on number of groups comes first, and then the error term is next. Okay, so this I don't know people are just go Bobs off by one boo-boos. What command in R. Would you expect to ": [
            1887.3, 
            1945.6, 
            66
        ], 
        "are doing some K - 1 you seen that before when we were dealing with alike standard deviation. Okay, so that should be a little familiar and what are you doing an estimate of the variability? We see in the K different sample means one for each group. Okay, so X bar you can see here is the meaning of all the data. So take all the data and forget ": [
            854.5, 
            878.3, 
            33
        ], 
        "are the two. That doesn't make sense. Okay, in order to do this study, you have to have little bins. There has to be some qualitative variable is stepping separating things like what state do you live in? So you can see what they did to hear. They broke coffee drinkers into different groups in byndom artificially a week. That's me to pick up today. Now you're up to like ": [
            2204.5, 
            2233.6, 
            73
        ], 
        "as we're going to see the problem is if you decide to move to the alternative hypothesis just said that one of them you eyes is different from the others. but it doesn't tell you which one or even how many it just says something is a foul with all of your means. I told you someone in here had won the lottery. You're like, oh great, but it doesn't ": [
            500.6, 
            531.2, 
            19
        ], 
        "boring thing General Isis is pattern, which is that they're all the same. Play alternative it gets interesting though. It just says that's some at least one of these Musa buys is different from the others. NFL you generalize the not equal to sign to a big list of things something is different. So it's a little strange. How did we actually do some calculations in these settings? So in ": [
            103.9, 
            132.4, 
            4
        ], 
        "but if you go back and look at every little thing They can all just be a little bit off each other, but it's not enough for you to be like a something crazy is going on. Hey, this is just an artifact of how the statistical infrastructure works. That's really counterintuitive for people. Definitely want that data. Thanks for your data. Let's see how you do with coffee? Do ": [
            2134.4, 
            2168.0, 
            71
        ], 
        "by side boxplots. So here what's going on is we've looked at 4 different positions in baseball. Outfielder infielder designated hitter in Catcher was with the letter stand for at the bottom. And what we're measuring about them is on base percentage, which is roughly like batting average, but I don't really know the difference cuz Sports that's not really my thing. Okay, so you might say like do certain ": [
            682.3, 
            708.3, 
            26
        ], 
        "can't I use my clever idea? There's just one problem with running lots and lots of tests. When you run lots and lots of tests. Things are going to show up statistically significant or interesting even though they're not a small percentage of the time. Assistant called a type 1 error. Nothing interesting is going on. But in the end you decide something interesting is going on and move to ": [
            368.1, 
            396.2, 
            14
        ], 
        "complicated you have each of these groups these different populations. You need the dots inside each group to be independent of each other. They should be influencing and helping you predict each other. But furthermore if you look across different groups, you need to make sure that a data point in group 2 doesn't help you decide anything about 1. Now you just sort of randomly choose people to fill ": [
            581.3, 
            603.7, 
            22
        ], 
        "dataframe and here I'm subtracting the number of groups. So I gave us to 6. So, can you see where these appear in the F Formula? Well, hopefully you remember back to the F Formula. Here it is. Right there, right. There's K - 1 and there's an - k So those things are useful. Okay, finally the p-value. So this helps you decide about the hypotheses. Do you want ": [
            1521.1, 
            1551.8, 
            55
        ], 
        "degree of Freedom here should be some men expression the minimum of the two sample sizes each decreased by one. So what are we going to do when we have three or more populations sadly? I can't do some clever step where I just subtract them and create one idea because now there's maybe 50 different numbers the average IQ in each of the 50 states in your samples. How ": [
            180.9, 
            210.3, 
            7
        ], 
        "distribution that is a two parameter family or two index family has two different degrees of freedom. Beauty distribution just has one so we'll talk about all of that as we go to the class and here's the language that people out in the world used to refer to all this. There's only one population. Then you say one sample sample from it and you're doing things on the T ": [
            262.0, 
            286.2, 
            10
        ], 
        "distribution. So it's called a t test then we have to sample and this is known as a Nova or analysis of variance. This is just a generalization. Now the first thing you might ask I think it's quite natural is star really need some new complicated architecture for this situation. I've got a super clever idea. Let me tell you about it. Here's my super clever idea. If there's ": [
            286.2, 
            314.1, 
            11
        ], 
        "effects, but you have decided are these numbers roughly the same? What do you think? One person said yes one person said no. Define does it matter we're going to move on anyway, so often if the numbers are a little different, I'll just say continue. Anyway, even though you've noted you should stop at this point because you don't really know what to do if you stop but it's ": [
            771.1, 
            803.0, 
            30
        ], 
        "everything. This is totally fine. Next the data in each group need to be nearly normal. Well, it's okay. If they're not nearly normal, as long as we have this large sample size thing that we always talk about but that's the starting place. You want to have nice pretty data. And finally, this is a new one for us. The spreads in each group are roughly equal. So this ": [
            603.7, 
            627.6, 
            23
        ], 
        "find the area that you care about? Tricky tricky. Let's see how this goes. Okay, if you choose B or C. We're currently trying to find an area. That's a probability. That's what the p means. Okay, so that's why B&C or false all the a people got too excited and didn't remember that. Are always goes from the very left place up to where you care about. So that's ": [
            1945.6, 
            2002.1, 
            67
        ], 
        "first of all you want to check that these box plots for the data that made them up or nearly normal. Well one way does this way to check that is to look at the box plots and if it looks well balanced or the line in the middle is roughly in the middle of the box, and it's probably normal. Okay, now equal spreads you need the heights of ": [
            731.1, 
            752.0, 
            28
        ], 
        "four means going on. For example, I'll just compare them all one by one. No seams reasonable, right? I'll compare me one damn you to maybe the t-test will say they're the same. Maybe you'll say it's different and someone you could just keep doing this, right. Now it seems like a good idea. The only problem is that this requires a lot of tests. And as the number of ": [
            314.1, 
            343.8, 
            12
        ], 
        "get the residual bro? Take the end total and subtract. subtract the number of groups now your mind is going to go crazy you seen the end minus one that comes up in the standard deviation formula using the K - 1 that's the group degree of freedom, and I seen the end minus k Tobira Freedom around the residual to the are terms. So you've just seen a lot. ": [
            2789.5, 
            2822.2, 
            84
        ], 
        "hard to decide how close is close enough for jazz if they say. That once you've checked all those conditions then you want to calculate the F stat now usually a computer does this but I will show you what all these things me. So first MSG stands for me and squared with Center Cross Keys groups are So you're the formula for MSG? And it's not totally ridiculous when ": [
            803.0, 
            831.5, 
            31
        ], 
        "help you. Sometimes it's how things are set up. So I was checking dependents who are typical randomization in less than 10% Don't dig too deep into your populations and choose people randomly says nothing new there. Now this last these last two you can't it through the same visualization. So here's a nicer visualization than what I showed you in the previous slide with Twisted individual data point side ": [
            658.1, 
            682.3, 
            25
        ], 
        "intimacy that number and that should be a place along a horizontal axis for some f distribution. No MSG in Embassy, you're also right here in the table. Okay. So the first row of this table is about the group's okay the years which regrouping on and splitting things into groups based on so I was I think about this role as a group idea. And I think about the ": [
            1438.5, 
            1467.9, 
            52
        ], 
        "is called homoscedasticity homo meaning same ski dastic meeting spread out in this so you want them to be roughly spread out similarly other ways to deal with the situation when they're not but those are super complicated and we'll just deal with the easier situations for now. Okay, so there you go. That's what you need. Now, how do you actually check all these conditions? So sometimes pictures will ": [
            627.6, 
            658.1, 
            24
        ], 
        "is. What you have to do is take the F value and you have to look that up on a curve and shade an area. It's the equivalent of when we found T statistics and Z statistics and look them up on normal distributions and T distribution. So let's introduce you to the F family. Now this is a frustrating family. First of all, it only exists to the right ": [
            1613.6, 
            1639.8, 
            58
        ], 
        "it by this thing the combined measure of the variability of all the groups. Okay. So how much do these groups vary within themselves are variances? Basically, they're going to take the variance that's going on in Group. I house spread out or IQs in California. House pet are they in Wyoming and we want to sort of wait them by how often they show up. And then we sort ": [
            981.5, 
            1006.6, 
            38
        ], 
        "like if you had an anova. Okay, so first of all there three different populations going on. And you're measuring something in them that the quantitative variable here just called outcome. Okay, and your data from each of your different populations in your sample just look like a bunch of dots. So the first thing has to do with what our first thing always is Independence, but he was more ": [
            557.2, 
            581.3, 
            21
        ], 
        "magnetic field change? Circulation of magma underneath the mantle how do you know that? Oh, thank God someone in the room. There's something about geology. Otherwise, otherwise, we would have had a problem cuz I didn't know the answer to that. I was going to say global warming cuz someone in the class told me that's always the answer. Okay. Now this p-value you can actually figure out what this ": [
            1575.8, 
            1613.6, 
            57
        ], 
        "matter. So you just divide the two and that's how you get the next thing. How do I get the F value? Divide someone said okay, I can divide the MSG and the MSE if you'd like I get 5.2. Now the last column is a P value the probability of getting something bigger than your f-statistic. So you would have to go write a line of code in our ": [
            2930.3, 
            2959.6, 
            88
        ], 
        "me here and spend time with me on Wednesday. I would love that cuz I always like seeing you guys. Okay, here we go. Appear that the more sophisticated techniques that people like you all might actually need one day. So it took me a long time to realize that this idea just generalized is something we've been doing all along. We've already dealt with means from one population and ": [
            29.0, 
            55.7, 
            1
        ], 
        "memes gets really high. The number of tests is basically quadratic and nature. So if you have 50 different states and you'd like to start comparing them one against each other suddenly you're doing 2500 comparisons. Now I know what you're going to say to that. Hey, I got this fancy thing called a computer it can do all of this sort of laborious stuff that I hate. So why ": [
            343.8, 
            368.1, 
            13
        ], 
        "next one residuals another word for that is error. So this won't this Rose about errors so that I know is MSG in MSE. Okay, so you can't wait to buy those two. You can go check 45/3 that's about 15. So the computer doing things right? I trust it. Next thing here that degrees of freedom in this problem. And we saw earlier that these expressions. What part of ": [
            1467.9, 
            1498.4, 
            53
        ], 
        "notation, and I'm just doing it in words. That's totally fine. If you like the word approach. They're all equal something is awry is our alternative here. We've got a problem. Next thing discuss the conditions for doing inference and whether they are met so I want someone to talk to us about these. You can take any of the conditioned to like and tell me how you feel about ": [
            2416.5, 
            2443.1, 
            79
        ], 
        "now that this ratio is of any value. Okay, I just like put some weird symbols all over the page. Like why did they follow any kind of distribution? a question Okay, why doesn't help us decide anything about hypothesis test good question. So that's something for later in life. So it's a little example and you'll see this one of my favorite examples in the top 10. Oh everytime. ": [
            1034.6, 
            1065.3, 
            40
        ], 
        "of take some average. I know this will seem utterly mysterious the first time you see it and the derivation of where all this comes from is super complicated like 181b 281 be complicated. If you want to go there. I think it's valuable at this level to have some sense of like what these are sort of measuring and be able to use them. Now it's not obvious right ": [
            1006.6, 
            1034.6, 
            39
        ], 
        "of these silly little tests is going to show significant difference just because of weird random noise screaming at you that something exciting is going on when in fact nothing might be going on. So the whole thing about a Nova, is it one test instead of pace weird tests? So it's a single test, which is really nice. But it's a little. When's a bad taste in your mouth ": [
            472.3, 
            500.6, 
            18
        ], 
        "of variance. Now, you tell me the date of frame call him. So our date of him is known as volcano and has the two columns angle and year. So what comes before this data expression is I need you to tell me a quantitative variable first. That is something that feels numeric and then put this little till 2 here and say I want to split it out a ": [
            1372.5, 
            1395.5, 
            49
        ], 
        "of zero and there infinitely many members of this family and they look lots of different ways, but in general they tend to sort of go up and come back down. They must always look like that except for extreme cases. So here you can see it like I do I do some different ones for different degrees of freedom in minitab. Okay. So if you ever want to find ": [
            1639.8, 
            1662.4, 
            59
        ], 
        "one and two-sided Alternatives anymore like there was back in the day. They're all equal something different and because of that very forced structure to how these look it forces us to always actually shade to the right. Okay. So if you had the ability to calculate MSG in NYC by yourself, then you can go find the F stat by yourself and then you could go drop in on ": [
            1687.7, 
            1716.7, 
            61
        ], 
        "or 6 is an answer. Silly me will make it harder next time same question how many total data points? Make up this huge data set. Okay, so here you just have to know the expression. The degree of Freedom around the error idea number of observations minus number of groups. So just rearranged. 112 + 8 what salary info on 1,200 people there split across five states you run ": [
            1833.4, 
            1887.3, 
            65
        ], 
        "or one column is just all the angle measurements and the second column is an indicator variable that helps you keep track of what year you're talkin about. Okay. So here the A's will be the 1669 and then you have the B's and C's you don't even have to list them all group together. Like I did the computer will figure it out, but it's easiest to do that. ": [
            1332.9, 
            1353.2, 
            47
        ], 
        "our formulas for MSG nmsc? Okay. So the first one here is called the DFG the degree of Freedom around the group number and it's always going to be K - 1 so we had three different years we cared about so we have to and the DFE is always defined to be and minus k So we had nine different data points are 9 rows in the The Volcano ": [
            1498.4, 
            1521.1, 
            54
        ], 
        "partition it or think about it based on what year it is. So this is the categorical variable right here that tells you what group or what population you're part of. So what it doesn't take the dataframe in it sucks away all the A's and it works with them and dust off and it sucks up the bees and does stuff and then the Seas and then it does ": [
            1395.5, 
            1415.2, 
            50
        ], 
        "people who drink different amounts of coffee? 10 to exercise different amounts So here we go. They did cups of coffee consumed now, that's normally a quantitative variable. And average exercise per week measured in these weird Mets that you see on the treadmill, but you're always like what is that? I'm going to ignore that and put calories. Which is really kilocalories. So everything so silly. Okay. So those ": [
            2168.0, 
            2204.5, 
            72
        ], 
        "people will get all heads. And you'll be like this point is definitely broken. So you can't just start doing something a bunch of times because when Randomness is involved you start seeing weird things pop up. I told my parents every time I drive home from school that now that I teach 800 students, I basically ca1 and 1000 event a lot once a week basically. So for example ": [
            421.3, 
            448.8, 
            16
        ], 
        "person themselves. Did the average exercise in your averaging together the averages? Okay, so here's the number. Mets does anyone know on Earth like what $0.20 what an m-80 is? Okay, I don't either good. We're all in the same place. Autism spread out in this. Okay, 12,000 people don't drink any coffee in their sample. Basically or they can have one cup set of parameters and hypotheses. So give ": [
            2260.7, 
            2293.6, 
            75
        ], 
        "positions in baseball have higher batting averages than other positions. Most people in the room would probably know that pitchers suck at batting. I mean, I know nothing about sports and I know that so if I know something then you guys definitely know it when it comes to that kind of stuff. So the pictures aren't even on really the list here. Okay. So what do we got the ": [
            708.3, 
            731.1, 
            27
        ], 
        "probably add things up to get there. How do I find the mean squared error? hopeless No. MSC is right here. Cuz this road residuals or the same things are terms. So just like a Nero and that's like an MS call him and they meet at MSE. How do I find either of these? You have an idea. Let's hear it. You just said the words some and square. ": [
            2848.8, 
            2905.7, 
            86
        ], 
        "really help you at. All. Right someone in the room is super rich who Could That Be So, Now if you run an F test in it says Hey something interesting is going on. Sometimes people will then move to individual T tests and try to sort out which one it is, which is the weird outlier mean that you're setting now the conditions to run an anova might look ": [
            531.2, 
            557.2, 
            20
        ], 
        "right lots and lots of muse. So I just say Let Me Lie and I just index them 1 through 5. B45 different groups and you have to really be careful about actually tell me what you're measuring the average weekly met level in women and are different categories. And hear the novus ordo boring. You can see me. I've already moved away from staying there all equal in math ": [
            2391.7, 
            2416.5, 
            78
        ], 
        "see how you do. Hopefully wrote some Greek letters on the page. Hope there's no X bars anywhere is I don't care about that yet. So let me see you one two and three be the angle of Earth's magnetic field in our three years. Harris's those are some numbers. I don't know if they are. Now when you write these Nolan Alternatives the easy way but no I was ": [
            1151.6, 
            1285.4, 
            44
        ], 
        "some curve by yourself and you could say to the right. using r at some point you either have to go to the F table. or the computer Now I'm not going to print out an F table. All because it's big and complicated now your 2 degrees of freedom. And you have a place along the horizontal axis to worry about so there's at least three things that are ": [
            1716.7, 
            1745.6, 
            62
        ], 
        "sort of the overall average of what's going on. Now if the null hypothesis is true in Texas looks like California looks like Wyoming looks like Idaho. Okay, and when you bring them all together and call them America, they look just like everything. It's all the same number. You're averaging together. Okay. So all these differences here will be near zero. If the null hypothesis really is true. Okay. ": [
            901.4, 
            926.8, 
            35
        ], 
        "sort of varying. That's the most things we've ever had and it's very hard to make tables like that you end up making lots of tables actually. Okay, so I if there's something about this on an exam like I presented in a different way and you'll see some of those examples coming out but let's go to Socrative. Please enter Network. Oh. Researchers doing an F test on the ": [
            1745.6, 
            1781.8, 
            63
        ], 
        "the Earth's magnetic field has changed. As for another one. If Anova suggest something is different, then we will be able to find it if we start using pairwise comparisons. There's a question that EA's will get wrong. You got to dig into the 80s or 90s before the TA start making mistakes. So you probably found the explanation when you read it. Amazingly it is possible for the Anova ": [
            2048.2, 
            2105.1, 
            69
        ], 
        "the alternative. It happens about 5% of the time or whatever your Alpha is. So if you're going to go run 20 tests. One of them is just going to buy random chance scream at you. Go to the alternative go to the alternative something cools happening when there's really nothing happening. Okay, if I ask everyone in the room to flip a quarter 10 times one of you strange ": [
            396.2, 
            421.3, 
            15
        ], 
        "the different coffee consumption categories into which they divided things for some reason. Oh my goodness. We're out of time. I'll see you later. ": [
            2994.6, 
            3008.5, 
            90
        ], 
        "the first setting we noticed that the teacher distribution could help us so we calculated it was called the t-stat take what's going on in your sample X bar. subtract the center of the universe you're expecting to get something near Mew not if you assume the null hypothesis and then / how spread out things are and it turned out that number gozanti 7 - 1 then we dealt ": [
            132.4, 
            156.6, 
            5
        ], 
        "the middle of all computer. I can't even imagine doing this before computers. I'm the only one in the room. I think he was born before computers really took off. 2018 most of you were born in 98 in the 90s somewhere around there computer started being real thing in like Junior well, but they were actual living rooms in 95. 94 something like that. Okay, starting to get big ": [
            2322.4, 
            2391.7, 
            77
        ], 
        "them. Go ahead. Independence So how do you know these women were chosen randomly? you just hoping part of a large National survey, not random Okay, so we're a little worried about that. What about 10% There are more than 500,000 women. A few more it's like waiting for you to say yes or something. There's not a trick question a couple more. So we're maybe a little worried cuz ": [
            2443.1, 
            2500.3, 
            80
        ], 
        "there's might not reflect the sizes of those States. You might draw the same size from everyone. Okay, so it does like a weighted average of how far each state is from the overall and it's telling you the mean the average square cuz you want to make things positive and this is across all the different groups here. Bottom MSE mean squared error. So apparently we need to divide ": [
            953.5, 
            981.5, 
            37
        ], 
        "these boxes to be roughly the same height of those boxes IQR interquartile range. That's one way of measuring spread. So if there are roughly the same you're good. So that's how you can do it from this picture and they can also do it from a summary here. You can look at the sample standard deviations. So that's a measure of spread. That's more susceptible to outliers another skew ": [
            752.0, 
            771.1, 
            29
        ], 
        "they cut some dirt out of the ground. It was part of the 1669 eruption and they measured the angle and then they repeated the process two more times and then I did it for the next year and then the following are so it helps when the volcano erupts cuz it creates data. First thing Define variables and write hypothesis for this problem. So give this a go and ": [
            1128.3, 
            1151.6, 
            43
        ], 
        "this a go. As you're doing this one thing you'll notice is most of the questions you ask around this. Are not actually calculating anything. It's mostly like how you set this up. How do you finish it? Can you talk to me a little about like Connections In The Middle? It feels a little like the middle is missing out of it. That's how I always feel like it's ": [
            2293.6, 
            2322.4, 
            76
        ], 
        "those words now. Here's an example of what you might see on exam. I love this. What's the computer broke? partial print out of an anova but you can't read the screen. Sorry. See if you can fill it all in. Okay, someone tell me how to get the First Column. What do I do? glad the group subtract line. Which row is it coffee row K. How do I ": [
            2562.0, 
            2789.5, 
            83
        ], 
        "time? Dallas blows your mind the first time you hear about it. You mean the direction of Earth's magnetic field is not constant. Or may not be constant. Well, that's what the problem is designed to figure out. Now. This is a pretty limited data set. This is what the real world actually looks like you're thinking about sample sizes of like 400 or 200 your n equals 3. Okay, ": [
            1098.7, 
            1128.3, 
            42
        ], 
        "to abandon H. Or do you want to keep it so you have some Alpha in your soul? I don't know what it is. But I'm guessing that our p-value here is less than what's in your soul. Which means we should have banned in the null hypothesis these data do not suggest that there's equinus between all those different years and the Earth's magnetic field. What would make earth ": [
            1551.8, 
            1575.8, 
            56
        ], 
        "to do this take the place 5.2 on the horizontal axis situated on the appropriate at distribution and then shade right? We get an incredibly small P value. It must mean that. One of these memes is different which suggests that somehow coffee consumption does affect exercise. I don't know how it does. It just does. It's a little strange. It appears that met levels are not the same across ": [
            2959.6, 
            2994.6, 
            89
        ], 
        "to suggest a difference in present. But when you do all pairwise comparisons, they're unable to detect the difference sensing corruption and present in the government for being unable to identify the particular source of a Works evidence for strangeness going on by looking at everything that's happening and all these little strangeness is can add up to a huge strangeness and it says, oh my goodness something crazy here, ": [
            2105.1, 
            2134.4, 
            70
        ], 
        "today is one in a thousand event student couldn't take the exam at 8 a.m. Because well, they live in Tijuana and they commute across the border every single day to UCSD got shut down because of Migrant Caravan. That sounds like a one in a thousand event. Right? But if you have a thousand students you see these things and then you have to deal with them. So. One ": [
            448.8, 
            472.3, 
            17
        ], 
        "we don't know how they were sampled. Maybe I chose my 50000 best female friends. You don't know my life don't judge me. Okay, what else we have to do someone else tell me about a different condition. Go ahead. We don't know if your normality but that is compensated for by the sample size being somewhere. So women's met averages at the gym expect to be crazy. Not normal. ": [
            2500.3, 
            2530.8, 
            81
        ], 
        "we learned how to deal with hypotheses. Okay, it be super boring if what we were studying was just equal to some value. I'll call this new not be some constant see if you want. And sometimes you might use an alternative. It's two-sided AR thing we're studying is not you not and then we moved on to two populations and be super boring if they were the same and ": [
            55.7, 
            81.7, 
            2
        ], 
        "where it came from and just dump it into a big pot. And find the average K. That's what is the overall average of all your data. Now XII bar is the average in the ice population or the ice sample here. Okay, so tells you like well, what's the average IQ in Texas and will subtract the average American IQ? So tells you how far is Texas away from ": [
            878.3, 
            901.4, 
            34
        ], 
        "why I have to do lower tail gets false. Oh silly are alternative. Then we will have identified the mean that is different than the rest. Hey, we're 25% above random guessing. This is the frustrating thing about a novas. It says something interesting is going on, but it doesn't tell you what lake did we ever decide? What year in the volcanologist study was the weird? You're no. Just ": [
            2002.1, 
            2048.2, 
            68
        ], 
        "with the harder situation the other day of what if there are two populations. So we ended up working with their difference is because it could turn two separate worlds into one world could then be studied the world of differences? And here you subtract 0 because that's the Bourne hypothesized value about the difference between these two worlds if they're equal their difference is 0 and we decided the ": [
            156.6, 
            180.9, 
            6
        ], 
        "you going to turn that into one pretty number? Well, so it turns out that the thing that's going to help us in this setting is called the F statistic named after sir. Ronald Fisher one of the top three statisticians of all time. She look back in history and how to vote. Oh my goodness. Look at this. Now this F statistic is admittedly quite complicated. We can do ": [
            210.3, 
            237.8, 
            8
        ], 
        "you might start getting excited if they different somehow either greater than or less than that could be exciting to you. Now. What are we going to do when we have more than two populations and we want to study this idea. For example in my care about average IQ in the 50 different states. That would be 50 different Muse me one through me or 50. Well the most ": [
            81.7, 
            103.9, 
            3
        ], 
        "you sit down like slowly think about what he's trying to do. Okay, so first of all, You can see the notation over here pay is the number of groups that was for and a baseball example. It was three in the picture on the previous slide where the three populations some sort of weird averages going on and we're not dividing by K, which is the number of groups ": [
            831.5, 
            854.5, 
            32
        ]
    }, 
    "File Name": "Statistical_Methods___A00___Quarfoot__David_James___Fall_2018-lecture_22.flac", 
    "Full Transcript": "Hey, y'all. Welcome back, Happy Thanksgiving week.  We are going to have class on Wednesday. I'm required by the school to hold class on Wednesday.  If you have some plans to take you away from class on Wednesday, I understand you don't need to send me an email to ask permission. You can watch the podcast if you need to that's fine with me. If you'd like to come join me here and spend time with me on Wednesday. I would love that cuz I always like seeing you guys. Okay, here we go. Appear that the more sophisticated techniques that people like you all might actually need one day. So it took me a long time to realize that this idea just generalized is something we've been doing all along. We've already dealt with means from one population and we learned how to deal with hypotheses. Okay, it be super boring if what we were studying was just equal to some value. I'll call this new not be some constant see if you want.  And sometimes you might use an alternative. It's two-sided AR thing we're studying is not you not and then we moved on to two populations and be super boring if they were the same and you might start getting excited if they different somehow either greater than or less than that could be exciting to you. Now. What are we going to do when we have more than two populations and we want to study this idea. For example in my care about average IQ in the 50 different states. That would be 50 different Muse me one through me or 50. Well the most boring thing General Isis is pattern, which is that they're all the same.  Play alternative it gets interesting though. It just says that's some at least one of these Musa buys is different from the others.  NFL you generalize the not equal to sign to a big list of things something is different.  So it's a little strange. How did we actually do some calculations in these settings? So in the first setting we noticed that the teacher distribution could help us so we calculated it was called the t-stat take what's going on in your sample X bar.  subtract the center of the universe you're expecting to get something near Mew not if you assume the null hypothesis and then / how spread out things are and it turned out that number gozanti 7 - 1  then we dealt with the harder situation the other day of what if there are two populations. So we ended up working with their difference is because it could turn two separate worlds into one world could then be studied the world of differences?  And here you subtract 0 because that's the Bourne hypothesized value about the difference between these two worlds if they're equal their difference is 0 and we decided the degree of Freedom here should be some men expression the minimum of the two sample sizes each decreased by one.  So what are we going to do when we have three or more populations sadly? I can't do some clever step where I just subtract them and create one idea because now there's maybe 50 different numbers the average IQ in each of the 50 states in your samples.  How you going to turn that into one pretty number? Well, so it turns out that the thing that's going to help us in this setting is called the F statistic named after sir. Ronald Fisher one of the top three statisticians of all time. She look back in history and how to vote.  Oh my goodness. Look at this. Now this F statistic is admittedly quite complicated. We can do all the theory behind if I can show you how to use it. So the ratio of two things MSG, you're probably eating that before and Emma's he will talk about with these meeting and that's a number that you were supposed to look up on this curve the F distribution now, you'll notice that there are two parameters that are deciding which F distribution. So this is your first distribution that is a two parameter family or two index family has two different degrees of freedom.  Beauty distribution just has one so we'll talk about all of that as we go to the class and here's the language that people out in the world used to refer to all this. There's only one population. Then you say one sample sample from it and you're doing things on the T distribution. So it's called a t test then we have to sample and this is known as a Nova or analysis of variance.  This is just a generalization.  Now the first thing you might ask I think it's quite natural is star really need some new complicated architecture for this situation. I've got a super clever idea. Let me tell you about it. Here's my super clever idea. If there's four means going on. For example, I'll just compare them all one by one.  No seams reasonable, right?  I'll compare me one damn you to maybe the t-test will say they're the same. Maybe you'll say it's different and someone you could just keep doing this, right.  Now it seems like a good idea. The only problem is that this requires a lot of tests.  And as the number of memes gets really high. The number of tests is basically quadratic and nature. So if you have 50 different states and you'd like to start comparing them one against each other suddenly you're doing 2500 comparisons.  Now I know what you're going to say to that. Hey, I got this fancy thing called a computer it can do all of this sort of laborious stuff that I hate. So why can't I use my clever idea?  There's just one problem with running lots and lots of tests.  When you run lots and lots of tests.  Things are going to show up statistically significant or interesting even though they're not a small percentage of the time.  Assistant called a type 1 error. Nothing interesting is going on. But in the end you decide something interesting is going on and move to the alternative. It happens about 5% of the time or whatever your Alpha is. So if you're going to go run 20 tests.  One of them is just going to buy random chance scream at you. Go to the alternative go to the alternative something cools happening when there's really nothing happening.  Okay, if I ask everyone in the room to flip a quarter 10 times one of you strange people will get all heads.  And you'll be like this point is definitely broken.  So you can't just start doing something a bunch of times because when Randomness is involved you start seeing weird things pop up. I told my parents every time I drive home from school that now that I teach 800 students, I basically ca1 and 1000 event a lot once a week basically. So for example today is one in a thousand event student couldn't take the exam at 8 a.m. Because well, they live in Tijuana and they commute across the border every single day to UCSD got shut down because of Migrant Caravan.  That sounds like a one in a thousand event. Right? But if you have a thousand students you see these things and then you have to deal with them. So.  One of these silly little tests is going to show significant difference just because of weird random noise screaming at you that something exciting is going on when in fact nothing might be going on. So the whole thing about a Nova, is it one test instead of pace weird tests?  So it's a single test, which is really nice.  But it's a little.  When's a bad taste in your mouth as we're going to see the problem is if you decide to move to the alternative hypothesis just said that one of them you eyes is different from the others.  but it doesn't tell you which one or even how many  it just says something is a foul with all of your means.  I told you someone in here had won the lottery.  You're like, oh great, but it doesn't really help you at. All. Right someone in the room is super rich who Could That Be So,  Now if you run an F test in it says Hey something interesting is going on. Sometimes people will then move to individual T tests and try to sort out which one it is, which is the weird outlier mean that you're setting now the conditions to run an anova might look like if you had an anova. Okay, so first of all there three different populations going on.  And you're measuring something in them that the quantitative variable here just called outcome.  Okay, and your data from each of your different populations in your sample just look like a bunch of dots.  So the first thing has to do with what our first thing always is Independence, but he was more complicated you have each of these groups these different populations. You need the dots inside each group to be independent of each other. They should be influencing and helping you predict each other. But furthermore if you look across different groups, you need to make sure that a data point in group 2 doesn't help you decide anything about 1.  Now you just sort of randomly choose people to fill everything. This is totally fine.  Next the data in each group need to be nearly normal.  Well, it's okay. If they're not nearly normal, as long as we have this large sample size thing that we always talk about but that's the starting place. You want to have nice pretty data. And finally, this is a new one for us. The spreads in each group are roughly equal.  So this is called homoscedasticity homo meaning same ski dastic meeting spread out in this so you want them to be roughly spread out similarly other ways to deal with the situation when they're not but those are super complicated and we'll just deal with the easier situations for now.  Okay, so there you go. That's what you need.  Now, how do you actually check all these conditions?  So sometimes pictures will help you. Sometimes it's how things are set up. So I was checking dependents who are typical randomization in less than 10% Don't dig too deep into your populations and choose people randomly says nothing new there. Now this last these last two you can't it through the same visualization. So here's a nicer visualization than what I showed you in the previous slide with Twisted individual data point side by side boxplots. So here what's going on is we've looked at 4 different positions in baseball.  Outfielder infielder designated hitter in Catcher was with the letter stand for at the bottom. And what we're measuring about them is on base percentage, which is roughly like batting average, but I don't really know the difference cuz Sports  that's not really my thing. Okay, so you might say like do certain positions in baseball have higher batting averages than other positions.  Most people in the room would probably know that pitchers suck at batting.  I mean, I know nothing about sports and I know that so if I know something then you guys definitely know it when it comes to that kind of stuff. So the pictures aren't even on really the list here. Okay. So what do we got the first of all you want to check that these box plots for the data that made them up or nearly normal. Well one way does this way to check that is to look at the box plots and if it looks well balanced or the line in the middle is roughly in the middle of the box, and it's probably normal.  Okay, now equal spreads you need the heights of these boxes to be roughly the same height of those boxes IQR interquartile range. That's one way of measuring spread. So if there are roughly the same you're good.  So that's how you can do it from this picture and they can also do it from a summary here. You can look at the sample standard deviations. So that's a measure of spread. That's more susceptible to outliers another skew effects, but you have decided are these numbers roughly the same?  What do you think?  One person said yes one person said no.  Define does it matter we're going to move on anyway, so often if the numbers are a little different, I'll just say continue. Anyway, even though you've noted you should stop at this point because you don't really know what to do if you stop but it's hard to decide how close is close enough for jazz if they say.  That once you've checked all those conditions then you want to calculate the F stat now usually a computer does this but I will show you what all these things me. So first MSG stands for me and squared with Center Cross Keys groups are  So you're the formula for MSG?  And it's not totally ridiculous when you sit down like slowly think about what he's trying to do. Okay, so first of all,  You can see the notation over here pay is the number of groups that was for and a baseball example. It was three in the picture on the previous slide where the three populations some sort of weird averages going on and we're not dividing by K, which is the number of groups are doing some K - 1 you seen that before when we were dealing with alike standard deviation. Okay, so that should be a little familiar and what are you doing an estimate of the variability? We see in the K different sample means one for each group.  Okay, so X bar you can see here is the meaning of all the data. So take all the data and forget where it came from and just dump it into a big pot.  And find the average K. That's what is the overall average of all your data. Now XII bar is the average in the ice population or the ice sample here.  Okay, so tells you like well, what's the average IQ in Texas and will subtract the average American IQ?  So tells you how far is Texas away from sort of the overall average of what's going on. Now if the null hypothesis is true in Texas looks like California looks like Wyoming looks like Idaho. Okay, and when you bring them all together and call them America, they look just like everything. It's all the same number. You're averaging together. Okay. So all these differences here will be near zero.  If the null hypothesis really is true.  Okay. Now when you calculate this difference, like how far is California from the average IQ? You want to wait it based on how many people are in California or in your sample? Okay, Wyoming. Sure, Wyoming might have a much different IQ than America but there's really not that many people in Wyoming so or in our sample, so who really cares?  These are the size of the samples now, there's might not reflect the sizes of those States. You might draw the same size from everyone. Okay, so it does like a weighted average of how far each state is from the overall and it's telling you the mean the average square cuz you want to make things positive and this is across all the different groups here.  Bottom MSE mean squared error. So apparently we need to divide it by this thing the combined measure of the variability of all the groups. Okay. So how much do these groups vary within themselves are variances? Basically, they're going to take the variance that's going on in Group. I house spread out or IQs in California.  House pet are they in Wyoming and we want to sort of wait them by how often they show up.  And then we sort of take some average.  I know this will seem utterly mysterious the first time you see it and the derivation of where all this comes from is super complicated like 181b 281 be complicated. If you want to go there. I think it's valuable at this level to have some sense of like what these are sort of measuring and be able to use them.  Now it's not obvious right now that this ratio is of any value.  Okay, I just like put some weird symbols all over the page. Like why did they follow any kind of distribution?  a question  Okay, why doesn't help us decide anything about hypothesis test good question. So that's something for later in life. So it's a little example and you'll see this one of my favorite examples in the top 10.  Oh everytime. I see it. It's so exciting.  Things are so sexy.  When lava hardens it reveals the direction of Earth's magnetic field, that's because there's iron in lava and the iron gets pulled by magnetism.  Taking 3 lava samples from Mount Etna eruptions in these various years volcanologist recorded the below data on the direction of Earth's magnetic field.  Do these data support the idea that the direction has changed over time?  Dallas blows your mind the first time you hear about it. You mean the direction of Earth's magnetic field is not constant.  Or may not be constant.  Well, that's what the problem is designed to figure out. Now. This is a pretty limited data set. This is what the real world actually looks like you're thinking about sample sizes of like 400 or 200 your n equals 3. Okay, they cut some dirt out of the ground. It was part of the 1669 eruption and they measured the angle and then they repeated the process two more times and then I did it for the next year and then the following are so it helps when the volcano erupts cuz it creates data.  First thing Define variables and write hypothesis for this problem. So give this a go and see how you do.  Hopefully wrote some Greek letters on the page.  Hope there's no X bars anywhere is I don't care about that yet. So let me see you one two and three be the angle of Earth's magnetic field in our three years.  Harris's those are some numbers. I don't know if they are. Now when you write these Nolan Alternatives the easy way but no I was I was just going to be there or they all have to be equal. Okay. Now if there's any different averages don't write them all down just say it's not all them years are equal just use words and hear the alternative don't give me any all the possibilities or maybe me one is different than Mewtwo and maybe Mewtwo is different than just a like some of this new I at least one is different if you want. It's up to you.  Now you saw the calculations were horrible.  If you want to find the F stat so usually this is the point where you go and you type your data into R. And I want to show you how our best likes you to put this data in so they want you to make a little dataframe here or one column is just all the angle measurements and the second column is an indicator variable that helps you keep track of what year you're talkin about. Okay. So here the A's will be the 1669 and then you have the B's and C's you don't even have to list them all group together. Like I did the computer will figure it out, but it's easiest to do that.  Okay, so you take that in and I have the state of frame and then you just want to go run an anova now. There's many different ways in our to run an anova believe it or not. So here is one of the ways if you know a different way it's going to give you basically the same results. So first thing aov I want to do an analysis of variance. Now, you tell me the date of frame call him. So our date of him is known as volcano and has the two columns angle and year. So what comes before this data expression is I need you to tell me a quantitative variable first.  That is something that feels numeric and then put this little till 2 here and say I want to split it out a partition it or think about it based on what year it is. So this is the categorical variable right here that tells you what group or what population you're part of.  So what it doesn't take the dataframe in it sucks away all the A's and it works with them and dust off and it sucks up the bees and does stuff and then the Seas and then it does all the calculations that it needs to.  Okay, and then I store the result of what's coming out of that into something. It does not be called results, but I chose that and then if you type summary of results, it'll print out a helpful little table here.  Now the temperature about most in this table is this number right here for the current discussion. That's the ratio of MSG intimacy that number and that should be a place along a horizontal axis for some f distribution.  No MSG in Embassy, you're also right here in the table.  Okay. So the first row of this table is about the group's okay the years which regrouping on and splitting things into groups based on so I was I think about this role as a group idea.  And I think about the next one residuals another word for that is error. So this won't this Rose about errors so that I know is MSG in MSE.  Okay, so you can't wait to buy those two. You can go check 45/3 that's about 15. So the computer doing things right? I trust it.  Next thing here that degrees of freedom in this problem.  And we saw earlier that these expressions.  What part of our formulas for MSG nmsc? Okay. So the first one here is called the DFG the degree of Freedom around the group number and it's always going to be K - 1 so we had three different years we cared about so we have to and the DFE is always defined to be and minus k  So we had nine different data points are 9 rows in the The Volcano dataframe and here I'm subtracting the number of groups. So I gave us to 6.  So, can you see where these appear in the F Formula?  Well, hopefully you remember back to the F Formula.  Here it is.  Right there, right. There's K - 1 and there's an - k  So those things are useful.  Okay, finally the p-value. So this helps you decide about the hypotheses. Do you want to abandon H. Or do you want to keep it so you have some Alpha in your soul? I don't know what it is. But I'm guessing that our p-value here is less than what's in your soul.  Which means we should have banned in the null hypothesis these data do not suggest that there's equinus between all those different years and the Earth's magnetic field.  What would make earth magnetic field change?  Circulation of magma underneath the mantle how do you know that?  Oh, thank God someone in the room. There's something about geology.  Otherwise, otherwise, we would have had a problem cuz I didn't know the answer to that.  I was going to say global warming cuz someone in the class told me that's always the answer.  Okay.  Now this p-value you can actually figure out what this is. What you have to do is take the F value and you have to look that up on a curve and shade an area.  It's the equivalent of when we found T statistics and Z statistics and look them up on normal distributions and T distribution. So let's introduce you to the F family.  Now this is a frustrating family.  First of all, it only exists to the right of zero and there infinitely many members of this family and they look lots of different ways, but in general they tend to sort of go up and come back down.  They must always look like that except for extreme cases. So here you can see it like I do I do some different ones for different degrees of freedom in minitab. Okay. So if you ever want to find a P value on one of these things first, you put down your F value or your ex that and then you're always going to shade to the right.  You notice that the null and alternative hypotheses always look the same for these problems. The Knoll is very boring. All of the means are equal. The alternative is also always the same at least something is different. So there isn't one and two-sided Alternatives anymore like there was back in the day.  They're all equal something different and because of that very forced structure to how these look it forces us to always actually shade to the right.  Okay.  So if you had the ability to calculate MSG in NYC by yourself, then you can go find the F stat by yourself and then you could go drop in on some curve by yourself and you could say to the right.  using r  at some point you either have to go to the F table.  or the computer  Now I'm not going to print out an F table.  All because it's big and complicated now your 2 degrees of freedom.  And you have a place along the horizontal axis to worry about so there's at least three things that are sort of varying. That's the most things we've ever had and it's very hard to make tables like that you end up making lots of tables actually.  Okay, so I if there's something about this on an exam like I presented in a different way and you'll see some of those examples coming out but let's go to Socrative.  Please enter Network.  Oh.  Researchers doing an F test on the F distribution. Will that make sense?  Third degree of Freedom around the group number is seven and the degree of Freedom are on the error idea is 112 how many groups?  Boom 6 2/3 of the room can instantly use formulas. So here's the expression for the degree of Freedom around the group idea number of groups - 1  to rearrange and add one.  I need to change the problems or 6 is an answer.  Silly me will make it harder next time same question how many total data points?  Make up this huge data set.  Okay, so here you just have to know the expression.  The degree of Freedom around the error idea number of observations minus number of groups. So just rearranged.  112 + 8  what salary info on 1,200 people there split across five states you run an anova?  Which curve defined area on?  This notation means the F distribution.  For the degrees of freedom are 5 + 1200.  Can you do that order? Let's see. What are the world decided on number of groups comes first, and then the error term is next.  Okay, so this I don't know people are just go Bobs off by one boo-boos.  What command in R. Would you expect to find the area that you care about?  Tricky tricky. Let's see how this goes.  Okay, if you choose B or C. We're currently trying to find an area. That's a probability. That's what the p means. Okay, so that's why B&C or false all the a people got too excited and didn't remember that.  Are always goes from the very left place up to where you care about. So that's why I have to do lower tail gets false. Oh silly are alternative. Then we will have identified the mean that is different than the rest.  Hey, we're 25% above random guessing. This is the frustrating thing about a novas. It says something interesting is going on, but it doesn't tell you what lake did we ever decide? What year in the volcanologist study was the weird?  You're no.  Just the Earth's magnetic field has changed.  As for another one.  If Anova suggest something is different, then we will be able to find it if we start using pairwise comparisons.  There's a question that EA's will get wrong. You got to dig into the 80s or 90s before the TA start making mistakes.  So you probably found the explanation when you read it.  Amazingly it is possible for the Anova to suggest a difference in present. But when you do all pairwise comparisons, they're unable to detect the difference sensing corruption and present in the government for being unable to identify the particular source of a Works evidence for strangeness going on by looking at everything that's happening and all these little strangeness is can add up to a huge strangeness and it says, oh my goodness something crazy here, but if you go back and look at every little thing  They can all just be a little bit off each other, but it's not enough for you to be like a something crazy is going on.  Hey, this is just an artifact of how the statistical infrastructure works. That's really counterintuitive for people.  Definitely want that data.  Thanks for your data.  Let's see how you do with coffee?  Do people who drink different amounts of coffee?  10 to exercise different amounts  So here we go. They did cups of coffee consumed now, that's normally a quantitative variable.  And average exercise per week measured in these weird Mets that you see on the treadmill, but you're always like what is that? I'm going to ignore that and put calories.  Which is really kilocalories. So everything so silly. Okay. So those are the two.  That doesn't make sense. Okay, in order to do this study, you have to have little bins. There has to be some qualitative variable is stepping separating things like what state do you live in? So you can see what they did to hear. They broke coffee drinkers into different groups in byndom artificially a week. That's me to pick up today. Now you're up to like 14 to 21 cups a week.  Starbucks Bill starting to get big greater than or equal to 4 cups a day. You have a problem.  This is part of a huge study that involves 50 thousand women. So women's health studies where this comes from. Okay. So now we have a qualitative into groups. And then the quantitative thing you're measuring about them is how much they exercise so each person themselves.  Did the average exercise in your averaging together the averages? Okay, so here's the number.  Mets does anyone know on Earth like what $0.20 what an m-80 is?  Okay, I don't either good. We're all in the same place.  Autism spread out in this. Okay, 12,000 people don't drink any coffee in their sample. Basically or they can have one cup set of parameters and hypotheses. So give this a go.  As you're doing this one thing you'll notice is most of the questions you ask around this.  Are not actually calculating anything. It's mostly like how you set this up. How do you finish it? Can you talk to me a little about like Connections In The Middle?  It feels a little like the middle is missing out of it. That's how I always feel like it's the middle of all computer.  I can't even imagine doing this before computers.  I'm the only one in the room. I think he was born before computers really took off.  2018 most of you were born in 98  in the 90s  somewhere around there computer started being real thing in like  Junior well, but they were actual living rooms in 95.  94  something like that.  Okay, starting to get big right lots and lots of muse. So I just say Let Me Lie and I just index them 1 through 5.  B45 different groups and you have to really be careful about actually tell me what you're measuring the average weekly met level in women and are different categories.  And hear the novus ordo boring. You can see me. I've already moved away from staying there all equal in math notation, and I'm just doing it in words. That's totally fine. If you like the word approach. They're all equal something is awry is our alternative here. We've got a problem.  Next thing discuss the conditions for doing inference and whether they are met so I want someone to talk to us about these.  You can take any of the conditioned to like and tell me how you feel about them.  Go ahead.  Independence  So how do you know these women were chosen randomly?  you just hoping  part of a large National survey, not random  Okay, so we're a little worried about that. What about 10%  There are more than 500,000 women.  A few more it's like waiting for you to say yes or something. There's not a trick question a couple more. So we're maybe a little worried cuz we don't know how they were sampled. Maybe I chose my 50000 best female friends.  You don't know my life don't judge me.  Okay, what else we have to do someone else tell me about a different condition. Go ahead.  We don't know if your normality but that is compensated for by the sample size being somewhere. So women's met averages at the gym expect to be crazy. Not normal. But look at how big these samples are 12000. I feel good. Last one. Go ahead.  You were going to decide for us.  Okay, roughly equal great. I don't have any like particular way to do that. You just look at the numbers and decide and you decided so there we got we're going to keep going.  Let's see. You said all those words?  Okay, good. We'll move on past those words now. Here's an example of what you might see on exam. I love this.  What's the computer broke?  partial print out of an anova  but you can't read the screen. Sorry.  See if you can fill it all in.  Okay, someone tell me how to get the First Column. What do I do?  glad  the group subtract line. Which row is it coffee row K. How do I get the residual bro?  Take the end total and subtract.  subtract the number of groups  now your mind is going to go crazy you seen the end minus one that comes up in the standard deviation formula using the K - 1 that's the group degree of freedom, and I seen the end minus k  Tobira Freedom around the residual to the are terms. So you've just seen a lot. Okay. So there you go. Hopefully put those numbers in  and if you want to add them together to do the sum total, bro, you can do that.  You notice I just adds up to something.  It adds up 10-1 if you want to check.  Okay, now you probably did the next one through subtraction.  Nothing magical there. If I give you something called the total column, then you would probably add things up to get there.  How do I find the mean squared error?  hopeless  No.  MSC is right here. Cuz this road residuals or the same things are terms. So just like a Nero and that's like an MS call him and they meet at MSE.  How do I find either of these?  You have an idea. Let's hear it.  You just said the words some and square. Hey, I got to call him that does it for me.  This, right here. Is those summations you see in those formulas? I didn't tell you that but that's what it is. Okay. So here's the MSG for example, is this piece right here? The first thing and I had that horrible nightmare that horrible nightmare is the sum of squares at the sum of squares of something. It doesn't matter.  So you just divide the two and that's how you get the next thing.  How do I get the F value?  Divide someone said okay, I can divide the MSG and the MSE if you'd like I get 5.2.  Now the last column is a P value the probability of getting something bigger than your f-statistic. So you would have to go write a line of code in our to do this take the place 5.2 on the horizontal axis situated on the appropriate at distribution and then shade right?  We get an incredibly small P value. It must mean that.  One of these memes is different which suggests that somehow coffee consumption does affect exercise.  I don't know how it does.  It just does.  It's a little strange. It appears that met levels are not the same across the different coffee consumption categories into which they divided things for some reason.  Oh my goodness. We're out of time.  I'll see you later. "
}