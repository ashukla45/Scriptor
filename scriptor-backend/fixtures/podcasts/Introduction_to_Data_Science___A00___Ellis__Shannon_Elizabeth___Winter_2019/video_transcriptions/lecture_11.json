{
    "Blurbs": {
        "About to pull up to give you the results you want at the tool to make sure you're doing the correct analysis upfront. Applebee's theme for this all use a lot of data about you all are towards the end of lecture to make the points that we've discussed in lecture. So this one I just wondering why I never hear this is the data set that I collected from ": [
            2810.1, 
            2837.6, 
            103
        ], 
        "All right, as people filter in will get started. So General course reminders as everybody gets seated for 3D assignment is due this Friday and your third assignment is due next Friday. I open up please so assignments just a reminder. Most of you did this right do they should all be submitted as groups if your group is submitting two things, that's not right to make sure everybody is ": [
            43.5, 
            70.8, 
            0
        ], 
        "All right, who's ready to start explaining what the axes represent? I would love to hear from lots of different you today, but I know it can be scary to answer question in front of lots of other people. So I'll never call anybody a dozen other hand up, but I would love to hear from lots of different people. So where the axes represent. Ada, okay. So age is ": [
            1215.5, 
            1243.2, 
            50
        ], 
        "All right. We were pretty even split. Does anybody want to tell me they're thinking and why they chose ARB? Yeah. pretty specific like something might like Okay. So the point that was zip code can be pretty specific and but they're supposed to be large. So if you want your specific Hometown that might be a little more specific or more granular. I'm in the dataset. I like both ": [
            2932.1, 
            2968.2, 
            106
        ], 
        "Autism cases and controls. Here if the outliers were not removed. So you can see here that the difference in expression is way different than everything else up here when the samples are moved suddenly the black in the red overlap with one another a peer P value. Is there a way to measure significant that's like the worst definition of a P value ever, but the lower it is ": [
            2658.9, 
            2681.1, 
            96
        ], 
        "But what this does is each point represents an individual and I'm looking at 6 different the global cultures the global differences in the sample. So what you want to see is that all the points are close to one another and then I get some distribution where nothing's really standing out here. We have some points separating from the group which catches my eye and as I look at ": [
            2503.2, 
            2526.3, 
            89
        ], 
        "I also would have noticed that the person who generated this plot initially in there now since they wanted to look at how gender is Alexander differs among the server responded what they did was they just took the females and males going forward and this represent 16000 people, but I just want to mention that there's a hundred fifty nine people and 74 people whose voice is the purpose ": [
            1605.8, 
            1627.8, 
            62
        ], 
        "I anticipated being the hardest question on the exam it required you to remember Concepts from two different pictures and put them together in a single question, which are always the toughest points are part of an exam. So this one has not been marked correctly for everybody. So two questions, everybody got right on the exam right off the bat. Everything else was greeted as you'd expect. So there ": [
            181.2, 
            203.8, 
            6
        ], 
        "I want classroom or technical there's an issue with the audio only podcast really briefly explain how this works before the quarter starts. I tell you that the I want my course be podcast it and then I get up here. Is everything and I'm supposed to expect that the podcast is going to work and I'm going to run right at sometimes it works at all. But there's like ": [
            416.9, 
            436.1, 
            17
        ], 
        "I'm going to show an example of it today where if you didn't do exploratory analysis and figure out what was going on with your data set you could report wrong findings. Any questions so far about what exploratory data analysis that is why you would do it. This quote is rejected. He's the same person we talked about before I looked at a quote from before about why we ": [
            782.9, 
            819.5, 
            33
        ], 
        "Okay. So I'm like the last one we were looking at count. We're now looking at $0.04 and as you pointed out that it's 80% mail and then everybody else is the other 20% anyting surprising funny. Is this what you expected about this plot? So question is is it okay to call this in distribution, even though the bottom is not a quantitative variable. So it's still how the ": [
            1520.8, 
            1551.8, 
            59
        ], 
        "So again, we're right here in the middle of the data science process. We've talked about this up till now and then next lecture will talk about communicating and then we'll sign the rest of the time talking about how to analyze your data. Surface on from Durant. Okay, who you all read about in the 50 years of data science first reading ETA is your detective work? This is ": [
            625.7, 
            647.9, 
            26
        ], 
        "Tale the reason that we don't just look at this graph. The statistics is here. So what are they considered a data set that had 11 observations were one variable had a mean of 9 the other had a mean of 7.5 and a standard deviation was 1.23 and the correlation between them was .8 Those data seems descriptive statistics might look something like this where you had your 11 ": [
            1009.8, 
            1031.5, 
            42
        ], 
        "There are a few more seconds. 3 2 1 Okay, so the majority of y'all said be bivariate which is the correct answer and I can see why people said this I'm so let's just make sure we're all clear here. So they're only two variables that we're finding information about even though it's broken down into 5 pot with sliding gender, which is what each of these characterizes and ": [
            2130.6, 
            2158.2, 
            75
        ], 
        "Thursday and next Tuesday topics have been flipped. I think it makes more sense to finish update of visualization this Thursday and then do entrance next Tuesday. And the exam first exam scores are on Triton Ed about data as possible. This is something may be a little different and how you would look at it if you started so I just wanted to describe to everybody here what's planet ": [
            94.0, 
            119.6, 
            2
        ], 
        "What use the year you are here easiest. I don't deserve a data what year you are in your study and you identify gender. So I joined them by ID or by name and then I coded the major by your two-letter code. So each major has a two-letter code, which I learned in doing this to CG is cognitive science. I want to go to gender only now if ": [
            3714.8, 
            3733.7, 
            132
        ], 
        "a different reason why except for this one outlier over here. So this is why we generate the past because the numbers don't tell you everything you need to know how the points are actually distributed exploratory data analysis. Johnny Potts looking at what the data actually look like is what allows you to avoid making incorrect assumptions. Okay, it's a general of exploratory data analysis. We do this to ": [
            1054.0, 
            1074.8, 
            44
        ], 
        "a few hands raise your hand if this is what you expected. All rights, we have Ikat same as we expected a few things is not what you expected So data science is an overwhelmingly male field that's changing over time. And it's something that I think at the undergraduate level we can do a lot to make sure that we're being inclusive of everybody else and not just mail. ": [
            1582.9, 
            1605.8, 
            61
        ], 
        "a lot of stuff about employment visuals learn the skills. They needed to be a data scientist what their current job is whether or not they're employed what languages that use with tools that use all of this is included in some 200 question and you were given the data set and asked to do something with it. The first thing you want to know is really what's in there ": [
            1117.7, 
            1136.3, 
            47
        ], 
        "a more significant it is and you can see that the P value increases here. So there's no real difference to remove outliers are removed. This would have been reported as something that was significantly different between cases and controls when clearly it was all driven by his outlier and it might be obvious cuz we're looking at this spot here, but alright to be a hundred thousand of these ": [
            2681.1, 
            2700.0, 
            97
        ], 
        "a survey of data scientist many people put that as their title, but there was lots of other titles that people have and when the end they identify as a scientist, this is really just to point out that you can do data science work without having the title of data scientist, you interpreted them and quickly have a much better understanding of the data that we know that amongst ": [
            2356.1, 
            2379.1, 
            82
        ], 
        "along the x-axis here and then count here. Do you also want to tell me the general pattern? Price of a lot of people clustered around twenty-eight or somebody else to tell me anything else that they've taken away from this spot. Yep. Okay, so there are no really young people. I'm going to say you really young is like less than 16. That is okay. So there's no not ": [
            1243.2, 
            1276.7, 
            51
        ], 
        "and I've asked 48 Anaya to give you all a little more feedback on your assignments this time going forward whether or not it's positive or negative. Just make sure you have some personalized be back on your signment. So as of now, you're halfway through the course y'all have done a lot so far and we will continue on doing data visualization and Analysis for the rest of the ": [
            502.6, 
            525.2, 
            21
        ], 
        "and males. We learned there more males and females in this course that UCSD major does not equal year in school and it showed up but it doesn't have a whole bunch of different Majors taking this course and zip code is not the whole story and with that if there any questions feel free to come up. Other than that, I will see you all on Thursday. Thursday ": [
            4040.6, 
            4061.0, 
            142
        ], 
        "and what information you have. So is it going to work if I'm going to show a pot and then I'm going to give you all a minute to look at it figure out what's going on. I'm will come back to that in a second and I want you to ask yourself three questions talk to your neighbor. What did axes represent what is a general pattern? And is ": [
            1136.3, 
            1155.1, 
            48
        ], 
        "anything more than that other people want more feedback on assignments and dislikes to get lecture, So the stuff that's actual now. This is stuff for the future but doesn't really affect you a time for the 4th and 5th reading. I already told you for the fourth reading I cut the reading and 1/2. I'll do the same for the 5th reading we'll just have one reading there. Going ": [
            457.2, 
            480.8, 
            19
        ], 
        "are 30 questions. Each one was worth 2 points. This is the distribution of all of your scores. Play median and mean work so you can see that media and we're 50 points out of 60. Enemy was right around the same 49.7 with a standard deviation of 8 points the mean and the median are really close to one another and to me this is good. That means there's ": [
            203.8, 
            228.7, 
            7
        ], 
        "are coded differently than everything else. These are the things your checking and exploratory analysis. You're also and we're going to do this today looking at lots and lots of clots as you're doing this and while all of the parts you generate an exploratory data analysis are not what you would eventually use to present to your boss or your co-workers for to anybody want to communicate your now ": [
            741.4, 
            761.5, 
            31
        ], 
        "asked questions on in what ZIP code were you born? And what is your hometown? So both of these could be used to answer the question where did cause nine students or what so I want to ask you which variable should we use to determine the answer to this question? Feel free to challenge each other convince each other. Are there be a few more seconds? 3 2 1 ": [
            2859.5, 
            2928.6, 
            105
        ], 
        "be a different response rate. We're starting to see that there might be some issue with zip code. So ZIP code here. We see a few rows of zip code with the hometown. How do I do this? I'm not going to do this one because we just talked about all these reasons. The one thing that I didn't mention is a tie required zip code to be numeric on ": [
            3082.0, 
            3104.9, 
            111
        ], 
        "be related here understand. There's a relationship between families with siblings and families with pets quickly. We looked at this before. So this is a distribution of individuals with sibling. So everybody over here has siblings and this person these people do not And then it is a distribution of the people in the class who have a pet. The more people habitat versus don't. What would be here when ": [
            3539.5, 
            3569.8, 
            126
        ], 
        "because we haven't done one like this. You have to take a look at the exies and then let me know what conclusion you draw from this spot. All right, who's drawing a conclusion from this plot? What conclusion did you draw? What are the tools most frequently used by data scientists? All right with python and then we are and then we have sequel or SQL. So these are ": [
            2221.3, 
            2311.2, 
            79
        ], 
        "better or topics. I could have been explained better. I'm not going to talk about the specific questions because there are a few people were finishing up taking the the makeup midterm today and I don't think we say Until everybody has taken it. Okay, is this one down here? That's almost everybody got wrong was a matter of semantics and I'll talk about that later. But this one because ": [
            140.0, 
            163.7, 
            4
        ], 
        "box plot that most respondents are employed and that the employment rates were similar across reporte gender, but not the same of know that among the four two genders males were employed at the highest rate. What are pythons secret and are the three most frequently used tools and a people learn in lots of different ways and there are lots of different job titles out there so quickly by ": [
            2398.8, 
            2418.8, 
            84
        ], 
        "case due to what assumptions were made and data collection. We had biased information in the zip code. We would have missed people in the world where there a were not numeric but there still are those pounds of your location that typos can cause a problem and he would have to go in and clean things up a little more to ensure that everything was correct. So we are ": [
            3241.5, 
            3261.0, 
            118
        ], 
        "cases and controls. So if you don't do it for three days, and now this you can report inaccurate results and you don't want to do that either for your boss or for scientific research because it will make you look bad. BatDad ETA is not always the answer to everything. If you have already analyze your data and got an answer that is not what you wanted or expected ": [
            2744.8, 
            2769.5, 
            100
        ], 
        "categories are distributed so it is but I see your point there so we can still talk about the back of the categories are distributed with most of them being in the mail category. But you wouldn't refer to this as a like a normal distribution. By show of hands if this is we're going to have to raise your hand if you are surprised by this despot. I retrieve ": [
            1551.8, 
            1582.9, 
            60
        ], 
        "categories is sometimes helpful to look at proportion. So this is that same plot and the conclusion drawn was correct that the proportion is similar about 60% between males and females but higher so now we're not looking at Raw count, but we're looking at the proportion within each gender that are within each category. Now, it's a little easier to see that about 60% little lower over here are ": [
            2049.3, 
            2073.1, 
            73
        ], 
        "chat with each other same time Pace to slow. I think that overall have to do with a course that we haven't gotten to what a lot of you may think alike the most exciting part about data science. So I hear you there people ask for a way to review lecture. They were confused by the programming portion. I totally understand all of the negative feedback. There are things ": [
            397.6, 
            416.9, 
            16
        ], 
        "clicker question whether or not what type of exploratory processes Give it a few more seconds. 3 2 1 Okay. So this is in fact the univariate the only variable we're looking at his age and we're looking at the count of 8. So this is an example of a univariate flat most of y'all got that and just wanted to make sure we had that terminology down. So we ": [
            1378.0, 
            1438.9, 
            57
        ], 
        "come to that conclusion? Pretty evenly distributed we don't see so they kind of are all over the place. They look pretty random. We don't see everybody up here and everything on here. It just kind of all random threw out there and that is absolutely correct. So there is no relationship here on the other one for those of you who said no relationship. We on the last one ": [
            3495.0, 
            3520.4, 
            124
        ], 
        "course are the readings were too long too boring to irrelevant. The quizzes were too hard. They weren't in class explanation and some people suggested that I provide interactive content rather than just the readings and I hear all of you for reading the report and we'll get back to that is too fast and paste is too slow. So I think as an instructor I could look at that ": [
            333.4, 
            356.0, 
            13
        ], 
        "course. We talked about descriptive analysis last lecture. And today we're going to start talking about exploratory data analysis, which is often referred to as Eda. The goal today is to explain why you should and need to do exploratory data analysis anytime. You are answering a question and to explain what steps you would do if I gave you a dataset to explore your data set. I said I ": [
            525.2, 
            555.1, 
            22
        ], 
        "did at this floor to read analysis. I see these points that are different than the rest of the samples and I have his hypothesis that there's sample contamination. So what's going on, I simulated contamination 10% of the sample of there being a pure sample vs. 90% I would see some pattern like this. We're here. There's less agreement between the DNA RNA and hear there's more agreement and ": [
            2610.1, 
            2638.1, 
            94
        ], 
        "difficult. Where is it supposed to be more generalizable and can get you the longitude and latitude pretty quickly, which is what you would want to do if you want to put them on him at any other thoughts yet. Okay. So the argument here is that zip codes can be problematic. If you're expecting some format, like what we would use in the United States, but that is not ": [
            3027.7, 
            3056.0, 
            109
        ], 
        "do descriptive analysis and we were talking about descriptive analysis. It's why do we take all this information in the data that and summarize it into a number like mean or median? And that's because our brains can't interpret an entire dataset just by looking at it and his what do you think here is descriptive statistics data analysis. We're moving a Step Beyond just calculating means and medians and ": [
            819.5, 
            842.4, 
            34
        ], 
        "do they look to one another? What do I do if they don't look similar? There's probably contamination because we know that they're supposed to look similar. So when I look at that and measure how similar are they between the DNA in the RNA be more similar? They are closed today with D20 and suddenly I see three samples popping out. And so this help my hypothesis. So I ": [
            2589.5, 
            2610.1, 
            93
        ], 
        "do you have missing data is that at random people just choose not to answer a question or is there a reason why you're systemically missing information about some of your individuals in your data set? Yes, I'm looking for outlier values are people Way Too Tall or way too short for you expected you're calculating those numerical summaries. So you still do calculate descriptive statistics your means. Your meeting ": [
            863.9, 
            885.5, 
            36
        ], 
        "doesn't differ a pun with in category? I'm up gender selection. Okay, same will go through. He's a little quicker as we start looking at it. I have somebody take a look at this and let me know what they see in this plot. Feel free to chat with each other. I'll give you like 40 seconds. All right. What do you see here? What do you conclude? A lot ": [
            1815.8, 
            1905.3, 
            68
        ], 
        "employed full-time across the categories. So sometimes when you're comparing groups that have different numbers in those groups, it's helpful to look at proportions rather than the wrong account. I think it ever had a great little easier to see that it's about 60% each of them when we're looking at proportion rather than raw count. All right, so I'll open it up. What type of exploratory plot is this. ": [
            2073.1, 
            2096.6, 
            74
        ], 
        "field. Lots of ways were people at London university courses. This is increasing over time many people are self-taught and there's a lot of people who have taken courses online to improve what they already know other people learned at work Chicago competitions or has some other way. And we can look at the titles of the survey responses to what is your job title. So unsurprisingly as this was ": [
            2332.9, 
            2356.1, 
            81
        ], 
        "for me? We're getting towards the end take a look chat with each other and let me know what you take away from it. All right. There's a lot going on here. What's one conclusion you drew from looking at this graph? That's hard to draw conclusions from this that is really hard to determine whether or not Dismount. This was different total versus that's okay. I'll give you the ": [
            3777.1, 
            3855.5, 
            135
        ], 
        "from this was that it would be helpful to have actual name down here because surprisingly I double check if he died. So easy is not economics best engineering and Ian is economics. I think or some of the codes didn't make sense intuitively with what they would be so it would be helpful to have Better Label. I think that is a great conclusion. It would also be helpful ": [
            3937.7, 
            3956.5, 
            137
        ], 
        "had a Canadian postal code would not have been able to enter data because we were required to be numeric based on our assumptions. So let's instead use Hometown. We do location based on what people said here to determine what their Hometown was anybody who had a typo here that could not be found or had a location that was found in multiple places, but didn't specify what else ": [
            3202.1, 
            3221.6, 
            116
        ], 
        "have an idea that most people answer the survey or in their twenties, but we do have a range from younger than 20 up to possibly hundreds of mostly up to 80 ish. Anything about this one? Look at the exies. What is the general pattern? Is there anything funny about this plot? Stephanie Talbot each other Eddie wants to walk me through the axes and a general pattern. Okay. ": [
            1438.9, 
            1520.8, 
            58
        ], 
        "have any questions you thought you got right? And this is just how many you thought you got right? 458 who responded versus how you actually did if you guess right you would follow along this black line so you can see a few people were right along where they thought they would be a few people thought they did much worse than actually did a few people did a ": [
            265.8, 
            284.9, 
            10
        ], 
        "have problems but now we have a map here again, we have size of circle and we can see based on location rather than just a zip code. Where are students come from? I didn't seem pretty cool map showing that y'all come from lots of different places all over the world, but it's likely reflects more what you expected to see based on where you grew up. So this ": [
            3221.6, 
            3241.5, 
            117
        ], 
        "have to spend time cleaning and matching back up to where it at the end. And if you want to do something like a Okay. So there are you here is home town could be have typos in it. And then you have to spend more time going through seeing which ones didn't Matt back and why and figure out what they meant for the cleaning. There can be super ": [
            2998.4, 
            3027.7, 
            108
        ], 
        "helps me know what not to change in the future and then hear the negative feedback is really really helpful to me to so this is the most common feedback that I got on at the mid course survey. I'm going to briefly go through what they were and then talk about what my plan is. The first one this is by far and away the least-liked part of the ": [
            313.1, 
            333.4, 
            12
        ], 
        "histogram a density or a bar plot all the types of visualizations. We looked at all ready to look at a single variable. Bivariate is using 2 and look in the relation to variables and looking at the relationship between them. This is where you would use a box plot a scatter plot a group flower pot or a Crock-Pot to use one variable that's quantitative along the y-axis and ": [
            938.5, 
            961.0, 
            39
        ], 
        "hundred which might be somebody who is a hundred and it might be somebody who entered their age because I didn't want to be identified. These are survey data. So we can't verify that ever be answered truthfully. We know from the data from this class that when we asked height, I think I was Maria somebody say they were 666 in you don't have to answer truthfully and that's ": [
            1298.3, 
            1319.8, 
            53
        ], 
        "in a second. So you wouldn't typically want to figure out why are on different scales and get all the information on the same scale as I'm just going to look at places where GTA with less than five so we can start to look at those individuals were GTA was on a similar scale between the two. So here we have GPA we have height and we have each ": [
            3407.1, 
            3429.9, 
            122
        ], 
        "individual pointed as it as a point on the plot. Now we've done that. What can we conclude about the relationship? every few more seconds Cancel Mason in decision on this one by a few people 3 2 1. More of you said that there is no relationship and explain to me how they came to a conclusion. What on the pot? What did you look at? What made you ": [
            3429.9, 
            3495.0, 
            123
        ], 
        "is your standard deviations. You look at with most common and you generate plus now to start exploring the relationships in tables still count Prosser great tables also are helpful in exploring. The relationship between variables are awesome. This is grayed out cuz we're not going to talk about it in detail. But sometimes you need to transform your variable so that data can be used to do the typing ": [
            885.5, 
            908.3, 
            37
        ], 
        "it takes a while for us to look at this and figure out exactly what's going on on Thursday were going to talk about ways to improve that and to make plastic better, but we're doing exploratory analysis. You're sitting there your computer looking at the spot you have time to figure out what's going on and look at each of the groups. We'll do a few more of these ": [
            2202.6, 
            2221.3, 
            78
        ], 
        "it's similar between males and females and then how did you determine that? Similar shape so you're saying there's more people here and in more out here. Is there a way that it would be easier to make that conclusion cuz I'm definitely the right conclusion, but that doesn't necessarily come through because RX taxis are different numbers here. Some guys are just as when you have different numbers within ": [
            2025.6, 
            2049.3, 
            72
        ], 
        "know the details of this. These are something called PCA I say cluster, but it allows you to get a snapshot of the entire day when there are lots and lots of variables and lots and lots of observations just by looking at a few dimensions of data. We're going to bury. We five area trees dimensionality reduction as all possible ways to do exploratory data analysis. As a cautionary ": [
            982.1, 
            1009.8, 
            41
        ], 
        "learning and data science survey of 2017. So this is an industry-wide of the data science Industry survey where they had more than 16,000 responded and they had up to 220 a multiple choice questions that they could have answered and you say that we're going to use today. This is a quick snapshot of it because the individuals are in Rose. We have any information about gender country age ": [
            1092.3, 
            1117.7, 
            46
        ], 
        "let me know what you think of this plant where you'd like to see what's confusing. All right, what's the difference between display and the last one? What do you conclude? What do you see here? What's going on? Okay. See you looking across and you see that it's broken down by the gender selection and you're looking right where you mention that female and male then you're saying proportionally, ": [
            1941.6, 
            2025.6, 
            71
        ], 
        "like there. She said is this what we expected? Okay right now data science as a new field. There are a lot of jobs for younger people and there are lots of higher level jobs at 10 to go to people with more experience. So this may be true, but you need to start thinking about that as you're looking at the distribution. Okay will quickly go back to the ": [
            1359.9, 
            1378.0, 
            56
        ], 
        "little worse than they thought they had. So I was just curious to see how this would look and I didn't exactly know how y'all with you. Okay? So I lost through exam. Any questions about exam scores questions on the exam. So I'm going to briefly talk about the mid-course survey as people on settle in. Thanks, everything answered very positive feedback helpful. And I sent before that that ": [
            284.9, 
            313.1, 
            11
        ], 
        "look at a distribution of single variable the relationship between them to get a real sense of how I date is that all fits together? So I'm going to use to explain to you how to do is I'm going to use three teeth. That is today. The first one we're going to look at a bunch of pots from a large dataset and it came from the castle machine ": [
            1074.8, 
            1092.3, 
            45
        ], 
        "look at the colors go across figure out how it differs from one. Sure to the other I'm going to go through this quickly as we're getting toward the end that we have mostly first years in the course, but I'm giving people that are not in the first and fourth year, but we don't have 15 of them displayed. If I look across the years and again look at ": [
            3973.9, 
            3993.5, 
            139
        ], 
        "looking at a lot of parts that you could generate a within a few minutes. You have a better understanding of what's going on in the dataset. Okay. Any questions about the categorical example? This next one is a kind of specific one. And I don't think I would be a professor if I didn't talk about my own work at some point in the course. So the details don't ": [
            2418.8, 
            2441.2, 
            85
        ], 
        "looking for work, so there are people in data science looking for jobs, but overall a lot of people are employed and this is emblematic of the field there alot of jobs black people getting jobs. Sometimes they're hard to get but they're out there and most people who took the survey are employed. What if we take a look at this one? What are we looking at now other ": [
            1920.9, 
            1941.6, 
            70
        ], 
        "matter time. You don't need to know anything about genetics understand example, but I'll just explain experiment very quickly. So we had autism France from individuals affected with autism and we had a brain from individuals who are not affected with autism to access controls and our goal was to look at the differences between the two measures Optical RNA level. It doesn't matter what that is, but we just ": [
            2441.2, 
            2460.2, 
            86
        ], 
        "my teaching perfect is it matters to me that it's not wildly different between Majors or years or gender because I just like being an entry-level class. I want everybody to get something out of it. It don't matter to me if some people are not So I took the iclicker responses. So the percent new and I joined them with information from your roster. So what major you have? ": [
            3693.5, 
            3714.8, 
            131
        ], 
        "next to each other and we can see here is on the conclusion Patti Drew on the last ones by looking cross. If I don't hear that employment is similar across the different groups except attire for men and slightly lower for those who chose not to give their gender on the survey. So sometimes each other is a little more helpful. There's still a lot going on here and ": [
            2181.0, 
            2202.6, 
            77
        ], 
        "not a few people that are doing much better than everybody else in the course of a few people that are doing much worse in the course, which would be a problem. If you did not do as well on this as you would have like there are other things in this class to get points on but I'm happy to chat and office hours. Go to office hours for ": [
            228.7, 
            244.7, 
            8
        ], 
        "nothing up here that tells me whether or not my podcast is going to work. So hopefully that will in the future design system. Remember that there should always be feedback to the user to let them know things are attached correctly. I have reached out to it for both the times that the audio podcast Audio Only podcast happen and they are looking into it and can't give me ": [
            436.1, 
            457.2, 
            18
        ], 
        "numbers. So if you were Canadian, you would not be able to put your ZIP code in there. I also for that map utilize only ZIP codes in the United States, which if you hadn't taken into account the fact that you were using a dataset to match for longitude and latitude that were only in the United States that you would get some problematic Mac going on anybody who ": [
            3182.3, 
            3202.1, 
            115
        ], 
        "of a child you then start looking through those people also of Ages that are less than 18 to use information in the state of that. That is not what you anticipated. That's what he would start to find out in an exploratory data analysis. Mention this before when you're doing a descriptive and exploratory analysis, you are understanding the ins and outs of every part of your data set. ": [
            602.2, 
            624.5, 
            25
        ], 
        "of analyzing data just got rid of to the point when you're getting rid of people from your now since you're really taking into account whether or not that's the right call and there was a free response for a different identity and these are kind of all over the place but there a lot of people that were removed from the analysis just by simply choose a different gender ": [
            1627.8, 
            1644.9, 
            63
        ], 
        "of people employed full-time for you look down here at the employed full-time and he looked at the x-axis and saw that there were a lot of people in this is the biggest box this probably stood out a lot cuz this is much bigger than all of this and that's what we're looking at employment here. And you say that the second most frequent category is not employed but ": [
            1905.3, 
            1920.9, 
            69
        ], 
        "of properties. What are the distributions about your variables? How do they relate to one another in doing that you discover patterns when one thing increases that something else increase are they not related? Did you think they would be related as you start understanding the data properties and discovering patterns in your data your stinking about how this will affect your now I'm going to go through all this ": [
            679.0, 
            700.3, 
            28
        ], 
        "of those arguments follow up. So the argument here is if you put in Hometown and just put in San Diego. What if there's another San Diego in Texas or California and I didn't specify how to say it. So you could have in San Diego, but we don't exactly know where that is. So I could be a problem with Hometown and the other thought is a Kik. You ": [
            2968.2, 
            2998.4, 
            107
        ], 
        "on a single find it when you submit to Grade School Cesar to help you get practice with python. They were previously just released in discussion. I realized another Rico's to discussion. So I posted them on Triton Ed the second one can be worked on in section this week and I'll post their answers on Trey night as well. Just a side note that it's not really important this ": [
            70.8, 
            94.0, 
            1
        ], 
        "only a few people got a right that question. Everybody was Mark right on the exam. This question was just a bad question. Sometimes I spend a lot of time on exams and think that they're all really really great question and I look at it see what is confused and realize that it was not a great question after all the every got that one right? This one here. ": [
            163.7, 
            181.2, 
            5
        ], 
        "or hoped to see or that would make your boss upset. You don't get to go back and start removing samples to make things look better so you can't go back and remove Staples to improve the correlation or to get an answer you one or two make something significant. This is up front to make you understand urinalysis, but you can't just go back and start changing things so ": [
            2769.5, 
            2789.9, 
            101
        ], 
        "or the 30 questions that were on the exam? So that's what the y-axis is how many questions and then what percentage of the class got the right to get a histogram and you can see that it's somewhere between 75 and 100% of the class. Got it. Right when I'm looking at this. I'm looking down here to see which questions I wrote that either I could have been ": [
            119.6, 
            140.0, 
            3
        ], 
        "out of analysis you and intended. A lot of times people breakdown exploratory data analysis based on whether or not you're looking at a university it by vereador dimensionality reduction. And this is just so you've heard the terms and you're familiar with them and we'll do some clicker questions to check on this if you're just looking at a single variable. This is a univariate exploratory data. Use a ": [
            908.3, 
            938.5, 
            38
        ], 
        "places where we're looking where they differ between the two with the idea being that individuals that we can start to understand what's going on in the brain defect with autism if we were to carry out this experiment Any questions on that? Control Brands autism Brands looking for differences at a hundred thousand different places. So this is an example of dimensionality reduction. You don't need to know details. ": [
            2480.5, 
            2503.2, 
            88
        ], 
        "points and you can see that as one increases. So does the other name of this somewhat linear relationship between the two? Boostane descriptive statistics also describe all four of these dataset. So this one is linear. This one is not as we have the curve here at this one is driven by a single outlier and here almost all of them have the same bear value in X. I'm ": [
            1031.5, 
            1054.0, 
            43
        ], 
        "pretty quick idea of where people in college 9 came from All right. What are we going to know whether or not students tend to have taller students tend to have higher GPA? Okay, take a look at the map figure out what the axes represent figure out the general pattern and let me know if there's anything funny about this spot before your child each other. What do you ": [
            3261.0, 
            3281.6, 
            119
        ], 
        "proportions because Juniors and seniors tend to assume the information before so this is something you might expect as these people haven't had more classes here overall. And then as standard we have more males in this class than females and the distribution looks a little different here and I don't have answers as to why but we can see that male tennis a less information was new to them ": [
            3993.5, 
            4016.9, 
            140
        ], 
        "range. How does a breakdown by Major? So this is the only part where I'll show you people less than 15 and these are all the different majors of people sitting in this course. Data science is the most common. So now when I start breaking down into categories, I'm only going to include those Majors were there more than 15 individuals from that? So who wants to interpret this ": [
            3753.1, 
            3777.1, 
            134
        ], 
        "really many people down here. Very small bars here. There are few, but not very many. What else did you conclude from this There's a spike around 50. So that's one of those. Is there anything funny so that should stick out to you as OK Swedish General downslope, but we do have this bike here and I'm at a point that we have somebody up here who is a ": [
            1276.7, 
            1298.3, 
            52
        ], 
        "reflective of the field and data science were most people around 25 and we have fewer and fewer. People as we get older, so if you think this is likely reflective of the field raise your hand. Okay, so we have more than half raising your hand and I the most likely true but didn't use it as things you should be thinking about as you were looking at data ": [
            1341.5, 
            1359.9, 
            55
        ], 
        "relationship between height and GPA? That's the next question? So what can we conclude? About the relationship between height and GPA. Give it a few more seconds. 3 2 1 I really pretty even split. Welcome back to this because we're going to do something quickly. We're pretty evenly split about whether or not there's no relationship or can't be determined will come back to us and talk about both ": [
            3345.5, 
            3407.1, 
            121
        ], 
        "relative to females. This is something you might want to break down within major is a year to really start understanding this trend we can see that more males have less was new and that's email 10 to shift towards a more information being now. Replay we watch American Horror Story analysis that there was less of the new material with new tend to be data science and Fiat Juniors ": [
            4016.9, 
            4040.6, 
            141
        ], 
        "same information on the proportion scale. I want to hear one conclusion from somebody in the class. So to chat with each other. Let me know you take away from this graph. Are you at the conclusion? They took from this grass? Science students based on this red orange on being there for that new tend to be a little bigger than the other group other conclusions. You can draw ": [
            3855.5, 
            3937.7, 
            136
        ], 
        "say? All right, who wants to explain to me? What's going on here? Okay, so they are pointy ears that GPA 10 Samuel appears to be on two different scales that a few people were maybe on a hundred point scale or some other scale where a lot of people are down here closer to the euro. I'm so because of that can we determine what's going on with the ": [
            3281.6, 
            3345.5, 
            120
        ], 
        "since I some people think it's too fast some people think it's too slow. I must be doing everything right and I don't think that's the case. I think it can simultaneously be too fast and if he pays can be too slow, so As a timer I grew up in Philadelphia that lives in Baltimore for 10 years and people in that region of the country are known for ": [
            356.0, 
            376.8, 
            14
        ], 
        "so we know that there are more points here with zip code. We can't really see the size difference. I know problems with this map. Anybody feel like their data is not being included in the state of set. Maybe okay. What is a mention I stepped aside intentionally that I wanted a numeric zip code. However Canadian post postal codes do not have only numbers they have letters and ": [
            3154.0, 
            3182.3, 
            114
        ], 
        "something to keep in mind. This is a survey of people in Industry who had data science jobs. So it makes sense that we don't have a ton of young people. What do you think about the fact that most people are around 25 do we think that this is reflective of the field stands on that? I let's do a vote will say if you think of this is ": [
            1319.8, 
            1341.5, 
            54
        ], 
        "speaking very quickly. I am known for speaking even quicker than people in that place where people speak really really fast so I know this and I'm working to slow down. I'm not there yet. So I'm going to work for the rest of the course to try to take more positive to give you all more time to think about it. When I ask you a question and a ": [
            376.8, 
            397.6, 
            15
        ], 
        "suddenly I see these three samples are up here with the highly contaminated samples in my experiment. Okay. So how do samples father's contamination? They look different than the rest of the samples. I had to figure out why it looks to me like they're sample contamination. I'm so what would happen if I didn't remove them from analysis? I got to remember we're looking for differences between DNA between ": [
            2638.1, 
            2658.9, 
            95
        ], 
        "tending toward young. So that's what we saw in the last thought that they tend to be somewhere around 28th. And then by looking at the sticker black barn metal, which is the median and so that is a measure of the median within group and we can see that it's pretty confident. It's it's a little lower for females. Do you start to get a sense that the age ": [
            1797.8, 
            1815.8, 
            67
        ], 
        "than the one he chose to analyze next next to take a look. I know some of the font is small. Casual in this lecture cuz these are just exploratory pots and I'll posed to be the prettiest place I've ever seen but they're supposed to start telling you the story of what's going on with the data. So take a look at what's the general pattern anything funny about ": [
            1644.9, 
            1664.8, 
            64
        ], 
        "that you get the answer you wanted there's a famous quote from The Economist. That's if you torture the data long enough, it will confess if you go in and manipulate things remove samples change variables transform things that you hadn't planned on transforming follow. This can change your answer, but you can't do it after the fact you have to decide beforehand how you're going to analyze your data. ": [
            2789.9, 
            2807.5, 
            102
        ], 
        "the 16000 responded. The median age is around 25 closer to twenty that they're likely some outliers and that if maybe is not representative the field that's something we want to check on we know that it is overwhelming the mail. Also something you want to see is whether or not this is representative of the field. We know the age is similar across standards. We saw that in the ": [
            2379.1, 
            2398.8, 
            83
        ], 
        "the date and how they relate that you can then determine whether or not the way you intended to analyze the data is appropriate. I got your checking those assumptions the whole time. I mention that do you have height of individuals that are outside what you would expect do you have ages that are outside. Our thing is coded as you expect them to be are the things that ": [
            721.7, 
            741.4, 
            30
        ], 
        "the direction of exploring the date of fully so that we can get to the scientific hypotheses. Not just word of the day to look like but how are they all related to one another in the entire data set? Okay, so when you're doing an exploratory analysis the first thing you'll do and we talked about this already is look for missing values and look for outlier values. So ": [
            842.4, 
            863.9, 
            35
        ], 
        "the ones we talked about Python and are at the programming language is SQL is a way to access on relational data in database. Is there a lot of people use the Far and Away those are the three most frequently used by data scientist? I'll walk through these briefly. These are similar to actually already looked at over here. We have how people learned before entering the data science ": [
            2311.2, 
            2332.9, 
            80
        ], 
        "the other dimensions, I start to see some point separating out and there was some to get far enough away that I'm confident enough to say that these are outliers. So it's far enough away from the rest of the group that I start to look and all colored and red and three different samples are identified here. This sample is the same as the sample suddenly. I see that ": [
            2526.3, 
            2549.4, 
            90
        ], 
        "the pot? Who's ready to explain taxis in the pattern? everyone explain the activities help for getting tired, but it has a distribution of the relationship between the two variables with looked at so far age and on the bottom of that gender select. There's one more category that was in the previous. What do the people who didn't respond and there was because their information were code is sna ": [
            1664.8, 
            1766.7, 
            65
        ], 
        "the same format that is used worldwide. So if we specify a format we want a zip code without taking into consideration, that could be problematic. So let's take a look. Sabrina care zip code 69 people did not respond to and Hometown 25 dances. So we're already seeing that there is maybe some issue cuz I couldn't think of a good reason why I zip code and hometown would ": [
            3056.0, 
            3082.0, 
            110
        ], 
        "the same if you think it's different raise your hand good while still awake OK as a go go in. So don't look at the comparison between his we're looking at the proportion here. So the fact is that we're now on the same scale and we see that there are more people do not have siblings and also do not have pets so that answers our question there. Now ": [
            3650.6, 
            3672.6, 
            129
        ], 
        "the survey intentionally so that we could have this discussion today to using zip codes. What I did was I took the zip codes map them to longitude and latitude and I counted how many people fell into the zip code and I parted each place on a map. And this is what I got. So you have longitude and latitude. We have a point where people are found with ": [
            3104.9, 
            3126.5, 
            112
        ], 
        "then we're getting all of this data if samples were to mix when I was happening. What would that look like? So details, not super important. We had two different measurements from each sample. So we had DNA and RNA and you should look similar based on what we know about biology so I could die if I take the DNA and I take this these samples hear how similar ": [
            2569.5, 
            2589.5, 
            92
        ], 
        "then we're looking at employment within genders. Are there only two variables because of that. It's a bivariate pot. The last time we went we just looked at you fast. When we look at the count of people employed within each gender. Then we looked at the proportion. Do you still have to look across five different plots and make the comparison? So sometimes it's helpful to put them all ": [
            2158.2, 
            2181.0, 
            76
        ], 
        "then you break it down by a categorical variable along the x-axis. Dimensionality reduction is something we won't talk about a time in his course, but there is a way to take a very large high-dimensional data set and projected into a lower dimensional data that so you can get an idea of what's going on. Your data sets, but only looking at an actress or two, you don't even ": [
            961.0, 
            982.1, 
            40
        ], 
        "there anything fun? Play about the spot and then we'll talk about it will come back to the clicker question. So I'm going to do a lot of asking you all to respond and less with the clickers today. So I think about these and then be ready to explain in a minute what the ashes represent what the general pattern is. And if there's anything funny about the plot. ": [
            1155.1, 
            1171.4, 
            49
        ], 
        "there are samples that look different than the rest of the samples in the date of that. And I'm going to Venn look for differences between individuals autism and control sample. I need to know why these samples look different than everybody else and I thought to myself a nation could be what contributed to that so I know the people are in a while and their pipetting stuff and ": [
            2549.4, 
            2569.5, 
            91
        ], 
        "this last one was because of my own interest. I ask you a question in class about how much of the information so far has been new to you. This is after the programming lecture. So these are all the topics we've covered up to that point. I showed it in class. We had this kind of flat distribution with some increase in people in the 2260 range, but for ": [
            3672.6, 
            3693.5, 
            130
        ], 
        "tired. We looked at so many grass. So we'll do our hands on this one before we move on to the next one. So. Maximum points if you think that more. That is the same between will do this. But okay will do. If you think it's a shame that people have siblings also have pet at the same rate raise your hand. All right, we got that. These are ": [
            3629.2, 
            3650.6, 
            128
        ], 
        "to do my very best to slow down and to take pauses and to let you all talk and think about the stuff that I'm saying due to my work speed speech some working on that include programming. I think the last one went a little better we slow down there was directed ideas for what to do during the programming portion. And so I'm still working on improving that ": [
            480.8, 
            502.6, 
            20
        ], 
        "to have fewer colors does the colors make it kind of hard to figure out what's going on. I'm able to order these in some way we can see that over here. We have a lot of people in the middle range, but that's probably the place where it's the largest over here and in Psychology, we have people wear a lot of information is new really just trying to ": [
            3956.5, 
            3973.9, 
            138
        ], 
        "variables and starting to figure out whether or not what you're seeing is what you expected to see whether or not their relationships you didn't anticipate. This is now in the realm of exploratory data analysis. I give you a data set and say that we have information from adults in the United States and they have been surveyed. If you didn't go and see Heights that would be indicative ": [
            577.6, 
            602.2, 
            24
        ], 
        "we had on his outlier to couldn't really determine what the relationship was because everything was compressed. Do you need to get everything on the same scale or remove the outliers before you can determine that there's no relationship and there is a physical ways in which you can put numbers on this and determined that is pretty darn flat but the height and the GPA do not seem to ": [
            3520.4, 
            3539.5, 
            125
        ], 
        "we put those together? What conclusions do you draw here when you take a look? Imma show the same plot just a little differently here and see what conclusions we draw here. What's the relationship between people in his class with siblings and those who have pet? Is it right the same between them to the differ? Who's more who's left? I know it's getting later in class. People are ": [
            3569.8, 
            3629.2, 
            127
        ], 
        "went to look at all the places within your brain that we could measure this do the values differ between individuals with autism and those who are not affected with autism and we had 71 sampled and then we had a hundred thousand measurements. So the assumption is that these values wouldn't differ that would be similar across most of them and we're looking for those places of those 100,000 ": [
            2460.2, 
            2480.5, 
            87
        ], 
        "weren't included in the other pot. So there's even more people that we had been out if we hadn't if we just analyzed female and male what are they saying about the overall trend in age across the categories? Similar very different a lot. Not sure. Okay, and how did you determine that? Okay. So you do a conclusion over there is that they're pretty similar across and they're all ": [
            1766.7, 
            1797.8, 
            66
        ], 
        "where you're seeing. What is in your data science how it all relates to one another? What is what you expected? What is what you didn't expect and it's your job to figure that out for your entire data set. So you think about what can the data tell us? This is why you're answering when you're doing idiot. More specifically when you're doing Eda it's to understand the date ": [
            647.9, 
            679.0, 
            27
        ], 
        "why is worth So important if you have outliers and they're driving your differences, you're going to report things that are untrue and you don't want to do that. So in this example, we learned that sample contamination is likely the culprit and these three samples and if those that have been removed from analysis, we would have reported it a completely different set of RNA that difference between Autism ": [
            2721.3, 
            2744.8, 
            99
        ], 
        "with example today, but they did as you're exploring your data. You'll then start thinking about what your hypothesis is has it changed now that you've seen the data and how will you go forward as you understand the data, I mentioned before that the distribution of your data set the shape that your data takes affect how you will analyze the data. So once you understand the shape of ": [
            700.3, 
            721.7, 
            29
        ], 
        "would show this for most of the lectures going forward last time. We said if you summarize the data and just calculate some descriptive statistics, how many samples do you have? What's the mean? What's the median with standard deviation? What is the distribution look like you're doing a descriptive analysis if you delve in further and do an exploratory analysis where you're starting to look at the relationships between ": [
            555.1, 
            577.6, 
            23
        ], 
        "you a lot of people from Southern California with you. Lots of people are from here in central people throughout and then we see what the size of the circle is proportional to the number to that live in that plot in that spot. All right. So what's going on here any problems with this? Yeah. Okay, so this isn't very clear at this doesn't mean you can't really match ": [
            3126.5, 
            3154.0, 
            113
        ], 
        "you all at the beginning of the course. We talked about this last lecture if they were 275 people that responded there were I think 19 variable that I've included in this data set and then she has how many people chose not to respond to each of these categories will come back to that in a in a bit. I want to know where my students grew up. I ": [
            2837.6, 
            2859.5, 
            104
        ], 
        "you are included in this despite there being more and the same information goes for you this year and major because I only want to include in places where people are more than 15 read the numbers 1 and 15 for identify ability reason and I drew the grass. So this is that same thing. I just showed you we see more people in the 20 to 60% new information ": [
            3733.7, 
            3753.1, 
            133
        ], 
        "you wouldn't make a plot for a hundred thousand book. They're all hundred thousand. So if I didn't know about this outlier, I would have said hey, this is something that's difference between Autism cases and controls. Let's go investigate that further or it's in the other direction to wear. These outliers said it was less significant and then it was significant when the outliers are removed. So that idea ": [
            2700.0, 
            2721.3, 
            98
        ], 
        "you're starting to see what is most important. So you're generating lots of some of which you would then use later on to show results. At the end if you don't display your data you could do an analysis that is completely worthless and not true and should could have been avoided had you done all of it. So don't be the person who were back there. Now. It says ": [
            761.5, 
            782.9, 
            32
        ], 
        "your t a r i a chat about what you're confused about and we can hopefully get everybody to do better on the second exam. I will release the questions and the answers later this week so that we can take a look. This is just for provide. Well for me, it's fine. I don't know about all u i a Sunday named course survey. How many points do you ": [
            244.7, 
            265.8, 
            9
        ]
    }, 
    "File Name": "Introduction_to_Data_Science___A00___Ellis__Shannon_Elizabeth___Winter_2019-lecture_11.flac", 
    "Full Transcript": "All right, as people filter in will get started. So General course reminders as everybody gets seated for 3D assignment is due this Friday and your third assignment is due next Friday.  I open up please so assignments just a reminder. Most of you did this right do they should all be submitted as groups if your group is submitting two things, that's not right to make sure everybody is on a single find it when you submit to Grade School Cesar to help you get practice with python. They were previously just released in discussion. I realized another Rico's to discussion. So I posted them on Triton Ed the second one can be worked on in section this week and I'll post their answers on Trey night as well.  Just a side note that it's not really important this Thursday and next Tuesday topics have been flipped. I think it makes more sense to finish update of visualization this Thursday and then do entrance next Tuesday. And the exam first exam scores are on Triton Ed about data as possible. This is something may be a little different and how you would look at it if you started so I just wanted to describe to everybody here what's planet or the 30 questions that were on the exam? So that's what the y-axis is how many questions and then what percentage of the class got the right to get a histogram and you can see that it's somewhere between 75 and 100% of the class. Got it. Right when I'm looking at this. I'm looking down here to see which questions I wrote that either I could have been better or topics. I could have been explained better. I'm not going to talk about the specific questions because there are a few people were finishing up taking the the makeup midterm today and I don't think we say  Until everybody has taken it. Okay, is this one down here? That's almost everybody got wrong was a matter of semantics and I'll talk about that later. But this one because only a few people got a right that question. Everybody was Mark right on the exam. This question was just a bad question. Sometimes I spend a lot of time on exams and think that they're all really really great question and I look at it see what is confused and realize that it was not a great question after all the every got that one right? This one here. I anticipated being the hardest question on the exam it required you to remember Concepts from two different pictures and put them together in a single question, which are always the toughest points are part of an exam. So this one has not been marked correctly for everybody. So two questions, everybody got right on the exam right off the bat. Everything else was greeted as you'd expect. So there are 30 questions. Each one was worth 2 points. This is the distribution of all of your scores.  Play median and mean work so you can see that media and we're 50 points out of 60.  Enemy was right around the same 49.7 with a standard deviation of 8 points the mean and the median are really close to one another and to me this is good. That means there's not a few people that are doing much better than everybody else in the course of a few people that are doing much worse in the course, which would be a problem. If you did not do as well on this as you would have like there are other things in this class to get points on but I'm happy to chat and office hours. Go to office hours for your t a r i a chat about what you're confused about and we can hopefully get everybody to do better on the second exam. I will release the questions and the answers later this week so that we can take a look.  This is just for provide. Well for me, it's fine. I don't know about all u i a Sunday named course survey. How many points do you have any questions you thought you got right? And this is just how many you thought you got right? 458 who responded versus how you actually did if you guess right you would follow along this black line so you can see a few people were right along where they thought they would be a few people thought they did much worse than actually did a few people did a little worse than they thought they had. So I was just curious to see how this would look and I didn't exactly know how y'all with you. Okay?  So I lost through exam. Any questions about exam scores questions on the exam.  So I'm going to briefly talk about the mid-course survey as people on settle in.  Thanks, everything answered very positive feedback helpful. And I sent before that that helps me know what not to change in the future and then hear the negative feedback is really really helpful to me to so this is the most common feedback that I got on at the mid course survey. I'm going to briefly go through what they were and then talk about what my plan is. The first one this is by far and away the least-liked part of the course are the readings were too long too boring to irrelevant. The quizzes were too hard. They weren't in class explanation and some people suggested that I provide interactive content rather than just the readings and I hear all of you for reading the report and we'll get back to that is too fast and paste is too slow. So I think as an instructor I could look at that since I some people think it's too fast some people think it's too slow. I must be doing everything right and I don't think that's the case. I think it can simultaneously be too fast and if he pays can be too slow, so  As a timer I grew up in Philadelphia that lives in Baltimore for 10 years and people in that region of the country are known for speaking very quickly. I am known for speaking even quicker than people in that place where people speak really really fast so I know this and I'm working to slow down. I'm not there yet. So I'm going to work for the rest of the course to try to take more positive to give you all more time to think about it. When I ask you a question and a chat with each other same time Pace to slow. I think that overall have to do with a course that we haven't gotten to what a lot of you may think alike the most exciting part about data science. So I hear you there people ask for a way to review lecture. They were confused by the programming portion. I totally understand all of the negative feedback. There are things I want classroom or technical there's an issue with the audio only podcast really briefly explain how this works before the quarter starts. I tell you that the I want my course be podcast it and then I get up here.  Is everything and I'm supposed to expect that the podcast is going to work and I'm going to run right at sometimes it works at all. But there's like nothing up here that tells me whether or not my podcast is going to work. So hopefully that will in the future design system. Remember that there should always be feedback to the user to let them know things are attached correctly. I have reached out to it for both the times that the audio podcast Audio Only podcast happen and they are looking into it and can't give me anything more than that other people want more feedback on assignments and dislikes to get lecture, So the stuff that's actual now. This is stuff for the future but doesn't really affect you a time for the 4th and 5th reading. I already told you for the fourth reading I cut the reading and 1/2. I'll do the same for the 5th reading we'll just have one reading there.  Going to do my very best to slow down and to take pauses and to let you all talk and think about the stuff that I'm saying due to my work speed speech some working on that include programming. I think the last one went a little better we slow down there was directed ideas for what to do during the programming portion. And so I'm still working on improving that and I've asked 48 Anaya to give you all a little more feedback on your assignments this time going forward whether or not it's positive or negative. Just make sure you have some personalized be back on your signment.  So as of now, you're halfway through the course y'all have done a lot so far and we will continue on doing data visualization and Analysis for the rest of the course.  We talked about descriptive analysis last lecture. And today we're going to start talking about exploratory data analysis, which is often referred to as Eda.  The goal today is to explain why you should and need to do exploratory data analysis anytime. You are answering a question and to explain what steps you would do if I gave you a dataset to explore your data set.  I said I would show this for most of the lectures going forward last time. We said if you summarize the data and just calculate some descriptive statistics, how many samples do you have? What's the mean? What's the median with standard deviation? What is the distribution look like you're doing a descriptive analysis if you delve in further and do an exploratory analysis where you're starting to look at the relationships between variables and starting to figure out whether or not what you're seeing is what you expected to see whether or not their relationships you didn't anticipate. This is now in the realm of exploratory data analysis. I give you a data set and say that we have information from adults in the United States and they have been surveyed. If you didn't go and see Heights that would be indicative of a child you then start looking through those people also of Ages that are less than 18 to use information in the state of that. That is not what you anticipated. That's what he would start to find out in an exploratory data analysis.  Mention this before when you're doing a descriptive and exploratory analysis, you are understanding the ins and outs of every part of your data set.  So again, we're right here in the middle of the data science process. We've talked about this up till now and then next lecture will talk about communicating and then we'll sign the rest of the time talking about how to analyze your data.  Surface on from Durant. Okay, who you all read about in the 50 years of data science first reading ETA is your detective work? This is where you're seeing. What is in your data science how it all relates to one another? What is what you expected? What is what you didn't expect and it's your job to figure that out for your entire data set.  So you think about what can the data tell us? This is why you're answering when you're doing idiot.  More specifically when you're doing Eda it's to understand the date of properties. What are the distributions about your variables? How do they relate to one another in doing that you discover patterns when one thing increases that something else increase are they not related? Did you think they would be related as you start understanding the data properties and discovering patterns in your data your stinking about how this will affect your now I'm going to go through all this with example today, but they did as you're exploring your data. You'll then start thinking about what your hypothesis is has it changed now that you've seen the data and how will you go forward as you understand the data, I mentioned before that the distribution of your data set the shape that your data takes affect how you will analyze the data. So once you understand the shape of the date and how they relate that you can then determine whether or not the way you intended to analyze the data is appropriate.  I got your checking those assumptions the whole time. I mention that do you have height of individuals that are outside what you would expect do you have ages that are outside. Our thing is coded as you expect them to be are the things that are coded differently than everything else. These are the things your checking and exploratory analysis. You're also and we're going to do this today looking at lots and lots of clots as you're doing this and while all of the parts you generate an exploratory data analysis are not what you would eventually use to present to your boss or your co-workers for to anybody want to communicate your now you're starting to see what is most important. So you're generating lots of some of which you would then use later on to show results.  At the end if you don't display your data you could do an analysis that is completely worthless and not true and should could have been avoided had you done all of it. So don't be the person who were back there. Now. It says I'm going to show an example of it today where if you didn't do exploratory analysis and figure out what was going on with your data set you could report wrong findings.  Any questions so far about what exploratory data analysis that is why you would do it.  This quote is rejected. He's the same person we talked about before I looked at a quote from before about why we do descriptive analysis and we were talking about descriptive analysis. It's why do we take all this information in the data that and summarize it into a number like mean or median? And that's because our brains can't interpret an entire dataset just by looking at it and his what do you think here is descriptive statistics data analysis. We're moving a Step Beyond just calculating means and medians and the direction of exploring the date of fully so that we can get to the scientific hypotheses. Not just word of the day to look like but how are they all related to one another in the entire data set?  Okay, so when you're doing an exploratory analysis the first thing you'll do and we talked about this already is look for missing values and look for outlier values. So do you have missing data is that at random people just choose not to answer a question or is there a reason why you're systemically missing information about some of your individuals in your data set?  Yes, I'm looking for outlier values are people Way Too Tall or way too short for you expected you're calculating those numerical summaries. So you still do calculate descriptive statistics your means. Your meeting is your standard deviations. You look at with most common and you generate plus now to start exploring the relationships in tables still count Prosser great tables also are helpful in exploring. The relationship between variables are awesome. This is grayed out cuz we're not going to talk about it in detail. But sometimes you need to transform your variable so that data can be used to do the typing out of analysis you and intended.  A lot of times people breakdown exploratory data analysis based on whether or not you're looking at a university it by vereador dimensionality reduction. And this is just so you've heard the terms and you're familiar with them and we'll do some clicker questions to check on this if you're just looking at a single variable. This is a univariate exploratory data. Use a histogram a density or a bar plot all the types of visualizations. We looked at all ready to look at a single variable.  Bivariate is using 2 and look in the relation to variables and looking at the relationship between them. This is where you would use a box plot a scatter plot a group flower pot or a Crock-Pot to use one variable that's quantitative along the y-axis and then you break it down by a categorical variable along the x-axis.  Dimensionality reduction is something we won't talk about a time in his course, but there is a way to take a very large high-dimensional data set and projected into a lower dimensional data that so you can get an idea of what's going on. Your data sets, but only looking at an actress or two, you don't even know the details of this. These are something called PCA I say cluster, but it allows you to get a snapshot of the entire day when there are lots and lots of variables and lots and lots of observations just by looking at a few dimensions of data.  We're going to bury. We five area trees dimensionality reduction as all possible ways to do exploratory data analysis.  As a cautionary Tale the reason that we don't just look at this graph. The statistics is here. So what are they considered a data set that had 11 observations were one variable had a mean of 9 the other had a mean of 7.5 and a standard deviation was 1.23 and the correlation between them was .8  Those data seems descriptive statistics might look something like this where you had your 11 points and you can see that as one increases. So does the other name of this somewhat linear relationship between the two?  Boostane descriptive statistics also describe all four of these dataset. So this one is linear. This one is not as we have the curve here at this one is driven by a single outlier and here almost all of them have the same bear value in X. I'm a different reason why except for this one outlier over here. So this is why we generate the past because the numbers don't tell you everything you need to know how the points are actually distributed exploratory data analysis. Johnny Potts looking at what the data actually look like is what allows you to avoid making incorrect assumptions.  Okay, it's a general of exploratory data analysis. We do this to look at a distribution of single variable the relationship between them to get a real sense of how I date is that all fits together? So I'm going to use to explain to you how to do is I'm going to use three teeth. That is today. The first one we're going to look at a bunch of pots from a large dataset and it came from the castle machine learning and data science survey of 2017.  So this is an industry-wide of the data science Industry survey where they had more than 16,000 responded and they had up to 220 a multiple choice questions that they could have answered and you say that we're going to use today. This is a quick snapshot of it because the individuals are in Rose. We have any information about gender country age a lot of stuff about employment visuals learn the skills. They needed to be a data scientist what their current job is whether or not they're employed what languages that use with tools that use all of this is included in some 200 question and you were given the data set and asked to do something with it. The first thing you want to know is really what's in there and what information you have. So is it going to work if I'm going to show a pot and then I'm going to give you all a minute to look at it figure out what's going on. I'm will come back to that in a second and I want you to ask yourself three questions talk to your neighbor. What did axes represent what is a general pattern? And is there anything fun?  Play about the spot and then we'll talk about it will come back to the clicker question. So I'm going to do a lot of asking you all to respond and less with the clickers today. So I think about these and then be ready to explain in a minute what the ashes represent what the general pattern is. And if there's anything funny about the plot.  All right, who's ready to start explaining what the axes represent? I would love to hear from lots of different you today, but I know it can be scary to answer question in front of lots of other people. So I'll never call anybody a dozen other hand up, but I would love to hear from lots of different people. So where the axes represent.  Ada, okay. So age is along the x-axis here and then count here. Do you also want to tell me the general pattern?  Price of a lot of people clustered around twenty-eight or somebody else to tell me anything else that they've taken away from this spot.  Yep. Okay, so there are no really young people. I'm going to say you really young is like less than 16.  That is okay. So there's no not really many people down here. Very small bars here. There are few, but not very many. What else did you conclude from this  There's a spike around 50. So that's one of those. Is there anything funny so that should stick out to you as OK Swedish General downslope, but we do have this bike here and I'm at a point that we have somebody up here who is a hundred which might be somebody who is a hundred and it might be somebody who entered their age because I didn't want to be identified. These are survey data. So we can't verify that ever be answered truthfully. We know from the data from this class that when we asked height, I think I was Maria somebody say they were 666 in you don't have to answer truthfully and that's something to keep in mind. This is a survey of people in Industry who had data science jobs. So it makes sense that we don't have a ton of young people. What do you think about the fact that most people are around 25 do we think that this is reflective of the field stands on that? I let's do a vote will say if you think of this is reflective of the field and data science were most people around 25 and we have fewer and fewer.  People as we get older, so if you think this is likely reflective of the field raise your hand.  Okay, so we have more than half raising your hand and I the most likely true but didn't use it as things you should be thinking about as you were looking at data like there. She said is this what we expected? Okay right now data science as a new field. There are a lot of jobs for younger people and there are lots of higher level jobs at 10 to go to people with more experience. So this may be true, but you need to start thinking about that as you're looking at the distribution. Okay will quickly go back to the clicker question whether or not what type of exploratory processes  Give it a few more seconds.  3 2 1  Okay. So this is in fact the univariate the only variable we're looking at his age and we're looking at the count of 8. So this is an example of a univariate flat most of y'all got that and just wanted to make sure we had that terminology down.  So we have an idea that most people answer the survey or in their twenties, but we do have a range from younger than 20 up to possibly hundreds of mostly up to 80 ish.  Anything about this one? Look at the exies. What is the general pattern? Is there anything funny about this plot?  Stephanie Talbot each other  Eddie wants to walk me through the axes and a general pattern.  Okay. Okay. So I'm like the last one we were looking at count. We're now looking at $0.04 and as you pointed out that it's 80% mail and then everybody else is the other 20% anyting surprising funny. Is this what you expected about this plot?  So question is is it okay to call this in distribution, even though the bottom is not a quantitative variable. So it's still how the categories are distributed so it is but I see your point there so we can still talk about the back of the categories are distributed with most of them being in the mail category.  But you wouldn't refer to this as a like a normal distribution.  By show of hands if this is we're going to have to raise your hand if you are surprised by this despot.  I retrieve a few hands raise your hand if this is what you expected.  All rights, we have Ikat same as we expected a few things is not what you expected  So data science is an overwhelmingly male field that's changing over time. And it's something that I think at the undergraduate level we can do a lot to make sure that we're being inclusive of everybody else and not just mail. I also would have noticed that the person who generated this plot initially in there now since they wanted to look at how gender is Alexander differs among the server responded what they did was they just took the females and males going forward and this represent 16000 people, but I just want to mention that there's a hundred fifty nine people and 74 people whose voice is the purpose of analyzing data just got rid of to the point when you're getting rid of people from your now since you're really taking into account whether or not that's the right call and there was a free response for a different identity and these are kind of all over the place but there a lot of people that were removed from the analysis just by simply choose a different gender than the one he chose to analyze next next to take a look. I know some of the font is small.  Casual in this lecture cuz these are just exploratory pots and I'll posed to be the prettiest place I've ever seen but they're supposed to start telling you the story of what's going on with the data. So take a look at what's the general pattern anything funny about the pot?  Who's ready to explain taxis in the pattern?  everyone explain the activities  help for getting tired, but it has a distribution of the relationship between the two variables with looked at so far age and on the bottom of that gender select. There's one more category that was in the previous. What do the people who didn't respond and there was because their information were code is sna weren't included in the other pot. So there's even more people that we had been out if we hadn't if we just analyzed female and male what are they saying about the overall trend in age across the categories?  Similar very different a lot. Not sure.  Okay, and how did you determine that?  Okay. So you do a conclusion over there is that they're pretty similar across and they're all tending toward young. So that's what we saw in the last thought that they tend to be somewhere around 28th. And then by looking at the sticker black barn metal, which is the median and so that is a measure of the median within group and we can see that it's pretty confident. It's it's a little lower for females. Do you start to get a sense that the age doesn't differ a pun with in category?  I'm up gender selection.  Okay, same will go through. He's a little quicker as we start looking at it. I have somebody take a look at this and let me know what they see in this plot.  Feel free to chat with each other. I'll give you like 40 seconds.  All right. What do you see here? What do you conclude?  A lot of people employed full-time for you look down here at the employed full-time and he looked at the x-axis and saw that there were a lot of people in this is the biggest box this probably stood out a lot cuz this is much bigger than all of this and that's what we're looking at employment here. And you say that the second most frequent category is not employed but looking for work, so there are people in data science looking for jobs, but overall a lot of people are employed and this is emblematic of the field there alot of jobs black people getting jobs. Sometimes they're hard to get but they're out there and most people who took the survey are employed.  What if we take a look at this one? What are we looking at now other let me know what you think of this plant where you'd like to see what's confusing.  All right, what's the difference between display and the last one? What do you conclude? What do you see here?  What's going on?  Okay. See you looking across and you see that it's broken down by the gender selection and you're looking right where you mention that female and male then you're saying proportionally, it's similar between males and females and then how did you determine that?  Similar shape so you're saying there's more people here and in more out here. Is there a way that it would be easier to make that conclusion cuz I'm definitely the right conclusion, but that doesn't necessarily come through because RX taxis are different numbers here.  Some guys are just as when you have different numbers within categories is sometimes helpful to look at proportion. So this is that same plot and the conclusion drawn was correct that the proportion is similar about 60% between males and females but higher so now we're not looking at Raw count, but we're looking at the proportion within each gender that are within each category. Now, it's a little easier to see that about 60% little lower over here are employed full-time across the categories. So sometimes when you're comparing groups that have different numbers in those groups, it's helpful to look at proportions rather than the wrong account.  I think it ever had a great little easier to see that it's about 60% each of them when we're looking at proportion rather than raw count.  All right, so I'll open it up. What type of exploratory plot is this.  There are a few more seconds.  3 2 1  Okay, so the majority of y'all said be bivariate which is the correct answer and I can see why people said this I'm so let's just make sure we're all clear here. So they're only two variables that we're finding information about even though it's broken down into 5 pot with sliding gender, which is what each of these characterizes and then we're looking at employment within genders. Are there only two variables because of that. It's a bivariate pot.  The last time we went we just looked at you fast. When we look at the count of people employed within each gender. Then we looked at the proportion. Do you still have to look across five different plots and make the comparison? So sometimes it's helpful to put them all next to each other and we can see here is on the conclusion Patti Drew on the last ones by looking cross. If I don't hear that employment is similar across the different groups except attire for men and slightly lower for those who chose not to give their gender on the survey. So sometimes each other is a little more helpful. There's still a lot going on here and it takes a while for us to look at this and figure out exactly what's going on on Thursday were going to talk about ways to improve that and to make plastic better, but we're doing exploratory analysis. You're sitting there your computer looking at the spot you have time to figure out what's going on and look at each of the groups.  We'll do a few more of these because we haven't done one like this. You have to take a look at the exies and then let me know what conclusion you draw from this spot.  All right, who's drawing a conclusion from this plot?  What conclusion did you draw?  What are the tools most frequently used by data scientists?  All right with python and then we are and then we have sequel or SQL. So these are the ones we talked about Python and are at the programming language is SQL is a way to access on relational data in database. Is there a lot of people use the Far and Away those are the three most frequently used by data scientist?  I'll walk through these briefly. These are similar to actually already looked at over here. We have how people learned before entering the data science field. Lots of ways were people at London university courses. This is increasing over time many people are self-taught and there's a lot of people who have taken courses online to improve what they already know other people learned at work Chicago competitions or has some other way.  And we can look at the titles of the survey responses to what is your job title. So unsurprisingly as this was a survey of data scientist many people put that as their title, but there was lots of other titles that people have and when the end they identify as a scientist, this is really just to point out that you can do data science work without having the title of data scientist, you interpreted them and quickly have a much better understanding of the data that we know that amongst the 16000 responded. The median age is around 25 closer to twenty that they're likely some outliers and that if maybe is not representative the field that's something we want to check on we know that it is overwhelming the mail. Also something you want to see is whether or not this is representative of the field. We know the age is similar across standards. We saw that in the box plot that most respondents are employed and that the employment rates were similar across reporte gender, but not the same of know that among the four two genders males were employed at the highest rate.  What are pythons secret and are the three most frequently used tools and a people learn in lots of different ways and there are lots of different job titles out there so quickly by looking at a lot of parts that you could generate a within a few minutes. You have a better understanding of what's going on in the dataset. Okay. Any questions about the categorical example?  This next one is a kind of specific one. And I don't think I would be a professor if I didn't talk about my own work at some point in the course. So the details don't matter time. You don't need to know anything about genetics understand example, but I'll just explain experiment very quickly. So we had autism France from individuals affected with autism and we had a brain from individuals who are not affected with autism to access controls and our goal was to look at the differences between the two measures Optical RNA level. It doesn't matter what that is, but we just went to look at all the places within your brain that we could measure this do the values differ between individuals with autism and those who are not affected with autism and we had 71 sampled and then we had a hundred thousand measurements. So the assumption is that these values wouldn't differ that would be similar across most of them and we're looking for those places of those 100,000 places where we're looking where they differ between the two with the idea being that individuals that we can start to understand what's going on in the brain defect with autism if we were to carry out this experiment  Any questions on that?  Control Brands autism Brands looking for differences at a hundred thousand different places.  So this is an example of dimensionality reduction. You don't need to know details. But what this does is each point represents an individual and I'm looking at 6 different the global cultures the global differences in the sample. So what you want to see is that all the points are close to one another and then I get some distribution where nothing's really standing out here. We have some points separating from the group which catches my eye and as I look at the other dimensions, I start to see some point separating out and there was some to get far enough away that I'm confident enough to say that these are outliers. So it's far enough away from the rest of the group that I start to look and all colored and red and three different samples are identified here. This sample is the same as the sample suddenly. I see that there are samples that look different than the rest of the samples in the date of that.  And I'm going to Venn look for differences between individuals autism and control sample. I need to know why these samples look different than everybody else and I thought to myself a nation could be what contributed to that so I know the people are in a while and their pipetting stuff and then we're getting all of this data if samples were to mix when I was happening. What would that look like?  So details, not super important. We had two different measurements from each sample. So we had DNA and RNA and you should look similar based on what we know about biology so I could die if I take the DNA and I take this these samples hear how similar do they look to one another? What do I do if they don't look similar? There's probably contamination because we know that they're supposed to look similar.  So when I look at that and measure how similar are they between the DNA in the RNA be more similar? They are closed today with D20 and suddenly I see three samples popping out. And so this help my hypothesis. So I did at this floor to read analysis. I see these points that are different than the rest of the samples and I have his hypothesis that there's sample contamination. So what's going on, I simulated contamination 10% of the sample of there being a pure sample vs. 90% I would see some pattern like this. We're here. There's less agreement between the DNA RNA and hear there's more agreement and suddenly I see these three samples are up here with the highly contaminated samples in my experiment.  Okay. So how do samples father's contamination? They look different than the rest of the samples. I had to figure out why it looks to me like they're sample contamination. I'm so what would happen if I didn't remove them from analysis? I got to remember we're looking for differences between DNA between Autism cases and controls.  Here if the outliers were not removed. So you can see here that the difference in expression is way different than everything else up here when the samples are moved suddenly the black in the red overlap with one another a peer P value. Is there a way to measure significant that's like the worst definition of a P value ever, but the lower it is a more significant it is and you can see that the P value increases here. So there's no real difference to remove outliers are removed. This would have been reported as something that was significantly different between cases and controls when clearly it was all driven by his outlier and it might be obvious cuz we're looking at this spot here, but alright to be a hundred thousand of these you wouldn't make a plot for a hundred thousand book. They're all hundred thousand. So if I didn't know about this outlier, I would have said hey, this is something that's difference between Autism cases and controls. Let's go investigate that further or it's in the other direction to wear. These outliers said it was less significant and then it was significant when the outliers are removed. So that idea why is worth  So important if you have outliers and they're driving your differences, you're going to report things that are untrue and you don't want to do that.  So in this example, we learned that sample contamination is likely the culprit and these three samples and if those that have been removed from analysis, we would have reported it a completely different set of RNA that difference between Autism cases and controls. So if you don't do it for three days, and now this you can report inaccurate results and you don't want to do that either for your boss or for scientific research because it will make you look bad.  BatDad  ETA is not always the answer to everything.  If you have already analyze your data and got an answer that is not what you wanted or expected or hoped to see or that would make your boss upset. You don't get to go back and start removing samples to make things look better so you can't go back and remove Staples to improve the correlation or to get an answer you one or two make something significant. This is up front to make you understand urinalysis, but you can't just go back and start changing things so that you get the answer you wanted there's a famous quote from The Economist. That's if you torture the data long enough, it will confess if you go in and manipulate things remove samples change variables transform things that you hadn't planned on transforming follow. This can change your answer, but you can't do it after the fact you have to decide beforehand how you're going to analyze your data.  About to pull up to give you the results you want at the tool to make sure you're doing the correct analysis upfront.  Applebee's theme for this all use a lot of data about you all are towards the end of lecture to make the points that we've discussed in lecture. So this one I just wondering why I never hear this is the data set that I collected from you all at the beginning of the course. We talked about this last lecture if they were 275 people that responded there were I think 19 variable that I've included in this data set and then she has how many people chose not to respond to each of these categories will come back to that in a in a bit.  I want to know where my students grew up.  I asked questions on in what ZIP code were you born? And what is your hometown? So both of these could be used to answer the question where did cause nine students or what so I want to ask you which variable should we use to determine the answer to this question?  Feel free to challenge each other convince each other.  Are there be a few more seconds?  3 2 1  All right. We were pretty even split. Does anybody want to tell me they're thinking and why they chose ARB? Yeah.  pretty specific like something might like  Okay. So the point that was zip code can be pretty specific and but they're supposed to be large. So if you want your specific Hometown that might be a little more specific or more granular. I'm in the dataset. I like both of those arguments follow up.  So the argument here is if you put in Hometown and just put in San Diego. What if there's another San Diego in Texas or California and I didn't specify how to say it. So you could have in San Diego, but we don't exactly know where that is. So I could be a problem with Hometown and the other thought is a Kik.  You have to spend time cleaning and matching back up to where it at the end. And if you want to do something like a  Okay. So there are you here is home town could be have typos in it. And then you have to spend more time going through seeing which ones didn't Matt back and why and figure out what they meant for the cleaning. There can be super difficult. Where is it supposed to be more generalizable and can get you the longitude and latitude pretty quickly, which is what you would want to do if you want to put them on him at any other thoughts yet.  Okay. So the argument here is that zip codes can be problematic. If you're expecting some format, like what we would use in the United States, but that is not the same format that is used worldwide. So if we specify a format we want a zip code without taking into consideration, that could be problematic.  So let's take a look.  Sabrina care zip code 69 people did not respond to and Hometown 25 dances. So we're already seeing that there is maybe some issue cuz I couldn't think of a good reason why I zip code and hometown would be a different response rate. We're starting to see that there might be some issue with zip code. So ZIP code here. We see a few rows of zip code with the hometown.  How do I do this? I'm not going to do this one because we just talked about all these reasons. The one thing that I didn't mention is a tie required zip code to be numeric on the survey intentionally so that we could have this discussion today to using zip codes. What I did was I took the zip codes map them to longitude and latitude and I counted how many people fell into the zip code and I parted each place on a map. And this is what I got. So you have longitude and latitude. We have a point where people are found with you a lot of people from Southern California with you. Lots of people are from here in central people throughout and then we see what the size of the circle is proportional to the number to that live in that plot in that spot. All right. So what's going on here any problems with this?  Yeah.  Okay, so this isn't very clear at this doesn't mean you can't really match so we know that there are more points here with zip code. We can't really see the size difference.  I know problems with this map.  Anybody feel like their data is not being included in the state of set.  Maybe okay. What is a mention I stepped aside intentionally that I wanted a numeric zip code. However Canadian post postal codes do not have only numbers they have letters and numbers. So if you were Canadian, you would not be able to put your ZIP code in there. I also for that map utilize only ZIP codes in the United States, which if you hadn't taken into account the fact that you were using a dataset to match for longitude and latitude that were only in the United States that you would get some problematic Mac going on anybody who had a Canadian postal code would not have been able to enter data because we were required to be numeric based on our assumptions. So let's instead use Hometown. We do location based on what people said here to determine what their Hometown was anybody who had a typo here that could not be found or had a location that was found in multiple places, but didn't specify what else have problems but now we have a map here again, we have size of circle and we can see based on location rather than just a zip code.  Where are students come from? I didn't seem pretty cool map showing that y'all come from lots of different places all over the world, but it's likely reflects more what you expected to see based on where you grew up. So this case due to what assumptions were made and data collection. We had biased information in the zip code. We would have missed people in the world where there a were not numeric but there still are those pounds of your location that typos can cause a problem and he would have to go in and clean things up a little more to ensure that everything was correct. So we are pretty quick idea of where people in college 9 came from  All right. What are we going to know whether or not students tend to have taller students tend to have higher GPA?  Okay, take a look at the map figure out what the axes represent figure out the general pattern and let me know if there's anything funny about this spot before your child each other. What do you say?  All right, who wants to explain to me? What's going on here?  Okay, so they are pointy ears that GPA 10 Samuel appears to be on two different scales that a few people were maybe on a hundred point scale or some other scale where a lot of people are down here closer to the euro. I'm so because of that can we determine what's going on with the relationship between height and GPA? That's the next question?  So what can we conclude?  About the relationship between height and GPA.  Give it a few more seconds.  3 2 1  I really pretty even split.  Welcome back to this because we're going to do something quickly.  We're pretty evenly split about whether or not there's no relationship or can't be determined will come back to us and talk about both in a second.  So you wouldn't typically want to figure out why are on different scales and get all the information on the same scale as I'm just going to look at places where GTA with less than five so we can start to look at those individuals were GTA was on a similar scale between the two. So here we have GPA we have height and we have each individual pointed as it as a point on the plot.  Now we've done that. What can we conclude about the relationship?  every few more seconds  Cancel Mason in decision on this one by a few people 3 2 1.  More of you said that there is no relationship and explain to me how they came to a conclusion. What on the pot? What did you look at? What made you come to that conclusion?  Pretty evenly distributed we don't see so they kind of are all over the place. They look pretty random. We don't see everybody up here and everything on here. It just kind of all random threw out there and that is absolutely correct. So there is no relationship here on the other one for those of you who said no relationship. We on the last one we had on his outlier to couldn't really determine what the relationship was because everything was compressed. Do you need to get everything on the same scale or remove the outliers before you can determine that there's no relationship and there is a physical ways in which you can put numbers on this and determined that is pretty darn flat but the height and the GPA do not seem to be related here understand. There's a relationship between families with siblings and families with pets quickly. We looked at this before. So this is a distribution of individuals with sibling. So everybody over here has siblings and this person these people do not  And then it is a distribution of the people in the class who have a pet. The more people habitat versus don't.  What would be here when we put those together?  What conclusions do you draw here when you take a look?  Imma show the same plot just a little differently here and see what conclusions we draw here.  What's the relationship between people in his class with siblings and those who have pet?  Is it right the same between them to the differ? Who's more who's left?  I know it's getting later in class. People are tired. We looked at so many grass. So we'll do our hands on this one before we move on to the next one. So.  Maximum points if you think that more. That is the same between will do this. But okay will do. If you think it's a shame that people have siblings also have pet at the same rate raise your hand.  All right, we got that. These are the same if you think it's different raise your hand good while still awake OK as a go go in.  So don't look at the comparison between his we're looking at the proportion here. So the fact is that we're now on the same scale and we see that there are more people do not have siblings and also do not have pets so that answers our question there.  Now this last one was because of my own interest. I ask you a question in class about how much of the information so far has been new to you. This is after the programming lecture. So these are all the topics we've covered up to that point. I showed it in class. We had this kind of flat distribution with some increase in people in the 2260 range, but for my teaching perfect is it matters to me that it's not wildly different between Majors or years or gender because I just like being an entry-level class. I want everybody to get something out of it. It don't matter to me if some people are not  So I took the iclicker responses. So the percent new and I joined them with information from your roster. So what major you have? What use the year you are here easiest. I don't deserve a data what year you are in your study and you identify gender. So I joined them by ID or by name and then I coded the major by your two-letter code. So each major has a two-letter code, which I learned in doing this to CG is cognitive science. I want to go to gender only now if you are included in this despite there being more and the same information goes for you this year and major because I only want to include in places where people are more than 15 read the numbers 1 and 15 for identify ability reason and I drew the grass. So this is that same thing. I just showed you we see more people in the 20 to 60% new information range. How does a breakdown by Major? So this is the only part where I'll show you people less than 15 and these are all the different majors of people sitting in this course.  Data science is the most common. So now when I start breaking down into categories, I'm only going to include those Majors were there more than 15 individuals from that?  So who wants to interpret this for me? We're getting towards the end take a look chat with each other and let me know what you take away from it.  All right. There's a lot going on here. What's one conclusion you drew from looking at this graph?  That's hard to draw conclusions from this that is really hard to determine whether or not Dismount. This was different total versus that's okay. I'll give you the same information on the proportion scale. I want to hear one conclusion from somebody in the class. So to chat with each other. Let me know you take away from this graph.  Are you at the conclusion? They took from this grass?  Science students based on this red orange on being there for that new tend to be a little bigger than the other group other conclusions. You can draw from this was that it would be helpful to have actual name down here because surprisingly I double check if he died. So easy is not economics best engineering and Ian is economics. I think or some of the codes didn't make sense intuitively with what they would be so it would be helpful to have Better Label. I think that is a great conclusion. It would also be helpful to have fewer colors does the colors make it kind of hard to figure out what's going on. I'm able to order these in some way we can see that over here. We have a lot of people in the middle range, but that's probably the place where it's the largest over here and in Psychology, we have people wear a lot of information is new really just trying to look at the colors go across figure out how it differs from one.  Sure to the other I'm going to go through this quickly as we're getting toward the end that we have mostly first years in the course, but I'm giving people that are not in the first and fourth year, but we don't have 15 of them displayed.  If I look across the years and again look at proportions because Juniors and seniors tend to assume the information before so this is something you might expect as these people haven't had more classes here overall.  And then as standard we have more males in this class than females and the distribution looks a little different here and I don't have answers as to why but we can see that male tennis a less information was new to them relative to females. This is something you might want to break down within major is a year to really start understanding this trend we can see that more males have less was new and that's email 10 to shift towards a more information being now.  Replay we watch American Horror Story analysis that there was less of the new material with new tend to be data science and Fiat Juniors and males. We learned there more males and females in this course that UCSD major does not equal year in school and it showed up but it doesn't have a whole bunch of different Majors taking this course and zip code is not the whole story and with that if there any questions feel free to come up. Other than that, I will see you all on Thursday.  Thursday "
}