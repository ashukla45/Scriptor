{
  "Blurbs": {
    "1 gigahertz and the cycle time is one nanosecond and then if we put all these together we get the first fundamental theorem of computer architecture, which is that late and sequels instruction count time since like the cycles per second time seconds per cycle and will summarize that this way is a lie, cuz i c x c p i x t t I know it's nice about this ": [
      1121.3,
      1141.7,
      24
    ],
    "1.4 to not 10x right respectable. If I really all I care about is picked up and throw things like it then that would not be a bad way to just spend my money and all eight or speed up write another kind of depends on you have to look at your system and what you're willing to pay and how important jpeg Depot jpg Dakotas to you. here it ": [
      3969.7,
      4006.5,
      97
    ],
    "10 seconds or so. 3 2 1 the bus. Alright. I must be d d is actually correct. So what's going on? So we the first thing we do is count the number of endemic instructions. soften as I can ask you Once right. So there's two how much is this going to execute? Once in between here, there are one two, three, four, five six extra instructions. How many ": [
      2349.3,
      2402.2,
      59
    ],
    "2 Benchmark. So this is taking a bunch of different software. There were at least 83 submissions. Right of people suggested. Hey, we can include this inspection in the way that they decide what goes in is all of the companies can veto any piece of software. So if in tell if someone suggests that we should run, I don't know python right like python seems like it would be ": [
      866.1,
      891.8,
      14
    ],
    "2.8 s Point to point to thank you. Oh, man, I hate math. All right. This Is Us Someone told me once that your IQ goes down by 20 points when you stand up. And then buy more when he's not in front of the class, I will tell you the answer is B. But I'm having trouble solving for B right now. What's 1 / 1.1? 0.2 / all ": [
      4227.9,
      4281.3,
      105
    ],
    "360 which is one of the coolest computers was ever built. It is almost universally the case that every time we talk to take like I Advanced computer architecture, which is like a CSC 240 a almost everything that is in computer architecture appeared first and some for me IBM system 360 Is there not fat Sims 4? Fat is fear uncertainty and doubt. It's a marketing strategy used by ": [
      3622.5,
      3656.7,
      86
    ],
    "AI system playing the game of Go Gene sequencer some chests a quantum mechanics emulator video compression discrete event simulation, which is like simulating on a no cars driving in the city or something some sort of pathfinding thing. This is like for robot planning and processing is a bunch of applications. There's some interesting like politics that goes into the creation of these benchmarks. We suspect end is Trey ": [
      787.9,
      820.3,
      11
    ],
    "Alright by benchmarks so one of the challenges in measuring computer performance is in making sure they're running the same or at least a comparable program because the pergande running determines the performance there's a kind of measure. so what we have done is so soft. Where is Messi, right. There's it's very complicated. This is especially true in things like the cloud will have a single application that's running ": [
      483.2,
      517.8,
      0
    ],
    "I don't think super well standing up so I will look at it. Later. But assuming these numbers are the only got them. This is the math that we should do. All right. There is the math. Go through and do all the math. carry out all right, we're going to put some TPI so different inputs make programs behave differently. So I asked you different functions will do different ": [
      3558.9,
      3588.2,
      84
    ],
    "I have a total of 112 instruction just like we did before and then we can compute the average CPI. It's just the weighted average. For these values in the table. And so we just add them up. So it's 5 * 42. It's 1 * 50 is 1 * 23 divided by the total which is right here and we get 2.5. What's the average CPI for this particular ": [
      2743.6,
      2766.0,
      72
    ],
    "I want to speed it up. I think it's probably this function. That's low functioning because I did not heed and And like nothing happened if I was like, oh that function even though it seemed important to like 1% of execution sodomising it doesn't help. There's an example we have start up and they are marketing a new processor and then has the Super jpeg Aranda super jpg O ": [
      3830.8,
      3856.0,
      93
    ],
    "Photoshop or something? That's not so interesting for folks like Google because they don't really care about how fast things actually right on your laptop. So Packers and organizations, see if you're curious about this. You can go to spec. Org. And you can tell this is right old organization because they have a short pronounceable. Org address in a bunch of different workloads and benchmarks is a particular should ": [
      595.0,
      629.6,
      4
    ],
    "Point other operations take between three and five Cycles integer divide is like a real killer really want to avoid this if you can floating Point boiling point of I was also slow and square root and so forth are slow and Loathing stores are highly variable. They can take between a single cycle up to maybe hundreds of Cycles if things go badly. So depending on how the processor ": [
      2656.9,
      2680.1,
      69
    ],
    "Rama 2010 until when I may be 5 2018 instructions by 10 x 10 times faster 10 times. That's a lot right act now while supplies last. There's also find friends. You know all kinds of things like a wrong or might not. It will not on ground principal decode pictures of Justin Bieber Lady Gaga. That's just kind of a moral issue when we run this right here is ": [
      3856.0,
      3899.3,
      94
    ],
    "Right. There's going to be some that are a better kind of emulation of the workload that you expect that you're going to want to run. And to make these Spence Benchmark really useful as we'd like them to be really easy to set up so that anyone can run the Benchmark right now leaving across the variety of different operating systems, but definitely crossed a bunch of different processors ": [
      657.6,
      682.0,
      6
    ],
    "So this is I think probably incriminating or this is my day. Track my wife attractive to do the comparison to the end that I'm going to store I back. this is Sylvester should be swapped. And then I could have that piece of code right there. It gets a lot shorter. All right. So now I have I was only one store instead of a whole bunch of stores ": [
      1856.1,
      1906.5,
      52
    ],
    "What do you think? Yeah. All right, go ahead and lock in your answers. 5 4 3 2 1 0 all right. Stuart from the performance equation so we have I thought there that's not what I want. So if I take the November speed up is going to be old / new and so I can rewrite this with the performance equation as the old instruction count. Which is ": [
      3285.0,
      3448.9,
      80
    ],
    "What in the world? Okay. Can you see the PlayStation Now anybody? Yes, all right. Alright BD it is. I'll give you there like 10 seconds or so. All right 3 to 1. Alright discuss hotels next to you. I walk around see if you agree if you agree. That's great. And then we can go out again. All right. So let's go luck on your answers. They're going to ": [
      2132.7,
      2349.3,
      58
    ],
    "You're likely to see another even more interesting detail is why there is spec engine spec Fe So spec FP is all this flooding Point stuff. It's a lot of matrix multiplication and floating point, you know, there's an earthquake simulator and a bunch of other stuff in there. So the reason that they're Speck in to inspect your pee if they tell you now it's like well, you know, ": [
      910.2,
      933.7,
      16
    ],
    "a good choice to have on this list. So maybe someone submitted python. I don't know, but maybe they did and maybe one of the companies was like super well on our processor so like it's out of here. It's all right. So this is sort of like the most boring set of applications possible. It's going to run pretty well and all of us are all the hard way. ": [
      891.8,
      910.2,
      15
    ],
    "across thousands of different machines. And so if I'm say Google and I want to be able to decide which processor I should buy and I'd like to be able to you don't have AMD and Intel and HP and over us as big as processors your tell me how fast is your processor, right? I can't build an entire data center. I'm going to run my entire Google software ": [
      517.8,
      540.0,
      1
    ],
    "an integer computation on I'll show you a list of those applications on the next compilers and which is the boiling point Ranch Park in this is more like scientific computation. And so that I could be the Benchmark that you're going to use for a particular experiment kind of depends on how you're going to use the computer while you're trying to measure if there's no single best benchmark. ": [
      629.6,
      656.9,
      5
    ],
    "and different computers to be relatively easy to set up tent sound if you get poor performance on one of the applications in a benchmark sleep then I can maybe tell you what that means about your processor. It has a bad memory system or its poor does a poor job of executing code that has a lot of branches and it said I'd like to know something about the ": [
      682.0,
      707.7,
      7
    ],
    "answer is 1.06 in the speed up again, it's sold over new. So that's 1.062 points 5 divided by 1.06 equals. 2.36 All right. All right, and there's a math again. So reducing CPI and This should not be in your CPR. There should be speed up. Alright, so now we are the two pieces of code and I know I have this broken across to slime. All right. So ": [
      3090.8,
      3147.0,
      78
    ],
    "are going to fall down. That sounds like a good plan right or a hundred million dollars on bridges help. no, because that optimization saving a little bit of money on Bridges is not widely applicable until have limited impact the same notion of your own personal finances, right? If you want to save extra money, right should you worry about rent or whether you get like a dollar fifty ": [
      3769.9,
      3802.6,
      91
    ],
    "as a model is that each one of these individual turned his pretty easy to understand and they're kind of independent of one another right to the number of instructions that we're going to execute that sort of a property of the of the programmer running. The cycles per instruction is a prot is a is a result of the architecture. So the implementation details of the processor that we've ": [
      1141.7,
      1166.4,
      25
    ],
    "at the answers and trying to back calculate which ones seem correct. I am cleverer than that. So there are several answers that will you know, if you back calculate they will lead you astray the weather in Graham. So this is how we just do 5 * 1 + 1 * 42 + 1 * 23 divided all that by 63 total there. And that would give you the ": [
      3060.2,
      3090.8,
      77
    ],
    "basically you can think about this. This is basically the weighted. This is the weighted average for latency. So we take the fraction of the program that we can speed up. We divide that by the speed up to speed up by to this thing. I'll go down by 1/2 and this is everything else you can think about this so you could think about this is being divided by ": [
      4027.7,
      4047.1,
      99
    ],
    "because they don't have a floating-point unit and so will look good to the customers that we care about some respeck FP right decision. And now you know, what the 30 years later whatever we have the same kind of structure in this Badu. This is a very influential benchmarks. I showed you that data early or the first week of a class where we showed performance growth over time ": [
      985.7,
      1006.1,
      19
    ],
    "built and then the cycle time it just a measure of kind of how fast that processor is running very kind of place between them. But I kind of breaks up performance into 3/9 pieces, then we can think about each of those independently. so Like I said, the performance equation is a mathematical model. So here it is again. So one of the nice things that tells us right ": [
      1166.4,
      1193.7,
      26
    ],
    "buying IBM, you know, whatever gets fired now for buying Microsoft genuine know why you smiling Because he's extremely rich. All right. So is that the basic observation here is that optimizations are not generally uniform they do not generally uniformly affect the entire program. So the more widely applicable technique is the more valuable it is. Armin conversely if you have an optimization that has limited applicability you can ": [
      3704.8,
      3741.0,
      89
    ],
    "by the spec organization. Nspec is a Consortium of a bunch of computer manufacturers. And so they want to be able to make comparisons but they're also kind of competing with each other. So companies like HP and apple and Intel and AMD and so far through in the spec Consortium and the way this works is that they go out and they find software all of these are open ": [
      820.3,
      843.5,
      12
    ],
    "candy bar or dollar twenty-five candy bar? Like that's not important you need to go for rent. Cuz that's where he goes to my mortgage this essential to all kinds of things, right. You can apply this basic idea everywhere. It's very important Computer Science and Arts of profiling tells you which parts of your programmers slow many times in my life. I have thought I've had a slow program. ": [
      3802.6,
      3830.8,
      92
    ],
    "change the processor. So that means that these two are equal and so I can just cross the mouth and then I can just take this product in this ends up being 4.19 which is be alright, so a lot of time, you know, usually we're not changing Everything at Once cycle time off and cancel. So it's kind of pay attention to that the same instructions the same program ": [
      3486.4,
      3513.6,
      82
    ],
    "code hard because there's not really any particular place in the Assembly Language that corresponds to the program that you wrote. Oh, all right. So here is What happened? Why don't I have my Alright, so here is the clicker question so over here we have a this is 13 static instructions on 112 Dynamic instructions here is version B, and I would like you to figure out the number ": [
      1950.5,
      1983.8,
      55
    ],
    "could be doing different types of playing a DVD probably take some more instructions than writing a Word document, right? Cuz you're decoding all the frames and doing lots of work. They're all the same programs can a different amount of work depending on its input. So if I compiled a thousand line program that's going to do less work on a hundred line program on the same program may ": [
      2449.5,
      2470.6,
      61
    ],
    "could try to reduce cycle time. That means increasing the clock right? We can reduce the instruction Cannery can reduce CPI and that should give us good ways to improve performance and we in these are like the basic things that we're going to look at in this class for how to improve latency or how to reduce latency each one of these will look at it will see that ": [
      1241.9,
      1259.4,
      29
    ],
    "count them up and that will give you the static instruction count. This is not relevant for computer perform. It's not just how many things are executed. So if you find yourself to dividing by a, you know, an instruction count that's like five during one of the homework's think carefully about whether or not that makes sense, right? All right. So how do I reduce construction count write them ": [
      1613.0,
      1643.4,
      44
    ],
    "different kinds of application classes. So if you go online and you look on someplace like Tom's Hardware something they will use these Benchmark sweets that are built for the desktop. So like PC Mark and so forth supposed to measure the performance of applications that you use on your say your laptop has Microsoft Word going to run or how fast are you going to be able to do ": [
      571.2,
      595.0,
      3
    ],
    "different structions take different amounts of time to execute procedure in different ways. So typically on average you can execute a single they're called into jury instructions, you like plus minus the binder or the bitwise operations and things like branches those take a single cycle on average in a germ X takes like 3 to 5 Cycles integer divide takes between 10 and maybe a hundred Cycles the floating ": [
      2626.0,
      2656.9,
      68
    ],
    "do besides implement or the compiler decides to implement things. You can have a huge variation and how many how what the average CPI is example of this is like integer multiplied takes between 3 and 5 Cycles but a bit shift takes only a single cycle multiplying by a power of 2 constant power of two. It can replace a multiplication with a right shift and it can reduce ": [
      2680.1,
      2706.2,
      70
    ],
    "drastically reduce the impact of the optimization. So always heat handles lot. This is really important. So and I tell you this it's not just for this class. This is like this applies all over the place. So the US federal budget, right? So we talked about how we should reduce the budget and people talk about how we should save a hundred million dollars from like repairing bridges that ": [
      3741.0,
      3769.9,
      90
    ],
    "efficient by reducing the number of instructions that will get executed. Those are the kind of the two ways. You can easily affect instruction count. So this is very simple, right? If one version requires further instructions Dynamic instructions in the p4xl be faster to the swimming at CPI in clock speed remain the same production. I see you should give a speed up, you know something like this about ": [
      1763.4,
      1791.4,
      49
    ],
    "everything corresponds do. You know, this is all very clear. What's what? This is probably about Hulu control but there are lots of extra instructions in here. This is 13 static instructions. There's 13 if I have to actually run a little bit turns out to be a hundred 1312 Dynamic instructions. So I can tell her I said hey what's going on everytime it wants to access a variable. ": [
      1827.6,
      1856.1,
      51
    ],
    "for processors and that was Speck in data because there's a huge database of the stuff going back a long way. They they have an agenda, right? They're not these perfect pristine things that are handed down to us. They are the product of some human processing so they have kind of the shortcomings and so forth. I can come with that. Fish always think are not what your benchmark ": [
      1006.1,
      1028.5,
      20
    ],
    "going to be a hundred and twelve. Time the old CPI which is going to be 2.5. Time's the old cycle time CT old is 1.06 times the CT new. All right. So now the challenge right of the one potential concern is what about the cycle time? So the cycle time change? Berlin Rosen change right because all I did was change the program that I'm executing. I didn't ": [
      3448.9,
      3486.4,
      81
    ],
    "here is the original color that has the instruction can of 100 112 in the old CP. I have the new key and the new CPI so very quickly calculate what the speed up should be between those two. using a performance equation, which I remind you is L equals i c x CPI Furniture CT 10 seconds or so? 5 4 3 2 1 alright discuss with your neighbors ": [
      3147.0,
      3254.6,
      79
    ],
    "higher than it is on x86 and we'll see if there are some trade-offs in particular the cycle time for x86 tends to go up to the benchmarks. You need to make sure that they're doing the same work. If you're doing the comparisons, they're executing. They need to be started executing the high-level tasks, right so I can compare a mixed machine to an x86 machine as long as ": [
      2494.5,
      2522.0,
      63
    ],
    "improvements are the most important performance improvements in computer science. I'm not supposed to be telling you this in computer architecture class, but it's true. I think there were a huge Gamescom right? I was at a conference yesterday and they reported a result. Where am I doing? Some cover algorithmic stuff, they factor of 10 to the 20th. It's a very large speed up. And obviously the thing was ": [
      1702.3,
      1727.8,
      47
    ],
    "is 1.3 and you stick in a point to 4X. This comes out. I believe the negative for something so negative value. Friday the 2nd and negative speed up so just tell this right is that we can ": [
      4786.2,
      4800.0,
      109
    ],
    "is before you go and measure performance with it important things in the class. So it will probably be on the midterm and the final so the performance equation is a model for processor performance model you taking physics, you know, it's in the same kind of mold as they much more complicated models we have for the other physical world Works us make some predictions about how particular processor ": [
      1028.5,
      1063.4,
      21
    ],
    "is formally so if we can speed up EXO, this is a fraction of the program between zero and one of a program by a so this is a speed up as we've defined speed up old over new animals law gives us the total speed up for applying at optimization best faction to program and here it is 1 / x / x + 1 - x This is ": [
      4006.5,
      4027.7,
      98
    ],
    "it because every, you know year or two we can cram more transistors under a single piece of silicon than the clock speed will go up and that means that our process processor to get faster. We talked a couple days. About how in the past you could just wait 18 months and your processor would go faster. It is mostly a product of this kind of effect. They would ": [
      1339.2,
      1361.4,
      33
    ],
    "it goes up pretty quickly. I'm so this is pressure to keep a cycle time longer like what time is also a function of manufacturing variation? So when I design a processor the processor has you know a few billion transistor. They're not all exactly the same. And so if I happen to get a slow transistor at a critical place in my processor that can mean to the cycle ": [
      1381.6,
      1403.5,
      35
    ],
    "it's going to be $150. So that means that the new the new latency equals 150 and we put that under 200 for old and that gives us if its 5/3 or something. Not 4/3 4/3, which is 1.33 cups equals or my wife or here. x / 1 / s tote -1 - x again Can I ax equals 0.2 if you go and stick in a stone, which ": [
      4732.8,
      4786.2,
      108
    ],
    "just divided by the clock speed and hurts if you want to thinking hurts. All right. This is an important kind of definition of thing. We talked about instruction catmaxx. So there are two ways to think about instruction count. I don't want you to get confused about this. So the terms that we use are the dynamic and static instruction count means that this is actually how many instructions ": [
      1556.1,
      1583.4,
      42
    ],
    "just for clarity and here's what happens if I use as an optimization. So now the screen part got 10 times smaller text 1/10 of time, but all this blue stuff was not affected because jpg a rama doesn't have any effect on that. And so the total execution time here is 21 seconds. The old execution time is 30 seconds in the actual speed up is there for Just ": [
      3944.3,
      3969.7,
      96
    ],
    "just shrink the chips and the chips would magically go faster but doesn't work as well as it used to but clock clock speeds do still go off when you can at least potentially go up if you make them smaller the problem though is that is across the clock speed increases power consumption also goes out the power consumption is roughly the square or so of the frequency, so ": [
      1361.4,
      1381.6,
      34
    ],
    "know, I encouraged I encourage it is a hobby if you have a lot of money in a lot of time. All right, I guess maybe this time which is the number of seconds per cycle, which is measured in like nanoseconds or picoseconds are something we also use Where is clock speed more in this is measured in hertz, like megahertz in a gigahertz and it's just the inverse ": [
      1498.6,
      1528.5,
      40
    ],
    "large companies to prevent or to undermine the sales of smaller companies. So Microsoft wasn't for this. It's basically that's right. So if you're trying to sell some softer to someone and they're like what what about Linux I could use Linux on the desktop and they're like well, I don't know it might work. I mean it's supported by a bunch of like random people around the world might ": [
      3656.7,
      3682.3,
      87
    ],
    "like The videos online are pretty entertaining. So what you do is you by the very fastest ship that you can and then you install some special hardware and software on your machine and you can clock the the clock up faster than it's rated for and I'll do things like dump liquid nitrogen on their processor to keep it cool and they can run stuff really really fast. You ": [
      1476.4,
      1498.6,
      39
    ],
    "linear it was CPI. So if I take longer on average to execute an instruction execution time will also increase and it's also changes with cycle time. So if I run my computer twice as fast, so the cycle time goes down by 50% then my execution time will go down by 50% as well. What kind of makes sense it also suggests that we can improve performance so we ": [
      1217.2,
      1241.9,
      28
    ],
    "look at a technique called pipelining that is really good at this all about reducing recycle time. So we'll make ourselves faster that way is also a function of process technology. So process technology is how we actually manufacture the chips have time that I'll go through a little a little bit of about how we manufacture chips. So roughly speaking if you take a particular design and you shrink ": [
      1313.1,
      1339.2,
      32
    ],
    "my class. You thought it was D. haha haha Mental math, what do you think? It's a All right, so you should have skipped actually going to probably just engineered from the multiple choice answers. All right. What do you think? I like that answer pretty well. All right. Why do you think it's B? Not sure you're not sure. All right. So how do you compute the CPI from ": [
      2900.7,
      2951.4,
      74
    ],
    "my program. Alright, so 18 cuz we just updated it. So we have picked up. What time do NJ PD code? That's a lot actually probably buy program standards. My program my laptop decode does jpeg around my 2k help. So here is a little schematic drawing of the execution of I picked up bench and here is the time it's been doing jpeg decode it probably is right here ": [
      3899.3,
      3944.3,
      95
    ],
    "now because they allow us to kind of think about how different changes will affect the system that we're studying. So for instance the model tells us that latency changes linearly with the instruction count. So roughly speaking of everything else is held constant. If I double the number of instructions, I can execute actual execution time will go up by a factor of to write latency is also a ": [
      1193.7,
      1217.2,
      27
    ],
    "of course in a messy environment with lots of other programs 2006 VIP pass every decade or so spec 2017 came out last year. So this is a reasonable approximation of what runs on your on your laptop. So we have a pearl. This is a pearl interpreter. This is a compression engine. This is the GCC compiler. This is a optimization kind of coming for optimization thing. This is ": [
      750.7,
      787.9,
      10
    ],
    "of cycle time. So if I have experts then I have one over X seconds per cycle. So a 2.5 gigahertz clock means I have a 400 out of 6 nanoseconds cycle time. So pay attention. I mean, it's pretty obvious about cycle time because that would mean that one cycle time took like a big a second. We should make it pretty slow. So pay attention to where you ": [
      1528.5,
      1556.1,
      41
    ],
    "of dynamic instructions and then compute the speed up for B. So small that over for a little bit and I'm going to set up the clicker device. It's on. That's a good question. Last time I said BD, but that was wrong, wasn't it? BD but that was what does remember what the right answer was from last time? That would never fix anything. Never. I had a friend ": [
      1983.8,
      2080.3,
      56
    ],
    "of that Equals 1.9 we can try again on the next slide. I will do it as well. I'll play along at home. All right, so here's another same thing. DNN how much do I need to how much how much faster to make the energy in it? So that it runs 50 hours faster. All right, North 2nd. locking your answers 3 2 1 a lot of dissension All ": [
      4281.3,
      4505.3,
      106
    ],
    "of time. It takes xq2 single instruction. The key is getting multiple instructions of the same time in maps and so this is the ratio of the CPI is the ratio of the Cycles required execute the program / the instruction count for that program. All right, so that it's an average. So the way that the process or they compiler effects this by something called instruction mix so I ": [
      2599.6,
      2626.0,
      67
    ],
    "once who is a lawyer. And I was over at his house and he was like, can you fix the internet? Cuz I guess I'm supposed to say my computer sounds like I can't help but that's not going to fix anything like that fixes everything. number one All right. Let me try starting up the software here. Here I'll see if you guys can still see the slide. whoa ": [
      2080.3,
      2130.0,
      57
    ],
    "one because it's a constant speed up nothing's changing and then it's just the weighted-average. Let me get the speed up from the latency. You take one over it and you get the new speed up. So I would not be surprised at this exact equation were on the homework or the midterms or the final or L3. So we can do some sanity checks on this. What if the ": [
      4047.1,
      4068.4,
      100
    ],
    "over here? Come on. That's just not fair. All right. Well 83% of you said it was easy, but I'm unable to move the window over there to show you for some reason. So you correct. So one one thing I noticed is people aware as I was walking and talking to people I encourage you to actually, you know, do the problem during the clicker sessions rather than looking ": [
      3025.8,
      3060.2,
      76
    ],
    "particular at execute a single instruction. This is an average will see that this is for a variety of reasons. It is not the length of time. It takes them to execute an individual instruction. But it's the average number of cycles that it takes executed instruction on the last term is a cycle time and that's how long are basically the inverse of our clock rate. So if its ": [
      1097.5,
      1121.3,
      23
    ],
    "piece of code is 2.5. I love you guys can work out with the new. Again, what the new CPI has and what the resulting speed up is for those pieces with the optimizations enable. I'll take a crack at that. Are you real are 10 seconds or so? All right 3 to 1. All right, but Scott's amongst ourselves. What do you guys think it is? This is not ": [
      2766.0,
      2900.7,
      73
    ],
    "really big factor and CPI because this is where the performance of the memory system shows up in the performance equation for this is not the number of Cycles. It takes to execute one instruction. So the process or something like one, but in fact, it takes 5 Cycles to execute a single instruction. I don't know what to talk about why that is but this is not the length ": [
      2570.6,
      2599.6,
      66
    ],
    "require a different number of instructions on different iOS A's. So remember this is the instruction set architecture the list of instructions of the program of the processor can execute So I'll see that nips tends to use a lot fewer instructions and x86 to accomplish the same out of work. So that means that the instruction count for MEPS is going to be a lot lower apartment a lot ": [
      2470.6,
      2494.5,
      62
    ],
    "right, I don't know what class that is, but your teacher is very happy that you remember that that was in login is there is N squared right So these things these terms translate more or less directly into instruction counts, right? So if I'm sorting I'm going to execute, you know, Big O of M login instructions if I'm bubble sorting on execute roughly M squared instructions to make ": [
      1676.1,
      1702.3,
      46
    ],
    "right, talk to lunch ourselves. 40 hours Show the equation. Another minute or so. All right, like in your answers. 3 2 1 All right, how we do? Come on, I don't know how decides which screen to put this on you. It's very all right. We'll 86% of UCSD. So the first question is what is what is a stoat so Estelle Drive 50 hours faster. So I mean ": [
      4505.3,
      4732.8,
      107
    ],
    "running the same input then you know, maybe the instruction cat would cancel out but you don't actually everything all the times. Yes. Because during the last cycle. He was still going to the group and running. over here And then jump rope. I am shocked. There's an error in my slides. I will check that out. I just looking at this. I think that you might be right. But ": [
      3513.6,
      3558.9,
      83
    ],
    "source because they it ships is source code that you can pile and then you run on your computer. So I got him a fine these different applications and these numbers are actually these are the submission that they got for spec 2006 are these are the original submission numbers. I just have carryover and so I actually think it's this the last year or is it the fourth version ": [
      843.5,
      866.1,
      13
    ],
    "speed up is one right? So we don't do anything then if I stick one in here for us I get 1 / 1 / s equals ass so I kind of make sense. All right. So here is an example of Daniel's law Protein Plus. I rewrote this just to be more up-to-date really call this deep. deep girl But only one of them so and the law says ": [
      4068.4,
      4103.3,
      101
    ],
    "still be around in 5 years. I don't know. And if they went away really bad things would happen. So I got really bad for you because you're a big company and you want people to do work. So, you know, that's probably how you might want it but I don't know. I just like lol good thing is that people say, you know, no one ever gets fired for ": [
      3682.3,
      3704.8,
      88
    ],
    "stuff and I can change the instructions that gets executed. So I'll change instruction mix and I can also change their for the CPI. All right, next stop animals law. No need to pay attention to this part of this isn't a part of me. Yeah, all right angles optimization. So is made by m know, this is Gene amdahl. He was one of the designers of the IBM system ": [
      3588.2,
      3622.5,
      85
    ],
    "suite on that data center. I have to get something smaller and easier to run and so those things are called benchmarks. So I Benchmark sweeping the set of programs that are representative of a class of problems. So a lot the different kinds of software rerun. We run games run compilers rerun artificial intelligence neural networks different kind of properties. So people have built different different Benchmark Suites are ": [
      540.0,
      571.2,
      2
    ],
    "that on average the whole lecture is only like 1% cooler. So I should go riding right deep neural Nets on all my slide hours on my current machine and it says 20% of its time doing integer stuff. Right? How much faster do I need to make my integer unit to make the code run 1.1 times faster? Alright, so I will do this one is an example then ": [
      4103.3,
      4131.7,
      102
    ],
    "that particular ship can run right? So they keep cranking out the cycle of the clock and eventually it starts failing they back it off a little bit and that's what they'll sell it to your eyes are the ones that they sell to you for. money This is just kind of a roll of a dice that also right in town will also if there's a big market for ": [
      1424.8,
      1451.2,
      37
    ],
    "that sort of a review of all right, you know percent speed up 20% and so forth we talked about last time. Should pay off pretty directly because of the performance equation example. price of gold per gram I'm going to do a little Loop. So this is the kind of code that will come out of GCC with no optimizations one is it it's very easy to see what ": [
      1791.4,
      1827.6,
      50
    ],
    "that table? Usher that's right. So it's the weighted average of the CPI call him time to Dynamic construction count on 35 * 1 + 1 * 42 + 1 * 20 / 63 Okay, so I ran through that and see what you get. All right locking your answers. 35 seconds or so at least get your clicker points. All right 3 to 1. Why did I put it ": [
      2951.4,
      3025.8,
      75
    ],
    "the CPI inflation called strength reduction might go ahead and do for you. So here is an examples of the same Cody. Look at earlier optimizations. We have a couple of different types over here. I've given you the average CPI that you should you can use for each of those. There's a static house which we don't particularly care about 42 memory operations 50 integer operations 20 branches. So ": [
      2706.2,
      2743.6,
      71
    ],
    "the lower end will actually take some of the faster processors and sell them a slower process. I don't know if they do this anymore of it used to be that companies would actually then put a limiter on the speed. So you couldn't let go in and clocked a processor faster than what you had purchased it 4-0 to hear overclocker. 1 overclock a couple of overclockers. This is ": [
      1451.2,
      1476.4,
      38
    ],
    "the processor executes while running a particular program has like a billion like literally a billion instructions or maybe maybe a trillion like lots and lots of instructions. The alternative is the static instruction count. And this is just the number of instructions that the compiler wrote down to represent your program. So you look at a program listing in assembly, you're looking at the static instructions and you can ": [
      1583.4,
      1613.0,
      43
    ],
    "there's different ways of doing that. It also allows us to evaluate potential trade-offs really easily. So if I want to reduce the cycle Time by 50% and increase the CPI by 1.5 equation to tell me that is Annette Winn because if I multiply 2.5 * 1.5 I get .75, so that means the product of CPI and Cycle time went down and that means at my execution time ": [
      1259.4,
      1286.4,
      30
    ],
    "they different application demand. So it should be like this will separate the metals are useful originally. The reason was it this was created by doing the original the original version of suspect 95, one of the the founding members of aspect Consortium that got the started was the company I forgotten. They've been saying I think maybe it was like HP or something, but they had this computer that ": [
      933.7,
      963.5,
      17
    ],
    "they had built a processor. And they were going to really stink on spec FP and star on the floating Point wear clothes that were inspecting so they were like, hey, let's have to Benchmark Suites will split it in half and then we'll do really well on spec end and you know will stink on floating point but no one will expect us to do to do that while ": [
      963.5,
      985.7,
      18
    ],
    "they're compiler starts cranking up the optimization. You can do really gnarly things to your code. It will take one function and if it determines that, you know, you you call a function they don't know anything of the result will just stop calling a function that use real combine a bunch of instructions into one or find all sorts of other creative ways to add to speed up your ": [
      1930.1,
      1950.5,
      54
    ],
    "they're doing the same work. And then I take into account the instructions will be different but still with a cycle time and the CPI. All right. Next up is cycles per instruction by the most complicated terms in the performance equation. Lots of things can affect it. So they can remember this is an average. So that means that the compiler can affect CPI by the different instructions are ": [
      2522.0,
      2550.0,
      64
    ],
    "time for that processor will go up there. When you go to Intel's website review by your processor's you'll see that there are different speed grades of processors, right? You can buy a 1 gigahertz Intel Xeon. Are you can buy a 3 gigahertz Intel Xeon and the way that they got a whole bunch of Intel Xeon off the line and they test them and they see how fast ": [
      1403.5,
      1424.8,
      36
    ],
    "time is all that can execute? 10 * so there is 60 instructions. So I guess is a total of 63. Dancer and then speed up, right? So to speed up speed up S equals old over new. equals 112 divided by 63 should equal 1.8. So you don't want it? make sense All right. So other than PacSun instruction count, so this is this is a dependent. So this ": [
      2402.2,
      2449.5,
      60
    ],
    "to be affected by the optimization. So point point to write 2 / 8. + 1 - 2.2 so I can simplify this I get one over. This becomes .8. So it's point to / us plus point eight. Simple math is hard. So no idea who this is. 22 / us + 28 * 1/2 Oliver one so I can slip it over I get asked over 2 + ": [
      4175.8,
      4227.9,
      104
    ],
    "to choose with some instructions take longer than others. And so to paint the compiler chooses to do the CPI will go up or down program info. It's going to affect basically all aspects of her good behavior. And so that can actually change which instructions get executed that will change the average CPI. The processors design can change it and soak in the memory system. This is actually a ": [
      2550.0,
      2570.6,
      65
    ],
    "to the second term there many ways to implement a particular computation, right? I could write down lots of different versions of the Assembly Language and there can be applied at different levels. So one very efficient way effective way is algorithmic improvements complexity at Big O, and it turns out that so quick started, right? What's the what's the what's the average case complexity of quicksort? Well done. All ": [
      1643.4,
      1676.1,
      45
    ],
    "very slow beforehand. Then be like if translated into actual execution time for residents to the instruction count the way that you can do. This is by compiler optimization. These are also pretty important. You can say past to GCC and what it will do is it will look at your code and it will think about it for a long time and see if they can make it more ": [
      1727.8,
      1763.4,
      48
    ],
    "want like a clean measurement of a performance they are doing on that machine the challenge. Of course, is it real soft? Where is none of these things right real soft versus hard to set up. It's not reportable. It's often not very well understood because you know, some programmers just wrote it. It's not stand alone because we build systems that have lots of interconnected suffer and it runs, ": [
      730.8,
      750.7,
      9
    ],
    "we'll go into another one. So let's start. Ask Cody equals 1 / x / us + 1 1 - x we go in this case. 1.1 Sarah's totes this is a stoat so I can write down 1.1 equals one over cuz I want to know what the speed of is going to be. So what sex? X what x is the fraction of my program that is going ": [
      4131.7,
      4175.8,
      103
    ],
    "went down as well. Hey, so do you still have thinking about performance? So what do we do first the first look at reducing cycle time? So cycle time is the function of the processors design. We'll talk a little bit about how that works in the next few classes. If a design does less work during a clock cycle at cycle time will generally be shorter. They're going to ": [
      1286.4,
      1313.1,
      31
    ],
    "will perform a particular measures Layton and it's meant to sort of quantify performance in terms of some pretty easy to measure architectural parameters. And the first one is instruction count. So this is just the number of instructions that I'm going to execute in my program instructions. Practice. The second term is a cycles per instruction. This is how many cycles it takes us on average to execute a ": [
      1063.4,
      1097.5,
      22
    ],
    "will see that number and operations are pretty slow is 9 static instructions and a lot fewer Dynamic instructions. How to code is also a little bit more complicated in this case it still happens to be pretty clear what's going on but it's not exactly clear where this what this construction is doing. It doesn't kind of map cleanly on anything over there and one thing that happens when ": [
      1906.5,
      1930.1,
      53
    ],
    "workload. This is so that it can be compared you wanted to be kind of independent of the environment that it's running in and I can't depend on a bunch of other software that also makes it easy to set up some standardized condition. So usually if you're running event Sweet you like kill everything else on the computer. So all it's doing is running a benchmark sweet because you ": [
      707.7,
      730.8,
      8
    ]
  },
  "File Name": "Intro_to_Computer_Architecture___A00___Swanson__Steven_James___Fall_2018-lecture_4.flac",
  "Full Transcript": "Alright by benchmarks  so one of the challenges in measuring computer performance is in making sure they're running the same or at least a comparable program because the pergande running determines the performance there's a kind of measure.  so  what we have done is so soft. Where is Messi, right. There's it's very complicated. This is especially true in things like the cloud will have a single application that's running across thousands of different machines. And so if I'm say Google and I want to be able to decide which processor I should buy and I'd like to be able to you don't have AMD and Intel and HP and over us as big as processors your tell me how fast is your processor, right? I can't build an entire data center. I'm going to run my entire Google software suite on that data center. I have to get something smaller and easier to run and so those things are called benchmarks.  So I Benchmark sweeping the set of programs that are representative of a class of problems. So a lot the different kinds of software rerun. We run games run compilers rerun artificial intelligence neural networks different kind of properties.  So people have built different different Benchmark Suites are different kinds of application classes. So if you go online and you look on someplace like Tom's Hardware something they will use these Benchmark sweets that are built for the desktop. So like PC Mark and so forth supposed to measure the performance of applications that you use on your say your laptop has Microsoft Word going to run or how fast are you going to be able to do Photoshop or something? That's not so interesting for folks like Google because they don't really care about how fast things actually right on your laptop. So  Packers and organizations, see if you're curious about this. You can go to spec. Org.  And you can tell this is right old organization because they have a short pronounceable. Org address in a bunch of different workloads and benchmarks is a particular should an integer computation on I'll show you a list of those applications on the next compilers and which is the boiling point Ranch Park in this is more like scientific computation. And so that I could be the Benchmark that you're going to use for a particular experiment kind of depends on how you're going to use the computer while you're trying to measure if there's no single best benchmark.  Right. There's going to be some that are a better kind of emulation of the workload that you expect that you're going to want to run.  And to make these Spence Benchmark really useful as we'd like them to be really easy to set up so that anyone can run the Benchmark right now leaving across the variety of different operating systems, but definitely crossed a bunch of different processors and different computers to be relatively easy to set up tent sound if you get poor performance on one of the applications in a benchmark sleep then I can maybe tell you what that means about your processor. It has a bad memory system or its poor does a poor job of executing code that has a lot of branches and it said I'd like to know something about the workload. This is so that it can be compared you wanted to be kind of independent of the environment that it's running in and I can't depend on a bunch of other software that also makes it easy to set up some standardized condition. So usually if you're running event  Sweet you like kill everything else on the computer. So all it's doing is running a benchmark sweet because you want like a clean measurement of a performance they are doing on that machine the challenge. Of course, is it real soft? Where is none of these things right real soft versus hard to set up. It's not reportable. It's often not very well understood because you know, some programmers just wrote it. It's not stand alone because we build systems that have lots of interconnected suffer and it runs, of course in a messy environment with lots of other programs 2006 VIP pass every decade or so spec 2017 came out last year. So this is a reasonable approximation of what runs on your on your laptop.  So we have a pearl. This is a pearl interpreter. This is a compression engine. This is the GCC compiler. This is a optimization kind of coming for optimization thing. This is AI system playing the game of Go Gene sequencer some chests a quantum mechanics emulator video compression discrete event simulation, which is like simulating on a no cars driving in the city or something some sort of pathfinding thing. This is like for robot planning and processing is a bunch of applications. There's some interesting like politics that goes into the creation of these benchmarks. We suspect end is Trey by the spec organization.  Nspec is a Consortium of a bunch of computer manufacturers. And so they want to be able to make comparisons but they're also kind of competing with each other. So companies like HP and apple and Intel and AMD and so far through in the spec Consortium and the way this works is that they go out and they find software all of these are open source because they it ships is source code that you can pile and then you run on your computer. So I got him a fine these different applications and these numbers are actually these are the submission that they got for spec 2006 are these are the original submission numbers. I just have carryover and so I actually think it's this the last year or is it the fourth version 2 Benchmark. So this is taking a bunch of different software. There were at least 83 submissions.  Right of people suggested. Hey, we can include this inspection in the way that they decide what goes in is all of the companies can veto any piece of software. So if in tell if someone suggests that we should run, I don't know python right like python seems like it would be a good choice to have on this list. So maybe someone submitted python. I don't know, but maybe they did and maybe one of the companies was like super well on our processor so like it's out of here.  It's all right. So this is sort of like the most boring set of applications possible. It's going to run pretty well and all of us are all the hard way. You're likely to see another even more interesting detail is why there is spec engine spec Fe  So spec FP is all this flooding Point stuff. It's a lot of matrix multiplication and floating point, you know, there's an earthquake simulator and a bunch of other stuff in there. So the reason that they're Speck in to inspect your pee if they tell you now it's like well, you know, they different application demand. So it should be like this will separate the metals are useful originally. The reason was it this was created by doing the original the original version of suspect 95, one of the the founding members of aspect Consortium that got the started was the company  I forgotten.  They've been saying I think maybe it was like HP or something, but they had this computer that they had built a processor.  And they were going to really stink on spec FP and star on the floating Point wear clothes that were inspecting so they were like, hey, let's have to Benchmark Suites will split it in half and then we'll do really well on spec end and you know will stink on floating point but no one will expect us to do to do that while because they don't have a floating-point unit and so will look good to the customers that we care about some respeck FP right decision. And now you know, what the 30 years later whatever we have the same kind of structure in this Badu. This is a very influential benchmarks. I showed you that data early or the first week of a class where we showed performance growth over time for processors and that was Speck in data because there's a huge database of the stuff going back a long way. They they have an agenda, right? They're not these perfect pristine things that are handed down to us. They are the product of some human processing so they have kind of the shortcomings and so forth. I can come with that.  Fish always think are not what your benchmark is before you go and measure performance with it important things in the class. So it will probably be on the midterm and the final  so the performance equation is a model for processor performance model you taking physics, you know, it's in the same kind of mold as they much more complicated models we have for the other physical world Works us make some predictions about how particular processor will perform a particular measures Layton and it's meant to sort of quantify performance in terms of some pretty easy to measure architectural parameters. And the first one is instruction count. So this is just the number of instructions that I'm going to execute in my program instructions.  Practice. The second term is a cycles per instruction. This is how many cycles it takes us on average to execute a particular at execute a single instruction. This is an average will see that this is for a variety of reasons. It is not the length of time. It takes them to execute an individual instruction. But it's the average number of cycles that it takes executed instruction on the last term is a cycle time and that's how long are basically the inverse of our clock rate. So if its 1 gigahertz and the cycle time is one nanosecond and then if we put all these together we get the first fundamental theorem of computer architecture, which is that late and sequels instruction count time since like the cycles per second time seconds per cycle and will summarize that this way is a lie, cuz i c x c p i x t t  I know it's nice about this as a model is that each one of these individual turned his pretty easy to understand and they're kind of independent of one another right to the number of instructions that we're going to execute that sort of a property of the of the programmer running. The cycles per instruction is a prot is a is a result of the architecture. So the implementation details of the processor that we've built and then the cycle time it just a measure of kind of how fast that processor is running very kind of place between them. But I kind of breaks up performance into 3/9 pieces, then we can think about each of those independently.  so  Like I said, the performance equation is a mathematical model. So here it is again. So one of the nice things that tells us right now because they allow us to kind of think about how different changes will affect the system that we're studying. So for instance the model tells us that latency changes linearly with the instruction count. So roughly speaking of everything else is held constant. If I double the number of instructions, I can execute actual execution time will go up by a factor of to write latency is also a linear it was CPI. So if I take longer on average to execute an instruction execution time will also increase and it's also changes with cycle time. So if I run my computer twice as fast, so the cycle time goes down by 50% then my execution time will go down by 50% as well.  What kind of makes sense it also suggests that we can improve performance so we could try to reduce cycle time. That means increasing the clock right? We can reduce the instruction Cannery can reduce CPI and that should give us good ways to improve performance and we in these are like the basic things that we're going to look at in this class for how to improve latency or how to reduce latency each one of these will look at it will see that there's different ways of doing that. It also allows us to evaluate potential trade-offs really easily. So if I want to reduce the cycle Time by 50% and increase the CPI by 1.5 equation to tell me that is Annette Winn because if I multiply 2.5 * 1.5 I get .75, so that means the product of CPI and  Cycle time went down and that means at my execution time went down as well.  Hey, so do you still have thinking about performance?  So what do we do first the first look at reducing cycle time? So cycle time is the function of the processors design. We'll talk a little bit about how that works in the next few classes. If a design does less work during a clock cycle at cycle time will generally be shorter. They're going to look at a technique called pipelining that is really good at this all about reducing recycle time. So we'll make ourselves faster that way is also a function of process technology. So process technology is how we actually manufacture the chips have time that I'll go through a little a little bit of about how we manufacture chips. So roughly speaking if you take a particular design and you shrink it because every, you know year or two we can cram more transistors under a single piece of silicon than the clock speed will go up and that means that our process processor to get faster. We talked a couple days.  About how in the past you could just wait 18 months and your processor would go faster. It is mostly a product of this kind of effect. They would just shrink the chips and the chips would magically go faster but doesn't work as well as it used to but clock clock speeds do still go off when you can at least potentially go up if you make them smaller the problem though is that is across the clock speed increases power consumption also goes out the power consumption is roughly the square or so of the frequency, so it goes up pretty quickly.  I'm so this is pressure to keep a cycle time longer like what time is also a function of manufacturing variation? So when I design a processor the processor has you know a few billion transistor. They're not all exactly the same. And so if I happen to get a slow transistor at a critical place in my processor that can mean to the cycle time for that processor will go up there. When you go to Intel's website review by your processor's you'll see that there are different speed grades of processors, right? You can buy a 1 gigahertz Intel Xeon. Are you can buy a 3 gigahertz Intel Xeon and the way that they got a whole bunch of Intel Xeon off the line and they test them and they see how fast that particular ship can run right? So they keep cranking out the cycle of the clock and eventually it starts failing they back it off a little bit and that's what they'll sell it to your eyes are the ones that they sell to you for.  money  This is just kind of a roll of a dice that also right in town will also if there's a big market for the lower end will actually take some of the faster processors and sell them a slower process. I don't know if they do this anymore of it used to be that companies would actually then put a limiter on the speed. So you couldn't let go in and clocked a processor faster than what you had purchased it 4-0 to hear overclocker.  1 overclock a couple of overclockers. This is like  The videos online are pretty entertaining. So what you do is you by the very fastest ship that you can and then you install some special hardware and software on your machine and you can clock the the clock up faster than it's rated for and I'll do things like dump liquid nitrogen on their processor to keep it cool and they can run stuff really really fast. You know, I encouraged I encourage it is a hobby if you have a lot of money in a lot of time. All right, I guess maybe this time which is the number of seconds per cycle, which is measured in like nanoseconds or picoseconds are something we also use  Where is clock speed more in this is measured in hertz, like megahertz in a gigahertz and it's just the inverse of cycle time. So if I have experts then I have one over X seconds per cycle. So a 2.5 gigahertz clock means I have a 400 out of 6 nanoseconds cycle time. So pay attention. I mean, it's pretty obvious about cycle time because that would mean that one cycle time took like a big a second. We should make it pretty slow. So pay attention to where you just divided by the clock speed and hurts if you want to thinking hurts.  All right. This is an important kind of definition of thing. We talked about instruction catmaxx. So there are two ways to think about instruction count. I don't want you to get confused about this. So the terms that we use are the dynamic and static instruction count means that this is actually how many instructions the processor executes while running a particular program has like a billion like literally a billion instructions or maybe maybe a trillion like lots and lots of instructions.  The alternative is the static instruction count.  And this is just the number of instructions that the compiler wrote down to represent your program. So you look at a program listing in assembly, you're looking at the static instructions and you can count them up and that will give you the static instruction count. This is not relevant for computer perform. It's not just how many things are executed. So if you find yourself to dividing by a, you know, an instruction count that's like five during one of the homework's think carefully about whether or not that makes sense, right? All right.  So how do I reduce construction count write them to the second term there many ways to implement a particular computation, right? I could write down lots of different versions of the Assembly Language and there can be applied at different levels. So one very efficient way effective way is algorithmic improvements complexity at Big O, and it turns out that so quick started, right? What's the what's the what's the average case complexity of quicksort?  Well done. All right, I don't know what class that is, but your teacher is very happy that you remember that that was in login is there is  N squared right  So these things these terms translate more or less directly into instruction counts, right? So if I'm sorting I'm going to execute, you know, Big O of M login instructions if I'm bubble sorting on execute roughly M squared instructions to make improvements are the most important performance improvements in computer science. I'm not supposed to be telling you this in computer architecture class, but it's true. I think there were a huge Gamescom right? I was at a conference yesterday and they reported a result. Where am I doing? Some cover algorithmic stuff, they factor of 10 to the 20th.  It's a very large speed up. And obviously the thing was very slow beforehand. Then be like if translated into actual execution time for residents to the instruction count the way that you can do. This is by compiler optimization. These are also pretty important. You can say past to GCC and what it will do is it will look at your code and it will think about it for a long time and see if they can make it more efficient by reducing the number of instructions that will get executed.  Those are the kind of the two ways. You can easily affect instruction count.  So this is very simple, right? If one version requires further instructions Dynamic instructions in the p4xl be faster to the swimming at CPI in clock speed remain the same production. I see you should give a speed up, you know something like this about that sort of a review of all right, you know percent speed up 20% and so forth we talked about last time. Should pay off pretty directly because of the performance equation example.  price of gold per gram  I'm going to do a little Loop. So this is the kind of code that will come out of GCC with no optimizations one is it it's very easy to see what everything corresponds do.  You know, this is all very clear. What's what?  This is probably about Hulu control but there are lots of extra instructions in here. This is 13 static instructions. There's 13 if I have to actually run a little bit turns out to be a hundred 1312 Dynamic instructions.  So I can tell her I said hey what's going on everytime it wants to access a variable. So this is I think probably incriminating or this is my day.  Track my wife attractive to do the comparison to the end that I'm going to store I back.  this is  Sylvester should be swapped.  And then I could have that piece of code right there.  It gets a lot shorter.  All right. So now I have I was only one store instead of a whole bunch of stores will see that number and operations are pretty slow is 9 static instructions and a lot fewer Dynamic instructions.  How to code is also a little bit more complicated in this case it still happens to be pretty clear what's going on but it's not exactly clear where this what this construction is doing. It doesn't kind of map cleanly on anything over there and one thing that happens when they're compiler starts cranking up the optimization. You can do really gnarly things to your code. It will take one function and if it determines that, you know, you you call a function they don't know anything of the result will just stop calling a function that use real combine a bunch of instructions into one or find all sorts of other creative ways to add to speed up your code hard because there's not really any particular place in the Assembly Language that corresponds to the program that you wrote.  Oh, all right. So here is  What happened?  Why don't I have my  Alright, so here is the clicker question so over here we have a this is 13 static instructions on 112 Dynamic instructions here is version B, and I would like you to figure out the number of dynamic instructions and then compute the speed up for B.  So small that over for a little bit and I'm going to set up the clicker device.  It's on.  That's a good question.  Last time I said BD, but that was wrong, wasn't it?  BD but that was what does remember what the right answer was from last time?  That would never fix anything. Never.  I had a friend once who is a lawyer.  And I was over at his house and he was like, can you fix the internet?  Cuz I guess I'm supposed to say my computer sounds like  I can't help but that's not going to fix anything like that fixes everything.  number one  All right. Let me try starting up the software here.  Here I'll see if you guys can still see the slide.  whoa  What in the world? Okay.  Can you see the PlayStation Now anybody?  Yes, all right.  Alright BD it is.  I'll give you there like 10 seconds or so.  All right 3 to 1.  Alright discuss hotels next to you. I walk around see if you agree if you agree. That's great.  And then we can go out again.  All right. So let's go luck on your answers.  They're going to 10 seconds or so.  3 2 1  the bus. Alright. I must be d d is actually correct.  So what's going on? So we the first thing we do is count the number of endemic instructions.  soften as I can ask you  Once right. So there's two how much is this going to execute?  Once in between here, there are one two, three, four, five six extra instructions. How many time is all that can execute?  10 * so there is 60 instructions. So I guess is a total of 63.  Dancer and then speed up, right? So to speed up speed up S equals old over new.  equals 112  divided by 63 should equal 1.8.  So you don't want it?  make sense  All right.  So other than PacSun instruction count, so this is this is a dependent. So this could be doing different types of playing a DVD probably take some more instructions than writing a Word document, right? Cuz you're decoding all the frames and doing lots of work. They're all the same programs can a different amount of work depending on its input. So if I compiled a thousand line program that's going to do less work on a hundred line program on the same program may require a different number of instructions on different iOS A's. So remember this is the instruction set architecture the list of instructions of the program of the processor can execute  So I'll see that nips tends to use a lot fewer instructions and x86 to accomplish the same out of work.  So that means that the instruction count for MEPS is going to be a lot lower apartment a lot higher than it is on x86 and we'll see if there are some trade-offs in particular the cycle time for x86 tends to go up to the benchmarks. You need to make sure that they're doing the same work. If you're doing the comparisons, they're executing. They need to be started executing the high-level tasks, right so I can compare a mixed machine to an x86 machine as long as they're doing the same work. And then I take into account the instructions will be different but still with a cycle time and the CPI.  All right. Next up is cycles per instruction by the most complicated terms in the performance equation. Lots of things can affect it. So they can remember this is an average. So that means that the compiler can affect CPI by the different instructions are to choose with some instructions take longer than others. And so to paint the compiler chooses to do the CPI will go up or down program info. It's going to affect basically all aspects of her good behavior. And so that can actually change which instructions get executed that will change the average CPI.  The processors design can change it and soak in the memory system. This is actually a really big factor and CPI because this is where the performance of the memory system shows up in the performance equation for this is not the number of Cycles. It takes to execute one instruction. So the process or something like one, but in fact, it takes 5 Cycles to execute a single instruction. I don't know what to talk about why that is but this is not the length of time. It takes xq2 single instruction. The key is getting multiple instructions of the same time in maps and so this is the ratio of the CPI is the ratio of the Cycles required execute the program / the instruction count for that program.  All right, so that it's an average.  So the way that the process or they compiler effects this by something called instruction mix so I different structions take different amounts of time to execute procedure in different ways. So typically on average you can execute a single they're called into jury instructions, you like plus minus the binder or the bitwise operations and things like branches those take a single cycle on average in a germ X takes like 3 to 5 Cycles integer divide takes between 10 and maybe a hundred Cycles the floating Point other operations take between three and five Cycles integer divide is like a real killer really want to avoid this if you can floating Point boiling point of I was also slow and square root and so forth are slow and Loathing stores are highly variable. They can take between a single cycle up to maybe hundreds of Cycles if things go badly.  So depending on how the processor do besides implement or the compiler decides to implement things. You can have a huge variation and how many how what the average CPI is example of this is like integer multiplied takes between 3 and 5 Cycles but a bit shift takes only a single cycle multiplying by a power of 2 constant power of two. It can replace a multiplication with a right shift and it can reduce the CPI inflation called strength reduction might go ahead and do for you.  So here is an examples of the same Cody. Look at earlier optimizations. We have a couple of different types over here. I've given you the average CPI that you should you can use for each of those. There's a static house which we don't particularly care about 42 memory operations 50 integer operations 20 branches. So I have a total of 112 instruction just like we did before and then we can compute the average CPI. It's just the weighted average.  For these values in the table. And so we just add them up. So it's 5 * 42. It's 1 * 50 is 1 * 23 divided by the total which is right here and we get 2.5. What's the average CPI for this particular piece of code is 2.5.  I love you guys can work out with the new.  Again, what the new CPI has and what the resulting speed up is for those pieces with the optimizations enable.  I'll take a crack at that.  Are you real are 10 seconds or so?  All right 3 to 1.  All right, but Scott's amongst ourselves.  What do you guys think it is?  This is not my class. You thought it was D.  haha  haha  Mental math, what do you think? It's a  All right, so you should have skipped actually going to probably just engineered from the multiple choice answers. All right.  What do you think?  I like that answer pretty well.  All right. Why do you think it's B?  Not sure you're not sure. All right. So how do you compute the CPI from that table?  Usher that's right. So it's the weighted average of the CPI call him time to Dynamic construction count on  35 * 1 + 1 * 42 + 1 * 20 / 63  Okay, so I ran through that and see what you get.  All right locking your answers.  35 seconds or so at least get your clicker points.  All right 3 to 1.  Why did I put it over here?  Come on.  That's just not fair.  All right. Well 83% of you said it was easy, but I'm unable to move the window over there to show you for some reason.  So you correct.  So one one thing I noticed is people aware as I was walking and talking to people I encourage you to actually, you know, do the problem during the clicker sessions rather than looking at the answers and trying to back calculate which ones seem correct. I am cleverer than that. So there are several answers that will you know, if you back calculate they will lead you astray the weather in Graham.  So this is how we just do 5 * 1 + 1 * 42 + 1 * 23 divided all that by 63 total there. And that would give you the answer is 1.06 in the speed up again, it's sold over new.  So that's 1.062 points 5 divided by 1.06 equals.  2.36  All right.  All right, and there's a math again.  So reducing CPI and  This should not be in your CPR. There should be speed up.  Alright, so now we are the two pieces of code and  I know I have this broken across to slime. All right. So here is the original color that has the instruction can of 100 112 in the old CP. I have the new key and the new CPI so very quickly calculate what the speed up should be between those two.  using a performance equation, which I remind you is L equals i c x  CPI Furniture CT  10 seconds or so?  5 4 3 2 1  alright discuss with your neighbors  What do you think?  Yeah.  All right, go ahead and lock in your answers.  5 4 3 2  1  0  all right.  Stuart from the performance equation so we have  I thought there that's not what I want.  So if I take the November speed up is going to be  old / new  and so I can rewrite this with the performance equation as the old instruction count.  Which is going to be a hundred and twelve.  Time the old CPI which is going to be 2.5.  Time's the old cycle time CT old is 1.06 times the CT new.  All right. So now the challenge right of the one potential concern is what about the cycle time? So the cycle time change?  Berlin Rosen change right because all I did was change the program that I'm executing. I didn't change the processor. So that means that these two are equal and so I can just cross the mouth and then I can just take this product in this ends up being 4.19 which is be  alright, so a lot of time, you know, usually we're not changing Everything at Once cycle time off and cancel. So it's kind of pay attention to that the same instructions the same program running the same input then you know, maybe the instruction cat would cancel out but you don't actually everything all the times. Yes.  Because during the last cycle.  He was still going to the group and running.  over here  And then jump rope.  I am shocked. There's an error in my slides. I will check that out. I just looking at this. I think that you might be right.  But I don't think super well standing up so I will look at it. Later.  But assuming these numbers are the only got them. This is the math that we should do.  All right.  There is the math.  Go through and do all the math.  carry out  all right, we're going to put some TPI so different inputs make programs behave differently. So I asked you different functions will do different stuff and I can change the instructions that gets executed. So I'll change instruction mix and I can also change their for the CPI.  All right, next stop animals law.  No need to pay attention to this part of this isn't a part of me.  Yeah, all right angles optimization.  So is made by m know, this is Gene amdahl. He was one of the designers of the IBM system 360 which is one of the coolest computers was ever built. It is almost universally the case that every time we talk to take like I Advanced computer architecture, which is like a CSC 240 a almost everything that is in computer architecture appeared first and some for me IBM system 360  Is there not fat Sims 4?  Fat is fear uncertainty and doubt. It's a marketing strategy used by large companies to prevent or to undermine the sales of smaller companies. So Microsoft wasn't for this. It's basically that's right. So if you're trying to sell some softer to someone and they're like what what about Linux I could use Linux on the desktop and they're like well,  I don't know it might work.  I mean it's supported by a bunch of like random people around the world might still be around in 5 years. I don't know.  And if they went away really bad things would happen.  So I got really bad for you because you're a big company and you want people to do work. So, you know, that's probably how you might want it but I don't know. I just like lol good thing is that people say, you know, no one ever gets fired for buying IBM, you know, whatever gets fired now for buying Microsoft genuine know why you smiling  Because he's extremely rich. All right.  So is that the basic observation here is that optimizations are not generally uniform they do not generally uniformly affect the entire program. So the more widely applicable technique is the more valuable it is.  Armin conversely if you have an optimization that has limited applicability you can drastically reduce the impact of the optimization.  So always heat handles lot.  This is really important. So and I tell you this it's not just for this class. This is like  this applies all over the place. So the US federal budget, right? So we talked about how we should reduce the budget and people talk about how we should save a hundred million dollars from like repairing bridges that are going to fall down. That sounds like a good plan right or a hundred million dollars on bridges help.  no, because that optimization  saving a little bit of money on Bridges is not widely applicable until have limited impact the same notion of your own personal finances, right? If you want to save extra money, right should you worry about rent or whether you get like a dollar fifty candy bar or dollar twenty-five candy bar? Like that's not important you need to go for rent. Cuz that's where he goes to my mortgage this essential to all kinds of things, right. You can apply this basic idea everywhere. It's very important Computer Science and Arts of profiling tells you which parts of your programmers slow many times in my life. I have thought I've had a slow program. I want to speed it up. I think it's probably this function. That's low functioning because I did not heed and  And like nothing happened if I was like, oh that function even though it seemed important to like 1% of execution sodomising it doesn't help.  There's an example we have start up and they are marketing a new processor and then has the Super jpeg Aranda super jpg O Rama 2010 until when I may be 5 2018 instructions by 10 x 10 times faster 10 times. That's a lot right act now while supplies last.  There's also find friends.  You know all kinds of things like a wrong or might not.  It will not on ground principal decode pictures of Justin Bieber Lady Gaga. That's just kind of a moral issue when we run this right here is my program.  Alright, so  18 cuz we just updated it. So we have picked up. What time do NJ PD code? That's a lot actually probably buy program standards. My program my laptop decode does jpeg around my 2k help.  So here is a little schematic drawing of the execution of I picked up bench and here is the time it's been doing jpeg decode it probably is right here just for clarity and here's what happens if I use as an optimization. So now the screen part got 10 times smaller text 1/10 of time, but all this blue stuff was not affected because jpg a rama doesn't have any effect on that. And so the total execution time here is 21 seconds. The old execution time is 30 seconds in the actual speed up is there for  Just 1.4 to not 10x right respectable. If I really all I care about is picked up and throw things like it then that would not be a bad way to just spend my money and all eight or speed up write another kind of depends on you have to look at your system and what you're willing to pay and how important jpeg Depot jpg Dakotas to you.  here it is formally so if we can speed up EXO, this is a fraction of the program between zero and one of a program by a so this is a speed up as we've defined speed up old over new animals law gives us the total speed up for applying at optimization best faction to program and here it is 1 / x / x + 1 - x  This is basically you can think about this. This is basically the weighted. This is the weighted average for latency. So we take the fraction of the program that we can speed up. We divide that by the speed up to speed up by to this thing. I'll go down by 1/2 and this is everything else you can think about this so you could think about this is being divided by one because it's a constant speed up nothing's changing and then it's just the weighted-average. Let me get the speed up from the latency. You take one over it and you get the new speed up.  So I would not be surprised at this exact equation were on the homework or the midterms or the final or L3.  So we can do some sanity checks on this.  What if the speed up is one right? So we don't do anything then if I stick one in here for us I get 1 / 1 / s equals ass so I kind of make sense.  All right. So here is an example of Daniel's law Protein Plus. I rewrote this just to be more up-to-date really call this deep.  deep  girl  But only one of them so and the law says that on average the whole lecture is only like 1% cooler. So I should go riding right deep neural Nets on all my slide hours on my current machine and it says 20% of its time doing integer stuff. Right? How much faster do I need to make my integer unit to make the code run 1.1 times faster?  Alright, so I will do this one is an example then we'll go into another one. So let's start.  Ask Cody equals 1 / x / us + 1 1 - x we go in this case.  1.1 Sarah's totes this is a stoat so I can write down 1.1 equals one over cuz I want to know what the speed of is going to be. So what sex?  X what x is the fraction of my program that is going to be affected by the optimization. So point point to write 2 / 8.  + 1 - 2.2  so I can simplify this I get one over.  This becomes .8. So it's  point to / us plus point eight.  Simple math is hard. So  no idea who this is.  22 / us  + 28 * 1/2  Oliver one so I can slip it over I get asked over 2 + 2.8 s  Point to point to thank you.  Oh, man, I hate math. All right.  This Is Us  Someone told me once that your IQ goes down by 20 points when you stand up.  And then buy more when he's not in front of the class, I will tell you the answer is B.  But I'm having trouble solving for B right now.  What's 1 / 1.1?  0.2 / all of that  Equals 1.9 we can try again on the next slide. I will do it as well. I'll play along at home. All right, so here's another same thing.  DNN how much do I need to how much how much faster to make the energy in it? So that it runs 50 hours faster.  All right, North 2nd.  locking your answers  3 2 1  a lot of dissension  All right, talk to lunch ourselves.  40 hours  Show the equation.  Another minute or so.  All right, like in your answers.  3 2 1  All right, how we do?  Come on, I don't know how decides which screen to put this on you. It's very  all right. We'll 86% of UCSD.  So the first question is what is what is a stoat so Estelle Drive 50 hours faster. So I mean it's going to be $150. So that means that the new the new latency equals 150 and we put that under 200 for old and that gives us if its 5/3 or something.  Not 4/3 4/3, which is 1.33 cups equals or my wife or here.  x / 1 / s tote  -1 - x again  Can I ax equals 0.2 if you go and stick in a stone, which is 1.3 and you stick in a point to 4X. This comes out. I believe the negative for something so negative value.  Friday the 2nd and negative speed up  so just tell this right is that we can "
}