{
  "Blurbs": {
    "1 my all to come to effectively become as my old one. That's where I'm going. And so I sort of downshift and I'm using the l25 a bigger cash a little bit slower, but now I can hold my working set. And then practiced you as I said, you make the L1 L2 as Ellen as big as you can within the cycle time in the L2 and L3 ": [
      2970.7,
      2993.1,
      71
    ],
    "40, which is how old I am but he seems really old when I was in college and in the math department and all of the classes were in a row there like for math classrooms in a row and every once in a while, you would hear sneak. Ron would be doing something on the board and one of his students would say, I think that you made a ": [
      4007.1,
      4029.0,
      106
    ],
    "All my menus are showing up as just the faintest outline with no texting them. So I just have to tap manually randomly. Definitely going to have a cape question about how copy my laptop is. So you can diffuse your anger CPI CPI. This is one mystery X Miss penalty and so on down the line, so there's our base CPI. So the first up is that so we ": [
      1637.6,
      1668.2,
      19
    ],
    "All right now it is the end. All right, at least have that slide back. There is actually not a slide deck. Thank goodness. Alright Advance cashing. So that's her the basics of how caches work. Now we just have seen how they can increase how they can increase. CPI and we've seen how the two kind of key things. They do worry about it. Here are the Mist times. ": [
      1753.1,
      1800.6,
      22
    ],
    "But I will never lower your grade based on what came out of the spreadsheet. Find bugs definitely tell me but this is I mean unless there are bugs so I don't think there are bugs but whoever thinks there are bugs right then this will be what we use for the final grades Starbucks. Things might change. any questions All right also, say the big midterm grades in here ": [
      915.3,
      944.7,
      0
    ],
    "Cash Line and performance can go up by quite a bit depending on your workload. So, is there something at the IRS can do? And I know you can do things in your program as well. If you buy kind of arranging or adjusting how you lay out your data structures a great deal of detail capacity occur. When the processor is trying to access more data than can fit ": [
      2798.3,
      2831.9,
      64
    ],
    "Dale to miss rate. And then there is maybe the L3 Miss rate. And the Miss rated any given level? Is relative to what's coming in. So if I have a 50% misread at the L1 and a 50% misread of the L2 then only 25% of my accesses are hitting in the L2 and only 25% Max has been missing in the L2 because half of them have been ": [
      1220.7,
      1246.2,
      9
    ],
    "Hit or Miss. Text Sarah castlen got twice as big which means that if there's a one here, that means that the we're still within the 32 bites a 16 or 32. So you think of this one is being in the way of the first bit of the next the next hour for bits actually still be a hit. So we got a bigger. Well, it's not increase our ": [
      3889.5,
      3921.5,
      102
    ],
    "I move from the first quadrant to the second I'll take a bunch of messages, but then I'll hit for the rest of the other nations. Tooth podcast tiling this is enormously important for scientific computation because scientific computation is almost all Matrix multiply or other major topmate Matrix Matrix operations, and they're doing these Matrix operations on huge arrays and their whole papers and books written about how to ": [
      3123.4,
      3149.8,
      78
    ],
    "I never access the rest of this then I've wasted all of this space and I picked out actually a bunch of other data, but I might have needed a hand. If I do eventually access all this then I will have really good performance have some pressure to keep the cash Lions really pays off is in a situation like this. So we have this Loop. You should definitely ": [
      2085.5,
      2111.8,
      35
    ],
    "If you go into the activity monitor you type P S on Linux, you'll get a list of like a hundred processes each one of those own private version of this map that Maps out its own virtual address space So now I need to represent represent in the map is harder because we need some sort of a sparse representation that only stores the parts that we are actually ": [
      4752.2,
      4778.2,
      133
    ],
    "Line and I'm going to compare. My old tag, that's how good is there with the tag on it with the tag part of my memory address and they match so that is definitely a hit. What kind of hit is it? Trick questions when one kind of fits the good kind of hex. All right. Next up is the tag. What is the index? One, alright that's going to ": [
      3692.7,
      3719.3,
      96
    ],
    "Loops. So that instead I do want it oration on the top left-hand quadrant. I do I do. I do All My Relations in the top left-hand quadrant Generations on the top right and in the bottom left in the bottom, right and now I will bring one of these into my cash and all computer over it multiple times and then I'll kick it all out. You know what ": [
      3102.7,
      3123.4,
      77
    ],
    "New Castle. I'm not I load the data from data equals I + 16 in to register 0, right. So Loudoun to register Zero have no effect because they hide it so you can change and this style be thrown away, but I will be in the cash. So it eventually I access it for real. I will get that value and I'll get a hit when I get back ": [
      2358.4,
      2382.6,
      46
    ],
    "So if I access one and tree in a cache Line 1 Word mccash line, I actually get the rest of the cash line for free. So if I access the first thing I get the last thing and that was so devoid of compulsory Miss because I am getting good access time for a piece of data that I have never asked for before what principle of racial equality ": [
      2024.0,
      2048.5,
      33
    ],
    "So if I have a 1 kg cash. And I'm performing Random Access has to 4 gigabytes of data the cash just going to have a poor hit Rich. There's not a lot I can do about that. I just want more data than the cash can hold its let the capacity Miss. I'm really got a couple different techniques for targeting each of the three C's as they are ": [
      1981.7,
      2003.3,
      31
    ],
    "So the missed penalty for the other one is equal to the LG to access time plus the Miss rates X dll to miss penalty. So this is the nominal time. It takes me to access DLC 2. This is the frequency with which I have to go in front of memory hierarchy and this is how long it takes me to go farther down the memory hierarchy + bl3 ": [
      1307.9,
      1333.8,
      12
    ],
    "They're only like two choices at either 8 or 0. What's my index for this Cash Line A List member access? 0 this thing right here second digit so it goes zero. So I'm going to go in this Castle. I'm now what's my tag going to be? Davison zeros will call this we're just going to call this a t Shorthand, and the data is going to be the ": [
      3622.2,
      3652.9,
      94
    ],
    "This will for a Compton cast capacity or reduce the number of lions. So that means if I double the width of my cache line and I am so this can hurt you because if you are you reading just a few bites here and there then I'm going to waste a lot of space in my cash. So in my example of cash line if I access this. And ": [
      2056.7,
      2085.5,
      34
    ],
    "Those are that's the first factor that determines our overall latency. And the second one is the Miss Right is the Miss right here. Right? So the question is we don't have a lot of control over the Miss X Charizard next weekend. We can make the cash as different sizes. But the way that the cash has the size of the cash instantly get set is a you take ": [
      1800.6,
      1827.4,
      23
    ],
    "You should punish Steve from six weeks ago because he made this mistake writing code. You would run a profile on determine whether or not you had a memory. I have a problem and the hardware performance counters. They will tell you how many L1 and L2 cache misses you have and how many Branch Miss predictions and all this stuff so you can go in and tell where your ": [
      3317.3,
      3344.6,
      85
    ],
    "a multi multiplayer program, I have lots of threads are all running the same code and a lot of times and programs the threads are all running the same cut at the same time. So I'll say, you know, each of you know, his 50 R16 thread go off and each of you add up a sequence of numbers and execute the same code to do that. That means that ": [
      2736.4,
      2758.0,
      61
    ],
    "a nice smooth way without a lot of hiccups and Bubbles and complexity. And so what year do if I could feel like cuckoo hashing then that means I'm going to look one place and then I'm going to look someplace else. I went someplace else and every time I look someplace else better than another that's my S Rampart is occupied for another cycle when I could be doing ": [
      3419.0,
      3439.8,
      88
    ],
    "all in cash and hit time is usually the same as a CPU cycle. So that means that in the the bay CPI memory operation is still just the base CPI of our normal operations, which is what sets are the starting place. If a lone star instruction, this isn't a line then we need to access tail to right so we pay the cost of accessing the current level ": [
      1122.1,
      1151.7,
      6
    ],
    "all their stocks tend to be in the same as well. And then each of those threats has its own stack and naively if you got you allocate a bunch of memory for the stack bridgeside. Maybe you'll get a megabyte of stack and gives you a line the address to the soul the Stax start at the same place all of the programme. All the threads are running the ": [
      2758.0,
      2777.9,
      62
    ],
    "an easy doubling a 3-2 and also people figure that 64 was bigger than you would ever possibly possibly need which so far has been the case, but of course will fail eventually, but this means we have four pages. Price out a lot of pages and each entry is 64 petabytes of mapping information that we need to store if you wanted to map all of it, right so ": [
      4658.8,
      4682.5,
      129
    ],
    "animals LA mejor right? That's not a question of like your level of computer science, like people's intuition about why their programs as slow is notoriously bad right software as complicated as behavior is complicated answer reasoning about why a particular piece of software isn't going as fast as you want your intuition about where your program spends most of his time is almost certainly wrong. And so if you'd ": [
      3202.7,
      3231.6,
      80
    ],
    "another memory access, right? So that's a missed opportunity for do it for servicing a load that I actually need. And so, you know in practice between on the complexity of may be better to just kick it down to the next level of the hierarchy because after I do like if I start doing 3 L1 accesses remember from the hierarchy if I start doing 301 accesses that's as ": [
      3439.8,
      3463.5,
      89
    ],
    "are all the same mod 4096 in my cache size. Alright, so this is a conflict must have a whole bunch of consequences. And what's even worse is that there is only in other son's relatively small number of cash lines with my cash lines are they should actually all fit into the cash write a Mexican got that much data. So most of my cash is just empty this ": [
      2642.5,
      2668.0,
      57
    ],
    "as big as you can while keeping it on chip. All right about the things we can actually do to fix this too so we can manage the working step by changing how we structure our programs. So there's lots of different ways to brew given a particular computation saeran. Look at Matrix multiplied because it's easy to reason about Autos lots of different ways in a lot of cases ": [
      2993.1,
      3017.6,
      72
    ],
    "at the beginning cuz otherwise it will work yet. There's actually it an even worse problem. Yes. That's right. Yeah. So this this address that I'm loading from the programmer never told me to load from so the processor is going to go it's going to calculate that. This could be in a pay a part of memory that doesn't exist, but it's not math. We'll talk about it, but ": [
      2430.4,
      2462.0,
      49
    ],
    "be 20 minutes in for a 64-bit machine will be 142 beds. I'm going to run that through the map and then we're going to give us the physical page number and then we will just tack on the page offset to the end of that and that will give us our physical address, which will also be 32 bits. Write for this is the translation process me to do ": [
      4567.9,
      4587.1,
      125
    ],
    "beer because the CPI base include the oven access time. The L1 time is the Miss penalty of the L1. So this is this is Hat Time. And this is Miss time. over here So that I know what is a missed penalty. This is the extra time I spend when I have to go to when I go to memory, but I spend going farther down the memory hierarchy. ": [
      1279.8,
      1307.9,
      11
    ],
    "big. And the cash is this big right to the cash is clearly too small to hold the array. So if we just did this lately and we did the yellow pass and then the purple pass in the Blue Palace in the red pass in the green pass. We would fill the cash once And then it would start erasing stuff and when we came back and we started ": [
      3039.6,
      3063.1,
      74
    ],
    "by looking at the cycle time to make sure converting from Cycles to nanoseconds whatever correctly. So this basic schematic make sense of how to do the math. It's not like I said, it's not like it's not really hard math, but it is easy to make mistakes. So let's consider the following question as a clicker problem. So we have this setup. We have an application 80% of the ": [
      1361.3,
      1387.8,
      14
    ],
    "bytes. So that's one thirds of a physical address. So if I want to map one physical address to the store for Fleming's at 4 megabytes of map that is not so bad we could deal with that. Especially the modern machine by modern machines have 64-bit addresses. They have 16 exabytes a virtual address space a very very large. We went to 64 bits for two reasons one. It's ": [
      4632.2,
      4658.8,
      128
    ],
    "cache line size that is good at removing compulsory misses and we just did that right that used to be a compulsory miss you get a longer casts. We brought in more data and now we live in a profession. We got rid of a compulsory, Miss. Are also be a head hitter mess. Miss again. The tag is going to be wrong to have a Miss in the same ": [
      3921.5,
      3945.9,
      103
    ],
    "call the page table that Maps virtual address is to physical addresses and the processor is going to generate virtual addresses. So everything that pops out of your you and your son in a story that's going to be a virtual address and then they're going to be translated by address translation to physical addresses by a combination of hardware and software but the the fast path Is definitely going ": [
      4456.3,
      4479.4,
      121
    ],
    "called. So the first one we're going like out of compulsory misses. So there's a couple ways that may seem the compulsory misses our kind of intractable. We can actually do some things to improve them are the first thing we can do is increase the cache line size. So the cash deal the data at the granularity of a castle and a cache line is bigger than a word. ": [
      2003.3,
      2024.0,
      32
    ],
    "can tell you how big the caches are on your computer. So if I access a little bit of data and then a little bit more like a smaller a over and over again than a bigger Ray over and over again what you'll see is that as the array size grows. It'll be really fast in this is latency. It'll be really fast and then it'll pop up here ": [
      2278.6,
      2297.7,
      42
    ],
    "capacity and conflict misses? ORCA pass conflict capacity in control services All right. three slide decks in one day All right, so virtual memory operating systems. Is it a prereq for this class? All rights reserved a virtual memory so one of the things that program's needs to do is they need to work with computers need to do is they need to run multiple programs so far but we ": [
      4088.6,
      4142.2,
      108
    ],
    "case second and tells you that you should not forget the uncommon case but the third corollary would just so obvious that I don't even put it on a slide is it you definitely should not screw up the common case, right? So memory is like a very common case. It's like one and five instructions we execute and so if you make each memory operation, it's actually worse than ": [
      4391.2,
      4413.7,
      118
    ],
    "cash. What that is going to look like? So here's address for iMac systems. So I'm accessing this is called a striated access pattern. So I'm accessing every 4096 bites. And if I have a 4 kilobyte cash each one of these cash lines at the beginning of these before kilobyte chunks of the survey are all going to map into the same part. Have my cash because their addresses ": [
      2611.4,
      2642.5,
      56
    ],
    "clearly we're not going to store a bigger a right that we could index in the fastest thing except. I couldn't keep it anywhere, but it would be the easiest thing to look up. We just look in that slot and we find the address for looking for but that is not going to work. So I would like to shrink the map. So that turns out you don't need ": [
      4682.5,
      4702.4,
      130
    ],
    "count that one. But the I cash can have all of a sudden all the same structure right now. I'm depending penalize there as well because if I get stalling stalling in the memory stage, so 5% Miss raid hit time of one cycle. Speedy Cash of the 10% misread to have time and want to hit time of on psycho BL2. What does unified so both the I cash ": [
      1415.9,
      1441.2,
      16
    ],
    "difference. And then we can be even more clever and we can say if if both of them want to allocate a whole bunch of memory, then we can also start dumping some of that memory onto disc and we will have the illusion of having a very very large amount of memory indeed and now I can think about you know, I can get a petabyte disgrace. I got ": [
      4352.7,
      4371.1,
      116
    ],
    "do matrix multiplication and efficient tile kind of cash and kind of way to make sure you're getting the most use possible out of each piece of data that you bring you in to the caches. All right. Any questions about those the three C's of those optimizations? Yes. That's a really good question. And this goes to I should actually add a slide about Amazon the night discussion of ": [
      3149.8,
      3202.7,
      79
    ],
    "don't count for the the regrades. So if you got to regrade him and gave him more points, you can go and make a copy of a spreadsheet and type in the new great that you got in those show you how it affects your score your broker. And yes. That's like that. assumption question The answer is quite a while, but the the other answer is that I do ": [
      944.7,
      988.4,
      1
    ],
    "end of the day that they don't really care. What kind of capacity conflict or compulsory? compulsory, Miss I like I haven't had animation. All right, it's compulsory. What's my next turn? Also zero, so is that and then what's the tag? So is that going to be a hit or a miss? The headright I am going to go to the same slot in my cash the same Cash ": [
      3652.9,
      3692.7,
      95
    ],
    "extraction the program that we're executing has access to all of that memory and that works fine. I like back in the olden days and there was just one program running on a computer and I could use I could refer to any address at 1 we can load from it and if I wanted to I can put my day to wherever I wanted and the one of the ": [
      4164.8,
      4191.1,
      110
    ],
    "filtered out by the by the upper layers of the memory hierarchy multiplication and addition but you kind of have to be careful and keep track of all of the pieces average CPI, which is what I want to plug in my performance equation play my bass CPI. I just won one and then I take my plus the L1. Access me, that's not right. We just said that the ": [
      1246.2,
      1278.5,
      10
    ],
    "from the bottom of that'll be fine. The problem will come if if I want to Malik more memory than I have. So if I have 64 kilobytes of memory to be very very small like much smaller than even an L2 cache now, but that's all I have and I asked I want a mouth like a whole bunch of memory. I'm going to be a sad little program ": [
      4243.5,
      4265.8,
      112
    ],
    "garbage but this single this one index is getting pounded and so it we have a port cache on this rate. So there's a couple things we can do we can increase the number of sets. So it'll increase the cash capacity. So that means you know, in this case if I double my cache size. Then some of them will end up here and some of them will end ": [
      2668.0,
      2693.0,
      58
    ],
    "go down and are the CPI memory operations will go down as well. It's kind of a famous kind of an ontology or a categorization of cache misses into three different categories. And the observation here is the record for different reasons. And if we think about them in terms of these three different reasons, then it'll suggest suggest different ways that we can go about attacking and getting rid ": [
      1886.7,
      1916.3,
      27
    ],
    "go here hit or miss. What kind of man? compulsory, Miss Compulsory math because I never said I did it before. Okay, what's next hit or miss? hits what's next are a mess? Ami's so am I my index again as one eye guy looking one I look at my tag with starting my cash. I look at my tagum address. They are not the same. Not equal so that ": [
      3719.3,
      3753.6,
      97
    ],
    "going to be at 3 to pay the cost of going to the L3? And then if you miss in the L3, then you have to pay the cost of going to Deer am so sorry this recursive process going down the memory hierarchy needs to account for all of this. There is a there is an L1. This is the L1 Miss rate is important here. And then there's ": [
      1199.2,
      1220.7,
      8
    ],
    "have 20% of our program is lodestar instructions instructions access instruction how many the instructions access instruction memory cache? All of them all instructions get fat so that means that hear what we have is we have a 5% misread for L1. I cash so that's the thing. I hear X some more stuff X the missed penalty. So that's a 10-second access time to the L2. There's 10 seconds ": [
      1668.2,
      1706.8,
      20
    ],
    "have been talking about is we have a processor and originally we had a very simple big array of bytes that was her memory and then we said okay well because there is a hierarchy of memories in the small ones are fast and the big ones are slowly just cashing thing to make it work, but we still have this assumption that in this kind of linear address space ": [
      4142.2,
      4164.8,
      109
    ],
    "have left. Are there capacity messages? Set a reducing there a couple things we can do. The first one is kind of obvious. We can just increased capacity, right so we can make our cash bigger and we can do that by adding more associative set. So I use Windex on my car tag a little bit smaller. That'll give us more room just cost area and makes the cash ": [
      2925.4,
      2950.5,
      69
    ],
    "here at the end of one pass. It'll be sort of the bottom half is it'll be in here, right what I needed the top half because that's what I'm going to start my next iteration. So I'm going to get a bunch of mrs. It's all because there's not room in my cat's what I can do instead as I can be clever and I could break up my ": [
      3086.8,
      3102.7,
      76
    ],
    "interested in that. So now I have to go fetch it from Deer am so it's compulsory the conflict mix. So in this case the program has access to do two previously. So I have read or written to it in the in the past but it was evicted because another piece of data came in and kicked it out of the sack. Or the kid out of the same ": [
      1936.0,
      1959.1,
      29
    ],
    "interested in. And so since we're out of time, I will tell you what that sparse representation is on Tuesday. I'll see you then. ": [
      4778.2,
      4787.9,
      134
    ],
    "into the cash. And a working set is the date of that is currently important to the program. Right? It's a little bit of a notion by the you know, if I'm working the same multiplying some raised together. My working said is those are as if I'm I know the workings that usually includes my stack for instance of they can think of it as sort of a hierarchy ": [
      2831.9,
      2857.2,
      65
    ],
    "is a mess. What kind of mess? No is not a conflict mix. Compulsory mess. Is it compulsory mess? Because I have never seen this address before. Right. So the eunuch it's about this mess. If not about some missing the future. We're going to get to that mess, but this mess is the compulsory Miss if I increase my associativity. Or increase my cache size or anything else do ": [
      3753.6,
      3789.3,
      98
    ],
    "is a virtual address space. The physical is a physical address space. We're going to break both of these places up in the pages. These are usually 4 kilobytes in size. There's some reasons to make it bigger that we'll talk about later and you know, how big are high performance systems do that. But for kilobyte is kind of still the default and then we're going to do something ": [
      4437.8,
      4456.3,
      120
    ],
    "it. This would still be a mess. Right. There's nothing I can do to fix it for prefetching. Nothing I can do to fix this. So it's a compulsory, Miss. All right, Next Up Hit or Miss. Head everything is the saying that one's easy next time hit or miss. hits hit or miss Miss okay. What kind of mess? Conflict Miss right because I had the data it was ": [
      3789.3,
      3816.1,
      99
    ],
    "kind of other than prefecture in the Empire just heard of stick them in to give you a little bit of helping your cash. The stuff is pretty common. All right. So that was a compulsory mrs. Prefetching is the big thing of the hardware tries to guess about what you're going to access that accesses some stuff for you. So nice II C consequences occur, when there was dated ": [
      2533.4,
      2560.4,
      53
    ],
    "like, I know I bet it's this I'm going to go off to my this you can spend a week optimize again. It'll be yours all school stuff you a little go back and your performance will be like 5% better. And at the end of law, right? You just totally broke and has lost because you optimize something. I didn't make that much difference. If you go there the ": [
      3231.6,
      3250.4,
      81
    ],
    "looking for a cache line. That was what you wanted. I'm sure there's been a paper on this number one number two. It's just really complicated asked to implement Hardware. So if you think about this feeling about our pipeline, right, I want to be executing my loads and stores in like a nice snooze, you know. I think it was like laminar flow. I wanted to execute things in ": [
      3389.0,
      3419.0,
      87
    ],
    "magical. All right, cool. Sorry about that. Give me a few more seconds. So 3 to 1 and we are done. All right, let's go through and do the math. How does little tiny Farm can people actually see that or even make a bigger now? Can't see it. That didn't help. Alright, so average CPI. the end my laptop is having a bad day. That's not what I wanted. ": [
      1469.2,
      1635.2,
      18
    ],
    "me if they can get an A in my class anymore because I can just find out for themselves. Spreadsheets are an interesting programming tool out the papers written about them actually so curious about that. You can go read some of them. All right? I got a new pen. You'll never believe how much do pens cost. $80 for a stupid little pain But at least I got a ": [
      1016.7,
      1060.2,
      3
    ],
    "mistake and with Dr. Vinnie keyboard. Cuz clearly if the truck stop has a little bit different now, but that's because of its got shifted over of Southern, Utah. What time compulsory hit or miss? hits hits hits hit or miss What kind? compulsory hit or miss We've gotten rid of all of our capacity and our compulsory are all of our capacity in Conflict misses. Alright any questions about ": [
      4029.0,
      4088.6,
      107
    ],
    "much cost of an L2 access. That's right. Yeah, you also yeah, that's a good point. It's a reasonable idea and if you go any take 240a, which is The Graduate architecture class, they will talk about kind of an alternate set of optimizations of people have applied to try to get around the associativity and hash Collision problem and the driving characteristic. I think your point about the fix ": [
      3463.5,
      3508.4,
      90
    ],
    "mystery X the d'ram access time because this is how long it'll take me back to see all three and then I miss and then the deer and access time it just a different time. another set of nested thing and so The the promise in the book ask for something like the average memory access time. So if they wanted the average access time, they need to translate that ": [
      1333.8,
      1361.3,
      13
    ],
    "need to do the translation. We have to do the translation really quickly on This Heart of two mechanisms that we're going to use to address each of those separately. So the first question we should think about is how big is the map. So in a 32-bit address space we have 4 gigabytes of virtual addresses and that's about 1 million pages. Each entry in that map is 4 ": [
      4608.6,
      4632.2,
      127
    ],
    "normally does. Cuz this car really slow. So really the size of the map should be on the order of the physical memory in the machine. So that's nice. So if I have 64 gigabyte machine on a 64-bit machine. 16 million pages in 128 megabytes the map so that's much more manageable write 120 megabytes. I can do nothing and there are lots of processes running on your computer. ": [
      4725.6,
      4752.2,
      132
    ],
    "not indent your code like this. PowerPoint is decided to Center my source code so and so are we are only going like this down the road. I'm going to take a Miss but then for the next the rest of that cash line, I'm going to hit. Set alarm for Cash Wise do really well like this. This is a I'll try to set up next animation simple example ": [
      2111.8,
      2152.2,
      36
    ],
    "nowadays everything is 64 bits, but the mechanics don't change at all winter break into two parts the Lord or bits are called the little bit confusing. So we have a page offset, which is Completely different from The Cash Line offset, right? So we're going to slice the pages are in a slice the address up in this way. And at the same time we're also going to be ": [
      4515.3,
      4545.6,
      123
    ],
    "of clever and people to work on it. But since Intel got really good with Foo Fighters, it's almost impossible to get this curve out and tells prefectures smart enough to make all of these pretty fast. By being very clever about how it goes and grab Data before you need it. So we can do this and Hardware we can also do this in software. So here's another piece ": [
      2317.0,
      2338.8,
      44
    ],
    "of code and this this so you could just write it almost you can't quite Express this and see if he could do it in a sembly the same piece of code only just add in this little conditional that says if I'm on 16 is equal to 0 which means and I happen to know that my cache line size of such as that means that I've crossed into ": [
      2338.8,
      2358.4,
      45
    ],
    "of particular class of mrs. Sew the first kind of Miss is a compulsory Miss so I can post your mess happens when I have a custom data that I've never accessed but I've never asked us before right? So in this case the cash is not a lot that I can do. Right? Just ask for some random address. I was like, okay. Well, I never knew you were ": [
      1916.3,
      1936.0,
      28
    ],
    "of something called prefetching the prefect trying to look at our same piece of code now formatted more reasonably and what the processor could do is it could be really smart and it could look at this code and I can watch it executed say Hey, you know this load right here or I'm loading and data I this load has a lot of regularity to it. And so what ": [
      2152.2,
      2181.5,
      37
    ],
    "of the cash. They always pay the cost of accessing the one we have to go inactive fail to sew the CPI of this instruction needs to include the cycles for accessing the L2. And then if we miss and also L1 and L2, then we have to go to some lower level of memory. Which nowadays is the L3. I got a new pen. So usually when are we ": [
      1151.7,
      1199.2,
      7
    ],
    "of the you know, there's the date of what I'm working on right this very very moment. Most actually in the registers is a little bit bigger kind of data that I might be working on a knife in the heart of the big set of data that I'm working on generally the cash you're currently looking at so for thinking about the L1 if my working set gets bigger ": [
      2857.2,
      2877.5,
      66
    ],
    "of your cash and then there's usually an L2 which is sort of somewhere in between. So we don't have a lot of control over these things or at least there are there have a constrained by the stuff. But the thing we can have some control over his the Miss rate, right? So if you can drive down there this raid, then the impact of them is time will ": [
      1868.8,
      1886.7,
      26
    ],
    "on the D Cash go there an ex has a 20% Miss rate in a 10-10 cycles and may never access is a hundred Cycles all three. So what is the average CPI? That is your question. Suppose all that for a little bit and I'll get the clicker thing up here. Sorry, I'm going to have to make this go away for a minute. Well, it's still there. That's ": [
      1441.2,
      1469.2,
      17
    ],
    "on the computer at the same time and I both want to put their Heats of the bottom in the stacks of the top then they're going to play with each other that's not going to work. So we want a way to give each program its own privates Vision version of memory and the grieving process will have its virtual address space. The approval process will have its own ": [
      4265.8,
      4299.9,
      113
    ],
    "operations ALU 20% of load store at the L1. Oh, I didn't talk about the I cash with a d cash. So if you do this you can do this separately for both the I cash in the D cash so I can have if I want to have to repeat all of this Plus. The I cast stuff. So this base Epi stays there. I don't get why only ": [
      1387.8,
      1415.9,
      15
    ],
    "out so we fill it with the with the with the day that we run out. We fill it in and run out and we come back to the second pass all of the data that we read. The first time is gone. So at the end of the first at the end of the first I threatened my computer and it work. That's awesome. Right so we'll be in ": [
      3063.1,
      3086.8,
      75
    ],
    "performance problems are. Yes. Huh? Write something good. That's a good question. So just for how many people does La Cucaracha use of a hash table? I can have it set up. So if I look where I want to put my item and that's full I can go and look somewhere else in cuckoo. Hashing is one way of doing that thing where you can chase through the cash ": [
      3344.6,
      3389.0,
      86
    ],
    "piece of software you on here is called a profiler in a lot of different kinds. There's no report. You need a memory profiler for this but there's also just instruction profilers. That's how you and which functions are spending most of your time. And you know, there are many times when I've been working a lot of software and it's slow and like why is it slow and then ": [
      3250.4,
      3271.3,
      82
    ],
    "place. And now we have acted everything next up at the compulsory medicine next up hit or a miss or kind. Conflict, Miss. Conflicts and then I got to be hit hit hit. All right, Next Step will increase the associativity and hopefully in the future decrease our font size size of 32 bytes. Play memory accesses. So here is the new breakdown of my drawings allowed to scale. But ": [
      3945.9,
      3980.6,
      104
    ],
    "plus the 20% Miss rate of the altars are here x the 100 cycles for the main memory. Then we added that extra for the 20% of instructions that are loads in stores plus are 10% Miss rates for L1 data cache hear X this stuff, which is again ten Cycles Plus. I 20% misread for the unified a cash x 3.14. The correct answer is eat. That makes sense. ": [
      1706.8,
      1740.5,
      21
    ],
    "pretty red one instead of the boring gray one. So that's worth it. Alright, so we were taking back cashing. Alright, so we need to think a little bit more about how to calculate the effects of cash cash is on performance. I remember the cash mostly has to do is CPI at least as far as her and talk about it in here. It's all about CPI. So the ": [
      1060.2,
      1090.6,
      4
    ],
    "purple a purple Hydro space and they'll access program. The hardware has a very important role. It's a sort of maintain this illusion. We're going to see how we do that. It will cost them behind those virtual memories are going to be the physical memory. And this is the actual like array of bytes this kind of correspond to the dims that are in your computer at does correspond ": [
      4299.9,
      4323.3,
      114
    ],
    "question is how does our cash organization affect the average latency for memory operations in a program. And then how does that in turn affect the average latency of infections generally and so that's all about CPI in the performance equation. so Generally speaking. And in this class is what we're going to do the load store instruction instruction hitson or load or store in so I can hit me ": [
      1090.6,
      1122.1,
      5
    ],
    "same code for all their Stacks end up in about the same spot in their stack space and that means that All of these accesses are going to conflict with each other in the caches. And so what some people realize that if you just be a little bit clever and you stagger your stack start or randomize it that all of a sudden now all these get their own ": [
      2777.9,
      2798.3,
      63
    ],
    "set up cash. And so this means that if I had been maybe a little bit clever about where I had stored things are what choices I made about what to evict in the past. Maybe I could have avoided this conflict Miss and if I don't want to come to Pasadena And these are our eyes because the program is just using more data than the cash can hold. ": [
      1959.1,
      1981.7,
      30
    ],
    "sizes important. But also there's a question of making it really easy to implement and Hardware because caches are already pretty hard information Hardware making them harder is not a good idea. Am I questions? Alright, so here's a simple example. Consider a direct mapped cache with 16 blocks in the block size of 16 bites on the application needs application will repeat the following memories access sequence. So first ": [
      3508.4,
      3541.3,
      91
    ],
    "slicing up into the offset tag and index for the cashing the casting stuff. But here it is an interest in the page offset. This is going to be pretty big. It's usually for queso this is usually 12 minutes. And that's going to be the lower two bits and then we're going to take this upper body of the rest of the address. And for a 32-bit machine will ": [
      4545.6,
      4567.9,
      124
    ],
    "slide. This is some little a practice for you to work on your sequels ABS computation will go back and look at this. So here's the same address sequence first access what they're going to be hit or miss. What kind yes compulsory Next Up Hit or Miss? How to get to intuition here are cache lines are bigger. So it's going to be a hat. All right, Next Up ": [
      3850.4,
      3889.5,
      101
    ],
    "slower. So the cash gets bigger the wires inside of get longer and it takes longer to access them and catch her keys are just kind of implicitly. So if you're working in the kind of term of Our Heroes falls out, if your work is that falls out of the old one, which means my working said gets too big for the L1 and I start missing me at ": [
      2950.5,
      2970.7,
      70
    ],
    "step is we have to break up this address into which three parts. The index the alright the tag was over here the tag and the office. Alright, so how many bytes how many bits of? Austin am I going to have 16 bytes how many what's the log base 2 of 16? 4 Orbitz, what is so that's going to be the lower two bits here conveniently. How did ": [
      3541.3,
      3581.2,
      92
    ],
    "than the other one. Then you are going to miss frequently. There's just nothing you can do about that because you want more data at hand then there's space for Capacity misses are hard to measure. So the easiest definition is that you look at the you look at the non-compulsory Miss rate in a fully is an equivalent fully associative. Cash and it wasn't fully associative cache. So if ": [
      2877.5,
      2904.3,
      67
    ],
    "that because instructions count to write so fetch every instruction Patches at least once since like a hundred and twenty percent of our instructions are memory operations. And so if you make that slow, then everything is going to get really bad. So this needs to be extremely efficient. So the mapping they were going to be able to see the virtual to physical mapping from a memory. The virtual ": [
      4413.7,
      4437.8,
      119
    ],
    "that could be a side fault. So what are the rules that they had? Is it a load the target register zero. Can I call the page fault so you can change and if something goes wrong it just ignores the segmentation fault that occurs. And I guess the only thing that they can do is they'll provide special prefetch instructions. So until Francisco's and how is your register so ": [
      2462.0,
      2491.4,
      50
    ],
    "that it's slow and so then you go and do that in like all of a sudden like my one night. I remember very clearly I sped up by three thousand times. It was awesome. My boss was so happy with me. And that was great. I didn't point out to my boss that this implies that the old version was terrible. Right? Like you shouldn't pray to Steve today. ": [
      3289.9,
      3317.3,
      84
    ],
    "that there is a function that will give you an aligned array. You can tell I want to allocate for megabytes when I want to be a boundary or something. That's one way you can make it more efficient. Even if you don't do that. This will probably be okay because if it's even if it's not at the beginning of the line while you're right, no dozen to be ": [
      2411.8,
      2430.4,
      48
    ],
    "that we that we needed and it was in the cash, but I got evicted evicted because we have cash in there was another request them after the same Cash Line this case we don't have a lot of control over I got evicted cuz there's only one option remember that there are many more than one Cash Line can fit it. And so more than any friendly associative lined ": [
      2560.4,
      2588.9,
      54
    ],
    "that work out conveniently? That's one hexadecimal digit 16 blocks. So, how big is Maya? What's my index going to be? Also for oh my gosh, so convenient and then my tag is going to be the top. So this is my back. So let's go through an example of stimulating a cash. So here's my sequence of accesses, I access 800,000 or whatever that is. What is my index? ": [
      3581.2,
      3613.8,
      93
    ],
    "that? Usually the L3 you make just as big as you can possibly make it kind of constrained by the cost of manufacturing your chip because that is the last barrier between your program and have to go hang out of Chip and is your call going off shift was like going to Saturn or something relative to accessing a register. And so that's sort of sense basically the size ": [
      1848.2,
      1868.8,
      25
    ],
    "the L1 cache and you make it as big as you possibly can without screwing up the cycle time of your processor, right? Because you're going to act like that all the time. So that needs to be I don't want to screw up the latency of kind of problem case instructions not as big as you can be the last level cache and let you up would you do ": [
      1827.4,
      1848.2,
      24
    ],
    "the low order bits do not go through translation. They just get copied but the hired of its do get translated. 32 basic problems that we needed to solve to make virtual memory work efficiently. The first one is that we need to store the map. I will need to start in a compact away because the map as well so you can be very large and then we also ": [
      4587.1,
      4608.6,
      126
    ],
    "the whole map, right? We can just store the parts of the map that matter and that will let the most more or less be the size of your physical address space. So if I have one gigabyte of memory in my computer, I don't need the store probably more than one gigabyte worth of mapping 41 process, right? We can go bigger because stuff goes to desperate in practice ": [
      4702.4,
      4725.6,
      131
    ],
    "then I'll hop up here and all you can see is that this is my L1 cache size and this is my L2 cache size because I was as I run out of space in the I want my latency goes up. Can I start missing all the time that it flattens out life in the L2 and then it goes up again and so forth. So I was kind ": [
      2297.7,
      2317.0,
      43
    ],
    "there and what they were as they were something and it was not quite this but it was an alligator stew Branch delay slots and the the compiler would actually want to do is hit one to align Branch targets to Cash Line boundary. So it needs extra little spaces that this would create it would just drop in these loads and I was like one of these loads what ": [
      2510.1,
      2533.4,
      52
    ],
    "there but now it's gone. And so I have a miss. hit or miss It's all right. very good new example eight blocks 32x in a cache line still direct Maps now, unfortunately things me a little more complicated so I had to break out of my bets. I hate that's how am I supposed to interpret that? All right. So that's the new address these things in the previous ": [
      3816.1,
      3850.4,
      100
    ],
    "they had a prefect instruction that think you can pass it in the address and it won't it won't hurt anything. I thought that was quite a lot. I used to work on a computer system. And when I went to look at the is very confusing. I was looking at the assembly code that came out and there were these weird low that it would just stick here and ": [
      2491.4,
      2510.1,
      51
    ],
    "things that they did and they still do actually is that the heat grows from the bottom up and the stack grows from the top down? And that means that everyone can put their Heap in their stack wherever they wanted to. Oh my goodness. hair we go hand I give up. All right, so I can put my stack up at the top. It'll go down the people go ": [
      4191.1,
      4243.5,
      111
    ],
    "this every quarter. I have been a professor for 12 years and I have taught that means something like 36 classes. So doing this one is much easier than like redoing it every time it's totally automated. It's very easy. I just have my graduate student my post at the columns and then the grades and I sent the Curves in the grades pop out. I know I never asked ": [
      988.4,
      1016.7,
      2
    ],
    "to be in Hardware. So here is the mapping again and we're going to figure out a way to store this complicated mapping between the virtual address space and the physical address space. We are almost out of time. He'll keep going Minot. Alright, so here's how this is basically going to work. We are going to take a virtual address. We're going to use 32-bit to this class. But ": [
      4479.4,
      4515.3,
      122
    ],
    "to break up the the date of that you're working on to make things more efficient. So here is an example of us are very common cashing optimization called tiling. Say that we have this array and we need to make a bunch of passes over the array. So we're going to do it over it. We're going to calculate some summary statistics or something and the array is this ": [
      3017.6,
      3039.6,
      73
    ],
    "to the dentist at your computer. So it's a zero and goes up the sun big number right could be hundreds of Terror Maps silver hear the heat was all nice together at the bottom for the blue guy and it's all nice to go to the bottom for the in Green for the green guy and but they could be all jumbled up and it won't make that much ": [
      4323.3,
      4352.7,
      115
    ],
    "to the illusion of a petabyte of memory, even though I have a much smaller amount of that in my actually my computer in D Ram. So the challenge is how do we make this work? And how do we make it fast? Right because animals law tells us right. So I have a lot to tell us a couple things first to tell you should focus on the common ": [
      4371.1,
      4391.2,
      117
    ],
    "up here, right? So that means that I'll do a little bit better. I could also increase my the nut the size of the set so I could increase my associativity. And so in this case if I went to double my associativity, and now there would be two slots here for those cash ones. Neither of those are really going to help in this case because I have a ": [
      2693.0,
      2713.6,
      59
    ],
    "up on the same spot in the cash. So something had to take it down in the thing that we got kicked out of turns out that we needed. so if we have some code like this. All right. So this is we're going to go from Michael's under a million, but we're going to take a stride at 4096 which is 4 kilobytes if I have a 4 kilobyte ": [
      2588.9,
      2611.4,
      55
    ],
    "we have the same the Lord or five bits are still the are still going to be the offset. The next two events are going to be the index. And then the tag is the top the top stuff. All right bad pain. All right. I had this professor. His name was Ronald beninca boards. And he would he was kind of a scrunchie older gentleman. He was probably like ": [
      3980.6,
      4007.1,
      105
    ],
    "we'll do is we'll calculate a Delta and we'll do is we'll look at the last address that this this instruction loaded from this load instruction letter from and will subtract that from the current address and I'll give me the distance between my previous access in my current access and then when I hit that instruction again, I will just start accessing at this address plus Delta. So if ": [
      2181.5,
      2207.2,
      38
    ],
    "whether or not when I get to the next address whether you know, whether the new the new address that I'm looking at matches this address. It will tell me that I am making a good prediction. I'm so current machines do this a lot. And so prefectures are very sophisticated than actually more closely guarded Secrets or at least equally guarded Secrets is Branch pictures. I think I told ": [
      2232.5,
      2257.6,
      40
    ],
    "whole lot of conflicts right? I've met him any cash lines are getting access to many many memory addresses to get map to the same cash line, but it would make things a little bit better. Compiling the operating system can help you as well. So this is a cool little trick that kind of showed up when when multi-core became a big thing. So this is if I have ": [
      2713.6,
      2736.4,
      60
    ],
    "with my cash. Does anyone see a potential problem with this? There is one very important detail that you have to get right. Yes. So that's a good point. So in order for this to work well or at least the best I would want to make sure that my data array was aligned. And so if you go and dig through the manual pages for lipsi, you will find ": [
      2382.6,
      2411.8,
      47
    ],
    "you go you're the profiler and some crazy thing like I'm looking up something in a hash table and like I put the hash look up in the wrong, you know, the wrong nesting of a loop or something. So it's doing it a billion times instead of you know, a million times. It's not incorrect because it's just the same value over and over again, but it turns out ": [
      3271.3,
      3289.9,
      83
    ],
    "you imagine you had a cash that was the same size and I can put anything anywhere that means that there are no conflict misses. And so that'll just tell me how much what the mystery would be if I could just hold any any set of data. That was that size. You can just take away the composed to take away the compulsory in the consequences in what you ": [
      2904.3,
      2925.4,
      68
    ],
    "you once a while ago that we had a when I was a graduate school in my advisor had a homework assignment where the students have to reverse-engineer the branch breaker and a bunch of them cried. So actually the same thing happen to the prefecture's the professors are also really complicated and the way this comes up is if you're clever, you can write a piece of code that ": [
      2257.6,
      2278.6,
      41
    ],
    "you're accessing every tenth word of memory their Hardware will learn that and it will start fetching every Tale start fetching 10 words ahead of you while you're walking to the survey. Now it could be wrong right? Maybe I'm accessing randomly. Maybe I'm jumping around so I might also keep some information about whether or not I am whether or not this tends to be useful. Which would mean ": [
      2207.2,
      2232.5,
      39
    ]
  },
  "File Name": "Intro_to_Computer_Architecture___A00___Swanson__Steven_James___Fall_2018-lecture_15.flac",
  "Full Transcript": "But I will never lower your grade based on what came out of the spreadsheet. Find bugs definitely tell me but this is I mean unless there are bugs so I don't think there are bugs but whoever thinks there are bugs right then this will be what we use for the final grades Starbucks. Things might change.  any questions  All right also, say the big midterm grades in here don't count for the the regrades. So if you got to regrade him and gave him more points, you can go and make a copy of a spreadsheet and type in the new great that you got in those show you how it affects your score your broker. And yes.  That's like that.  assumption question  The answer is quite a while, but the the other answer is that I do this every quarter.  I have been a professor for 12 years and I have taught that means something like 36 classes.  So doing this one is much easier than like redoing it every time it's totally automated. It's very easy. I just have my graduate student my post at the columns and then the grades and I sent the Curves in the grades pop out.  I know I never asked me if they can get an A in my class anymore because I can just find out for themselves.  Spreadsheets are an interesting programming tool out the papers written about them actually so curious about that. You can go read some of them. All right?  I got a new pen. You'll never believe how much do pens cost.  $80 for a stupid little pain  But at least I got a pretty red one instead of the boring gray one. So that's worth it.  Alright, so we were taking back cashing.  Alright, so we need to think a little bit more about how to calculate the effects of cash cash is on performance. I remember the cash mostly has to do is CPI at least as far as her and talk about it in here. It's all about CPI. So the question is how does our cash organization affect the average latency for memory operations in a program. And then how does that in turn affect the average latency of infections generally and so that's all about CPI in the performance equation.  so  Generally speaking. And in this class is what we're going to do the load store instruction instruction hitson or load or store in so I can hit me all in cash and hit time is usually the same as a CPU cycle. So that means that in the the bay CPI memory operation is still just the base CPI of our normal operations, which is what sets are the starting place.  If a lone star instruction, this isn't a line then we need to access tail to right so we pay the cost of accessing the current level of the cash. They always pay the cost of accessing the one we have to go inactive fail to sew the CPI of this instruction needs to include the cycles for accessing the L2.  And then if we miss and also L1 and L2, then we have to go to some lower level of memory. Which nowadays is the L3. I got a new pen.  So usually when are we going to be at 3 to pay the cost of going to the L3? And then if you miss in the L3, then you have to pay the cost of going to Deer am so sorry this recursive process going down the memory hierarchy needs to account for all of this. There is a there is an L1. This is the L1 Miss rate is important here.  And then there's Dale to miss rate.  And then there is maybe the L3 Miss rate.  And the Miss rated any given level?  Is relative to what's coming in. So if I have a 50% misread at the L1 and a 50% misread of the L2 then only 25% of my accesses are hitting in the L2 and only 25% Max has been missing in the L2 because half of them have been filtered out by the by the upper layers of the memory hierarchy multiplication and addition but you kind of have to be careful and keep track of all of the pieces average CPI, which is what I want to plug in my performance equation play my bass CPI. I just won one and then I take my plus the L1.  Access me, that's not right.  We just said that the  beer  because the CPI base include the oven access time. The L1 time is the Miss penalty of the L1. So this is  this is Hat Time.  And this is Miss time.  over here  So that I know what is a missed penalty. This is the extra time I spend when I have to go to when I go to memory, but I spend going farther down the memory hierarchy. So the missed penalty for the other one is equal to the LG to access time plus the Miss rates X dll to miss penalty. So this is the nominal time. It takes me to access DLC 2.  This is the frequency with which I have to go in front of memory hierarchy and this is how long it takes me to go farther down the memory hierarchy + bl3 mystery X the d'ram access time because this is how long it'll take me back to see all three and then I miss and then the deer and access time it just a different time.  another set of nested thing and so  The the promise in the book ask for something like the average memory access time.  So if they wanted the average access time, they need to translate that by looking at the cycle time to make sure converting from Cycles to nanoseconds whatever correctly.  So this basic schematic make sense of how to do the math.  It's not like I said, it's not like it's not really hard math, but it is easy to make mistakes.  So let's consider the following question as a clicker problem. So we have this setup. We have an application 80% of the operations ALU 20% of load store at the L1.  Oh, I didn't talk about the I cash with a d cash. So if you do this you can do this separately for both the I cash in the D cash so I can have if I want to have to repeat all of this Plus.  The I cast stuff. So this base Epi stays there. I don't get why only count that one. But the I cash can have all of a sudden all the same structure right now. I'm depending penalize there as well because if I get stalling stalling in the memory stage, so 5% Miss raid hit time of one cycle.  Speedy Cash of the 10% misread to have time and want to hit time of on psycho BL2. What does unified so both the I cash on the D Cash go there an ex has a 20% Miss rate in a 10-10 cycles and may never access is a hundred Cycles all three. So what is the average CPI?  That is your question.  Suppose all that for a little bit and I'll get the clicker thing up here.  Sorry, I'm going to have to make this go away for a minute.  Well, it's still there. That's magical. All right, cool.  Sorry about that.  Give me a few more seconds.  So 3 to 1 and we are done. All right, let's go through and do the math.  How does little tiny Farm can people actually see that or even make a bigger now? Can't see it.  That didn't help.  Alright, so average CPI.  the end  my laptop is having a bad day.  That's not what I wanted.  All my menus are showing up as just the faintest outline with no texting them. So I just have to tap manually randomly.  Definitely going to have a cape question about how copy my laptop is.  So you can diffuse your anger CPI CPI. This is one mystery X Miss penalty and so on down the line, so there's our base CPI. So the first up is that so we have 20% of our program is lodestar instructions instructions access instruction how many the instructions access instruction memory cache?  All of them all instructions get fat so that means that hear what we have is we have a 5% misread for L1. I cash so that's the thing. I hear X some more stuff X the missed penalty. So that's a 10-second access time to the L2.  There's 10 seconds plus the 20% Miss rate of the altars are here x the 100 cycles for the main memory. Then we added that extra for the 20% of instructions that are loads in stores plus are 10% Miss rates for L1 data cache hear X this stuff, which is again ten Cycles Plus. I 20% misread for the unified a cash x 3.14. The correct answer is eat.  That makes sense.  All right now it is the end.  All right, at least have that slide back. There is actually not a slide deck. Thank goodness. Alright Advance cashing.  So that's her the basics of how caches work.  Now we just have seen how they can increase how they can increase.  CPI and we've seen how the two kind of key things. They do worry about it. Here are the Mist times. Those are that's the first factor that determines our overall latency.  And the second one is the Miss Right is the Miss right here. Right? So the question is we don't have a lot of control over the Miss X Charizard next weekend. We can make the cash as different sizes. But the way that the cash has the size of the cash instantly get set is a you take the L1 cache and you make it as big as you possibly can without screwing up the cycle time of your processor, right? Because you're going to act like that all the time. So that needs to be I don't want to screw up the latency of kind of problem case instructions not as big as you can be the last level cache and let you up would you do that? Usually the L3 you make just as big as you can possibly make it kind of constrained by the cost of manufacturing your chip because that is the last barrier between your program and have to go hang out of Chip and is your call going off shift was like going to Saturn or something relative to accessing a register.  And so that's sort of sense basically the size of your cash and then there's usually an L2 which is sort of somewhere in between. So we don't have a lot of control over these things or at least there are there have a constrained by the stuff. But the thing we can have some control over his the Miss rate, right? So if you can drive down there this raid, then the impact of them is time will go down and are the CPI memory operations will go down as well.  It's kind of a famous kind of an ontology or a categorization of cache misses into three different categories. And the observation here is the record for different reasons. And if we think about them in terms of these three different reasons, then it'll suggest suggest different ways that we can go about attacking and getting rid of particular class of mrs. Sew the first kind of Miss is a compulsory Miss so I can post your mess happens when I have a custom data that I've never accessed but I've never asked us before right? So in this case the cash is not a lot that I can do. Right? Just ask for some random address. I was like, okay. Well, I never knew you were interested in that. So now I have to go fetch it from Deer am so it's compulsory the conflict mix.  So in this case the program has access to do two previously. So I have read or written to it in the in the past but it was evicted because another piece of data came in and kicked it out of the sack.  Or the kid out of the same set up cash. And so this means that if I had been maybe a little bit clever about where I had stored things are what choices I made about what to evict in the past. Maybe I could have avoided this conflict Miss and if I don't want to come to Pasadena  And these are our eyes because the program is just using more data than the cash can hold. So if I have a 1 kg cash.  And I'm performing Random Access has to 4 gigabytes of data the cash just going to have a poor hit Rich. There's not a lot I can do about that. I just want more data than the cash can hold its let the capacity Miss. I'm really got a couple different techniques for targeting each of the three C's as they are called.  So the first one we're going like out of compulsory misses.  So there's a couple ways that may seem the compulsory misses our kind of intractable. We can actually do some things to improve them are the first thing we can do is increase the cache line size. So the cash deal the data at the granularity of a castle and a cache line is bigger than a word. So if I access one and tree in a cache Line 1 Word mccash line, I actually get the rest of the cash line for free. So if I access the first thing I get the last thing and that was so devoid of compulsory Miss because I am getting good access time for a piece of data that I have never asked for before what principle of racial equality  This will for a Compton cast capacity or reduce the number of lions. So that means if I double the width of my cache line and I am so this can hurt you because if you are you reading just a few bites here and there then I'm going to waste a lot of space in my cash. So in my example of cash line if I access this.  And I never access the rest of this then I've wasted all of this space and I picked out actually a bunch of other data, but I might have needed a hand. If I do eventually access all this then I will have really good performance have some pressure to keep the cash Lions really pays off is in a situation like this. So we have this Loop. You should definitely not indent your code like this.  PowerPoint is decided to Center my source code so and so are we are only going like this down the road. I'm going to take a Miss but then for the next the rest of that cash line, I'm going to hit.  Set alarm for Cash Wise do really well like this. This is a  I'll try to set up next animation simple example of something called prefetching the prefect trying to look at our same piece of code now formatted more reasonably and what the processor could do is it could be really smart and it could look at this code and I can watch it executed say Hey, you know this load right here or I'm loading and data I this load has a lot of regularity to it. And so what we'll do is we'll calculate a Delta and we'll do is we'll look at the last address that this this instruction loaded from this load instruction letter from and will subtract that from the current address and I'll give me the distance between my previous access in my current access and then when I hit that instruction again, I will just start accessing at this address plus Delta.  So if you're accessing every tenth word of memory their Hardware will learn that and it will start fetching every Tale start fetching 10 words ahead of you while you're walking to the survey.  Now it could be wrong right? Maybe I'm accessing randomly. Maybe I'm jumping around so I might also keep some information about whether or not I am whether or not this tends to be useful.  Which would mean whether or not when I get to the next address whether you know, whether the new the new address that I'm looking at matches this address. It will tell me that I am making a good prediction.  I'm so current machines do this a lot. And so prefectures are very sophisticated than actually more closely guarded Secrets or at least equally guarded Secrets is Branch pictures. I think I told you once a while ago that we had a when I was a graduate school in my advisor had a homework assignment where the students have to reverse-engineer the branch breaker and a bunch of them cried. So actually the same thing happen to the prefecture's the professors are also really complicated and the way this comes up is if you're clever, you can write a piece of code that can tell you how big the caches are on your computer. So if I access a little bit of data and then a little bit more like a smaller a over and over again than a bigger Ray over and over again what you'll see is that as the array size grows.  It'll be really fast in this is latency. It'll be really fast and then it'll pop up here then I'll hop up here and all you can see is that this is my L1 cache size and this is my L2 cache size because I was as I run out of space in the I want my latency goes up. Can I start missing all the time that it flattens out life in the L2 and then it goes up again and so forth. So I was kind of clever and people to work on it. But since Intel got really good with Foo Fighters, it's almost impossible to get this curve out and tells prefectures smart enough to make all of these pretty fast.  By being very clever about how it goes and grab Data before you need it.  So we can do this and Hardware we can also do this in software. So here's another piece of code and this this so you could just write it almost you can't quite Express this and see if he could do it in a sembly the same piece of code only just add in this little conditional that says if I'm on 16 is equal to 0 which means and I happen to know that my cache line size of such as that means that I've crossed into New Castle. I'm not I load the data from data equals I + 16 in to register 0, right. So Loudoun to register Zero have no effect because they hide it so you can change and this style be thrown away, but I will be in the cash. So it eventually I access it for real. I will get that value and I'll get a hit when I get back with my cash. Does anyone see a potential problem with this?  There is one very important detail that you have to get right.  Yes.  So that's a good point. So in order for this to work well or at least the best I would want to make sure that my data array was aligned. And so if you go and dig through the manual pages for lipsi, you will find that there is a function that will give you an aligned array. You can tell I want to allocate for megabytes when I want to be a boundary or something. That's one way you can make it more efficient. Even if you don't do that. This will probably be okay because if it's even if it's not at the beginning of the line while you're right, no dozen to be at the beginning cuz otherwise it will work yet. There's actually it an even worse problem. Yes.  That's right. Yeah. So this this address that I'm loading from the programmer never told me to load from so the processor is going to go it's going to calculate that. This could be in a pay a part of memory that doesn't exist, but it's not math. We'll talk about it, but that could be a side fault. So what are the rules that they had? Is it a load the target register zero. Can I call the page fault so you can change and if something goes wrong it just ignores the segmentation fault that occurs.  And I guess the only thing that they can do is they'll provide special prefetch instructions. So until Francisco's and how is your register so they had a prefect instruction that think you can pass it in the address and it won't it won't hurt anything.  I thought that was quite a lot. I used to work on a computer system. And when I went to look at the is very confusing. I was looking at the assembly code that came out and there were these weird low that it would just stick here and there and what they were as they were something and it was not quite this but it was an alligator stew Branch delay slots and the the compiler would actually want to do is hit one to align Branch targets to Cash Line boundary. So it needs extra little spaces that this would create it would just drop in these loads and I was like one of these loads what kind of other than prefecture in the Empire just heard of stick them in to give you a little bit of helping your cash.  The stuff is pretty common.  All right. So that was a compulsory mrs. Prefetching is the big thing of the hardware tries to guess about what you're going to access that accesses some stuff for you. So nice II C consequences occur, when there was dated that we that we needed and it was in the cash, but I got evicted evicted because we have cash in there was another request them after the same Cash Line this case we don't have a lot of control over I got evicted cuz there's only one option remember that there are many more than one Cash Line can fit it. And so more than any friendly associative lined up on the same spot in the cash. So something had to take it down in the thing that we got kicked out of turns out that we needed.  so  if we have some code like this.  All right. So this is we're going to go from Michael's under a million, but we're going to take a stride at 4096 which is 4 kilobytes if I have a 4 kilobyte cash.  What that is going to look like?  So here's address for iMac systems. So I'm accessing this is called a striated access pattern. So I'm accessing every 4096 bites.  And if I have a 4 kilobyte cash each one of these cash lines at the beginning of these before kilobyte chunks of the survey are all going to map into the same part.  Have my cash because their addresses are all the same mod 4096 in my cache size.  Alright, so this is a conflict must have a whole bunch of consequences. And what's even worse is that there is only in other son's relatively small number of cash lines with my cash lines are they should actually all fit into the cash write a Mexican got that much data. So most of my cash is just empty this garbage but this single this one index is getting pounded and so it we have a port cache on this rate.  So there's a couple things we can do we can increase the number of sets. So it'll increase the cash capacity. So that means you know, in this case if I double my cache size.  Then some of them will end up here and some of them will end up here, right? So that means that I'll do a little bit better. I could also increase my the nut the size of the set so I could increase my associativity. And so in this case if I went to double my associativity, and now there would be two slots here for those cash ones. Neither of those are really going to help in this case because I have a whole lot of conflicts right? I've met him any cash lines are getting access to many many memory addresses to get map to the same cash line, but it would make things a little bit better.  Compiling the operating system can help you as well. So this is a cool little trick that kind of showed up when when multi-core became a big thing. So this is if I have a multi multiplayer program, I have lots of threads are all running the same code and a lot of times and programs the threads are all running the same cut at the same time. So I'll say, you know, each of you know, his 50 R16 thread go off and each of you add up a sequence of numbers and execute the same code to do that. That means that all their stocks tend to be in the same as well. And then each of those threats has its own stack and naively if you got you allocate a bunch of memory for the stack bridgeside. Maybe you'll get a megabyte of stack and gives you a line the address to the soul the Stax start at the same place all of the programme. All the threads are running the same code for all their Stacks end up in about the same spot in their stack space and that means that  All of these accesses are going to conflict with each other in the caches. And so what some people realize that if you just be a little bit clever and you stagger your stack start or randomize it that all of a sudden now all these get their own Cash Line and performance can go up by quite a bit depending on your workload.  So, is there something at the IRS can do?  And I know you can do things in your program as well. If you buy kind of arranging or adjusting how you lay out your data structures a great deal of detail capacity occur. When the processor is trying to access more data than can fit into the cash.  And a working set is the date of that is currently important to the program. Right? It's a little bit of a notion by the you know, if I'm working the same multiplying some raised together. My working said is those are as if I'm I know the workings that usually includes my stack for instance of they can think of it as sort of a hierarchy of the you know, there's the date of what I'm working on right this very very moment. Most actually in the registers is a little bit bigger kind of data that I might be working on a knife in the heart of the big set of data that I'm working on generally the cash you're currently looking at so for thinking about the L1 if my working set gets bigger than the other one. Then you are going to miss frequently. There's just nothing you can do about that because you want more data at hand then there's space for  Capacity misses are hard to measure. So the easiest definition is that you look at the you look at the non-compulsory Miss rate in a fully is an equivalent fully associative.  Cash and it wasn't fully associative cache. So if you imagine you had a cash that was the same size and I can put anything anywhere that means that there are no conflict misses. And so that'll just tell me how much what the mystery would be if I could just hold any any set of data. That was that size. You can just take away the composed to take away the compulsory in the consequences in what you have left. Are there capacity messages?  Set a reducing there a couple things we can do. The first one is kind of obvious. We can just increased capacity, right so we can make our cash bigger and we can do that by adding more associative set. So I use Windex on my car tag a little bit smaller. That'll give us more room just cost area and makes the cash slower. So the cash gets bigger the wires inside of get longer and it takes longer to access them and catch her keys are just kind of implicitly. So if you're working in the kind of term of Our Heroes falls out, if your work is that falls out of the old one, which means my working said gets too big for the L1 and I start missing me at 1 my all to come to effectively become as my old one. That's where I'm going. And so I sort of downshift and I'm using the l25 a bigger cash a little bit slower, but now I can hold my working set.  And then practiced you as I said, you make the L1 L2 as Ellen as big as you can within the cycle time in the L2 and L3 as big as you can while keeping it on chip.  All right about the things we can actually do to fix this too so we can manage the working step by changing how we structure our programs.  So there's lots of different ways to brew given a particular computation saeran. Look at Matrix multiplied because it's easy to reason about Autos lots of different ways in a lot of cases to break up the the date of that you're working on to make things more efficient. So here is an example of us are very common cashing optimization called tiling.  Say that we have this array and we need to make a bunch of passes over the array. So we're going to do it over it. We're going to calculate some summary statistics or something and the array is this big.  And the cash is this big right to the cash is clearly too small to hold the array. So if we just did this lately and we did the yellow pass and then the purple pass in the Blue Palace in the red pass in the green pass. We would fill the cash once  And then it would start erasing stuff and when we came back and we started out so we fill it with the with the with the day that we run out. We fill it in and run out and we come back to the second pass all of the data that we read. The first time is gone. So at the end of the first at the end of the first  I threatened my computer and it work. That's awesome. Right so we'll be in here at the end of one pass. It'll be sort of the bottom half is it'll be in here, right what I needed the top half because that's what I'm going to start my next iteration. So I'm going to get a bunch of mrs. It's all because there's not room in my cat's what I can do instead as I can be clever and I could break up my Loops. So that instead I do want it oration on the top left-hand quadrant. I do I do. I do All My Relations in the top left-hand quadrant Generations on the top right and in the bottom left in the bottom, right and now I will bring one of these into my cash and all computer over it multiple times and then I'll kick it all out. You know what I move from the first quadrant to the second I'll take a bunch of messages, but then I'll hit for the rest of the other nations.  Tooth podcast tiling this is enormously important for scientific computation because scientific computation is almost all Matrix multiply or other major topmate Matrix Matrix operations, and they're doing these Matrix operations on huge arrays and their whole papers and books written about how to do matrix multiplication and efficient tile kind of cash and kind of way to make sure you're getting the most use possible out of each piece of data that you bring you in to the caches.  All right. Any questions about those the three C's of those optimizations? Yes.  That's a really good question. And this goes to I should actually add a slide about Amazon the night discussion of animals LA mejor right? That's not a question of like your level of computer science, like people's intuition about why their programs as slow is notoriously bad right software as complicated as behavior is complicated answer reasoning about why a particular piece of software isn't going as fast as you want your intuition about where your program spends most of his time is almost certainly wrong. And so if you'd like, I know I bet it's this I'm going to go off to my this you can spend a week optimize again. It'll be yours all school stuff you a little go back and your performance will be like 5% better.  And at the end of law, right? You just totally broke and has lost because you optimize something. I didn't make that much difference. If you go there the piece of software you on here is called a profiler in a lot of different kinds. There's no report. You need a memory profiler for this but there's also just instruction profilers. That's how you and which functions are spending most of your time. And you know, there are many times when I've been working a lot of software and it's slow and like why is it slow and then you go you're the profiler and some crazy thing like I'm looking up something in a hash table and like I put the hash look up in the wrong, you know, the wrong nesting of a loop or something. So it's doing it a billion times instead of you know, a million times. It's not incorrect because it's just the same value over and over again, but it turns out that it's slow and so then you go and do that in like all of a sudden like my one night. I remember very clearly I sped up by three thousand times.  It was awesome. My boss was so happy with me. And that was great. I didn't point out to my boss that this implies that the old version was terrible. Right? Like you shouldn't pray to Steve today. You should punish Steve from six weeks ago because he made this mistake writing code. You would run a profile on determine whether or not you had a memory. I have a problem and the hardware performance counters. They will tell you how many L1 and L2 cache misses you have and how many Branch Miss predictions and all this stuff so you can go in and tell where your performance problems are. Yes.  Huh?  Write something good. That's a good question. So just for how many people does La Cucaracha use of a hash table? I can have it set up. So if I look where I want to put my item and that's full I can go and look somewhere else in cuckoo. Hashing is one way of doing that thing where you can chase through the cash looking for a cache line. That was what you wanted. I'm sure there's been a paper on this number one number two. It's just really complicated asked to implement Hardware. So if you think about this feeling about our pipeline, right, I want to be executing my loads and stores in like a nice snooze, you know.  I think it was like laminar flow. I wanted to execute things in a nice smooth way without a lot of hiccups and Bubbles and complexity. And so what year do if I could feel like cuckoo hashing then that means I'm going to look one place and then I'm going to look someplace else. I went someplace else and every time I look someplace else better than another that's my S Rampart is occupied for another cycle when I could be doing another memory access, right? So that's a missed opportunity for do it for servicing a load that I actually need. And so, you know in practice between on the complexity of may be better to just kick it down to the next level of the hierarchy because after I do like if I start doing 3 L1 accesses remember from the hierarchy if I start doing 301 accesses that's as much cost of an L2 access.  That's right. Yeah, you also yeah, that's a good point.  It's a reasonable idea and if you go any take 240a, which is The Graduate architecture class, they will talk about kind of an alternate set of optimizations of people have applied to try to get around the associativity and hash Collision problem and the driving characteristic. I think your point about the fix sizes important. But also there's a question of making it really easy to implement and Hardware because caches are already pretty hard information Hardware making them harder is not a good idea.  Am I questions?  Alright, so here's a simple example.  Consider a direct mapped cache with 16 blocks in the block size of 16 bites on the application needs application will repeat the following memories access sequence. So first step is we have to break up this address into which three parts.  The index the alright the tag was over here the tag and the office.  Alright, so how many bytes how many bits of?  Austin am I going to have  16 bytes how many what's the log base 2 of 16?  4  Orbitz, what is so that's going to be the lower two bits here conveniently. How did that work out conveniently? That's one hexadecimal digit 16 blocks. So, how big is Maya? What's my index going to be?  Also for oh my gosh, so convenient and then my tag is going to be the top. So this is my back. So let's go through an example of stimulating a cash.  So here's my sequence of accesses, I access 800,000 or whatever that is. What is my index?  They're only like two choices at either 8 or 0.  What's my index for this Cash Line A List member access?  0 this thing right here second digit so it goes zero. So I'm going to go in this Castle. I'm now what's my tag going to be?  Davison zeros  will call this we're just going to call this a t  Shorthand, and the data is going to be the end of the day that they don't really care. What kind of capacity conflict or compulsory?  compulsory, Miss  I like I haven't had animation. All right, it's compulsory. What's my next turn?  Also zero, so is that and then what's the tag?  So is that going to be a hit or a miss?  The headright I am going to go to the same slot in my cash the same Cash Line and I'm going to compare.  My old tag, that's how good is there with the tag on it with the tag part of my memory address and they match so that is definitely a hit. What kind of hit is it?  Trick questions when one kind of fits the good kind of hex. All right. Next up is the tag. What is the index?  One, alright that's going to go here hit or miss.  What kind of man?  compulsory, Miss  Compulsory math because I never said I did it before. Okay, what's next hit or miss?  hits  what's next are a mess?  Ami's so am I my index again as one eye guy looking one I look at my tag with starting my cash. I look at my tagum address. They are not the same.  Not equal so that is a mess. What kind of mess?  No is not a conflict mix.  Compulsory mess. Is it compulsory mess? Because I have never seen this address before.  Right. So the eunuch it's about this mess. If not about some missing the future. We're going to get to that mess, but this mess is the compulsory Miss if I increase my associativity.  Or increase my cache size or anything else do it. This would still be a mess.  Right. There's nothing I can do to fix it for prefetching. Nothing I can do to fix this. So it's a compulsory, Miss.  All right, Next Up Hit or Miss.  Head everything is the saying that one's easy next time hit or miss.  hits hit or miss  Miss okay. What kind of mess?  Conflict Miss right because I had the data it was there but now it's gone. And so I have a miss.  hit or miss  It's all right.  very good  new example eight blocks 32x in a cache line still direct Maps now, unfortunately things me a little more complicated so I had to break out of my bets.  I hate that's how am I supposed to interpret that? All right. So that's the new address these things in the previous slide. This is some little a practice for you to work on your sequels ABS computation will go back and look at this.  So here's the same address sequence first access what they're going to be hit or miss.  What kind yes compulsory Next Up Hit or Miss?  How to get to intuition here are cache lines are bigger.  So it's going to be a hat.  All right, Next Up Hit or Miss.  Text Sarah castlen got twice as big which means that if there's a one here, that means that the we're still within the 32 bites a 16 or 32. So you think of this one is being in the way of the first bit of the next the next hour for bits actually still be a hit. So we got a bigger. Well, it's not increase our cache line size that is good at removing compulsory misses and we just did that right that used to be a compulsory miss you get a longer casts. We brought in more data and now we live in a profession. We got rid of a compulsory, Miss.  Are also be a head hitter mess.  Miss again. The tag is going to be wrong to have a Miss in the same place. And now we have acted everything next up at the compulsory medicine next up hit or a miss or kind.  Conflict, Miss.  Conflicts and then I got to be hit hit hit.  All right, Next Step will increase the associativity and hopefully in the future decrease our font size size of 32 bytes.  Play memory accesses. So here is the new breakdown of my drawings allowed to scale. But we have the same the Lord or five bits are still the are still going to be the offset. The next two events are going to be the index. And then the tag is the top the top stuff. All right bad pain.  All right. I had this professor. His name was Ronald beninca boards.  And he would he was kind of a scrunchie older gentleman. He was probably like 40, which is how old I am but he seems really old when I was in college and in the math department and all of the classes were in a row there like for math classrooms in a row and every once in a while, you would hear sneak. Ron would be doing something on the board and one of his students would say, I think that you made a mistake and with Dr. Vinnie keyboard.  Cuz clearly if the truck stop has a little bit different now, but that's because of its got shifted over of Southern, Utah.  What time compulsory hit or miss?  hits hits hits hit or miss  What kind?  compulsory hit or miss  We've gotten rid of all of our capacity and our compulsory are all of our capacity in Conflict misses.  Alright any questions about capacity and conflict misses?  ORCA pass conflict capacity in control services  All right.  three slide decks in one day  All right, so virtual memory operating systems.  Is it a prereq for this class?  All rights reserved a virtual memory so one of the things that program's needs to do is they need to work with computers need to do is they need to run multiple programs so far but we have been talking about is we have a processor and originally we had a very simple big array of bytes that was her memory and then we said okay well because there is a hierarchy of memories in the small ones are fast and the big ones are slowly just cashing thing to make it work, but we still have this assumption that in this kind of linear address space extraction the program that we're executing has access to all of that memory and that works fine. I like back in the olden days and there was just one program running on a computer and I could use I could refer to any address at 1 we can load from it and if I wanted to  I can put my day to wherever I wanted and the one of the things that they did and they still do actually is that the heat grows from the bottom up and the stack grows from the top down?  And that means that everyone can put their Heap in their stack wherever they wanted to.  Oh my goodness.  hair we go  hand  I give up.  All right, so I can put my stack up at the top. It'll go down the people go from the bottom of that'll be fine.  The problem will come if if I want to Malik more memory than I have. So if I have 64 kilobytes of memory to be very very small like much smaller than even an L2 cache now, but that's all I have and I asked I want a mouth like a whole bunch of memory. I'm going to be a sad little program on the computer at the same time and I both want to put their Heats of the bottom in the stacks of the top then they're going to play with each other that's not going to work. So we want a way to give each program its own privates Vision version of memory and the grieving process will have its virtual address space. The approval process will have its own purple a purple Hydro space and they'll access program.  The hardware has a very important role. It's a sort of maintain this illusion. We're going to see how we do that. It will cost them behind those virtual memories are going to be the physical memory. And this is the actual like array of bytes this kind of correspond to the dims that are in your computer at does correspond to the dentist at your computer. So it's a zero and goes up the sun big number right could be hundreds of Terror Maps silver hear the heat was all nice together at the bottom for the blue guy and it's all nice to go to the bottom for the in Green for the green guy and but they could be all jumbled up and it won't make that much difference.  And then we can be even more clever and we can say if if both of them want to allocate a whole bunch of memory, then we can also start dumping some of that memory onto disc and we will have the illusion of having a very very large amount of memory indeed and now I can think about you know, I can get a petabyte disgrace. I got to the illusion of a petabyte of memory, even though I have a much smaller amount of that in my actually my computer in D Ram.  So the challenge is how do we make this work? And how do we make it fast? Right because animals law tells us right. So I have a lot to tell us a couple things first to tell you should focus on the common case second and tells you that you should not forget the uncommon case but the third corollary would just so obvious that I don't even put it on a slide is it you definitely should not screw up the common case, right? So memory is like a very common case. It's like one and five instructions we execute and so if you make each memory operation, it's actually worse than that because instructions count to write so fetch every instruction Patches at least once since like a hundred and twenty percent of our instructions are memory operations. And so if you make that slow, then everything is going to get really bad. So this needs to be extremely efficient.  So the mapping they were going to be able to see the virtual to physical mapping from a memory. The virtual is a virtual address space. The physical is a physical address space. We're going to break both of these places up in the pages. These are usually 4 kilobytes in size. There's some reasons to make it bigger that we'll talk about later and you know, how big are high performance systems do that. But for kilobyte is kind of still the default and then we're going to do something call the page table that Maps virtual address is to physical addresses and the processor is going to generate virtual addresses. So everything that pops out of your you and your son in a story that's going to be a virtual address and then they're going to be translated by address translation to physical addresses by a combination of hardware and software but the the fast path  Is definitely going to be in Hardware.  So here is the mapping again and we're going to figure out a way to store this complicated mapping between the virtual address space and the physical address space.  We are almost out of time.  He'll keep going Minot.  Alright, so here's how this is basically going to work. We are going to take a virtual address. We're going to use 32-bit to this class. But nowadays everything is 64 bits, but the mechanics don't change at all winter break into two parts the Lord or bits are called the little bit confusing. So we have a page offset, which is  Completely different from The Cash Line offset, right? So we're going to slice the pages are in a slice the address up in this way. And at the same time we're also going to be slicing up into the offset tag and index for the cashing the casting stuff. But here it is an interest in the page offset. This is going to be pretty big. It's usually for queso this is usually 12 minutes.  And that's going to be the lower two bits and then we're going to take this upper body of the rest of the address. And for a 32-bit machine will be 20 minutes in for a 64-bit machine will be 142 beds. I'm going to run that through the map and then we're going to give us the physical page number and then we will just tack on the page offset to the end of that and that will give us our physical address, which will also be 32 bits.  Write for this is the translation process me to do the low order bits do not go through translation. They just get copied but the hired of its do get translated.  32 basic problems that we needed to solve to make virtual memory work efficiently. The first one is that we need to store the map. I will need to start in a compact away because the map as well so you can be very large and then we also need to do the translation. We have to do the translation really quickly on This Heart of two mechanisms that we're going to use to address each of those separately. So the first question we should think about is how big is the map. So in a 32-bit address space we have 4 gigabytes of virtual addresses and that's about 1 million pages.  Each entry in that map is 4 bytes. So that's one thirds of a physical address. So if I want to map one physical address to the store for Fleming's at 4 megabytes of map that is not so bad we could deal with that. Especially the modern machine by modern machines have 64-bit addresses. They have 16 exabytes a virtual address space a very very large. We went to 64 bits for two reasons one. It's an easy doubling a 3-2 and also people figure that 64 was bigger than you would ever possibly possibly need which so far has been the case, but of course will fail eventually, but this means we have four pages.  Price out a lot of pages and each entry is 64 petabytes of mapping information that we need to store if you wanted to map all of it, right so clearly we're not going to store a bigger a right that we could index in the fastest thing except. I couldn't keep it anywhere, but it would be the easiest thing to look up. We just look in that slot and we find the address for looking for but that is not going to work. So I would like to shrink the map.  So that turns out you don't need the whole map, right? We can just store the parts of the map that matter and that will let the most more or less be the size of your physical address space. So if I have one gigabyte of memory in my computer, I don't need the store probably more than one gigabyte worth of mapping 41 process, right? We can go bigger because stuff goes to desperate in practice normally does. Cuz this car really slow. So really the size of the map should be on the order of the physical memory in the machine. So that's nice. So if I have 64 gigabyte machine on a 64-bit machine. 16 million pages in 128 megabytes the map so that's much more manageable write 120 megabytes. I can do nothing and there are lots of processes running on your computer. If you go into the activity monitor you type P S on Linux, you'll get a list of like a hundred processes each one of those  own private version of this map that Maps out its own virtual address space  So now I need to represent represent in the map is harder because we need some sort of a sparse representation that only stores the parts that we are actually interested in.  And so since we're out of time, I will tell you what that sparse representation is on Tuesday. I'll see you then. "
}