{
    "Blurbs": {
        "+ 70 So here's the here's the idea for this space spanning set. So that means that V1. Can be written as some a1u 1 + a B-1 YouTube. Everyone is in the span of you wanting you to if you want is a vector in the Subspace and therefore it's in the span of the basis vectors. also V2 is equal to sum a 2-1 + B2 U2. and ": [
            2357.1,
            2410.2,
            72
        ],
        "1 x 1 plus a 2 x 2 + 83 x 3. I'm going to move by the second column by X as well. And I guess maybe one x 1 plus a b 2 x 2 + B 3 x 3. And what I'm told is that that is the zero Vector. So what I have is there's some non-trivial coefficients X1 X2 and X3. So that 00 How ": [
            2553.7,
            2589.4,
            77
        ],
        "Maybe I'll have a basis with 76 has been another one with only three vectors. So clearly I want to use the one with only three factors. Well, sorry to disappoint you but all the bases will be equally efficient or inefficient. Do you have any two basis for a Subspace have the same number of vectors? In other words I said there is no space. All of them have ": [
            2244.8,
            2272.4,
            68
        ],
        "Seen everything that's on that homework set. We're going to finish section 4.3 in the first 20 minutes of today's lecture. So homework for is now due tomorrow by 11:59 p.m. For five questions on that homework set are things that stuff that we will do in today's lecture related to those. On your next my mess up homework that is already posted and it is due next Tuesday. So ": [
            0.7000000000000001,
            27.1,
            0
        ],
        "So how about let's give these guys names on V2 V3 V4 and V5 form a basis for H. No. Okay, so you're at not talking about pivot. So you're jumping ahead that which is good. That's what we're going to say next. But the key Point here is what we need to check. We need to check if those remaining four columns are linearly independent and it's no longer ": [
            901.4,
            939.0,
            29
        ],
        "Those are very different from the original Vector space. It really doesn't matter which factors you use you could use this but I could just as well have chosen to of those. Okay, I could take a 2 by 3 Matrix. maybe it's something like this one here. So look at the the first two vectors there in 102 and 3 - 1 1 now if I do row operations ": [
            1554.7,
            1586.9,
            48
        ],
        "V1 V2 V3. Is another Subspace for it? So here's the idea. I'm going to give a proof by contradiction already discussed this a lot. How do you how are you going to prove something like linear Independence for some abstract factors linear Independence is a negative property. So typically he's going to prove by contradiction saying I want to prove their linearly independent. Let's assume that they're not that ": [
            2311.1,
            2337.4,
            70
        ],
        "V3 is equal to A3 you 1 + B3 YouTube okay each one of the vectors V1 V2 and V3 because they're in the Subspace. They must be expressible as linear combinations of the basis vectors. Do you want in YouTube? consider the Matrix A1 A2 A3 B1 B2 B3 Hey, this is the moment not much to do with these Originals actors are associated with them, but I can ": [
            2410.2,
            2458.0,
            73
        ],
        "What's the other kind of Subspace that we've mostly been focusing on in the last couple of lectures? So if I give you a matrix is a Subspace of the codomain but of the domain instead of which you can multiply a number of components equal to the number of columns, and we know how to find this. This is literally lecture one for the null-space of a Can be ": [
            1840.4,
            1878.9,
            57
        ],
        "a 3 Okay, and similarly? We see that the first column. a 5 is equal to 3 A 1 - 2 a 3 Okay, so that's what we see from the registration form of the Matrix. But here's the thing. Look over it the original Matrix now a we already noted. That V2 is equal to -2 V 1. I know I claim that we can also check for is ": [
            1110.0,
            1150.4,
            35
        ],
        "a Subspace Subspace of some bigger Vector space. then some collection among those factors is a basis of that set of vectors is a basis. Just what I just said, you just proved it until you get down to look at a concrete example now relevant to your homework into our understanding of the class. So the most important kind of subspaces we deal with here are so far are ": [
            770.9,
            803.7,
            25
        ],
        "a basis, there's some Vector in there that the linear combination of the others. I find one of them I remove it and I keep going until I get down to a basis. Is this a bassist the ones that I get from this procedure is that set linearly independent or not going to give you Thirty Seconds to Talk Amongst yourselves and decide. All right. So sounds like you're ": [
            2006.2,
            2068.9,
            62
        ],
        "a few minutes. We will be able to prove that that is a serum. Every Subspace is the span of some set of vectors. Stephen is not presented. That way you can always find some set of vectors this planet. For example, the column space is presented to you as the span of the set of column actress. But that might not be the most efficient description. Because there can ": [
            127.2,
            151.1,
            4
        ],
        "a great question. I swear I didn't plant them in the audience because we're going to go into that on the next flight question was is there a minimum number of vectors that you need to form a basis? And that is a phenomenal question actually one more slide after that. So hold on the answer is yes, but no, but before we get there, let's talk about the other. ": [
            1812.2,
            1838.9,
            56
        ],
        "a minimal description animal set nearly independent. So it's a linearly independent standing set. Definition and we saw several examples as we saw you looking for a basis of R3. Then what you're looking for are three columns who's Matrix of those columns has a pivot in every row and every column we saw that has to be the case so you can see from that. But if you're looking ": [
            196.5,
            243.9,
            7
        ],
        "are linearly independent because as we know if we're going to check their linearly independent, what would we do we would do row reduction and see if they were pivotal pivotal basis for the column space. Form a basis for the column space today. So that's a restatement of what we just said, so let's do another example Matrix 3 columns in R3. So maybe maybe these columns fan all ": [
            1366.0,
            1405.5,
            42
        ],
        "are parallel. So think about it this way. We don't do column operations when we're doing row operations. We don't swap columns, but would call him as me swapping columns means that we're renaming the variables. Like if we're thinking of a matrix is the coefficient Matrix of a system of linear equations in two variables X1 and X2. I'm calling them next to a next one. That will change ": [
            1712.5,
            1741.3,
            53
        ],
        "are the directions. In the three dimensional space so the span of those vectors is the XY plane. but the originals actor is 102 + 3 - 111 those two planes kind of look alike. They're both planes, but the similarities in their original column is not the same as I think that's critical here. You want to find a basis for the for the column space you do row ": [
            1620.4,
            1658.9,
            50
        ],
        "at the columns or look at the Rose. Over here and look at these coefficients. Let's Go Fishin Sakina there. Those are the rose. Those are the entries that this Matrix ax but those are zero. And so this is the zero Factor. So what if I got I've got a non-trivial linear combination of the Vees that equals 0 and that is a contradiction. To the fact that you ": [
            2709.4,
            2738.5,
            81
        ],
        "bases. Like we saw on the first slide here. This example here they ended up deciding that we could use the first two vectors there as a basis which is true, but we could have also use the second or the first in the third pair of those vectors is a perfectly fine basis. And that would also be true in this example here. Because no two of those vectors ": [
            1685.8,
            1712.5,
            52
        ],
        "be repetitions. Hey are they can be redundancy in that collection of information. For example, if I tell you the span of the vectors 111 + 111 + 111, that's kind of silly. Right? Well, that's just the span of the vector 111. I could also said the span of the vector 111 in the vector 2 2 2 again pretty silly because the second Vector is already in the ": [
            151.1,
            175.3,
            5
        ],
        "can always just revert back to the definition. And say a basis is a linearly independent spanning set. So the first thing I need to do is find a spanning set find a set of vectors is linearly independent. Okay. So the first part is often done for us where the Subspace is presented. What do I do if they're not so let's look there's an example here are three ": [
            267.7,
            300.1,
            9
        ],
        "can we do that? Well, we need to yes. You were just raising you are just had a muscle cramp then okay, that's totally cool. Hope it gets better. So. Well, we we don't have to start over and throw these away. Where can I find there is a bassist hiding in there hiding in plain sight and here's the here's the idea. What we want to do is reduce ": [
            364.9,
            390.9,
            12
        ],
        "checking that it is closed under those operations and that the sum of two vectors in h, which is a vector in the largest space. typically We found that. Subspaces are presented to us as the span of some set of vectors every Subspace we've seen actually is of that form either presented to us that way or turns out we can figure it out. It looks like that in ": [
            98.6,
            127.2,
            3
        ],
        "column and it has two nonzero entries there. I should use different color so that the second one is to accommodation of the previous column forms. Help us look for before I can build it out of the previous columns III by taking -1 times they won. Plus two times a three because they're standard 0 + y x 0 1 so that second equation there a one. + 2 ": [
            1052.5,
            1110.0,
            34
        ],
        "columns in The Matrix the way we do our algorithm could have happened that we could have chosen other vectors from Among The Columns to find a basis. I'm not recommending you do that. This is just one basis. But this is a good basis. You can always use this one. So if you're asked to find a basis for the column space, this is what you should do. What ": [
            1780.5,
            1812.2,
            55
        ],
        "combination of those three vectors x1u + x 2 + x 3 w. for some X1 X2 X3 Steeler Nation, that's what it means to say that everything in AIDS is a linear combination of vectors, but we've also got this relationship down here. So let's substitute. I didn't say. Well actually, let's write this as x1u + x 2 V + x 3 x w is equal to you ": [
            420.0,
            462.3,
            14
        ],
        "combination of you is a skeletal muscle. that says X1 A14 the you want in the first term + X2 a24 the you want in the second term + x 383 Those are all the things that multiply you one. And for the second terms that multiply you to I get X1 V1. x2b 2 and x 3 V 3 okay times you too. But hey, wait a minute. Look ": [
            2664.6,
            2709.4,
            80
        ],
        "described as a set of vectors X1 X2 X3 X4 and X5. Search that okay, we look at the reduced row Echelon form. We have the same thing now we can only look at one form. We have are there. That means that x 3 X1 and X3 are going to be expressed in terms of the other columns, right? We're going to have three variables three variables. And then ": [
            1878.9,
            1911.3,
            58
        ],
        "does it really mean that the courts want a free variables? Will we know what that means if we're riding down the solutions that which will do on the next flight when we talked about the null space, but they tell us something critical in the column space as well. So we already noted from the original Matrix that V2 is -2 times we want. But notice that we can ": [
            1000.3,
            1020.6,
            32
        ],
        "does that help me? What does that have to do with these original vectors? Well, let me just start. pull out of the following Let's those coefficient forsake those axes. And look at x 1 V 1 + x 2 V 2 + x 3 V 3. What's this compute with that thing is well. I have some equations up here. Set can that I can use to express the ": [
            2589.4,
            2625.3,
            78
        ],
        "equal to - the OnePlus 2 V3 and V5. Is equal to 3 V 1 - 2 V 3. Let's check that second one before equation before it's supposed to be - 51 + 2 V 3/8 if I take - V1 I get four. + 2 V 3 so4 + - hold on a sec. So I'm supposed to take. -51 which gives me at 3 in the first ": [
            1150.4,
            1187.3,
            36
        ],
        "equal to the span of just you and me. So we can eliminate one of those vectors. Okay. No, by the way, we had some choices here. We didn't have to eliminate W. Cuz I could have rearranged this from consideration and found that this is also equal to the stand of v&w and similar be a sequel to the fan of you and I could be of any two ": [
            524.8,
            556.4,
            17
        ],
        "eventually it terminates. If you want to have all polynomials going to have all possible polynomials that you have to have terms of arbitrary degree. Any polynomial will be a linear combination of only finitely many of those but if you want to have an arbitrary polynomial, then you have to have all of those Powers there. They're all linearly independent. So what we find is the dimension Of the ": [
            3050.1,
            3078.9,
            92
        ],
        "first Vector is 100. The second letter is 010001. Here is how I find the null space what once I take get the reduced row Echelon form of the Matrix. All I do is I take the coefficients read across in the crows. I put negative signs in front of interspersed them with the standard basis vectors in the three variables slots. That's what this was. And here's the point ": [
            2135.3,
            2173.0,
            65
        ],
        "for a basis of our three, it has to have three vectors you have to have three columns and not just any three columns will do The Columns of an invertible. Matrix would be another way to put it but if we have a Subspace Then there's a trick that seems trickier. How do we even find a basis it? What's the generic principle for finding a basis? Well, we ": [
            243.9,
            267.7,
            8
        ],
        "for you. By the way. The Subspace is presented or will be easy to infer from some techniques. We've already learned as we'll see is to prune it. Okay, you need to say okay now, is it a basis check? I didn't you have to check if it's linearly independent. If not by definition. That means at least one of those vectors is in the span of the others find ": [
            686.1,
            710.0,
            22
        ],
        "go ahead and say well in your combinations of those Not from the context of what we're interested in right now, which is finding a basis. okay, what that tells us is that V1 V1 and V3 form a basis for the column space of a Okay, that's this procedure. We want to find a basis from a US tanning set. What we do is we take a sentence that ": [
            1299.4,
            1341.9,
            40
        ],
        "guys are not linearly independent, right? So if I call this you this V and this W, then what we see is that you minus V equals W. So there is a non-trivial linear combination of those equals 0 u - b - W equals 0 so it's not really independent standing set, but it's not linearly independent. So, okay. We wanted to find a linearly independent Spanish that how ": [
            338.0,
            364.9,
            11
        ],
        "guys at. right of -3 + 2 * -1 is -2 + 3 is 1 - 1 + 2 * 2 is 4 minus 1 is 3 + - 2 + 10 is 8 okay. So there we go verify that that same relationship but we don't need to do that ever again because that's that's exactly how operations work. That's the point operations. They mess up the columns change ": [
            1214.2,
            1255.1,
            38
        ],
        "have to go to any row Echelon form because I've already got a zero in the second row below the pivotal one twice the first row from the Third. Can you give me a zero there a -5 there? and -5 there looks like 0 - 1 - 1 + I can see that I'm not going to get a basis for all of our three here because the second ": [
            1426.8,
            1455.9,
            44
        ],
        "having an active discussion. I see some people have a really pained expression on their face. So let me end your misery and let's just take a vote how many people think that these are linearly independent. Even the paint guy thinks they're okay. That's good. How many people think they are linearly dependent? One or two hands, okay with somebody who thinks they're linearly independent like to explain why ": [
            2068.9,
            2089.8,
            63
        ],
        "how we describe the solutions that but in terms of questions, like are these vectors linearly independent are the effects that doesn't change those questions at all. So we could have reordered these vectors just as well and that I would find in that case that the first two columns were still pivotal which order you put them in but the point is that there are some of the nonpareil ": [
            1741.3,
            1780.5,
            54
        ],
        "if I take a linearly independent set like a standard basis vectors and then I got pain some more entries in other places will not make them because if you have a non-trivial linear combination of the bigger vectors Vanishing, then it will also be a combination of the the components so we get that these guys are linearly independent. It's always going to happen following this procedure. For finding ": [
            2173.0,
            2212.0,
            66
        ],
        "if you remember the definition of linear dependence one of the two equivalent definitions was that at least one of the other two the vectors you envy Okay, do those to form a basis? I heard someone say no or maybe they said yes, it was too quiet to hear. So how about by a show of hands how many people think those two form of bases? Most people how ": [
            580.6,
            624.4,
            19
        ],
        "is one of the other know we have a zero in one spot and the other that's you're never going to have linear dependence in that case. Unless one of us is actually the zero vector. So this is a linearly independent spanning set. And therefore it is a basis. And that's exactly how you find a basis in general. The Subspace first thing you need to do is done ": [
            654.2,
            686.1,
            21
        ],
        "it. So just a reminder from last lecture, but gave this definition this new definition of basis of a Subspace. What's the idea here? a Subspace is a subset of a vector space that is itself a vector space in its own right meaning that in the same operations addition and scalar multiplication using the same zero it forms a vector space. Are you going to confirm that just by ": [
            70.9,
            98.6,
            2
        ],
        "its columns. By definition there is a spanning set. No, I'd like to find a basis for the column space. So the first question is maybe that's the basis right there. Maybe that's set of 5 vectors is a basis. What do you think? Is it a bassist? Y'all know why not someone in the back. heard some voices from the back so Get out of the back or in ": [
            831.9,
            865.2,
            27
        ],
        "many people think they don't want a basis. Nobody, okay. So that's correct. These two vectors form a basis. Why do they form a basis? Because they are linearly independent and they are a spanning set. So by definition he rages is vectors and those two those two are linearly independent. And normally we would have to check that by doing. This is another case where it's easy to check ": [
            624.4,
            654.2,
            20
        ],
        "means it if we want to find a basis of the column space. those first two columns 1 0 2 and 3 - 1 1 form a basis for the column space today. zz's. Now what am I to important caveat there highlight to important caveats. The first is that and I already said this it's really important that we use. The Columns of the original Matrix a state they ": [
            1486.9,
            1524.3,
            46
        ],
        "minus V. I know let's recombined terms appears in two of those terms. Let's collect them. So this is x 1 x well + x 3 x you bus x 2 - x 3 x b those new coefficients there x 1 + x 3 + x 2 - x 3 they're not the same coefficients we had before but they're just too real coefficients in the point. Is that ": [
            462.3,
            499.0,
            15
        ],
        "of our three. Maybe the column space is all of our three. Maybe. We just have to check if I doing row reduction row reduction here. Okay, when we need to get this one form, it's not so bad. It's pretty close already actually are we don't actually need to go all the way to reduce. We only need to check which columns are pivotal to do that. We only ": [
            1405.5,
            1426.8,
            43
        ],
        "of these factors, but we have some choices to make it not going to be unique by any means the point is that I can throw away one of those vectors. And still have a span expect that's what's always going to happen. Here is the key idea that if you have a linearly dependent set you can always throw one of them away without changing the fan. In fact, ": [
            556.4,
            580.6,
            18
        ],
        "of this Matrix, one of those columns, at least one of those columns is going to be non pivotal. But we know then is that. So there is some. non-trivial Vector X1 X2 X3 such that if I take this Matrix gire This is the vector X such that a x x equals 0. But that's what we know we know that there is a non-trivial solution to the homogeneous ": [
            2490.5,
            2523.7,
            75
        ],
        "on just those two vectors are those two vectors linearly independent know they are because they are pivotal in this Matrix here. If I were to carry the Matrix just those first two columns to reduced row Echelon form. I would get one zero zero zero one zero, that's what you always get. If you have linearly independent now those two vectors 100 and 010. Those are the standard. Those ": [
            1586.9,
            1620.4,
            49
        ],
        "one week after that. Okay. Today. We are going to be continuing with the stuff from section 4.2 and 4.3 faces and bases of the importance of space Tacoma space in the null space of a matrix. And then on to section 4.5 and 4.6 Dimension and rank. Okay, and so we are changing faces next time section 4.4. Which is coordinates? So that's the plan. And let's get to ": [
            27.1,
            70.9,
            1
        ],
        "operations just in order to tell which Columns of the Matrix are pivotal those columns in the original Matrix. You don't use the columns in the registration form. Those are not related to the Subspace General. What's the first cabinet which is written down here? Typically, the column space of a on the column space of is reduced row Echelon form are different things different subspaces. There are zillions of ": [
            1658.9,
            1685.8,
            51
        ],
        "out the free variables and express that says x 2 x 0 0 0 plus x 4 times a vector which is in this case one 0 - 210 plus X 5 X Factor. which is -3 / 0 201 okay, so there's a perfectly good description of the null space. It's the set of linear combinations of those three vectors in other words. It is the span. Of those ": [
            1943.8,
            1980.7,
            60
        ],
        "preserve a relationship I think about it this way. If I had a matrix whose columns were all pivotal 3 by 3. Matrix is called. Then we know that that forms the basis of our three we saw that last time but the reduced row Echelon form of any such Matrix is the identity Matrix. Okay, so that means that those vectors are the standard basis vectors on the right. ": [
            1524.3,
            1554.7,
            47
        ],
        "row and the third row are parallel to each other like when I know subtract when I subtract 5 times the second row from the third I'm going to get there. And now I'm in row Echelon form. I'm in row Echelon form and I can see That these two columns are pivotal, but the third one is not which means the same holds true in the original Matrix, which ": [
            1455.9,
            1486.9,
            45
        ],
        "same number of elements and that gives us a fact hear a new word to add to your list of vocabulary, you know this word before you've been using you've heard it a lot. We've used it already. But now we're making it precise. The word is dimension. So if I have a vector space it could be an abstract Vector space. It could be a Subspace of a vector ": [
            2813.3,
            2840.3,
            84
        ],
        "see that immediately in the reduced row Echelon form, right? So if you look at it this minus two and three right there. That -2 entry tells you that a 2. Is equal to -2 times they want because a one is just the first so if you want to see if you just have to check and indeed that's true. Now, let's look at a for a Forza non-committal ": [
            1020.6,
            1052.5,
            33
        ],
        "space but one way or another five of vector space dimension of vector space is the number of vectors in any given basis for it. We just saw that if you have two different bases. They will have the same number of actors in them. So this is a well-defined quantity the dimension of a Subspace or a vector space is the number of vectors in any basis for that ": [
            2840.3,
            2866.1,
            85
        ],
        "space of all polynomials is actually Infinity. Does it evolve polynomials is an infinite dimensional Vector space doesn't work for it in this room, so don't worry. ": [
            3078.9,
            3097.5,
            93
        ],
        "space that tells you that this Subspace the column space of that Matrix has Dimension 2 is a two-dimensional Subspace. It's a plane in R3 Any other bases you find you put in this case you could use any two of The Columns that Matrix and that will be a basis you could also do all sorts of other things. You could take three times the First Column and 76 ": [
            2893.7,
            2921.9,
            87
        ],
        "space. So for example here is a vector space. It's the span of these three vectors in R3. This is an example. We saw a few slides ago. And we saw that these two columns in the reduced row Echelon form are the pivotal columns in the third one is non pivotal has to Total columns. Now, we saw that if you want to find a basis for the column ": [
            2866.1,
            2893.7,
            86
        ],
        "span of the first thing about the span of those two vectors. It's really just a fan of either one of them. So it's inefficient to have those redundancies. There might not be as obvious stuff. I have three vectors, for example, the three factors that are my arms and my head in this plane. That plane is found by any two of those factors. So efficient to include in ": [
            175.3,
            196.5,
            6
        ],
        "system with that Matrix as its coefficient Matrix because there are free variables there because there aren't enough columns to go around Rose to go around to make all the columns pivotal. What's 8 * x * X? Is equal to okay. Well, I know how to multiply matrices that last reminder. So so I'm going to multiply that First Column by x + 3 by entry and get a ": [
            2523.7,
            2553.7,
            76
        ],
        "take those coefficients that I just found and I can make a matrix out of this rectangular Matrix came from the two elements and the three elements in the two base. What do we know about rectangular matrices? We know that if I have more columns and rows than those columns can't be linearly independent. Right, we know that if I take if I compute the reduced row Echelon form ": [
            2458.0,
            2490.5,
            74
        ],
        "that Subspace consisting of those for polynomials. And those for polynomials are linearly independent because I cannot find a numerical linear combination of 1 and X that is equal to zero. I can't say oh + 3 that's equal to 0. I mean it is equal to 041 choice of X, but these are atoms the basic objects. There's no numbers A&B for which a x + B is always ": [
            2986.6,
            3016.2,
            90
        ],
        "that leads to a contradiction same idea here. I'm going to assume I have two bases that have different numbers of vectors in them. And just to make things concrete. I'm going to assume that I have one that has two elements and one that has three elements, but you'll see that this idea of this proof is going to generalize immediately to if I have a 76 + 1 ": [
            2337.4,
            2357.1,
            71
        ],
        "the Matrix and use it before but let me make this a little more precise in this example to cement it. So here are the five columns of the reduced row Echelon form. You are the five columns of a matrix. Now in the reduced row Echelon form we can see that there are only two pivotal cops are the pivotal columns and the others correspond to free variables. What ": [
            965.7,
            1000.3,
            31
        ],
        "the back or is that your arm cramp? Perfect. The second Vector is manifestly twice - 2 * the first Factor, so it's definitely the set of exercises definitely linearly dependent independent. So following our nose following are pruning procedure that we talked about in the last flights. What we should do is throw away that Vector going to respond by the other four vectors just as well. Okay, great. ": [
            865.2,
            901.4,
            28
        ],
        "the column space in the null-space of a matrix structure the same one we had last lecture and use it several times this lecture. This is a 3 by 5 Matrix its column consists of those five vectors in R3 the column space of H H is equal to the column space of the Matrix a definition of column space of a matrix is defined to be the span of ": [
            803.7,
            831.9,
            26
        ],
        "the column space the column space of a is a totally different column space of the registration form with a the three row operations that we can use in sequence to get from The Preserve linear relationships between so you can pick off from the reduced row Echelon form dependencies between the three columns on the pivotal Collins our relationships we have so that's the reason why we can just ": [
            1255.1,
            1299.4,
            39
        ],
        "the null-space. You're going to get a you're going to get out of space on a basis for the null space. Again. There are zillions of these are not the only ones but these will be Alright great. Now let's get back to your question. Is there a one basis is better than another can I always find what was the what's the minimum number of elements of a basis? ": [
            2212.0,
            2244.8,
            67
        ],
        "the same number of vectors in actually prove that there a special case of that there so suppose. Let's do it with where I finally have a basis was two elements. I should really do this for a basis with n elements, but I'm going to stick the two to make them easier suppose that you won you too. Is a basis. for a Subspace and let's also suppose that ": [
            2272.4,
            2311.1,
            69
        ],
        "the set of vectors by throwing away some that are in the sign of the others. So let's let's look at this again. So yes. any Vector ex is in h the X's have portrait cuz when he was asked for the coefficients, so let's call it a if any better a is in a peach. Then by definition of span that means that a is equal to some linear ": [
            390.9,
            420.0,
            13
        ],
        "the space of polynomials of degree less than or equal to 3 which were polynomials of the form a x cubed. philosophy x squared plus BX plus c They were a b c and d. Are arbitrary real numbers that are free variables here? So what that means? Is that this is the span? of the vectors x cubed x squared x + 1 there is a spanning set for ": [
            2947.0,
            2986.6,
            89
        ],
        "the two non-trivial equations that we get when we interpret. Reduced row Echelon form as the coefficient Matrix of the system. Tell us that x 1 is equal to 2 x 2. + x 4 - 3 x 5 Are the x 3 is equal to -2 x 4 + 2 x 5? It's a homogeneous system. and then the standard thing we do now is to start a factor ": [
            1911.3,
            1943.8,
            59
        ],
        "they think they'll any of the independence. Yes. Fantastic, perfect explanation each one of the vectors has a 1 in a place where the other two have a zero, let's look closely. so let's look at these entries these entries centuries Okay, if I look at the entries that correspond to the three variables to four and five in this case and I look at only those entries than the ": [
            2089.8,
            2135.3,
            64
        ],
        "this thing? Is in the span? I've just the vectors u and v it's only a combination of the vectors u and v we started here with his arbitrary Vector A and H. which by definition means if it's something a linear combination of the three vectors and we found that any such arbitrary a is actually in the span of u and v so in fact each is also ": [
            499.0,
            524.8,
            16
        ],
        "thought + 2 x V3 which gives me a 4 so minus. Positive 3 - 4 is equal to one. Is that true? I apparently need to actually write it down to see I'm caught in the black Ford Field even though I'm not using the the Blackboard this field that emanates from the black boy that makes you stupid. Okay, so I may just come over here with you ": [
            1187.3,
            1214.2,
            37
        ],
        "three vectors. Let me call them A B and C. So I have to rewrite them over here. So the the algorithm that we use to solve systems of equations standing set for the null space. So I now got a settings that and so I can ask the question. Is it a basis if it's not I know what to do. I just start pruning it if it's not ": [
            1980.7,
            2006.2,
            61
        ],
        "times the second column that's not going to change the fact that they're a basis. You could also mix them up and add two of them together and subtract the other two that'll also work and give you a new bassist. There's no matter what exactly two vectors in it. That's the dimension of the column space. Craigslist quickly, look at a couple more here was a Subspace. We saw ": [
            2921.9,
            2947.0,
            88
        ],
        "true that you could obviously see that one of them is a multiple of another one. That's not true anymore. But that just means that no pair of parallel. What does it mean that you couldn't have three of them that are linearly in linearly dependent? Great, and we don't have to do the road option that loved it is for us. So there's a reduced row Echelon form of ": [
            939.0,
            965.7,
            30
        ],
        "vectors in R3 and H is defined to be the span of those vectors linearly independent. Then they would spend all of our 3H would actually be all of our three are these guys linearly independent. No, what do you think? What why not? Someone said no. And then I heard indiscernible mumbling. Would someone like to erase? Correct. This first Spectrum on a second Vector equals 2/3. So these ": [
            300.1,
            338.0,
            10
        ],
        "views in terms of the use to let's do that here. This is x 1 x. A1 you one plus B1 U2 suspects two times a day to you two plus two you two plus x 3 x a3u 1 + V3 YouTube I know this is a linear combination. There's six terms there. But if I multiply it out Andre Shuffle things I can express this as a linear ": [
            2625.3,
            2664.6,
            79
        ],
        "wanted me to Envy 3 as a basis. That's the core idea here if I have two sets of basis vectors. Then I can write down a matrix that expresses one set as linear combinations of the other. and vice versa I have two bases with different numbers of vectors. That means that Matrix. But that will be linearly dependent. If you have any set of three or more vectors ": [
            2738.5,
            2782.8,
            82
        ],
        "we start with and we start pruning it by removing factors that are linear combinations of the others. Well, the reduced row Echelon form tells me that the non pivotal columns are linear combinations of the pivotal wants so we'll just throw out all the known non-committal columns and we won't change the column space in that context. That is the column space is fake. And the pivotal columns those ": [
            1341.9,
            1366.0,
            41
        ],
        "which one it is or which one of the ones that is it and now you have a smaller set of vectors. Is it a basis check check if that's dependent? If it's not find one of the vectors is linearly dependent on the others remove it and it'll write this procedure and this procedure will eventually stopped right because those vectors there spam the Subspace which is nonempty eventually ": [
            710.0,
            735.3,
            23
        ],
        "will automatically be linearly dependent. That's what this shows. So you can never have more than two no more than two vectors in a basis, but you couldn't have less than two either for the same reasoning because if you had less than nearly dependence by the same argument in Reverse, okay. So this is the key factor of linear algebra the most important there any two faces have the ": [
            2782.8,
            2813.3,
            83
        ],
        "you're going to get there are no more that are already in the span of the other says that have a basis of finitely many vectors. We'll see in a few minutes. That's not always the case. Okay, so I called that a corollary, but I should really call it a serum cuz we didn't stay that they're on the at the says this is a theorem. If I have ": [
            735.3,
            770.9,
            24
        ],
        "zero those are linearly independent vectors. So that means that the dimension of P3 Is 4 because there is a basis with four vectors in it. So lost. What's the dimension of the vector space of all polynomials? Well, let's see if we can write down a basis everything in there. Looks like you know, there could be a constant an Xterra Man X Squared term in X cubed term ": [
            3016.2,
            3050.1,
            91
        ]
    },
    "File Name": "Linear_Algebra___B00___Kemp__Todd_Aahron___Winter_2018-lecture_15.flac",
    "Full Transcript": "Seen everything that's on that homework set. We're going to finish section 4.3 in the first 20 minutes of today's lecture. So homework for is now due tomorrow by 11:59 p.m. For five questions on that homework set are things that stuff that we will do in today's lecture related to those.  On your next my mess up homework that is already posted and it is due next Tuesday. So one week after that. Okay. Today. We are going to be continuing with the stuff from section 4.2 and 4.3 faces and bases of the importance of space Tacoma space in the null space of a matrix.  And then on to section 4.5 and 4.6 Dimension and rank.  Okay, and  so we are changing faces next time section 4.4.  Which is coordinates?  So that's the plan.  And let's get to it.  So just a reminder from last lecture, but gave this definition this new definition of basis of a Subspace. What's the idea here?  a Subspace  is a subset of a vector space that is itself a vector space in its own right meaning that in the same operations addition and scalar multiplication using the same zero it forms a vector space. Are you going to confirm that just by checking that it is closed under those operations and that the sum of two vectors in h, which is a vector in the largest space.  typically  We found that.  Subspaces are presented to us as the span of some set of vectors every Subspace we've seen actually is of that form either presented to us that way or turns out we can figure it out. It looks like that in a few minutes. We will be able to prove that that is a serum. Every Subspace is the span of some set of vectors. Stephen is not presented. That way you can always find some set of vectors this planet. For example, the column space is presented to you as the span of the set of column actress.  But that might not be the most efficient description.  Because there can be repetitions.  Hey are they can be redundancy in that collection of information. For example, if I tell you the span of the vectors 111 + 111 + 111, that's kind of silly. Right? Well, that's just the span of the vector 111. I could also said the span of the vector 111 in the vector 2 2 2 again pretty silly because the second Vector is already in the span of the first thing about the span of those two vectors. It's really just a fan of either one of them. So it's inefficient to have those redundancies. There might not be as obvious stuff. I have three vectors, for example, the three factors that are my arms and my head in this plane.  That plane is found by any two of those factors. So efficient to include in a minimal description animal set nearly independent.  So it's a linearly independent standing set.  Definition and we saw several examples as we saw you looking for a basis of R3. Then what you're looking for are three columns who's Matrix of those columns has a pivot in every row and every column we saw that has to be the case so you can see from that. But if you're looking for a basis of our three, it has to have three vectors you have to have three columns and not just any three columns will do The Columns of an invertible. Matrix would be another way to put it but if we have a Subspace  Then there's a trick that seems trickier. How do we even find a basis it? What's the generic principle for finding a basis? Well, we can always just revert back to the definition.  And say a basis is a linearly independent spanning set. So the first thing I need to do is find a spanning set find a set of vectors is linearly independent. Okay. So the first part is often done for us where the Subspace is presented. What do I do if they're not so let's look there's an example here are three vectors in R3 and H is defined to be the span of those vectors linearly independent.  Then they would spend all of our 3H would actually be all of our three are these guys linearly independent.  No, what do you think? What why not? Someone said no.  And then I heard indiscernible mumbling.  Would someone like to erase?  Correct. This first Spectrum on a second Vector equals 2/3. So these guys are not linearly independent, right? So if I call this you this V and this W, then what we see is that you minus V equals W. So there is a non-trivial linear combination of those equals 0 u - b - W equals 0 so it's not really independent standing set, but it's not linearly independent.  So, okay. We wanted to find a linearly independent Spanish that how can we do that? Well, we need to yes.  You were just raising you are just had a muscle cramp then okay, that's totally cool. Hope it gets better. So.  Well, we we don't have to start over and throw these away.  Where can I find there is a bassist hiding in there hiding in plain sight and here's the here's the idea. What we want to do is reduce the set of vectors by throwing away some that are in the sign of the others. So let's let's look at this again. So yes.  any Vector ex is in h the X's have portrait cuz when he was asked for the coefficients, so let's call it a  if any better a is in a peach.  Then by definition of span that means that a is equal to some linear combination of those three vectors x1u + x 2 + x 3 w.  for some X1 X2 X3  Steeler Nation, that's what it means to say that everything in AIDS is a linear combination of vectors, but we've also got this relationship down here.  So let's substitute. I didn't say. Well actually, let's write this as x1u + x 2 V + x 3 x w is equal to you minus V.  I know let's recombined terms appears in two of those terms. Let's collect them. So this is x 1 x well + x 3 x you  bus x 2 - x 3 x b  those new coefficients there x 1 + x 3 + x 2 - x 3 they're not the same coefficients we had before but they're just too real coefficients in the point. Is that this thing?  Is in the span?  I've just the vectors u and v it's only a combination of the vectors u and v we started here with his arbitrary Vector A and H.  which by definition means if it's something a linear combination of the three vectors and we found that any such arbitrary a is actually in the span of u and v  so in fact  each is also equal to the span of just you and me.  So we can eliminate one of those vectors.  Okay. No, by the way, we had some choices here. We didn't have to eliminate W. Cuz I could have rearranged this from consideration and found that this is also equal to the stand of v&w and similar be a sequel to the fan of you and I could be of any two of these factors, but we have some choices to make it not going to be unique by any means the point is that I can throw away one of those vectors.  And still have a span expect that's what's always going to happen. Here is the key idea that if you have a linearly dependent set you can always throw one of them away without changing the fan. In fact, if you remember the definition of linear dependence one of the two equivalent definitions was that at least one of the other two  the vectors  you  envy  Okay, do those to form a basis?  I heard someone say no or maybe they said yes, it was too quiet to hear. So how about by a show of hands how many people think those two form of bases?  Most people how many people think they don't want a basis.  Nobody, okay. So that's correct. These two vectors form a basis. Why do they form a basis?  Because they are linearly independent and they are a spanning set. So by definition he rages is vectors and those two those two are linearly independent.  And normally we would have to check that by doing. This is another case where it's easy to check is one of the other know we have a zero in one spot and the other that's you're never going to have linear dependence in that case. Unless one of us is actually the zero vector.  So this is a linearly independent spanning set.  And therefore it is a basis.  And that's exactly how you find a basis in general. The Subspace first thing you need to do is done for you. By the way. The Subspace is presented or will be easy to infer from some techniques. We've already learned as we'll see is to prune it.  Okay, you need to say okay now, is it a basis check?  I didn't you have to check if it's linearly independent. If not by definition. That means at least one of those vectors is in the span of the others find which one it is or which one of the ones that is it and now you have a smaller set of vectors. Is it a basis check check if that's dependent? If it's not find one of the vectors is linearly dependent on the others remove it and it'll write this procedure and this procedure will eventually stopped right because those vectors there spam the Subspace which is nonempty eventually you're going to get there are no more that are already in the span of the other says that have a basis of finitely many vectors. We'll see in a few minutes. That's not always the case.  Okay, so I called that a corollary, but I should really call it a serum cuz we didn't stay that they're on the at the says this is a theorem.  If I have a Subspace Subspace of some bigger Vector space.  then  some collection among those factors is a basis of that set of vectors is a basis. Just what I just said, you just proved it until you get down to look at a concrete example now relevant to your homework into our understanding of the class. So the most important kind of subspaces we deal with here are so far are the column space in the null-space of a matrix structure the same one we had last lecture and use it several times this lecture. This is a 3 by 5 Matrix its column consists of those five vectors in R3  the column space  of H H is equal to the column space of the Matrix a definition of column space of a matrix is defined to be the span of its columns.  By definition there is a spanning set. No, I'd like to find a basis for the column space.  So the first question is maybe that's the basis right there. Maybe that's set of 5 vectors is a basis. What do you think?  Is it a bassist?  Y'all know why not someone in the back.  heard some voices from the back so  Get out of the back or in the back or is that your arm cramp?  Perfect. The second Vector is manifestly twice - 2 * the first Factor, so it's definitely the set of exercises definitely linearly dependent independent. So following our nose following are pruning procedure that we talked about in the last flights. What we should do is throw away that Vector going to respond by the other four vectors just as well. Okay, great. So how about let's give these guys names on V2 V3 V4 and V5 form a basis for H.  No.  Okay, so you're at not talking about pivot. So you're jumping ahead that which is good. That's what we're going to say next. But the key Point here is what we need to check.  We need to check if those remaining four columns are linearly independent and it's no longer true that you could obviously see that one of them is a multiple of another one. That's not true anymore. But that just means that no pair of parallel. What does it mean that you couldn't have three of them that are linearly in linearly dependent?  Great, and we don't have to do the road option that loved it is for us. So there's a reduced row Echelon form of the Matrix and use it before but let me make this a little more precise in this example to cement it. So here are the five columns of the reduced row Echelon form. You are the five columns of a matrix.  Now in the reduced row Echelon form we can see that there are only two pivotal cops are the pivotal columns and the others correspond to free variables. What does it really mean that the courts want a free variables? Will we know what that means if we're riding down the solutions that which will do on the next flight when we talked about the null space, but they tell us something critical in the column space as well.  So we already noted from the original Matrix that V2 is -2 times we want.  But notice that we can see that immediately in the reduced row Echelon form, right? So if you look at it  this minus two and three right there.  That -2 entry tells you that a 2.  Is equal to -2 times they want because a one is just the first so if you want to see if you just have to check and indeed that's true. Now, let's look at a for a Forza non-committal column and it has two nonzero entries there.  I should use different color so that the second one is to accommodation of the previous column forms. Help us look for before I can build it out of the previous columns III by taking -1 times they won.  Plus two times a three because they're standard 0 + y x 0 1 so that second equation there a one.  + 2 a 3  Okay, and similarly?  We see that the first column.  a 5 is equal to 3 A 1 - 2 a 3  Okay, so that's what we see from the registration form of the Matrix. But here's the thing. Look over it the original Matrix now a we already noted.  That V2 is equal to -2 V 1.  I know I claim that we can also check for is equal to - the OnePlus 2 V3 and V5.  Is equal to 3 V 1 - 2 V 3.  Let's check that second one before equation before it's supposed to be - 51 + 2 V 3/8 if I take - V1 I get four.  + 2 V 3 so4 + - hold on a sec.  So I'm supposed to take.  -51 which gives me at 3 in the first thought + 2 x V3 which gives me a 4 so minus.  Positive 3 - 4 is equal to one. Is that true?  I apparently need to actually write it down to see I'm caught in the black Ford Field even though I'm not using the the Blackboard this field that emanates from the black boy that makes you stupid. Okay, so I may just come over here with you guys at.  right of -3  + 2 * -1  is -2 + 3 is 1 - 1 + 2 * 2 is 4 minus 1 is 3 + - 2 + 10 is 8 okay. So there we go verify that that same relationship but we don't need to do that ever again because that's that's exactly how operations work. That's the point operations. They mess up the columns change the column space the column space of a is a totally different column space of the registration form with a  the three row operations that we can use in sequence to get from The Preserve linear relationships between so you can pick off from the reduced row Echelon form dependencies between the three columns on the pivotal Collins our relationships we have so that's the reason why we can just go ahead and say well in your combinations of those  Not from the context of what we're interested in right now, which is finding a basis.  okay, what that tells us is that  V1  V1 and V3  form a basis  for the column space of a  Okay, that's this procedure. We want to find a basis from a US tanning set. What we do is we take a sentence that we start with and we start pruning it by removing factors that are linear combinations of the others. Well, the reduced row Echelon form tells me that the non pivotal columns are linear combinations of the pivotal wants so we'll just throw out all the known non-committal columns and we won't change the column space in that context. That is the column space is fake.  And the pivotal columns those are linearly independent because as we know if we're going to check their linearly independent, what would we do we would do row reduction and see if they were pivotal pivotal basis for the column space.  Form a basis for the column space today. So that's a restatement of what we just said, so let's do another example Matrix 3 columns in R3. So maybe maybe these columns fan all of our three. Maybe the column space is all of our three. Maybe. We just have to check if I doing row reduction row reduction here. Okay, when we need to get this one form, it's not so bad. It's pretty close already actually are we don't actually need to go all the way to reduce.  We only need to check which columns are pivotal to do that. We only have to go to any row Echelon form because I've already got a zero in the second row below the pivotal one twice the first row from the Third.  Can you give me a zero there a -5 there?  and -5 there looks like  0 - 1 - 1 + I can see that I'm not going to get a basis for all of our three here because the second row and the third row are parallel to each other like when I know subtract when I subtract 5 times the second row from the third I'm going to get there.  And now I'm in row Echelon form. I'm in row Echelon form and I can see  That these two columns are pivotal, but the third one is not which means the same holds true in the original Matrix, which means it if we want to find a basis of the column space.  those first two columns 1 0 2 and 3 - 1 1  form a basis  for the column space today.  zz's.  Now what am I to important caveat there highlight to important caveats. The first is that and I already said this it's really important that we use.  The Columns of the original Matrix a state they preserve a relationship  I think about it this way.  If I had a matrix whose columns were all pivotal 3 by 3. Matrix is called.  Then we know that that forms the basis of our three we saw that last time but the reduced row Echelon form of any such Matrix is the identity Matrix.  Okay, so that means that those vectors are the standard basis vectors on the right. Those are very different from the original Vector space. It really doesn't matter which factors you use you could use this but I could just as well have chosen to of those. Okay, I could take a 2 by 3 Matrix.  maybe it's something like  this one here.  So look at the the first two vectors there in 102 and 3 - 1 1  now if I do row operations on just those two vectors  are those two vectors linearly independent know they are because they are pivotal in this Matrix here. If I were to carry the Matrix just those first two columns to reduced row Echelon form. I would get one zero zero zero one zero, that's what you always get. If you have linearly independent now those two vectors 100 and 010. Those are the standard. Those are the directions.  In the three dimensional space so the span of those vectors is the XY plane.  but the originals actor is 102 + 3 - 111  those two planes kind of look alike. They're both planes, but the similarities in their original column is not the same as  I think that's critical here. You want to find a basis for the for the column space you do row operations just in order to tell which Columns of the Matrix are pivotal those columns in the original Matrix. You don't use the columns in the registration form. Those are not related to the Subspace General.  What's the first cabinet which is written down here? Typically, the column space of a on the column space of is reduced row Echelon form are different things different subspaces. There are zillions of bases. Like we saw on the first slide here.  This example here they ended up deciding that we could use the first two vectors there as a basis which is true, but we could have also use the second or the first in the third pair of those vectors is a perfectly fine basis.  And that would also be true in this example here.  Because no two of those vectors are parallel. So think about it this way. We don't do column operations when we're doing row operations. We don't swap columns, but would call him as me swapping columns means that we're renaming the variables. Like if we're thinking of a matrix is the coefficient Matrix of a system of linear equations in two variables X1 and X2. I'm calling them next to a next one.  That will change how we describe the solutions that but in terms of questions, like are these vectors linearly independent are the effects that doesn't change those questions at all. So we could have reordered these vectors just as well and that I would find in that case that the first two columns were still pivotal which order you put them in but the point is that there are some of the nonpareil columns in The Matrix the way we do our algorithm could have happened that we could have chosen other vectors from Among The Columns to find a basis. I'm not recommending you do that.  This is just one basis. But this is a good basis. You can always use this one. So if you're asked to find a basis for the column space, this is what you should do.  What a great question. I swear I didn't plant them in the audience because we're going to go into that on the next flight question was is there a minimum number of vectors that you need to form a basis? And that is a phenomenal question actually one more slide after that. So hold on the answer is yes, but no, but before we get there, let's talk about the other.  What's the other kind of Subspace that we've mostly been focusing on in the last couple of lectures? So if I give you a matrix is a Subspace of the codomain but of the domain instead of which you can multiply a number of components equal to the number of columns, and we know how to find this. This is literally lecture one for the null-space of a  Can be described as a set of vectors X1 X2 X3 X4 and X5.  Search that okay, we look at the reduced row Echelon form. We have the same thing now we can only look at one form. We have are there.  That means that x 3 X1 and X3 are going to be expressed in terms of the other columns, right? We're going to have three variables three variables.  And then the two non-trivial equations that we get when we interpret.  Reduced row Echelon form as the coefficient Matrix of the system. Tell us that x 1 is equal to 2 x 2.  + x 4 - 3 x 5  Are the x 3 is equal to -2 x 4 + 2 x 5?  It's a homogeneous system.  and then the standard thing we do now is to start a factor out the free variables and express that says x 2 x 0 0 0  plus x 4 times a vector which is in this case one 0 - 210  plus X 5 X Factor.  which is -3 / 0  201  okay, so there's a perfectly good description of the null space. It's the set of linear combinations of those three vectors in other words. It is the span.  Of those three vectors. Let me call them A B and C. So I have to rewrite them over here.  So the the algorithm that we use to solve systems of equations standing set for the null space.  So I now got a settings that and so I can ask the question. Is it a basis if it's not I know what to do. I just start pruning it if it's not a basis, there's some Vector in there that the linear combination of the others. I find one of them I remove it and I keep going until I get down to a basis.  Is this a bassist the ones that I get from this procedure is that set linearly independent or not going to give you Thirty Seconds to Talk Amongst yourselves and decide.  All right. So sounds like you're having an active discussion. I see some people have a really pained expression on their face. So let me end your misery and let's just take a vote how many people think that these are linearly independent.  Even the paint guy thinks they're okay. That's good. How many people think they are linearly dependent?  One or two hands, okay with somebody who thinks they're linearly independent like to explain why they think they'll any of the independence.  Yes.  Fantastic, perfect explanation each one of the vectors has a 1 in a place where the other two have a zero, let's look closely.  so let's look at  these entries  these entries  centuries  Okay, if I look at the entries that correspond to the three variables to four and five in this case and I look at only those entries than the first Vector is 100. The second letter is 010001. Here is how I find the null space what once I take get the reduced row Echelon form of the Matrix. All I do is I take the coefficients read across in the crows. I put negative signs in front of interspersed them with the standard basis vectors in the three variables slots. That's what this was.  And here's the point if I take a linearly independent set like a standard basis vectors and then I got pain some more entries in other places will not make them because if you have a non-trivial linear combination of the bigger vectors Vanishing, then it will also be a combination of the the components so we get that these guys are linearly independent.  It's always going to happen following this procedure.  For finding the null-space. You're going to get a you're going to get out of space on a basis for the null space. Again. There are zillions of these are not the only ones but these will be  Alright great.  Now let's get back to your question.  Is there a one basis is better than another can I always find what was the what's the minimum number of elements of a basis? Maybe I'll have a basis with 76 has been another one with only three vectors. So clearly I want to use the one with only three factors. Well, sorry to disappoint you but all the bases will be equally efficient or inefficient. Do you have any two basis for a Subspace have the same number of vectors? In other words I said there is no space.  All of them have the same number of vectors in actually prove that there a special case of that there so suppose.  Let's do it with where I finally have a basis was two elements. I should really do this for a basis with n elements, but I'm going to stick the two to make them easier suppose that you won you too.  Is a basis.  for a Subspace  and let's also suppose that V1 V2 V3.  Is another Subspace for it? So here's the idea. I'm going to give a proof by contradiction already discussed this a lot. How do you how are you going to prove something like linear Independence for some abstract factors linear Independence is a negative property. So typically he's going to prove by contradiction saying I want to prove their linearly independent. Let's assume that they're not that that leads to a contradiction same idea here. I'm going to assume I have two bases that have different numbers of vectors in them. And just to make things concrete. I'm going to assume that I have one that has two elements and one that has three elements, but you'll see that this idea of this proof is going to generalize immediately to if I have a 76 + 1 + 70  So here's the here's the idea for this space spanning set.  So that means that V1.  Can be written as some a1u 1 + a B-1 YouTube.  Everyone is in the span of you wanting you to if you want is a vector in the Subspace and therefore it's in the span of the basis vectors.  also  V2 is equal to sum a 2-1 + B2 U2.  and V3  is equal to  A3 you 1 + B3  YouTube okay each one of the vectors V1 V2 and V3 because they're in the Subspace. They must be expressible as linear combinations of the basis vectors. Do you want in YouTube?  consider the Matrix  A1 A2 A3 B1 B2 B3  Hey, this is the moment not much to do with these Originals actors are associated with them, but I can take those coefficients that I just found and I can make a matrix out of this rectangular Matrix came from the two elements and the three elements in the two base.  What do we know about rectangular matrices? We know that if I have more columns and rows than those columns can't be linearly independent.  Right, we know that if I take if I compute the reduced row Echelon form of this Matrix, one of those columns, at least one of those columns is going to be non pivotal.  But we know then is that.  So there is some.  non-trivial  Vector X1 X2 X3  such that if I take this Matrix gire  This is the vector X such that a x x equals 0.  But that's what we know we know that there is a non-trivial solution to the homogeneous system with that Matrix as its coefficient Matrix because there are free variables there because there aren't enough columns to go around Rose to go around to make all the columns pivotal.  What's 8 * x * X?  Is equal to okay. Well, I know how to multiply matrices that last reminder. So so I'm going to multiply that First Column by x + 3 by entry and get a 1 x 1 plus a 2 x 2 + 83 x 3.  I'm going to move by the second column by X as well.  And I guess maybe one x 1 plus a b 2 x 2 + B 3 x 3.  And what I'm told is that that is the zero Vector. So what I have is there's some non-trivial coefficients X1 X2 and X3. So that 00  How does that help me? What does that have to do with these original vectors? Well, let me just start.  pull out of the following  Let's those coefficient forsake those axes.  And look at x 1 V 1 + x 2 V 2 + x 3 V 3.  What's this compute with that thing is well. I have some equations up here.  Set can that I can use to express the views in terms of the use to let's do that here.  This is x 1 x.  A1 you one plus B1  U2  suspects two times a day to you two plus two you two plus  x 3 x a3u 1 + V3 YouTube  I know this is a linear combination. There's six terms there. But if I multiply it out Andre Shuffle things I can express this as a linear combination of you is a skeletal muscle.  that says X1 A14 the you want in the first term + X2 a24 the you want in the second term + x 383  Those are all the things that multiply you one.  And for the second terms that multiply you to I get X1 V1.  x2b 2 and x 3 V 3  okay times you too.  But hey, wait a minute.  Look at the columns or look at the Rose.  Over here and look at these coefficients.  Let's Go Fishin Sakina there. Those are the rose. Those are the entries that this Matrix ax but those are zero.  And so this is the zero Factor. So what if I got I've got a non-trivial linear combination of the Vees that equals 0 and that is a contradiction.  To the fact that you wanted me to Envy 3 as a basis.  That's the core idea here if I have two sets of basis vectors.  Then I can write down a matrix that expresses one set as linear combinations of the other.  and vice versa  I have two bases with different numbers of vectors. That means that Matrix.  But that will be linearly dependent. If you have any set of three or more vectors will automatically be linearly dependent. That's what this shows.  So you can never have more than two no more than two vectors in a basis, but you couldn't have less than two either for the same reasoning because if you had less than nearly dependence by the same argument in Reverse, okay. So this is the key factor of linear algebra the most important there any two faces have the same number of elements and that gives us a fact hear a new word to add to your list of vocabulary, you know this word before you've been using you've heard it a lot.  We've used it already. But now we're making it precise. The word is dimension.  So if I have a vector space it could be an abstract Vector space. It could be a Subspace of a vector space but one way or another five of vector space dimension of vector space is the number of vectors in any given basis for it. We just saw that if you have two different bases.  They will have the same number of actors in them. So this is a well-defined quantity the dimension of a Subspace or a vector space is the number of vectors in any basis for that space.  So for example here is a vector space. It's the span of these three vectors in R3.  This is an example. We saw a few slides ago. And we saw that these two columns in the reduced row Echelon form are the pivotal columns in the third one is non pivotal has to Total columns. Now, we saw that if you want to find a basis for the column space that tells you that this Subspace the column space of that Matrix has Dimension 2 is a two-dimensional Subspace. It's a plane in R3  Any other bases you find you put in this case you could use any two of The Columns that Matrix and that will be a basis you could also do all sorts of other things. You could take three times the First Column and 76 times the second column that's not going to change the fact that they're a basis.  You could also mix them up and add two of them together and subtract the other two that'll also work and give you a new bassist. There's no matter what exactly two vectors in it. That's the dimension of the column space.  Craigslist quickly, look at a couple more here was a Subspace. We saw the space of polynomials of degree less than or equal to 3 which were polynomials of the form a x cubed.  philosophy x squared plus BX plus c  They were a b c and d.  Are arbitrary real numbers that are free variables here?  So what that means?  Is that this is the span?  of the vectors x cubed x squared x + 1  there is a spanning set for that Subspace consisting of those for polynomials.  And those for polynomials are linearly independent because I cannot find a numerical linear combination of 1 and X that is equal to zero. I can't say oh + 3 that's equal to 0. I mean it is equal to 041 choice of X, but these are atoms the basic objects. There's no numbers A&B for which a x + B is always zero those are linearly independent vectors. So that means that the dimension of P3  Is 4 because there is a basis with four vectors in it. So lost.  What's the dimension of the vector space of all polynomials?  Well, let's see if we can write down a basis everything in there. Looks like you know, there could be a constant an Xterra Man X Squared term in X cubed term eventually it terminates.  If you want to have all polynomials going to have all possible polynomials that you have to have terms of arbitrary degree. Any polynomial will be a linear combination of only finitely many of those but if you want to have an arbitrary polynomial, then you have to have all of those Powers there. They're all linearly independent. So what we find is the dimension  Of the space of all polynomials is actually Infinity.  Does it evolve polynomials is an infinite dimensional Vector space doesn't work for it in this room, so don't worry. "
}