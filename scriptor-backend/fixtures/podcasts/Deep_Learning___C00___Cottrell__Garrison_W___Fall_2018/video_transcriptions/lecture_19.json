{
    "Blurbs": {
        "A1 category I would have 100 times 99 div 2 pairs of those. So that's like Fifty and a hundred which is 5000. Examples of Paris and then I randomly choose 5000 examples that aren't that category in an in a batch. I'll have half and half of same different. different categories you don't need to know the number of categories in advance cuz you're just telling it same and ": [
            3725.7,
            3766.3,
            67
        ],
        "Appear what they're showing is that these are one kind of thing. These are another kind of thing and just the third kind of thing in a researcher knows what these molecules are would say that this is the right structure that the dean should be between the A's in the seas. And this is just saying here's the China. Okay. This is the outer core. Where are the three ": [
            4057.7,
            4119.4,
            75
        ],
        "Barker and change it on eight Nvidia p100 gpus the smaller Corpus took 12 hours the larger 13.5 days. Is your all on the same CPU? Any batting state-of-the-art new stores, and what's interesting? Is the other networks are? Look at the training cost in terms of floating Point operations here. previous methods I'd like a lot of lot of training end of the 19th * 2.3 while you were ": [
            2073.9,
            2138.2,
            30
        ],
        "Gans. There was a pretty cool tutorial on. Automatic machine learning where the hyperparameters of your system car learned by some other system. For example, one of them used reinforcement learning to figure out the hyperparameters of your learning system. Are you have a lunar and then you have something controlling the the hyperparameters of the learner insert basically searching for the best hyperparameters and it's sometimes another neural network ": [
            2722.1,
            2767.0,
            43
        ],
        "Say more is more Quan. And they were hiring the postdoc each. We have like four or five labs. and our goal is to develop a website where researchers are Spectre the nearest results from using essential you don't answer. and we're working on improving the architecture. using an auger objective That is developed the salsa version of the strip and chewable that is within a cluster. You want all ": [
            4284.7,
            4369.9,
            79
        ],
        "So it's weird thing. But the shock Max confused a you know where you're paying attention to and it's all learned by background. There's actually three matrices coming out of each didn't doctor WKBW Kingwood WV and They have some more they have some description of this that I think of. Where to put a human face on this bed. They think of you WK as the key WQMX the ": [
            1472.7,
            1524.4,
            23
        ],
        "Turing machines on trim to dress a bowl memory. So it's got a particular operation that it does but it's differentiable. And it allows the attentional filter to to pay attention to different inputs. In fact, they're actually intentional heads at every position. So it can even pay attention to eight to four parts of the input Eddie position. The inputs to the attention layer of the outputs of the ": [
            1150.9,
            1194.9,
            17
        ],
        "Where are we now? near me No. You can hear me now. I can't hear you. Say something. for rent near me Green Bay Hear me now. started last time 30 Target I'm going to if you have a question raise your hand all will ask me the question. Okay. So remember last time I talked about how I always said mapping time into space isn't as good as this ": [
            235.0,
            417.7,
            0
        ],
        "a minute. It's minor league complex, but not too bad. These things can attend the different positions in the sentence in so Example if I say I crossed the river and went into the bank. You would need information. From nearby words to realize that this isn't a river bank but is a bank bank money bank will see an example about a little later. Their Computing these transformations of ": [
            844.0,
            892.3,
            11
        ],
        "about the pieces because you're training on pairs of data point they essentially amplifier dataset. It's not in square exactly. I mean given and training examples in the limit of M squared pairs, but you know, it's basically the number of things in each category X the number of things in the other category That's How many pairs you can you can get so if I had 100 examples of ": [
            3685.1,
            3724.4,
            66
        ],
        "also called an energy function. So there's a kind of graph of this for one of them in the garage after the other and squared are so this looks like a parabola. And the idea here is you pushing things closer together or are you pulling on this brings out to some margin this with the circle around it mean? Doug and the basic idea is you been the to ": [
            3919.0,
            3952.6,
            72
        ],
        "and hopefully this will be accepted despite the stupid reviewer just barely about that because they're recurrent and recurrent networks are touring equivalent. These are also touring equivalent. And now again, it's a recurrent Network because It's basically being enrolled in time and it decides itself how much time to run for each position? That's pretty cool. I think. Any questions about that? Yeah, I heard some word for phrase ": [
            2432.6,
            2498.4,
            37
        ],
        "and overtraining it's told that all the yellows the same all the blues are the same but the yellows and the blues are different. And after 50,000 decorations you got this. What's interesting here is that the red is a 0 and this is a sick. So these are both things with loose and over here is one. And even though they're both lines when it has a little bit ": [
            3602.6,
            3638.9,
            64
        ],
        "and then they have linear output units, but they're not trained there. No targets are these linear output units instead if you put in two inputs here and say it's the Aspen wenton. Here's a and b you tell them that work these two are the same and then you try and move their output factors closer together. This is an aspen went in and this is one of those ": [
            3424.7,
            3461.5,
            59
        ],
        "and there's a tower of network over every word position and it's taking an encoding of the word. And then there's an attentional component which will talk about or directly soon as I eat for network. And then there's another attentional filter for Hyundai feed for network. And this is just replicated six times. So The Columns of shirred Weights because they're all exactly the same network. What's different is ": [
            759.1,
            798.2,
            9
        ],
        "and they raced blue score on English to German translation by Pulte points. Remember how we typically do it? We have an LS Cam Newton in motor not work. It takes in my feet hurt and then end of sentence and then there's a second Network. That's a generator Network. In-N-Out puts one word at a time and feeds it. So now put back into itself to produce the next ": [
            499.0,
            535.8,
            3
        ],
        "and you can think of it as the fingerprint of the compound. And using deep convolutional Siamese neural network, we've developed the system that clusters the compounds directly from their enemies are Spectrum based on their structure though. We map from the NMR Spectrum to a cluster space where things with similar structures are near one another in the state. And that allows new compounds to be mapped into that ": [
            3087.5,
            3126.4,
            51
        ],
        "ask but when they're the same you put it in the and ask for 110 and Chandon a known and say they're different and so it's going to move those outputs farther apart. I'm so sorry. the guy at the beginning it's a pretty good was it looked up the Journal of natural products online? And cut out from the PDF the NMR Spectra for 4,000 different compounds. Now who ": [
            3952.6,
            4012.8,
            73
        ],
        "at the top and then Etc. I told you everything I know about those. I didn't go back and read the Alex Graves paper where they were first put in but that's the story. So this is pretty cool heads. the same architecture but even fewer parameters because did Shirley reuse the same weights? Organics it's running through inattentional filter feed-forward Network attentional filter each word network, but in each ": [
            2538.7,
            2579.3,
            39
        ],
        "attentional filter so I can pay attention to the importance of Any of the words in the sentence and then it's Travis reduce an output. That is the translation of the first word. and then that goes into the attentional filter of the decoder Network just like in the lstm version where you copy the output back to the input. There's another bit of network. I'm not telling you about ": [
            932.9,
            968.7,
            13
        ],
        "case the weights are all the same. This is a poster. I just saw him about an hour ago. And this is the Transformer output blue score and ears their blue store. And so they've raised to Blue Square another two points. Do they compare this to Transformer networks? What they did here is They put the Importer in the Deep Burger are all sharing weights. And this time down ": [
            2579.3,
            2637.0,
            40
        ],
        "closest family and Foster man, and that gives you some indication of what other things do you speak? Which is a fingerprint of the compound and from that you're typing into a state where you are by structures are near one another. I think that's that's pretty cool. Are we getting a lot? Restarting company got a big night and just recently got another Grant from the Gordon Moore Foundation. ": [
            4224.1,
            4282.8,
            78
        ],
        "cluster space and based on what their near you can get some hints as to what their actual structure is usually and I'll show you examples of what that is. To Dianna Mars a technique that gives indications of bonds between atoms in a molecule and I've told you everything I know now. This is an example of a 2d NMR. Basically you get the spots on a on a ": [
            3126.4,
            3168.0,
            52
        ],
        "comes from its. of this weighted arm of the Hidden unit vectors with H1 inner product with WQAD is looking for a particular pattern. and when the Emaps is that you get. a large number when it doesn't You got a small number? I have no money. I'm desktop laptop. Okay. story Corpus German sentences Order a half million. And then English to French Corpus, that's much larger. Betty X ": [
            1948.5,
            2073.9,
            29
        ],
        "could answer. Okay, so Universal Transformer networks are A variation on these? Where is Transformer Networks? And again, they're shared weights between every Tower but not shared weights between the different rows of Aquanauts. That's Computing a different function at every layer and it's just doing six steps of feed for Network before it gets to the final and coating of each word in the sentence, which has been going ": [
            2195.7,
            2247.4,
            32
        ],
        "different colors here correspond to different attention has there's one two three, four, five six seven eight of them and these guys are basically only paying And this one was it? And this one's going to be Sprint store on one and one position. I don't know mind. based on the app You don't know what? I mean, I don't know if they've investigated on the Aquarius. reasonable and then ": [
            1628.5,
            1714.9,
            26
        ],
        "different. You won't even have to have examples for all the categories and these are especially suitable for domains where you have a large number of categories, but small number of examples. And again if you think about that face one. Given a new person it's going to map that person into a portion of the space near the other people that that person looks like but hopefully not exactly ": [
            3766.3,
            3801.1,
            68
        ],
        "dimensions so you can view it and the different colors correspond to different compounds, but we ran out of the colors. So this read these roads are different. These roads are different these Reds and then you can going to play with us and see what's near other things. And where Chen wants to do is put this in virtual reality and have a researcher be able to explore the ": [
            4119.4,
            4150.2,
            76
        ],
        "don't have to get stuff out of the field extract molecules for a minute and then try and figure out what they are. And the bottlenecks are right there in the middle or 2D NMR is like nuclear magnetic resonance imaging. So if you've had an MRI. Using the same technology and our goal is to speed up structure determination after 2D NMR. Please start with the 2D NMR spectrum ": [
            3043.5,
            3087.5,
            50
        ],
        "flops. And I did better. Although I don't know about this guy. Well, it's not quite as big as. This difference here is too loose for two Blues. I guess you. Posey's Transformer networks use Earl computation and every level 8 Ford, they simply replicate the network for every input. Are very fast to train? And they achieved state-of-the-art performance without recurrence. Any questions on Transformer networks that maybe I ": [
            2138.2,
            2195.7,
            31
        ],
        "for it. I forget Universal. Computation time unit or something like that. It's it's just a sigmoid that gets input at every layer and when it reaches a large threshold large value then he stopped. Each one of these has one of those stop units and in the first visit then stop after two steps in the back in position that got bigger and bigger until it reached the Threshold ": [
            2498.4,
            2538.7,
            38
        ],
        "gets longer this is this helps scaling. Is turkey something like 00100 Etc? There's another way. W. And that's why I didn't operate. Basically you see my pointer. There's a third one Federer and doors are multiplied directly X. This guy the second one by the end of one of the most part. I'm so shy and so that game. Richard from another weight Matrix of the transformation wooden bucket ": [
            1402.1,
            1471.5,
            22
        ],
        "has this attention layer here. That's what these little lines are showing and then it's outputting the word send again told you everything I know so well after your dad paper, it's got to be online in the next website or Noritz as we call it now. Okay, so that's Transformers. Any joke again. This is too very fast-moving field. I saw some number of papers with new kinds of ": [
            2681.3,
            2722.1,
            42
        ],
        "here means that this is stacked for there's some number of of these things may be fixed again. I don't know but then at the output itself putting the words in the other language and I told you everything I know but basically there's no separate decoder and encoder study entering the decoder are talking to each other at every layer. Because of these because they share weights and it ": [
            2637.0,
            2681.3,
            41
        ],
        "in particular. I'm going to leave out positional encoding but all that does is it adds it just directly adds to each input embedding Vector some number that's different for every position because one of the things about Is Transformer Network says they don't actually know you know, which which of the inputs is the first word in which is the second so they they just directly add some numbers ": [
            572.3,
            611.0,
            5
        ],
        "increasingly gets bigger until you decide based on some threshold of how big it is. And now tells you when to stop. what that means is that different words can be encoded can be run for different numbers of steps and it's adapt on the network itself decides when to stop and what I'm showing here is that instead Example the first word is run for 2 steps. The second ": [
            2338.0,
            2385.3,
            35
        ],
        "input from the attentional filter and that's why it's called a Transformer Network. And this structure is replicated. Text Terrence. Is there a question? No record that works for the tensional filters. wish malicious text-based okay, we're going to see that hold your horses will get to the As you see it, it's in putting the same English sentence. We talked about earlier with the lstm networks my feet hurt ": [
            683.6,
            759.1,
            8
        ],
        "is graduating this year and PornHub is the master student who graduated last year. When I gave this chocolate Scott, so they're trying to University of Technology. I'm going to talk about what natural products research is why it's important and then I'm going to talk about Siamese convolutional neural networks where they're cool and then talk about our system smart for small-molecule accurate recognition technology. Although it doesn't actually ": [
            2862.8,
            2905.5,
            46
        ],
        "is mask so that it's still on a regressive meaning that the mail only depends on J. Not opa my high school French is coming in handy up here not. But and then went to generate so it only pays attention to game all and not PA. 1/3 causal it goes from left to right. repair Okay, so the attentional filter is a kind of built-in Gadget like the neural ": [
            1101.1,
            1150.9,
            16
        ],
        "is to basically find Things that nature is produced that are useful for for things like that. So here is Bill himself collecting samples from the Palmyra atoll that's out here in the middle of nowhere fix the 10 researchers have any one time? Airports near pooler's penicillin which came from old axle and more recently don't Statin 10 and that was drive from Missy hair looks like a big ": [
            2945.1,
            2996.8,
            48
        ],
        "kicks in and you're trying to minimize the distance. This is the distance between the output of the first Network applied to X1 and the output of the second Network applied X2. You're trying to minimize this disc. That's a squared error. But it's the difference between the two identical networks mapping the same thing or sorry mapping two things are the same category to the output to this is ": [
            3840.3,
            3877.1,
            70
        ],
        "mall or organizing this with me. Newport ": [
            4481.8,
            4487.6,
            81
        ],
        "map and time into the state of the network. and and I was wrong wrong wrong and So the reason I was wrong is because I was thinking about Brands not normal next. And so what if we ignored the brain and gave each location its own network just called more Network when we need it. We use the same network at every location. So all the weights are the ": [
            417.7,
            454.1,
            1
        ],
        "me and me Wireless unless they are being. Is it okay now? Derek I can help Okay, if I don't get a question. Okay, so there's this. Call Brien Ford net worth. The sheltered that's why it's called. this is the and again, I found I think it's a problem. awkward Spell work better. Okay, so obviously on details here that I'm leaving out. estimate main idea the outputs of ": [
            1722.8,
            1856.9,
            27
        ],
        "more on it than the other so it Maps even though it's told these are different. Just by, you know this mapping and put similar things in similar locations in the state of Kansas. Okay. Makes sense so far. Yeah, I know. Okay, so cool. Thanks. I love Siamese that works as I told you I had sell yesterday. He looked at me like I was anyway the cool things ": [
            3638.9,
            3685.1,
            65
        ],
        "moving them closer together on the other hand if is there different. So this one kicks in noticed there's a minus sign indeed. So you're trying to increase the distance, but there's a margin so if the distance is bigger, And the margin this will be negative and then the loss is zero. They're basically wanted to move things M apart. It doesn't need to learn on those anymore. Are ": [
            3877.1,
            3919.0,
            71
        ],
        "networks are pairs of networks that are actually the same network and although it says F1 and F2 Junior. I really should say F1 and f-1b mean these are identical Networks. And you put two inputs into them. They sure wait so they're like sharing organs. And I take two inputs and share this symmetric loss function, which I'll talk about in a little bit. And they can be convolutional ": [
            3387.0,
            3424.7,
            58
        ],
        "of the category? We're trying to Max. Okay, so on Thursday I'm going to talk about. Essex I like to close my classes with that should be. Market Revolution Okay. 788 Well, I want see you want to see me. I forgot to stick. stacked laundry city government in lanzhou, China I have with the collaborators from the southern China University of Technology. Any leftover parts? Okay. Thank you and ": [
            4369.9,
            4481.8,
            80
        ],
        "of the words. So this isn't the whole encoder. This is just the first you this could be a look up to work it back so that you have some Vector representation of the word and gaskets map to a hidden Vector. That's now the input to the rest of the network. Then it's an ex layer up. There's an attentional filter followed by a feed-forward network that transforms the ": [
            646.7,
            683.6,
            7
        ],
        "one perhaps one location in the input and that's skating. The input started you mostly get what you're paying attention to. This is called self attention. It's in the entered South attention and then the decoder pays attention to the end Kotor which is not self attention because it's paying attention to a different network. In this case. It's called self attention cuz you're attending to your own representations it ": [
            1242.7,
            1279.8,
            19
        ],
        "other things you gave them farther apart. And so you're trying to reduce the squared error or the distance between the outputs of these and you change all the weights by the same amount. Where is there different? You try and increase the difference between the outputs? Bristol paper by Rhea Hansel who I met yesterday for the first time and Ian laocoon and one other author and the ideas, ": [
            3461.5,
            3501.9,
            60
        ],
        "paying attention to making and more difficult. The idea is that it's it's skipping over this the registration and voting process in and pay attention to the fact that it's making more difficult. In this particular step examples in the paper that are less compelling. This is an actual figure from the appendix in a paper. the wrecks happened. It actually has some of them have the same place. the ": [
            1577.8,
            1628.5,
            25
        ],
        "previous layer. And they come in three ways matrices to computer the attention waiting which is again a softmax. So I think I Maybe talked about attention before but basically you generate it's it's it's like the neural turing machine look up of a memory location. There is a peak in the soft Max and that's * * the inputs in order to get a filter. So the people pick ": [
            1194.9,
            1242.7,
            18
        ],
        "query and if those two match then you pay attention to this part and wipe you guess this is weighted some of the Hidden another Vector a linear transformation of the Hidden unit doctors in each position waited by your attention doctor. That makes sense. Here's an example where? This is one layer of this network ended. ocean background for making and it's looking at the previous locations and it ": [
            1524.4,
            1577.8,
            24
        ],
        "recognize anything. You'll see what happens. So about half of the approved drugs in the last 30 years or drive from natural products and you got these natural products by diving in the sea, or you can collect them from land animals or from tree bark and an example is taxol, which is from you bark and it kills cancer one of the first effective Cancer drugs. So the goal ": [
            2905.5,
            2945.1,
            47
        ],
        "research project. so I didn't send collaboration between my lab and Annabelle gurwitch Lab at Scripps And this work was started by urinal in when he was a master student here and there is a PhD student at UC Merced and Zhang was a grad student in Nano engineering believe it or not that had this idea. And then wash and Nick are undergrads or Josh was an undergrad. Nick ": [
            2811.9,
            2862.8,
            45
        ],
        "same at every location and we allow them to interact through this shared attention idea. So last I looked you said 850 citations. We're going to talk about how they work and then talk about Universal Transformer Networks. What are the and I'll talk about the poster. I just saw that feeds Transformer Networks. These are feed-forward networks. And they as a result, they train much faster and recurrent networks, ": [
            454.1,
            499.0,
            2
        ],
        "same place in the output space. And the cool thing about this is that it should generalize the new faces. So I'm going to give you an mnist example and we're going to use to Output units so that we can so this is it I put you in one. Southport unit 2 and this is work. One of my grad students Masters student did a couple of years ago. ": [
            3567.9,
            3601.4,
            63
        ],
        "slide and later was it turned out that it was the cyanobacteria that at 8 that give rise to this molecule. Salon of Natural Products Research is about structure Discovery. So here's some papers call like finding stuff in trees and figuring out what it is. And then hopefully it's something that will cure cancer or not. And so basically there's a lot of steps in natural products Discovery. You ": [
            2996.8,
            3043.5,
            49
        ],
        "space. When were you seeing how these things are performing his ill look at what's called Precision recall curve? And you want this purple pig? Let me see other techniques and a better attitude like some other machine learning type techniques. So now the idea is that given these hsqc uniform sampling no told you everything I know. You can take those map them into the embedding space. Find the ": [
            4150.2,
            4224.1,
            77
        ],
        "that actually pays attention to these inputs. You don't need to know that. Jay is put in and then ball comes out. Shannon PA comes out and then generates end of sentence. So any questions about this so far, I still haven't explained intentional filter yet. the word as in I mean It's just another input to the network. There's no for example backpropagation through that blue line. Back to ": [
            968.7,
            1044.7,
            14
        ],
        "the input at each position but the rose have different weights. So the first network does one function II network does the second function and the last component does a 6 transformation of the input data? And what's a black arrows are supposed to be suggesting is that these at each position the attentional component can listen to different input positions and we'll talk again about the attentional filter in ": [
            798.2,
            844.0,
            10
        ],
        "the input in the context of the Hidden representation at other of other Towers. And then there's the decoder and that's taking in the top layer of the Empire odor from each position. So between the bottom of my feet hurt in the turquoise attentional filter, there's that whole bunch of layers that I've just left out and then the decoder network is basically the same architecture. It's got an ": [
            892.3,
            932.9,
            12
        ],
        "the output of the previous Time stuff. So it's just copying what it up with and giving it again as input just like you guys did with the beer Annette. Does that make sense? But they do have the same attention to that they are to each other as the as the blue ones too, but it's fixed so that it can't pay attention to the Future. So the attention ": [
            1044.7,
            1101.1,
            15
        ],
        "the same number each time for each position. So that the same number that sounded the position one a different number gets out into position to Etc and they use a sine wave for this but My student Henry says you can just add random vectors 3 position and and that works too. So the way it works is again, we have an encoder Network. That's just learning and embedding ": [
            611.0,
            646.7,
            6
        ],
        "the same so you can tell if that person is different from other people. Let's ignore the spring analogy for the numbing but this is the last function and why is 1/4 a different pair than 0% So if its 1 this term is 0 and use this term, so if it's a different pair will it start with why being you're a stranger in this one? And this one ": [
            3801.1,
            3840.3,
            69
        ],
        "these are our usually is a variant and the others to do things that are could be down here either to hydrogen and oxygen. But there's a lot of noise. So when you do random are you you put the sample that you have through solvent to break it up and then it goes into the end of our machine and these things are noise. These are three again three ": [
            3243.3,
            3281.0,
            55
        ],
        "these weights for every position and then there just corrected. animatrix and so what the mid? the soft Mac I'm sorry. inner product possession okay. And now I've told you everything I know about that. Are these matrices in these K matrices that are learned through backprop? There is the same at every location. but they're actually eight of them and so there's this is where the sock Max input ": [
            1856.9,
            1948.5,
            28
        ],
        "they thought it was that so, you know, not a good idea. It's really important to get the correct structure. I'm so enter deep learning. This is for an audience. That isn't UFC 190. thirsty on again Okay, and then you seen all this? Okay. Now we haven't seen a Siamese or network. So we've looked at Cross entropy this these networks have a very different objective function. Siamese neural ": [
            3333.1,
            3387.0,
            57
        ],
        "times and They have some similarities, but there's a whole lot of noise here. That suggests we should use computer vision, right? And if you make mistakes can be costly so this one lab in Berlin. Got this actually got this thing. Which is an isomer Goose thing. This one is anti leukemia. This one is not. and they wasted a whole probably either I guess working on this when ": [
            3281.0,
            3333.1,
            56
        ],
        "to all of these differences between these pictures of the same guy. Current popular if you have something like this, you'd like it to be in Burien to these differences in this guy's faking a profile orientation. So it has to learn to be in Burien to these differences when it's given these two it's told to move the output factors closer together. You're learning to map it to the ": [
            3534.1,
            3567.9,
            62
        ],
        "to be decoded by the decoder Network. Are are Universal Transformer Network uses Jared weights between the different rows. So essentially this is now a recurrent Network because it's going like some number of steps forward in time. But instead of the time being from left or right like it is in the lstm that works its from bottom to top. So it's it's doing some number of recurrent steps ": [
            2247.4,
            2285.9,
            33
        ],
        "took applications. We're going to look at one of these. And it's called scale. Product attention. It takes in a hidden vector. all the hidden doctors two ways matrices W sand K&W you learned by Bachrach. But what is the lead out perks of these two transformations of the previous didn't doctor. Or dot product ID with each other more hair product did Teresa lineup you have a maximum. Product ": [
            1279.8,
            1334.0,
            20
        ],
        "using reinforcement learning or there was a genetic algorithms type. system for searching for better parameters we're hyperparameters. So that was cool. And that's what I've heard so far, so I have another talk. I want to give you and the remaining. 25 minutes. I I think I mentioned at some point. Amy's networks and I'm going to talk about them, but I'm here to talk about them again a ": [
            2767.0,
            2811.9,
            44
        ],
        "what I mean by the fingerprints now a researcher will Look at this and through a process of logical deduction based on their experience. They'll finger figure out what the structure is, but it's a long painful process. Each one of these has a different chemical structure, but they're similar so you can see the similarities here between he's just by looking at them. You don't have to understand what ": [
            3210.4,
            3243.3,
            54
        ],
        "when these two weight matrices produced very similar and you get a high amount score. W k w w x h 1 transfers w x h one that's the inner product operator. It's a weighted sum. Wk1 wqh one product then their run through the stock Max. And then they're actually scaled by the square root of the dimension. They make some maybe argument in the paper. When the doctor ": [
            1334.0,
            1402.1,
            21
        ],
        "white background and has Dimensions that are parts per million. And you similar so all these papers from Natural Products Research. Usually they extract different compounds from the same thing. And so they become a family of compounds. So. Pure 3 ask the wintons and you can either they're somewhat similar. They've got a bunch of things that there are things down here in these again or the fingerprints. That's ": [
            3168.0,
            3210.4,
            53
        ],
        "with each computation. For the same population is performed over and over. and the other difference so it's the difference just one difference. Renault Twizy page numbers getting bigger And then the other difference is that instead of six steps. Arison output based on some work by Alex Graves I believe is one of the authors on the neural turing machine paper where there's like a Stig mortal output that ": [
            2285.9,
            2338.0,
            34
        ],
        "word is run for four steps in the third word is 143 steps. What's that for cases where you have highly ambiguous words that may need more processing to decide which sense do you mean like River Banker or Money Bank? Okay. And they do better than Transformer Networks. Raise the blue score another point nine. and it turns out they can do tasks that the Transformer Network Camp to ": [
            2385.3,
            2431.3,
            36
        ],
        "word until it gets to end of sentence. So in particular here time goes from left to right and what we're going to see in Transformer Networks. Is not time goes for masquerade but time goes from input to Output. It's protocol instead of horizontal like that. And this is the figure from the paper which I couldn't figure out. I'm not going to give you all of these details ": [
            535.8,
            572.3,
            4
        ],
        "would do that this guy? We all know people that think outside of the box. But with Chen there is no box. It's kind of a researcher. You know it down to a journalism is what I'm talking about. So this it is. I'm about an unknown things into the cluster map and they're near one another they're from the same compound that was not part of the training set. ": [
            4012.8,
            4056.8,
            74
        ],
        "you know, if these are all the same. I knew you would like that work to give him the same representation. You can tell these pictures are from the 80s for these aviator glasses are the same and Pates is not the same as that guy. And so what this is going to do if it matched them to the same location in the output space, then it's becoming invariant ": [
            3501.9,
            3534.1,
            61
        ]
    },
    "File Name": "Deep_Learning___C00___Cottrell__Garrison_W___Fall_2018-lecture_19.flac",
    "Full Transcript": "Where are we now?  near me  No.  You can hear me now.  I can't hear you. Say something.  for rent near me  Green Bay  Hear me now.  started  last time  30 Target  I'm going to  if you have a question raise your hand all will ask me the question.  Okay.  So remember last time I talked about how I always said mapping time into space isn't as good as this map and time into the state of the network.  and  and I was wrong wrong wrong and  So the reason I was wrong is because I was thinking about Brands not normal next. And so what if we ignored the brain and gave each location its own network just called more Network when we need it.  We use the same network at every location. So all the weights are the same at every location and we allow them to interact through this shared attention idea.  So last I looked you said 850 citations. We're going to talk about how they work and then talk about Universal Transformer Networks.  What are the and I'll talk about the poster. I just saw that feeds Transformer Networks.  These are feed-forward networks. And they as a result, they train much faster and recurrent networks, and they raced blue score on English to German translation by Pulte points.  Remember how we typically do it? We have an LS Cam Newton in motor not work. It takes in my feet hurt and then end of sentence and then there's a second Network. That's a generator Network.  In-N-Out puts one word at a time and feeds it. So now put back into itself to produce the next word until it gets to end of sentence.  So in particular here time goes from left to right and what we're going to see in Transformer Networks.  Is not time goes for masquerade but time goes from input to Output. It's protocol instead of horizontal like that.  And this is the figure from the paper which I couldn't figure out. I'm not going to give you all of these details in particular. I'm going to leave out positional encoding but all that does is it adds it just directly adds to each input embedding Vector some number that's different for every position because one of the things about  Is Transformer Network says they don't actually know you know, which which of the inputs is the first word in which is the second so they they just directly add some numbers the same number each time for each position. So that the same number that sounded the position one a different number gets out into position to Etc and they use a sine wave for this but  My student Henry says you can just add random vectors 3 position and and that works too.  So the way it works is again, we have an encoder Network. That's just learning and embedding of the words. So this isn't the whole encoder. This is just the first you this could be a look up to work it back so that you have some Vector representation of the word and gaskets map to a hidden Vector. That's now the input to the rest of the network.  Then it's an ex layer up. There's an attentional filter followed by a feed-forward network that transforms the input from the attentional filter and that's why it's called a Transformer Network.  And this structure is replicated.  Text Terrence. Is there a question?  No record that works for the tensional filters.  wish  malicious text-based  okay, we're going to see that hold your horses will get to the  As you see it, it's in putting the same English sentence. We talked about earlier with the lstm networks my feet hurt and there's a tower of network over every word position and it's taking an encoding of the word.  And then there's an attentional component which will talk about or directly soon as I eat for network. And then there's another attentional filter for Hyundai feed for network. And this is just replicated six times. So The Columns of shirred Weights because they're all exactly the same network. What's different is the input at each position but the rose have different weights. So the first network does one function II network does the second function and the last component does a 6 transformation of the input data?  And what's a black arrows are supposed to be suggesting is that these at each position the attentional component can listen to different input positions and we'll talk again about the attentional filter in a minute. It's minor league complex, but not too bad. These things can attend the different positions in the sentence in so  Example if I say I crossed the river and went into the bank.  You would need information.  From nearby words to realize that this isn't a river bank but is a bank bank money bank will see an example about a little later.  Their Computing these transformations of the input in the context of the Hidden representation at other of other Towers.  And then there's the decoder and that's taking in the top layer of the Empire odor from each position. So between the bottom of my feet hurt in the turquoise attentional filter, there's that whole bunch of layers that I've just left out and then the decoder network is basically the same architecture. It's got an attentional filter so I can pay attention to the importance of  Any of the words in the sentence and then it's Travis reduce an output. That is the translation of the first word.  and then  that goes into the attentional filter of the decoder Network just like in the lstm version where you copy the output back to the input. There's another bit of network. I'm not telling you about that actually pays attention to these inputs. You don't need to know that.  Jay is put in and then ball comes out.  Shannon PA comes out and then generates end of sentence.  So any questions about this so far, I still haven't explained intentional filter yet.  the word as in I mean  It's just another input to the network.  There's no for example backpropagation through that blue line.  Back to the output of the previous Time stuff.  So it's just copying what it up with and giving it again as input just like you guys did with the beer Annette.  Does that make sense?  But they do have the same attention to that they are to each other as the as the blue ones too, but it's fixed so that it can't pay attention to the Future.  So the attention is mask so that it's still on a regressive meaning that the mail only depends on J. Not opa my high school French is coming in handy up here not.  But and then went to generate so it only pays attention to game all and not PA.  1/3 causal it goes from left to right.  repair  Okay, so the attentional filter is a kind of built-in Gadget like the neural Turing machines on trim to dress a bowl memory. So it's got a particular operation that it does but it's differentiable.  And it allows the attentional filter to to pay attention to different inputs. In fact, they're actually intentional heads at every position. So it can even pay attention to eight to four parts of the input Eddie position.  The inputs to the attention layer of the outputs of the previous layer.  And they come in three ways matrices to computer the attention waiting which is again a softmax. So I think I  Maybe talked about attention before but basically you generate it's it's it's like the neural turing machine look up of a memory location. There is a peak in the soft Max and that's * * the inputs in order to get a filter. So the people pick one perhaps one location in the input and that's skating.  The input started you mostly get what you're paying attention to.  This is called self attention.  It's in the entered South attention and then the decoder pays attention to the end Kotor which is not self attention because it's paying attention to a different network. In this case. It's called self attention cuz you're attending to your own representations it took applications.  We're going to look at one of these.  And it's called scale. Product attention.  It takes in a hidden vector.  all the hidden doctors  two ways matrices W sand K&W you learned by Bachrach. But what is the lead out perks of these two transformations of the previous didn't doctor.  Or dot product ID with each other more hair product did Teresa lineup you have a maximum. Product when these two weight matrices produced very similar and you get a high amount score.  W k w w x h 1 transfers w x h one that's the inner product operator. It's a weighted sum.  Wk1 wqh one product then their run through the stock Max.  And then they're actually scaled by the square root of the dimension. They make some maybe argument in the paper.  When the doctor gets longer this is this helps scaling.  Is turkey something like 00100 Etc?  There's another way. W.  And that's why I didn't operate. Basically you see my pointer.  There's a third one Federer and doors are multiplied directly X. This guy the second one by the end of one of the most part. I'm so shy and so that game.  Richard from another weight Matrix of the transformation wooden bucket  So it's weird thing.  But the shock Max confused a you know where you're paying attention to and it's all learned by background.  There's actually three matrices coming out of each didn't doctor WKBW Kingwood WV and  They have some more they have some description of this that I think of.  Where to put a human face on this bed. They think of you WK as the key WQMX the query and if those two match  then you pay attention to this part and wipe you guess this is weighted some of the Hidden another Vector a linear transformation of the Hidden unit doctors in each position waited by your attention doctor.  That makes sense.  Here's an example where?  This is one layer of this network ended.  ocean background for making  and it's looking at the previous locations and it paying attention to making and more difficult.  The idea is that it's it's skipping over this the registration and voting process in and pay attention to the fact that it's making more difficult.  In this particular step examples in the paper that are less compelling.  This is an actual figure from the appendix in a paper.  the wrecks happened.  It actually has some of them have the same place.  the different colors here correspond to different attention has there's one two three, four, five six seven eight of them and these guys are basically only paying  And this one was it?  And this one's going to be Sprint store on one and one position.  I don't know mind.  based on the app  You don't know what?  I mean, I don't know if they've investigated on the Aquarius.  reasonable and then  me and me Wireless  unless they are being.  Is it okay now?  Derek I can help  Okay, if I don't get a question.  Okay, so there's this.  Call Brien Ford net worth.  The sheltered that's why it's called.  this is the  and again, I found  I think it's a problem.  awkward  Spell work better.  Okay, so obviously on details here that I'm leaving out.  estimate main idea  the outputs of these weights for every position  and then there just corrected.  animatrix  and so  what the mid?  the soft Mac  I'm sorry.  inner product  possession  okay.  And now I've told you everything I know about that.  Are these matrices in these K matrices that are learned through backprop?  There is the same at every location.  but they're actually  eight of them  and  so there's this is where the sock Max input comes from its.  of this weighted arm of the Hidden unit vectors  with  H1 inner product with WQAD  is looking for a particular pattern.  and when the  Emaps is that you get.  a large number when it doesn't  You got a small number?  I have no money.  I'm desktop laptop.  Okay.  story  Corpus  German  sentences  Order a half million.  And then English to French Corpus, that's much larger.  Betty X Barker  and change it on eight Nvidia p100 gpus the smaller Corpus took 12 hours the larger 13.5 days.  Is your all on the same CPU?  Any batting state-of-the-art new stores, and what's interesting?  Is the other networks are?  Look at the training cost in terms of floating Point operations here.  previous methods  I'd like a lot of lot of training end of the 19th * 2.3 while you were flops.  And I did better.  Although I don't know about this guy.  Well, it's not quite as big as.  This difference here is too loose for two Blues. I guess you.  Posey's Transformer networks use Earl computation and every level  8 Ford, they simply replicate the network for every input.  Are very fast to train?  And they achieved state-of-the-art performance without recurrence.  Any questions on Transformer networks that maybe I could answer.  Okay, so Universal Transformer networks are A variation on these?  Where is Transformer Networks?  And again, they're shared weights between every Tower but not shared weights between the different rows of Aquanauts. That's Computing a different function at every layer and it's just doing six steps of feed for Network before it gets to the final and coating of each word in the sentence, which has been going to be decoded by the decoder Network.  Are are Universal Transformer Network uses Jared weights between the different rows. So essentially this is now a recurrent Network because it's going like some number of steps forward in time.  But instead of the time being from left or right like it is in the lstm that works its from bottom to top. So it's it's doing some number of recurrent steps with each computation.  For the same population is performed over and over.  and the other difference  so it's the difference just one difference.  Renault Twizy  page numbers getting bigger  And then the other difference is that instead of six steps.  Arison output based on some work by Alex Graves I believe is one of the authors on the neural turing machine paper where there's like a Stig mortal output that increasingly gets bigger until  you decide based on some threshold of how big it is.  And now tells you when to stop.  what that means is that  different words can be encoded can be run for different numbers of steps and it's adapt on the network itself decides when to stop and what I'm showing here is that  instead  Example the first word is run for 2 steps. The second word is run for four steps in the third word is 143 steps.  What's that for cases where you have highly ambiguous words that may need more processing to decide which sense do you mean like River Banker or Money Bank?  Okay.  And they do better than Transformer Networks.  Raise the blue score another point nine.  and it turns out they can do tasks that the Transformer Network Camp to  and hopefully this will be accepted despite the stupid reviewer just barely about that because they're recurrent and recurrent networks are touring equivalent. These are also touring equivalent.  And now again, it's a recurrent Network because  It's basically being enrolled in time and it decides itself how much time to run for each position?  That's pretty cool. I think.  Any questions about that?  Yeah, I heard some word for phrase for it. I forget Universal.  Computation time unit or something like that. It's it's just a sigmoid that gets input at every layer and when it reaches a large threshold large value then he stopped.  Each one of these has one of those stop units and in the first visit then stop after two steps in the back in position that got bigger and bigger until it reached the Threshold at the top and then Etc.  I told you everything I know about those. I didn't go back and read the Alex Graves paper where they were first put in but  that's the story. So this is pretty cool heads.  the same architecture but even fewer parameters because  did Shirley reuse the same weights?  Organics it's running through inattentional filter feed-forward Network attentional filter each word network, but in each case the weights are all the same.  This is a poster. I just saw him about an hour ago.  And this is the Transformer output blue score and ears their blue store. And so they've raised to Blue Square another two points. Do they compare this to Transformer networks? What they did here is  They put the Importer in the Deep Burger are all sharing weights.  And this time down here means that this is stacked for there's some number of of these things may be fixed again. I don't know but then at the output itself putting the words in the other language and I told you everything I know but basically there's no separate decoder and encoder study entering the decoder are talking to each other at every layer.  Because of these because they share weights and it has this attention layer here. That's what these little lines are showing and then it's outputting the word send again told you everything I know so well after your dad paper, it's got to be online in the next website or Noritz as we call it now.  Okay, so that's Transformers.  Any joke again. This is too very fast-moving field. I saw some number of papers with new kinds of Gans. There was a pretty cool tutorial on.  Automatic machine learning where the hyperparameters of your system car learned by some other system. For example, one of them used reinforcement learning to figure out the hyperparameters of your learning system. Are you have a lunar and then you have something controlling the the hyperparameters of the learner insert basically searching for the best hyperparameters and it's sometimes another neural network using reinforcement learning or there was a genetic algorithms type.  system for searching for better parameters  we're hyperparameters. So that was cool. And that's what I've heard so far, so  I have another talk.  I want to give you and the remaining.  25 minutes. I I think I mentioned at some point.  Amy's networks and I'm going to talk about them, but I'm here to talk about them again a research project.  so I didn't send collaboration between my lab and  Annabelle gurwitch Lab at Scripps  And this work was started by urinal in when he was a master student here and there is a PhD student at UC Merced and Zhang was a grad student in Nano engineering believe it or not that had this idea.  And then wash and Nick are undergrads or Josh was an undergrad. Nick is graduating this year and PornHub is the master student who graduated last year.  When I gave this chocolate Scott, so they're trying to University of Technology.  I'm going to talk about what natural products research is why it's important and then I'm going to talk about Siamese convolutional neural networks where they're cool and then talk about our system smart for small-molecule accurate recognition technology. Although it doesn't actually recognize anything. You'll see what happens.  So about half of the approved drugs in the last 30 years or drive from natural products and you got these natural products by diving in the sea, or you can collect them from land animals or from tree bark and an example is taxol, which is from you bark and it kills cancer one of the first effective Cancer drugs. So the goal is to basically find  Things that nature is produced that are useful for for things like that.  So here is Bill himself collecting samples from the Palmyra atoll that's out here in the middle of nowhere fix the 10 researchers have any one time?  Airports near pooler's penicillin which came from old axle and more recently don't Statin 10 and that was drive from Missy hair looks like a big slide and later was it turned out that it was the cyanobacteria that at 8 that give rise to this molecule.  Salon of Natural Products Research is about structure Discovery. So here's some papers call like finding stuff in trees and figuring out what it is. And then hopefully it's something that will cure cancer or not.  And so basically there's a lot of steps in natural products Discovery. You don't have to get stuff out of the field extract molecules for a minute and then try and figure out what they are.  And the bottlenecks are right there in the middle or 2D NMR is like nuclear magnetic resonance imaging. So if you've had an MRI.  Using the same technology and our goal is to speed up structure determination after 2D NMR.  Please start with the 2D NMR spectrum and you can think of it as the fingerprint of the compound.  And using deep convolutional Siamese neural network, we've developed the system that clusters the compounds directly from their enemies are Spectrum based on their structure though. We map from the NMR Spectrum to a cluster space where things with similar structures are near one another in the state.  And that allows new compounds to be mapped into that cluster space and based on what their near you can get some hints as to what their actual structure is usually and I'll show you examples of what that is.  To Dianna Mars a technique that gives indications of bonds between atoms in a molecule and I've told you everything I know now.  This is an example of a 2d NMR. Basically you get the spots on a on a white background and has Dimensions that are parts per million.  And you similar so all these papers from Natural Products Research. Usually they extract different compounds from the same thing. And so they become a family of compounds. So. Pure 3 ask the wintons and you can either they're somewhat similar. They've got a bunch of things that there are things down here in these again or the fingerprints. That's what I mean by the fingerprints now a researcher will  Look at this and through a process of logical deduction based on their experience. They'll finger figure out what the structure is, but it's a long painful process.  Each one of these has a different chemical structure, but they're similar so you can see the similarities here between he's just by looking at them. You don't have to understand what these are our usually is a variant and the others to do things that are could be down here either to hydrogen and oxygen.  But there's a lot of noise. So when you do random are you you put the sample that you have through solvent to break it up and then it goes into the end of our machine and these things are noise. These are three again three times and  They have some similarities, but there's a whole lot of noise here.  That suggests we should use computer vision, right?  And if you make mistakes can be costly so this one lab in Berlin.  Got this actually got this thing.  Which is an isomer Goose thing. This one is anti leukemia. This one is not.  and  they wasted a whole probably either I guess working on this when they thought it was that so, you know, not a good idea. It's really important to get the correct structure.  I'm so enter deep learning.  This is for an audience. That isn't UFC 190.  thirsty on again  Okay, and then you seen all this?  Okay. Now we haven't seen a Siamese or network. So we've looked at Cross entropy this these networks have a very different objective function.  Siamese neural networks are pairs of networks that are actually the same network and although it says F1 and F2 Junior. I really should say F1 and f-1b mean these are identical Networks.  And you put two inputs into them.  They sure wait so they're like sharing organs.  And I take two inputs and share this symmetric loss function, which I'll talk about in a little bit.  And they can be convolutional and then they have linear output units, but they're not trained there. No targets are these linear output units instead if you put in two inputs here and say it's the Aspen wenton. Here's a and b you tell them that work these two are the same and then you try and move their output factors closer together.  This is an aspen went in and this is one of those other things you gave them farther apart. And so you're trying to reduce the squared error or the distance between the outputs of these and you change all the weights by the same amount. Where is there different? You try and increase the difference between the outputs?  Bristol paper by  Rhea Hansel who I met yesterday for the first time and Ian laocoon and one other author and the ideas, you know, if these are all the same. I knew you would like that work to give him the same representation.  You can tell these pictures are from the 80s for these aviator glasses are the same and Pates is not the same as that guy. And so what this is going to do if it matched them to the same location in the output space, then it's becoming invariant to all of these differences between these pictures of the same guy.  Current popular if you have something like this, you'd like it to be in Burien to these differences in this guy's faking a profile orientation.  So it has to learn to be in Burien to these differences when it's given these two it's told to move the output factors closer together. You're learning to map it to the same place in the output space.  And the cool thing about this is that it should generalize the new faces.  So I'm going to give you an mnist example and we're going to use to Output units so that we can so this is it I put you in one.  Southport unit 2 and this is work. One of my grad students Masters student did a couple of years ago.  and  overtraining  it's told that all the yellows the same all the blues are the same but the yellows and the blues are different.  And after 50,000 decorations you got this. What's interesting here is that the red is a 0 and this is a sick. So these are both things with loose and over here is one.  And even though they're both lines when it has a little bit more on it than the other so it Maps even though it's told these are different.  Just by, you know this mapping and put similar things in similar locations in the state of Kansas.  Okay.  Makes sense so far.  Yeah, I know.  Okay, so cool. Thanks. I love Siamese that works as I told you I had sell yesterday.  He looked at me like I was anyway the cool things about the pieces because you're training on pairs of data point they essentially amplifier dataset. It's not in square exactly. I mean given and training examples in the limit of M squared pairs, but you know, it's basically the number of things in each category X the number of things in the other category That's How many pairs you can  you can get so if I had  100 examples of  A1 category  I would have 100 times 99 div 2 pairs of those. So that's like Fifty and a hundred which is 5000.  Examples of Paris and then I randomly choose 5000 examples that aren't that category in an in a batch. I'll have half and half of same different.  different categories  you don't need to know the number of categories in advance cuz you're just telling it same and different.  You won't even have to have examples for all the categories and these are especially suitable for domains where you have a large number of categories, but small number of examples.  And again if you think about that face one.  Given a new person it's going to map that person into a portion of the space near the other people that that person looks like but hopefully not exactly the same so you can tell if that person is different from other people.  Let's ignore the spring analogy for the numbing but this is the last function and why is 1/4 a different pair than 0% So if its 1 this term is 0 and use this term, so if it's a different pair will it start with why being you're a stranger in this one? And this one kicks in and you're trying to minimize the distance. This is the distance between the output of the first Network applied to X1 and the output of the second Network applied X2. You're trying to minimize this disc. That's a squared error.  But it's the difference between the two identical networks mapping the same thing or sorry mapping two things are the same category to the output to this is moving them closer together on the other hand if is there different. So this one kicks in noticed there's a minus sign indeed. So you're trying to increase the distance, but there's a margin so if the distance is bigger,  And the margin this will be negative and then the loss is zero. They're basically wanted to move things M apart. It doesn't need to learn on those anymore.  Are also called an energy function. So there's a kind of graph of this for one of them in the garage after the other and squared are so this looks like a parabola.  And the idea here is you pushing things closer together or are you pulling on this brings out to some margin this with the circle around it mean?  Doug and the basic idea is you been the to ask but when they're the same you put it in the  and ask for 110 and Chandon a known and say they're different and so it's going to move those outputs farther apart.  I'm so sorry.  the guy at the beginning  it's a pretty good was it looked up the Journal of natural products online?  And cut out from the PDF the NMR Spectra for 4,000 different compounds.  Now who would do that this guy? We all know people that think outside of the box.  But with Chen there is no box.  It's kind of a researcher.  You know it down to a journalism is what I'm talking about.  So this it is.  I'm about an unknown things into the cluster map and they're near one another they're from the same compound that was not part of the training set.  Appear what they're showing is that these are one kind of thing. These are another kind of thing and just the third kind of thing in a researcher knows what these molecules are would say that this is the right structure that the dean should be between the A's in the seas.  And this is just saying here's the China.  Okay.  This is the outer core.  Where are the three dimensions so you can view it and the different colors correspond to different compounds, but we ran out of the colors. So this read these roads are different. These roads are different these Reds and then you can going to play with us and see what's near other things.  And where Chen wants to do is put this in virtual reality and have a researcher be able to explore the space.  When were you seeing how these things are performing his ill look at what's called Precision recall curve?  And you want this purple pig?  Let me see other techniques and a better attitude like some other machine learning type techniques.  So now the idea is that given these hsqc uniform sampling no told you everything I know.  You can take those map them into the embedding space.  Find the closest family and Foster man, and that gives you some indication of what other things do you speak?  Which is a fingerprint of the compound and from that you're typing into a state where you are by structures are near one another. I think that's that's pretty cool.  Are we getting a lot?  Restarting company got a big night and just recently got another Grant from the Gordon Moore Foundation.  Say more is more Quan.  And they were hiring the postdoc each. We have like four or five labs.  and our goal is to develop a website where  researchers are Spectre the nearest  results from  using essential  you don't answer.  and  we're working on improving the architecture.  using an auger  objective  That is developed the salsa version of the strip and chewable that is within a cluster. You want all of the category?  We're trying to Max.  Okay, so  on Thursday  I'm going to talk about.  Essex I like to close my classes with that should be.  Market Revolution  Okay. 788  Well, I want see you want to see me.  I forgot to stick.  stacked laundry city government in lanzhou, China  I have with the collaborators from the southern China University of Technology.  Any leftover parts?  Okay. Thank you and mall or organizing this with me.  Newport "
}